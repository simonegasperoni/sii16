<forum name="hardforum">
	<post id="3c349aec-01a3-4b5d-ba86-8778aa66f27b" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"AMD FX-8150 Multi-GPU Gameplay Performance Review - We are taking the new AMD FX-8150 and giving it the power of Dual and Triple-SLI GeForce GTX 580 video cards. We are going to take the new CPU up to large NV Surround resolutions and see how performance stacks up when it comes to high-end gaming scenarios."</post>
   <post id="da0d17b3-985a-473e-9e31-3397ad970318" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"I was so hoping the Bulldozer was going to rock it a bit... Guess I m waiting a little long for it to mature."</post>
   <post id="2ae71ddb-e2a7-4282-a623-31df8c6589d9" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Wow - the failboat has pulled into dock on this one. This again reaffirmed my decision to get a 2500k instead of waiting for bulldozer."</post>
   <post id="e0937278-f8d6-4bb2-916c-1151d4659d81" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"[RIP]Zeus;1037971681 said: I was so hoping the Bulldozer was going to rock it a bit... Guess I m waiting a little long for it to mature. Click to expand... That would have been wishful thinking at best. We ve seen nothing to indicate Bulldozer would be especially good at anything compared to Sandy Bridge, Sandy Bridge-E or Ivy Bridge. Well perhaps encoding, but that s about it. It may be compelling for owners of AM3 / AM3+ motherboards since that s the only upgrade path they have after Phenom II. I m sure those stuck in that upgrade path (without spending the cash on an Intel chipset based board) wish it was better, but wishing for a thing does not make it so."</post>
   <post id="c766019e-f245-4b36-8152-1aa61f33f99b" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"conclusion=bulldozer still sucks You can slap "FX" all over the architecture as much as you like but it will still only be fit for mainstream use."</post>
   <post id="4fbef5ce-e11f-40a2-b735-d9556b166a46" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"So disappointed."</post>
   <post id="98099743-109b-4fd7-837d-2ea255254b9b" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Bulldozer architecture = Train wreck AMD s stock may have gone up recently because of their above expectations quarterly earnings and demand for their APU s SELL SELL SELL!!!"</post>
   <post id="240ab067-fbb2-4336-a124-57c61671a0bb" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"It would be interesting to see results on CF too - Nvidia SLI tends to require more CPU power in games."</post>
   <post id="69ce86f3-4d81-4110-89fb-9ecda61e4d18" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Michaelius said: ↑ It would be interesting to see results on CF too - Nvidia SLI tends to require more CPU power in games. Click to expand... This is just speculation but if anything I think we d see Bulldozer do a little better with Crossfire and CrossfireX than it does with SLI, but this certainly represents a case for the most demanding setup. In which case you need to look toward Intel if you need the performance. I don t think adding Crossfire / CrossfireX into the mix would change the outcome of the evaluation."</post>
   <post id="709a5d95-ed53-4da4-91ba-831af7b7814a" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"I love AMD and really wanted BD to kick ass. Honestly. When I built a 1090T AMD system mid 2010 and OC d it to around 3.9ghz stable, the games I was playing at the time seemed "sluggish". This was coming from an older Intel 920. After msybe 6 months of what I consider half-baked performance, the Intel Sandy Bridge came out and I moved to it. With all due respect to AMD / Intel fans alike, my findings were were exactly what Kyle and company discovered. AMD 1090 / 1100 and Bulldozer just do not compete with Intel. I saw 40% performance gains mentioned. One story I will share is about World of Warcraft. When I went from the 1090T at 3.9 / 4.0Ghz to Intel SB, I saw a performance gain for nearly 100% in frame rates. It was just an earth-shattering night and day difference. Thanks for the review. I appreciate it. I will tell people this. Buy what you can afford or what you want. Impress no one but yourself. Don t worry about others. If you do not care about gaming and low performance is ok with you, then BD will be perfectly fine for you. Otherwise, like the review points out, Intel 2500k is the way to go."</post>
   <post id="9017e7a0-10ec-4ada-9271-6ae448b3599d" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Michaelius said: ↑ It would be interesting to see results on CF too - Nvidia SLI tends to require more CPU power in games. Click to expand... I don t think it matters. The test here quite clearly shows the large gap between the two chips and how quickly the bulldozer is CPU limited. Swapping an x-fire setup instead of the SLI wouldn t change those results. I d be willing to bet that at stock speeds the bulldozer would probably reach it s CPU limitation ceiling before, say, a Phenom II 980. That s the truly sad part. It really is a trainwreck. It s looking worse and worse for AMD here and us AMD fans aren t happy. At all. Why in the world would you market this thing for gamers as a gaming chip? If we look at the piss-poor increase in scaling when increasing cor...err, modules, in games, then the increased core count factor is, too, thrown out the window. And there s like 2 games that utilize more than 4? There s no point. Let s hope they reconsider and toss out the bulldozer architecture in favor of something new or resembling a phenom II // Thuban shrink. Shorter pipelines, please"</post>
   <post id="f6fc4add-1730-4a16-a494-672269e7a58c" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"I didn t expect anything to change regarding how well Bulldozer would do regardless of how many video cards were used. But two requests to perhaps give BD a slightly better outcome.. 1 - Test using Windows 8 - I doubt a big difference but perhaps the improved thread scheduler in Win 8 might even things out a bit. 2 - use Radeon cards - all the sites that actually recommended Bulldozer (Overclockers Club; Neoseeker; Legit Reviews; Benchmark Reviews; Hi Tech Legion.. to name a few) ALL used Radeons. I believe I only found one review that recommended BD that tested with an nVidia card. I know it is a sad state of affairs when a CPU can t do well regardless of the manufacturer of the video card but apparently AMD s Scorpius platform works better with it s own brand of cards. I assume AMD feels if someone buys their CPU, they are also going to use their video cards."</post>
   <post id="f405ba8d-340a-4e5b-b22a-296d741d6c74" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"So basically you have to use a OC d BD FX-8xxx series chips to have a hope at reasonable sli/xfire performance at higher resolutions. I thought that BD might excel in this area or at least not suck as much....how sad."</post>
   <post id="c20c4f92-1b02-4c81-a317-04d49ef73fdb" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Well, there you have it. People always say, benchmarking at low "unrealistic" resolutions gives stupid results. They fail to understand that these results can translate very quickly into reality when you increase GPU power. Not every reviewer has 2 GTX580, let alone 3. This is a massacer for the FX, nothing pretty here."</post>
   <post id="f93dd374-92aa-4109-9b5c-4b1cffafd702" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Dan_D said: ↑ This is just speculation but if anything I think we d see Bulldozer do a little better with Crossfire and CrossfireX than it does with SLI, but this certainly represents a case for the most demanding setup. In which case you need to look toward Intel if you need the performance. I don t think adding Crossfire / CrossfireX into the mix would change the outcome of the evaluation. Click to expand... I m not disputing verdict just saying that with the difference of CPU overhead beetween SLI and CF the triple card scenarios would probably look slightly better for AMD (by which i mean losing slightly less). Still I d make even more decisive conclusion (almost Rage! like )"</post>
   <post id="d0272c26-bf79-467f-aa98-6647bc926b29" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"AMD so far for eh last few years: Amazing graphics Cards!!! You guys rule the roost with your graphics card division. AMD Fails with the new so-called "Bulldozer" platform. I was not expecting "Athlon Like" performance. However, I was expecting to be able to at least keep up with the Core i5/7 series..."</post>
   <post id="d0500fff-39dc-46b3-9b3b-30d55756d440" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Michaelius said: ↑ I m not disputing verdict just saying that with the difference of CPU overhead beetween SLI and CF the triple card scenarios would probably look slightly better for AMD (by which i mean losing slightly less). Still I d make even more decisive conclusion (almost Rage! like ) Click to expand... I don t think making Bulldozer look slightly less bad on purpose will help anyone. The only value I see in that (just my opinion) is letting Crossfire / CrossfireX users know what they are in for if they "upgrade" to Bulldozer / Zambezi. But, most of you have no idea how long that would take. I d wager that article took well more than 30 hours to complete with all that testing. And I m being generous with that estimate. The real-world testing method is slow to say the least."</post>
   <post id="29c949d6-c4f8-4cd2-a136-b2b27547903b" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"Waiting for the classic "But I can reuse my motherboard which I had to upgrade to use bulldozer from my old AM3 system, but I mean I can upgrade the CPU in the future unlike intel rabble rabble rabble." I don t see anyone ever buying these unless they re being horribly mis-lead by people  helping them , or they re really dead set on using anything Intel. There is no budgetary win, no performance win, nothing but a higher price tag and power bill."</post>
   <post id="62e9c026-e2e2-496f-9f28-31b85eabc91b" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"What a colossal failure. I can t imagine that some of these results weren t seen a long time ago; no wonder they let the CEO go, the plug should have been pulled on this architecture years ago."</post>
   <post id="84b646d3-7e79-4397-91c9-df246cbdcd4f" section="AMD Processors" discussion="AMD FX-8150 Multi-GPU Gameplay Performance Review @ [H]">"The only bright side I can come up with is maybe this will embarrass AMD enough that they ll really get down to the grind stone and come out with something worth having."</post>
   <post id="a4111a32-b408-4d16-900c-2f5866c459d7" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"AMD FX 8300 vs. Intel i3 6100. Yes, it is a 7 min video. Those i3 s do have a ton of single thread performance. Just needs more cores to be useful though. The i3 definitely won in the heat category. It was much cooler according to the tester. Otherwise the FX 8300 walked all over it in frame rate, minimum frame rate, rendering speed, etc. 5 year old 32nm tech still doesn t look bad compared to the new 2016 14nm tech."</post>
   <post id="526dc42a-1852-45a3-8780-11e3505b37cc" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Awesome"</post>
   <post id="e51ec7cf-5fd4-4b0f-8ebd-b0078d8a10c7" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Having owned an i3-6100, I would honestly take an FX any day unless I was doing emulators or something purely single threaded. That i3 was the most miserable, stuttery gaming experience I ve ever had. Add in the fact that the overclocking options are going away fast and it is even less appealing."</post>
   <post id="01a58d9a-7adb-4ddb-9b03-558d0d6ecae3" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"best $50CAN I ever spent was a used FX-8120 to replace my fx-4100(both run at 4560). LigTasm said: ↑ unless I was doing emulators Click to expand... every emu ive used works fine. what have you had issues with?"</post>
   <post id="8dd37322-6712-4821-8c8b-5d278ad00533" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"pendragon1 said: ↑ best $50CAN I ever spent was a used FX-8120 to replace my fx-4100(both run at 4560). every emu ive used works fine. what have you had issues with? Click to expand... I have none, I was just suggesting a possible use for the i3 if you were looking for just single-thread performance."</post>
   <post id="785663d8-99b8-4a81-b6ba-eebff59eef78" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Cool Beans, dude. I love the 6300 and 8300 chips."</post>
   <post id="df335dc8-c52b-46b7-92a9-6a29645fe07f" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Well hopefully this will put to rest some posters need to tout the i3 as some super-chip over the FXs. Some how I doubt it will quell their agenda... But I gotta say, he must have been using the stock cooler, because even a modest tower cooler can sneeze 4.4 to 4.6 Ghz. Those stock coolers are terrible for the 8 cores."</post>
   <post id="3cb8b295-73b2-410f-b053-dba3e2174462" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"JustReason said: ↑ Well hopefully this will put to rest some posters need to tout the i3 as some super-chip over the FXs. Some how I doubt it will quell their agenda... But I gotta say, he must have been using the stock cooler, because even a modest tower cooler can sneeze 4.4 to 4.6 Ghz. Those stock coolers are terrible for the 8 cores. Click to expand... I thought the same thing. I ve lost count of how many 8-core FX chips I ve owned (about to pick up another 8320E tomorrow) and getting 4400mhz was as easy as 200x22 with any adequate motherboard. He said it was using a Kraken X31 cooler, so I m not sure why it was so hard. Maybe the worst FX chip in history?"</post>
   <post id="51564cf6-b583-43c2-bdae-b5453f09bee2" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Shitty mobo maybe? I don t recall if he said which mobo he was using. 4.4 should be a breeze. I switched from my 4100 @ 4560 to my 8120 @ 4560, used the same 212evo with the same bios settings, just dropped it in and out worked. Either it s shitty mobo or worst FX chip ever."</post>
   <post id="42ba56f3-be04-4137-bb5a-69ced38b5b43" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"The top-end FX processors just barely edge out the bottom of the line i3? AMD needs to rush out new product quick. Intel thinks they can rip us off unless they ve got some competition. Dolphin (Gamecube and Wii) would be an emulator where you want single-threaded performance."</post>
   <post id="c2dd7335-b2f2-457a-bb7d-df0fb3c03e18" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"8300 isn t the top chip. You know that. When comparing AMD vs Intel you have to look at cost/performance AND usage. with the 6100 vs 8300, current price on newegg.ca is $360 vs $170. That s a HUGE difference in cost vs performance. You can get a 8300, mobo and ram for the price of the 6100. And the only place you ll see a difference is in encoding and an occasional game. So like the conclusion of the video says if you need encoding/rendering power go Intel. Gaming and everyday use go AMD. To a point... Because, unfortunately they don t have a fast enough CPU to support their highest gpu but hopefully Zen will fix that. Edit: Forgot about the emus. no problem there. Every emu works fine with AMD now. Years ago was a different story. And emus as an Intel over AMD argument is pretty weak."</post>
   <post id="a5618bf4-3247-48e0-b810-c7f9a0f3ecf1" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Quix said: ↑ The top-end FX processors just barely edge out the bottom of the line i3? AMD needs to rush out new product quick. Intel thinks they can rip us off unless they ve got some competition. Dolphin (Gamecube and Wii) would be an emulator where you want single-threaded performance. Click to expand... Both CPU are priced the same. This isn t a top level FX chip. Actually the FX won the rendering test also. The only thing it was slower at was Tomb Raider under DX11. FX-8300 is $118.95. i3-6100 is $117.95 The FX-8300 kicked ass."</post>
   <post id="c7a2040b-3e5f-46f0-a371-995993499946" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"pendragon1 said: ↑ 8300 isn t the top chip. You know that. When comparing AMD vs Intel you have to look at cost/performance AND usage. with the 6100 vs 8300, current price on newegg.ca is $360 vs $170. That s a HUGE difference in cost vs performance. You can get a 8300, mobo and ram for the price of the 6100. And the only place you ll see a difference is in encoding and an occasional game. So like the conclusion of the video says if you need encoding/rendering power go Intel. Gaming and everyday use go AMD. To a point... Because, unfortunately they don t have a fast enough CPU to support their highest gpu but hopefully Zen will fix that. Click to expand... what...? i3 6100 = 115$, FX8300 = 120$.. actually the FX8300 in US market is more expensive.. about the topic, what now a couple of slides with random numbers from a un-known guy are the truth? what about a reputable site? The Best CPU for the Money: Intel Core i3-6100 Skylake Tested"</post>
   <post id="283fc015-4068-415b-9fdf-c34278b8ffce" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"yeah idk what was going on with the pricing on the i3... its now says its $165. I followed a link somewhere, maybe it was a combo with a mobo. yeah f this guy. I commented that the price difference was better than he thought and got a dick response about how he doesn t care about prices not in USD. BUT your link does not compare OC to OC scores. yes at stock the i3 is slightly faster."</post>
   <post id="456f7ac0-776c-4596-83a3-3d6fd2a055a1" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"It is nice to see that the FX is holding it s own against an i3, but the thing is when you search 6100 vs 8350 in youtube the first page is just full of videos where the i3 is beating it in most games. Since we are just going to be impressed by random youtube uploaders testing these 2 CPUs, it is not hard to see that there are cases here when at low 1080/720p the dual core can score upto 50 FPS more in games like fallout 4 but it is very impressive that the 8-core can even run these newer titles. I am a bit late to the party but this is going to be the most hilarious thread in this forum where someone is trying to prove the impossible. Yes the 8 cores are going to help and win in productivity benchmarks, where the 2 cores are still pretty impressive because of the massive IPC difference. But they stand no chance in gaming - from a 380 to 970 to 980ti. FX does clearly win in witcher 3 though. Keep in mind you are spending just under 160$ for the i3 combo whereas you would need atleast a semi-decent mobo for the FX because you want to OC. Intel Core i3-6100 - System Build - PCPartPicker"</post>
   <post id="154328c5-8621-4dda-9fdb-e239569555de" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"Someone who is interested should really check out these vids, one of the dudes even has 300k subscribers which gives some a little more psuedo-credibility i suppose. ( i think the last one)"</post>
   <post id="6bca12b4-458f-4f26-a10f-bcb6a77ecabd" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"a3venom said: ↑ But they stand no chance in gaming - from a 380 to 970 to 980ti. Click to expand... pendragon1 said: ↑ if you need encoding/rendering power go Intel. Gaming and everyday use go AMD. To a point... Because, unfortunately they don t have a fast enough CPU to support their highest gpu but hopefully Zen will fix that. Click to expand... that was what I was pointing out here. yes with the very highest end gpus fx chips cannot keep up. hopefully zen will improve on that. but on another note, if your capped at 60FPS like most players you would not see the higher fps BUT you do see the visual improvements the difference between a 960 and a 980ti or a 380 and a furyx will make. being able to do 60fps@ultra vs 60fps medium. that make sense?"</post>
   <post id="b45e9cb3-04a3-4a29-bbf5-6b86df41b877" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"The guy goes as far to say he is only giving the truth and cant believe he is recommending the 8350 in the scenario he is. And keep in mind this is another extreme OCing issue with the i3 which at default is locked. More than enough proof that the 8350 can easily OC to 4.4-4.6Ghz or even further with slightly better cooling. So taking that into consideration, again the 8350 would be the clear winner in gaming. And keep in mind he mentions DX12 and the use of more cores. i3s for Gaming are asinine to begin with and even more so under DX12 or any game that can utilize cores. Remember I think it was COD III in his gaming benchmark that he said ran better on lower core counts: SOME GAMES SHUT DOWN ASPECTS TO ALLOW LOWER CORES TO RUN THE GAME ADEQUATELY so comparing them ever in any benchmark is more often than not, an apples to oranges debate. Even as I mentioned in another thread for AotS: In Ashes, the AI operates on multiple CPU cores at once (a minimum of 4) and does so asynchronously from the rest of the game simulation. 4. The hardware requirements had a significant impact on our sales reach Our hardware requirements include a 2GB GDDR 5 video card and a CPU with at least 4 cores. Those requirements cut off about half the user base. We knew this going in and it was a price we were willing to pay to make sure we could create a future-proof game Click to expand... Postmortem: Stardock and Oxide Games  Ashes of the Singularity (a really good read by the way)"</post>
   <post id="8b838a2c-e13f-4f88-b2db-5969268a0bef" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"JustReason said: ↑ The guy goes as far to say he is only giving the truth and cant believe he is recommending the 8350 in the scenario he is. And keep in mind this is another extreme OCing issue with the i3 which at default is locked. More than enough proof that the 8350 can easily OC to 4.4-4.6Ghz or even further with slightly better cooling. So taking that into consideration, again the 8350 would be the clear winner in gaming. And keep in mind he mentions DX12 and the use of more cores. i3s for Gaming are asinine to begin with and even more so under DX12 or any game that can utilize cores. Remember I think it was COD III in his gaming benchmark that he said ran better on lower core counts: SOME GAMES SHUT DOWN ASPECTS TO ALLOW LOWER CORES TO RUN THE GAME ADEQUATELY so comparing them ever in any benchmark is more often than not, an apples to oranges debate. Even as I mentioned in another thread for AotS: Postmortem: Stardock and Oxide Games  Ashes of the Singularity (a really good read by the way) Click to expand... So you completely ignore the videos i posted (like what? 9) in which the FX is obliterated? You also completely ignore the fact that windows recognizes an i3 as 2 physical cores and 4 logical cores. Same way as a 8350 would be recognized as 4 physical cores and 8 logical cores. Which doesn t mean anything it is indeed 2 cores vs 8 but everything really cares about how many threads it sees. It is so too that there isn t a single benchmark/website in which the fx 8350 had more fps than an i3 6100 in DX 12 Ashes Benchmark. What is the counter argument to benchmarks that show results? It is not supposed to even run on dual cores and all tech sites are owned by intel??"</post>
   <post id="24d55ae0-d491-4f3d-93a8-2cb991ad98e4" section="AMD Processors" discussion="AMD FX 8300 vs. Intel i3 6100 benched. (video)">"I3venom said: ↑ So you completely ignore the videos i posted (like what? 9) in which the FX is obliterated? You also completely ignore the fact that windows recognizes an i3 as 2 physical cores and 4 logical cores. Same way as a 8350 would be recognized as 4 physical cores and 8 logical cores. Which doesn t mean anything it is indeed 2 cores vs 8 but everything really cares about how many threads it sees. It is so too that there isn t a single benchmark/website in which the fx 8350 had more fps than an i3 6100 in DX 12 Ashes Benchmark. Click to expand... But you are ignoring the video that is in the original topic. I3 is a dead cpu. DX12 engines will make use of more cores. It is the only way to get more performance."</post>
   <post id="ec7b6d8e-02da-40a5-a89a-352b3d92eb00" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Doom (2016) CPU analysis. Doom тест GPU | Action / FPS / TPS | Тест GPU Guess it s time to retire these AMD CPUs since they are lagging so far behind the competition in newer console ports. I might upgrade to a i3 for this game. /sarcasm /dry wit In all seriousness these FX processors are like the Energizer Bunny. They just keep going and going and going... Intel load percentages. AMD load percentages. That one core that could on the FX-8350. I also found it interesting that the game uses almost 8GB of ram if you have 32GB installed. At any rate feel free to discuss. The game is a monster according to Kyle. Anyone Getting Their DOOM On?"</post>
   <post id="8932cfe7-423c-496a-8267-037fe6304337" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"idk if i would really look much into that chart.....for one it shows the amd cpus with a full 1700MHZ clock advantage above the Intel ones WTF? Also it shows by turning Hyperthreading off on the intel cpu it gives double the performance? Yeah Right..I believe that one For those with high clocked AMD 8core cpus holding out till Zen to upgrade.....I get it why not? It will do ok till then..but to brag about them performance wise is pushing it a bit LOL"</post>
   <post id="e03c05e6-21b3-487c-97f3-6fc8c0036ee9" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ idk if i would really look much into that chart.....for one it shows the amd cpus with a full 1700MHZ clock advantage above the Intel ones WTF? Also it shows by turning Hyperthreading off on the intel cpu it gives double the performance? Yeah Right..I believe that one Click to expand... The 5960X thing may be an issue with to many threads: GTAV wont even run with 16 or more threads, DOOM may have a bug that causes an issue. And these processors are all at stock frequencies."</post>
   <post id="0bdf9985-4778-4de4-af9d-d64bdedebe27" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"I was just about to mention they were all running at stock hahaha. I wonder how they all fair when overclocked?"</post>
   <post id="9a06f562-aaa5-418f-b2c1-f5db88145ba1" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ idk if i would really look much into that chart.....for one it shows the amd cpus with a full 1700MHZ clock advantage above the Intel ones WTF? Also it shows by turning Hyperthreading off on the intel cpu it gives double the performance? Yeah Right..I believe that one For those with high clocked AMD 8core cpus holding out till Zen to upgrade.....I get it why not? It will do ok till then..but to brag about them performance wise is pushing it a bit LOL Click to expand... This is why Intel had to layoff people due to poor sales. This should have been a massacre going by the age of the FX processors. If you toss every AMD number off the chart, and just go by the Intel ones; why would someone with a 2600K upgrade to something new? To save 5 cent a month in electricity?"</post>
   <post id="99e6f5bd-d513-47db-bac7-aa567f3cf6c5" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"One has nothing to do with the other.....lol...sure from a purely gaming pov the gains are very limited...doing other stuff like large video encodes can be huge time savers over the amd cpus (like many hours lol)"</post>
   <post id="5bc8516b-0ff8-4502-8694-381682c400be" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ One has nothing to do with the other.....lol...sure from a purely gaming pov the gains are very limited...doing other stuff like large video encodes can be huge time savers over the amd cpus (like many hours lol) Click to expand... I think you misunderstood what I said. Take all of the red figures off the first chart. Then compare say the 2600K to the 4770K. There really isn t much difference in the two processors. This is proof that Intel hasn t really increased their processor power over the years. That s also why the AMD CPUs can hang right in there with the best that Intel has. Also AMD CPUs are very good at encoding. Not as good as a 12 or 16 thread Intel of course. But they can hold their own encoding."</post>
   <post id="001d27bf-7812-49f2-8589-b988966db2b0" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Honestly....games will always be limited by consoles since thats were the money is really made in game sales....if it were not for that then it be different"</post>
   <post id="36da6531-d2ea-45af-b154-09f79e30908d" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ Honestly....games will always be limited by consoles since thats were the money is really made in game sales....if it were not for that then it be different Click to expand... Unfortunately there isn t that big of a difference. I mean you might shave some seconds off here and there. In the long run unless you re doing encoding professionally 8 hours a day you won t notice the difference. Mutimedia Testing - Intel Skylake Core i7-6700K IPC &amp; Overclocking Review"</post>
   <post id="96ac461b-b5f3-4e19-a15d-85105c50c34d" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"cageymaru said: ↑ I think you misunderstood what I said. Take all of the red figures off the first chart. Then compare say the 2600K to the 4770K. There really isn t much difference in the two processors. This is proof that Intel hasn t really increased their processor power over the years. That s also why the AMD CPUs can hang right in there with the best that Intel has. Also AMD CPUs are very good at encoding. Not as good as a 12 or 16 thread Intel of course. But they can hold their own encoding. Click to expand... There are benefits besides pure speed, platform improvements going from Z68 to either Z87 or up through Z170 may very well be worth it for some. If you re only talking pure speed, I can see what you mean. Not much to get hyped about in the last 5 years from either camp. If you have a 2600k, there isn t anywhere meaningful to go, from either AMD or Intel. As far as I m concerned, anyone who purchased Sandy back in the day should be happy that they haven t had a reason to upgrade for so long. The days of needing a new processor every year are behind us, for better or worse."</post>
   <post id="8c74d933-3b66-477c-8284-367587570010" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"cageymaru said: ↑ Unfortunately there isn t that big of a difference. I mean you might shave some seconds off here and there. In the long run unless you re doing encoding professionally 8 hours a day you won t notice the difference. Mutimedia Testing - Intel Skylake Core i7-6700K IPC &amp; Overclocking Review Click to expand... 4 core skylakes are hore shit anyway.....if im building a cutting edge new build in 2016 its going to be at least 16 logical cores...quad cores are for baby pcs"</post>
   <post id="e1887504-af13-48ea-bbef-66ed0eeb0495" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Oniigumo said: ↑ As far as I m concerned, anyone who purchased Sandy back in the day should be happy that they haven t had a reason to upgrade for so long. The days of needing a new processor every year are behind us, for better or worse. Click to expand... this is how us AMD users feel. our chips have held up pretty good over the years and dx12 is breathing new life into them."</post>
   <post id="23da1e69-4251-47b7-b432-a143a9119e41" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ iAlso it shows by turning Hyperthreading off on the intel cpu it gives double the performance? Yeah Right..I believe that one Click to expand... I ll let that hang in the air there for those who actually understand what hyperthreading is. Go do some reading- you re busted there Sparky."</post>
   <post id="5e8a3284-80af-4f53-8651-576d260bf5a4" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"pendragon1 said: ↑ this is how us AMD users feel. our chips have held up pretty good over the years and dx12 is breathing new life into them. Click to expand... The whole takeaway from my post was supposed to be that yeah, Intel hasn t really gone anywhere meaningful from sandy outside of platform improvements and efficiency, but neither has AMD relative to sandy. It s been good for the wallet, and for longevity of our chips for both camps, for some time now. It s not, and shouldn t be about either AMD or Intel. The CPU market as a whole, has stagnated. I m pulling for AMD to deliver with Zen, because competition is a great thing. It could mean a price war, or bringing the focus back to performance, but whatever happens it d be a good thing for all of us consumers if AMD somehow lights a fire under Intel s ass."</post>
   <post id="0df0e697-64b0-4881-a3b4-8deac0f65795" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Spirit_Retro said: ↑ I ll let that hang in the air there for those who actually understand what hyperthreading is. Go do some reading- you re busted there Sparky. Click to expand... lol Is there something odd about wanting an 8 core cpu with HT.....I was talking about cpu like an intel 5960x"</post>
   <post id="90e7488e-c00f-4272-8230-dff53f3de0d9" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"primetime said: ↑ lol i have no idea what you talking about? lol Click to expand... Exactly."</post>
   <post id="a5650c52-7c60-4d23-9d08-0322970e6b1a" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Spirit_Retro said: ↑ Exactly. Click to expand... oh ok that explains everything (i guess) Thanks for clearing that up...Sarcasm? idk"</post>
   <post id="7f220267-f78c-48ff-9f19-55ab4e617bcf" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"Oniigumo said: ↑ There are benefits besides pure speed, platform improvements going from Z68 to either Z87 or up through Z170 may very well be worth it for some. If you re only talking pure speed, I can see what you mean. Not much to get hyped about in the last 5 years from either camp. If you have a 2600k, there isn t anywhere meaningful to go, from either AMD or Intel. As far as I m concerned, anyone who purchased Sandy back in the day should be happy that they haven t had a reason to upgrade for so long. The days of needing a new processor every year are behind us, for better or worse. Click to expand... I m looking at possibly an I3 skylake in a server board (if that is supported these days), solely for the DMI/pci-e lane improvements... Processor speed has been "good enough" for quite some time..."</post>
   <post id="8cb1e122-afcb-4d4b-8c5f-d040efa85caa" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"KazeoHin said: ↑ The 5960X thing may be an issue with to many threads: GTAV wont even run with 16 or more threads, DOOM may have a bug that causes an issue. And these processors are all at stock frequencies. Click to expand... It does bring up a good question about why the performance difference...Right no im guessing the game doesn t play well with HT or like you said if you only allowed a certain amount of cores to the game it would regain the performance. Since kyle and company has the game we should get an article sooner or latter. If its just an HT thing that easy enough to disable before hand but i wonder if there is a quicker software method instead of going in the bios...Regardless i bet this game gets a few patches and whoever writes up an article better finish it well before the next patch lol. Im not going to argue the benefits of ht cause i dont care tbh....Has there been another game in the past that had a huge loose in performance from having ht on? I just havent run into it before. Last one i remember was BF3 when it first came out was smoother with ht off but latter got patched and fixed"</post>
   <post id="ea46c43c-1b10-4b25-a62e-d8811ff4e9b0" section="AMD Processors" discussion="Doom (2016) CPU analysis.">"This is one of the limited times that the FX 8 cores are scaling very well with clock speed - means they are being utilized very well. But the HT off thing seems kinda weird. Also here are benchmarks from a reputed site - DOOM Benchmarked: Graphics &amp; CPU Performance Tested The only processors to really drop off in terms of performance were the AMD FX-4320, 6350, 8320E and Athlon X4 860K. The Pentium G3258 and G4400 both sustained over 90fps, while the Core i3 processors were good for 100fps+. Click to expand... FX 8 cores cant really demolish an i3 in any game, even when fully utilized."</post>
   <post id="ac29ccd4-b1bf-49ab-a273-694bd83caa4f" section="AMD Processors" discussion="Best bang for buck build advice">"Long time (over 15 years lol) hardocp reader, first time poster. I just sold my complete 2500k rig that has been pretty faithful for a few years, but I m waiting on Zen to be released later this year, so I m not looking to spend a lot of money. I m using an old HP celeron laptop and its pretty painful for even browsing the internet. So I figure I ll build something to hold me over. With some light gaming in mind -- I m not exactly looking to break the fps records here -- what would be the best bang for the buck CPU setup? I ll be using a discrete GPU eventually, so that is an option, but I won t mind holding out for polaris with an apu for the while. I don t mind used either, keep that in mind. I m budgeting $200 max for motherboard and CPU. Any advice?"</post>
   <post id="046f20d3-5926-4fdd-9770-8a1eab29e794" section="AMD Processors" discussion="Best bang for buck build advice">"zer0xp said: ↑ Long time (over 15 years lol) hardocp reader, first time poster. Click to expand... I have no answer for you... I just wanted to say - IT S ABOUT DAMNED TIME YOU SAID SOMETHING! Welcome!"</post>
   <post id="dadf4f23-2e0e-4855-ad61-aaab6bcd3129" section="AMD Processors" discussion="Best bang for buck build advice">"Bang for buck is prebuilt domain. ebay an HP elite, or Dell Optiplex that fits budget and chill until zen."</post>
   <post id="d55de62b-da11-46b9-b3c2-f02b5f42a8d6" section="AMD Processors" discussion="Best bang for buck build advice">"If you want something thats not used. Check out the new Athlon X4 845. Pair it with an Asrock A68M-ITX and 8GBs of 2133 (and whatever video card, ssd/hard drive/case/psu of your choice) and you d have a decent little ITX rig to play around with."</post>
   <post id="75671e7a-f7bc-45ea-b9d4-68c9368897f7" section="AMD Processors" discussion="Best bang for buck build advice">"I think used will be your best option, you can find used 6 core xeons + server mobo for 200 on ebay, you can also get i3 6100 + h170 for 200, you can get a 860k + mobo + ram for 200. but if you are going to add a discrete GPU costing more than 100 bucks i recommend the i3 - it is the best (not used) bang for buck CPU out right now. with 860k you save some money on cost of performance, but it is kinda worth it if u just need it for 7-9 months"</post>
   <post id="017bbc73-be70-46ac-8d4c-929e117c3871" section="AMD Processors" discussion="Best bang for buck build advice">"If you are sticking with AMD look for something as a 970 board and maybe FX 8320e depending on your "needs" scale down to less cores but be warned that you need to keep track of the motherboard phases if you want to overclock ...."</post>
   <post id="b62f3099-6f47-4c20-9bd1-40e1e09469d2" section="AMD Processors" discussion="Best bang for buck build advice">"Pieter3dnow said: ↑ If you are sticking with AMD look for something as a 970 board and maybe FX 8320e depending on your "needs" scale down to less cores but be warned that you need to keep track of the motherboard phases if you want to overclock .... Click to expand... He s going to use it till Zen, why waste money on an expensive mobo trying to overclock a really slow CPU? Above the 860k there is no budget offering in the AMD side. he shouldnt be spending more than 40 bucks on a mobo"</post>
   <post id="e220dc7f-aada-44fb-b07d-de788304dfe2" section="AMD Processors" discussion="Best bang for buck build advice">"Thanks for the input so far! Clearly I haven t been following the CPU market for some time... I didn t realize AMD s offerings were THAT bad. I was kinda leaning towards an APU setup, but from what I ve gathered, anything other than an A10-7860k or higher probably won t make any sense. Other than that, investing in an FM2 setup is probably another bad idea at this point seeing as the platform is pretty much dead when bristol ridge comes out, right? It s not that I honestly have preference for AMD over Intel, but there is some nostalgia affecting my decision making. After being intel since Northwood, I kinda wanted to come back to AMD, hence the whole "waiting for zen" thing. I don t care to have the fastest gaming rig known to man, but getting my money worth is pretty important to me. With that said, how does an FX6300 w/ a 970 chipset stack up to something in a similar price range, i.e. an i3-4160 w/ h81? I can t find much comparing the two."</post>
   <post id="6e633467-940c-40bd-afe8-158e79a3b9be" section="AMD Processors" discussion="Best bang for buck build advice">"zer0xp said: ↑ Thanks for the input so far! Clearly I haven t been following the CPU market for some time... I didn t realize AMD s offerings were THAT bad. I was kinda leaning towards an APU setup, but from what I ve gathered, anything other than an A10-7860k or higher probably won t make any sense. Other than that, investing in an FM2 setup is probably another bad idea at this point seeing as the platform is pretty much dead when bristol ridge comes out, right? It s not that I honestly have preference for AMD over Intel, but there is some nostalgia affecting my decision making. After being intel since Northwood, I kinda wanted to come back to AMD, hence the whole "waiting for zen" thing. I don t care to have the fastest gaming rig known to man, but getting my money worth is pretty important to me. With that said, how does an FX6300 w/ a 970 chipset stack up to something in a similar price range, i.e. an i3-4160 w/ h81? I can t find much comparing the two. Click to expand... The i3 4160 is inarguably superior to the FX 6300 while even beating the 8350 at some titles, while the 6100 is inarguably superior the the 8350. [Gaming] If you aren t doing anything heavy just web browsing, I d still get an i3 because the FX platform is just too slow on the IPC department and 6 cores are really helpful only when you render, virtualize etc... Don t even think about an APU - you can get a dGPU + CPU for the price of the a10-7860k which will outperform it by 10 -20%, APUs are really bad for the money at top end. If you are going to buy a new one later on, i suggest doing this - 290 bucks with a GTX 950, will play you most games at 1080p nicely. Don t buy an i3 if you really are going to upgrade very soon to Zen. If you are spending some money now, then just get an i5 as there is no way Zen will be faster than Skylake. PCPartPicker part list / Price breakdown by merchant CPU: AMD Athlon X4 860K 3.7GHz Quad-Core Processor ($69.99 @ Amazon) Motherboard: ASRock FM2A68M-DG3+ Micro ATX FM2+ Motherboard ($44.99 @ SuperBiiz) Memory: A-Data XPG V2 8GB (2 x 4GB) DDR3-2400 Memory ($34.99 @ Newegg) Video Card: EVGA GeForce GTX 950 2GB Video Card ($138.98 @ Newegg) Total: $288.95 Prices include shipping, taxes, and discounts when available Generated by PCPartPicker 2016-04-03 15:55 EDT-0400"</post>
   <post id="d170bde9-720a-4d73-9989-bb015ecc9c73" section="AMD Processors" discussion="Best bang for buck build advice">"That motherboard layout isn t great and is that a 3 phase power setup? Asrock A68M-ITX For $20 more, you get an 8 pin cpu plug and from what I can tell a 5 phase power setup. I recommended the Athlon 845 because at these prices, you re not gonna get a motherboard that has heatsinks on the VRMs. I wouldn t reccomend overclocking on any of the the cheap AMD boards anyway since most manufactures kind of neglect the AMD side of things. Anyhow, from what I ve seen the 845 performs above or equivelant to the the 860K and for less money and a lower TDP."</post>
   <post id="178142e5-37cc-4acf-947e-8e31f6e3c001" section="AMD Processors" discussion="Best bang for buck build advice">"Best bang for your buck is going to come from a whole used machine. I buy allot of Intel i3 and i5 Sandybridge generation Dell refurbs off Amazon. $200 quad core complete machine. $150 dual core i3 machines. http://www.amazon.com/gp/offer-list...olp_refurbished?ie=UTF8&amp;condition=refurbished I m sure HP has the same but I don t know their product stack. Dell Optiplex 790 has been my go-to for awhile. I typically reimage them onto a $40 SSD for small businesses. They are excellent."</post>
   <post id="02283b75-eb37-44ed-8d85-63757f443137" section="AMD Processors" discussion="Best bang for buck build advice">"Private_Ops said: ↑ That motherboard layout isn t great and is that a 3 phase power setup? Asrock A68M-ITX For $20 more, you get an 8 pin cpu plug and from what I can tell a 5 phase power setup. I recommended the Athlon 845 because at these prices, you re not gonna get a motherboard that has heatsinks on the VRMs. I wouldn t reccomend overclocking on any of the the cheap AMD boards anyway since most manufactures kind of neglect the AMD side of things. Anyhow, from what I ve seen the 845 performs above or equivelant to the the 860K and for less money and a lower TDP. Click to expand... It is bad to recommend spending an extra $20 on mobo for better overclocking on a budget build, next he would need a cheap cooler like CM 212, another 20 - 30 bucks. Even if he gets 5 GHz with that it is an utter waste of money as that puts him more than an i3 build with 2400 Mhz ram. And the lowest i3 SKU will destroy the 860k at any frequency. I3 6100 is 112.99 and you can get a motherboard for less than 45. That removes the AMD build from the equation. The 845 is 3$ cheaper than the 860k so they are basically same cost. When you do budget builds you don t look at quality of your mobo s power phases, it is simply not a good idea to do so. Cheapest = Best. Spending extra $30 to overclock your 860k destroys the "budget" point of the 860k and puts it in same price territory as the i3 which is a much faster CPU. ochadd said: ↑ Best bang for your buck is going to come from a whole used machine. I buy allot of Intel i3 and i5 Sandybridge generation Dell refurbs off Amazon. $200 quad core complete machine. $150 dual core i3 machines. Amazon.com: Buying Choices: Dell Optiplex 790 Intel i5 3100 MHz 250Gig Serial ATA HDD 4096mb DDR3 Memory DVD ROM Genuine Windows 7 Professional 32 Bit Desktop PC Computer I m sure HP has the same but I don t know their product stack. Dell Optiplex 790 has been my go-to for for awhile. I typically reimage them onto a $40 SSD for small businesses. They are excellent. Click to expand... This is probably going to be the best option if going used, I agree. Can add 750ti to it and play games decently."</post>
   <post id="0ef271d4-5c27-4b05-929c-71a422de1a90" section="AMD Processors" discussion="Best bang for buck build advice">"The best choice would be an i3 6100+z170 with the non k oc bios or get an i5 unlocked on z68/77/87/97"</post>
   <post id="84dee3de-2a86-43a3-a31b-697ff65faa3e" section="AMD Processors" discussion="Best bang for buck build advice">"I d get a 2500k used on ebay and a Z68 board. Seriously, best you can get for $200."</post>
   <post id="3c820df2-45f0-461b-9bc4-d5e8f4ccad51" section="AMD Processors" discussion="Best bang for buck build advice">"mid range APU laptops can be had around the $200 price range from time to time. Not sure if portability is worth anything to you, but it s something to look at."</post>
   <post id="40a458ca-47dc-4ebf-9ab5-139cabf98110" section="AMD Processors" discussion="Best bang for buck build advice">"6300 viscera is serving faithfully"</post>
   <post id="26e8e0e9-d454-4959-a645-90bb591ce22b" section="AMD Processors" discussion="Best bang for buck build advice">"AMD chips do work fine, but nothing that is really an upgrade from your 2500. bang for the buck im pretty happy with my $55 860k but sometimes i wonder if id be happier with an i3-6100 and some ddr4 to play with. I personally dont like the apu for anything other then media center -- the graphics are not powerful enough for much over angry birds at 1080p. Im playing the division right now on an overclock 860k, 380x and only averaging 40fps on 1080p / high settings."</post>
   <post id="f57b1ffa-08c5-4e13-8f44-d09bb2d87f32" section="AMD Processors" discussion="Best bang for buck build advice">"Do you have a microcenter around? You can get a 8320e and Mobo for around $100 AR, maybe a 7770k and Mobo for $110, You could do an i3 6100 and msi h81m-e33 for about $120 AR."</post>
   <post id="f0b99f63-e650-4157-91b1-dfcb0101ed82" section="AMD Processors" discussion="Best bang for buck build advice">"I ve been looking at bang for buck options myself. My Phenom x4 955 is ancient. Still just about doing the job for gaming paired with a R9 285. I can t complain, 6/7 years of faithful service. I d be wanting to double or treble my CPU speed really to get the most valve for money. Zen would be preferable if the price is right. The more time that passes - the more I think it could be disappointing on launch. What if it doesn t even match Haswell? If it does match Haswell - is it worth it to buy Zen at current Intel prices or will it be less? How much less over Skylake or newer? I think they ve got quite the dilemma. Nonsensical in going with FM2 (Athlon 880K) or AM3+ (FX 8350, 8370, 8370E) due to the horrid retail pricing in the UK and general age of the design. No chance I m paying £132 / $191 for a FX 8350 plus the cost of a decent board. (unfortunately I ve got AM3) I d prefer not get an i3 6320 - I don t think the chip will age well compared to Intel s better offerings. So then there s used... Phenom X6 and FX chips are hitting stupidly high prices on eBay. I can t believe the older Intel chips (2500K, 2600K) are still holding their value - 5/6 years after their introduction. New boards are scarce now. The platform is a bit old in the tooth... I ve seen used Haswell parts sell for close to their initial retail price! There s no bargains to be had here = ( LGA 2011 is being price gauged on - I d grab a Xeon E5-2670 without hesitation otherwise. (If only it would work in a 2011v3 socket!) I wish I d had the foresight to grab a 2011 board! Maybe an Asrock EPC602D8A might be worth a buy? Or just keeping trying to grab a cheap X79. I think a dual socket board would be overkill. Overall it s cheaper than a Haswell-E or a Skylake setup and just as powerful. I think the three best choices are: &gt; E5 2670 + LGA 2011 &gt; Wait for Zen &gt; Cheap Sandy Bridge 2600K, Ivy Bridge 3770K + LGA 1155 Ideally I d do a complete overhaul - bite the bullet and pick up a LGA 2011v3 and 5820K; that setup will last for years. (drop in a xeon v3 in the future, maybe?)"</post>
   <post id="07c780de-93ac-4493-b8b2-1c5b6363f6ed" section="AMD Processors" discussion="Best bang for buck build advice">"zer0xp said: ↑ Thanks for the input so far! Clearly I haven t been following the CPU market for some time... I didn t realize AMD s offerings were THAT bad. I was kinda leaning towards an APU setup, but from what I ve gathered, anything other than an A10-7860k or higher probably won t make any sense. Other than that, investing in an FM2 setup is probably another bad idea at this point seeing as the platform is pretty much dead when bristol ridge comes out, right? It s not that I honestly have preference for AMD over Intel, but there is some nostalgia affecting my decision making. After being intel since Northwood, I kinda wanted to come back to AMD, hence the whole "waiting for zen" thing. I don t care to have the fastest gaming rig known to man, but getting my money worth is pretty important to me. With that said, how does an FX6300 w/ a 970 chipset stack up to something in a similar price range, i.e. an i3-4160 w/ h81? I can t find much comparing the two. Click to expand... Here is a idea try and find a 1090t overclock it a mb and a 970 video card and you have a fair rig for cheap.What I use and it runs just fine"</post>
   <post id="eb458a26-b466-4996-bb49-210c06571f33" section="AMD Processors" discussion="Trinity A10, raidxpert">"The last driver package is I can install is 15.7 but they have a newer 16.4 raidxpert. Does raidxpert need to match the driver package even though it s optional for compatibility? I could not find anything in the FAQ at AMD on this subject. Thanks."</post>
   <post id="7c7679d4-026b-4e38-ab46-7f919a53ac04" section="AMD Processors" discussion="Trinity A10, raidxpert">"I haven t used RAID on AMD boards in a couple of years so my knowledge may be outdated but no, they didn t have to match. I often skipped the RAID portion of the driver updates because twice I got builds that would bluescreen my system. Both times I had to boot to a DOS disk and copy over an older version of the RAID driver to get everything working again. Hopefully their driver team is doing a better job these days."</post>
   <post id="e2f1b6c2-6f5b-419a-8944-2d5e2f2d27b7" section="AMD Processors" discussion="Trinity A10, raidxpert">"Does you pc actually use the "raidxpert"? if it does then go ahead and install it....i have downloaded different packages just to get the sata driver my laptop needed...worked like a charm. the way amd puts the driver packages together can be a bit confusing"</post>
   <post id="4008fac9-01d1-49a2-a9a6-d641dde2a991" section="AMD Processors" discussion="Trinity A10, raidxpert">"Yes, the board in question is using two raptors in raid1 but the "package" is probably two years old. It s been solid but newer drivers might add something, hard to say since there is no doc with the driver on site. I can confirm that promise is the raid chipset that they used on this board, Gigabyte UP4 It s basically software like RST, the array was created pre-OS in bios. I read with Intel using the same ROM number as the driver apparently works the best but not necessary."</post>
   <post id="db060601-92f5-4798-8e50-b227caf9f134" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"AMD Athlon X4 880K Review. AMD Athlon X4 880K Review - ComputerShopper.com Not bad for a true quad core that overclocks to 4.5GHz using the stock Wraith cooler. I would want this over a dual core Intel due to some games automatically blocking the dual cores. I doubt anyone in this price range is willing to edit .ini files to make their games run. Windows Store doesn t even allow you to see the game files as everything is hidden. The $250 i5-6600K they tested it against was impressive. Too bad it is 2.5 times as much in price."</post>
   <post id="b820e1b5-ceef-4ab2-9df7-96222cd512cc" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"They needed to test it against an i3 which is also a 4 threaded 2 module processor. The $250 i5-6600K they tested it against was impressive. Too bad it is 2.5 times as much in price. Click to expand... And also 2 times the number of modules."</post>
   <post id="ee72941b-5e5b-4b22-98cb-56674588a759" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"cageymaru said: ↑ Not bad for a true quad core that overclocks to 4.5GHz using the stock Wraith cooler. I would want this over a dual core Intel due to some games automatically blocking the dual cores. I doubt anyone in this price range is willing to edit .ini files to make their games run. Windows Store doesn t even allow you to see the game files as everything is hidden. The $250 i5-6600K they tested it against was impressive. Too bad it is 2.5 times as much in price. Click to expand... Don t forget to mention that the stock frequency is 4ghz, while in the 6600K is 3.5ghz and it scale hugely with overclock so both overclocked at 4.5ghz should mean a way more than the ~50% presented in that review (which sadly don t include any gaming) you are paying 150$ more but you are getting a totally better and way modern platform. About your point, yes I know what you did there dual core pentium isn t the same as dual core i3, those mentioned games that refuse to run on dual core doesn t have any trouble with i3, as i3 are recognized as fully 4 threads under windows, the game is unable to tell which one are logic or physical cores, they detect 4 threads then the game run.. so even for 250$ you are getting a true quad core chip that perform much better than a 4Modules/8Threads FX8370 even in Heavy Multi-threaded applications, so you can expect a much bigger difference while gaming, i3 skylake still will mean a gargantuan upgrade over an Athlon X4 880K which is just 30 bucks more. drescherjm said: ↑ They needed to test it against an i3 which is also a 4 threaded 2 module processor. And also 2 times the number of modules. Click to expand... That s correct, the i5 6600K is just another league, Just look how even it outperform the FX8370 even in heavy multi-tasking synth benchmarks which was always the winner point on FX Octa Chips versus intel i5s, I would have expected they compared against an i3 6100."</post>
   <post id="68ec1ea6-c466-4239-8423-64d9bdab8d1c" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"It s still $30 cheaper than an i3."</post>
   <post id="a4474f3a-5114-4022-a72e-890865d63fb5" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"kirbyrj said: ↑ It s still $30 cheaper than an i3. Click to expand... It s still performance that fails to compete with years old Intel tech. If someone has a super limited budget, used Intel hardware is a better deal."</post>
   <post id="5ff63b1a-0591-4e97-bb01-e90f69f82707" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Its a soldered-lid speedbump 860k. Same as the 870k, just a speed bin higher."</post>
   <post id="2560bf57-60df-40bb-9cb2-062695c105b4" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Ocellaris said: ↑ It s still performance that fails to compete with years old Intel tech. If someone has a super limited budget, used Intel hardware is a better deal. Click to expand... And you can always find used FM2+ tech. A guy in FS/FT was selling a 870K that clocks to 4.5Ghz, A88M board, and 2x4GB of RAM for $100 shipped. I don t know that you re going to find a better deal on a "super limited budget.""</post>
   <post id="6fdfede7-6a57-4bf8-8504-1157181bca98" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"kirbyrj said: ↑ And you can always find used FM2+ tech. A guy in FS/FT was selling a 870K that clocks to 4.5Ghz, A88M board, and 2x4GB of RAM for $100 shipped. I don t know that you re going to find a better deal on a "super limited budget." Click to expand... lol that was me Good chip btw, the soldered lid keeps temps insanely low compared to an 860k, I was seeing an average of 20C cooler comparing them side by side and the 870k took 100mv more for the same clock speed (the 860k stops scaling at about 4.4ghz and 1.350V while the 870k was still going up when the board couldn t handle any more without throttling at 1.475V and 4.6ghz). Let it be known that this architecture really doesn t gain much past 4.3-4.4 or so though anyways, even with good cooling. We ve seen it for a while with Kaveri, unlike Vishera it does not keep getting better the more clock speed you pile into it, and I blame the super anemic memory bus and L1/L2 cache. For comparisons sake, Skylake L3 cache is almost twice as fast as Kaveri L1."</post>
   <post id="42b97570-382c-4c70-be3f-bab8ad359050" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Haha...I knew I saw it somewhere. I thought it was a good deal FWIW."</post>
   <post id="9a72e23a-e05b-468a-87d7-527e09ba221a" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"LigTasm said: ↑ lol that was me Good chip btw, the soldered lid keeps temps insanely low compared to an 860k, I was seeing an average of 20C cooler comparing them side by side and the 870k took 100mv more for the same clock speed (the 860k stops scaling at about 4.4ghz and 1.350V while the 870k was still going up when the board couldn t handle any more without throttling at 1.475V and 4.6ghz). Let it be known that this architecture really doesn t gain much past 4.3-4.4 or so though anyways, even with good cooling. We ve seen it for a while with Kaveri, unlike Vishera it does not keep getting better the more clock speed you pile into it, and I blame the super anemic memory bus and L1/L2 cache. For comparisons sake, Skylake L3 cache is almost twice as fast as Kaveri L1. Click to expand... I am not a big fan of the fsb being locked to pci-e. I am fsb oc-er but looks like I am a dinosaur with these APUs."</post>
   <post id="58f1106a-2f65-4927-adad-da463cea2f86" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"JustReason said: ↑ I am not a big fan of the fsb being locked to pci-e. I am fsb oc-er but looks like I am a dinosaur with these APUs. Click to expand... Yeah it would be nice if we could adjust that. I enjoy the chips just because they re cheap and powerful for the price. Fun to play with. If I was buying new I would definitely get the 870/880k though, the soldered lid and better binning helps a lot."</post>
   <post id="d9072f31-cf1c-4895-bc38-11538ff992e1" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Why is the A10-7890K so much faster than the 880K (Handbrake and Povray) ... there s only 100MHz difference both base and turbo. Both rated 95W. Same cache sizes."</post>
   <post id="edc799ab-fe3b-46bd-aee6-cdac8adcec8d" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"I suspect the GPU contributes. Seems logical. but logic.."</post>
   <post id="55e0a05c-88c1-49f6-aeb8-57b54a2240a2" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"wtourist said: ↑ I suspect the GPU contributes. Seems logical. but logic.. Click to expand... The 880K must have had an add-in card with a GPU also."</post>
   <post id="1cb05062-2932-47b0-ad14-c228518545c6" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"I built three new computers for my family using 860k, fm2+ gigabyte a88 board and 8gb of ddr3 2400 for $125 each. Very happy with the performance / cost ratio"</post>
   <post id="c796ecc1-0094-4e7d-8d80-f7ba98a063ee" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"buttons said: ↑ I built three new computers for my family using 860k, fm2+ gigabyte a88 board and 8gb of ddr3 2400 for $125 each. Very happy with the performance / cost ratio Click to expand... I got the 7870K for my Wife when I thought my/her 965BE board died. Cool part is both that the 7870K came with a great MoBo deal and the 965BE MoBo was actually fine."</post>
   <post id="9b739470-0051-40b8-90bc-63f617b5ee49" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Do they mention what speed ram? I didn t see it."</post>
   <post id="bd1113a0-b417-4e72-be5d-cfd5f26f687b" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"Private_Ops said: ↑ Do they mention what speed ram? I didn t see it. Click to expand... Common problem with APU reviews, mystery ram speed and if it was single or dual channel even, quite often."</post>
   <post id="3df9913a-480c-4d0e-8507-da44ca393c5e" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"xorbe said: ↑ Common problem with APU reviews, mystery ram speed and if it was single or dual channel even, quite often. Click to expand... Yeah I remember one using 1600 intentionally whilst knowing 2133/2400 made about 20% improvements."</post>
   <post id="71901134-5458-480c-96e1-d7d2dc791d1d" section="AMD Processors" discussion="AMD Athlon X4 880K Review">"JustReason said: ↑ Yeah I remember one using 1600 intentionally whilst knowing 2133/2400 made about 20% improvements. Click to expand... Yea, I hate that. Is 2400 good for the Athlons? I ve thought about grabbing one of these when they come out just to play around with."</post>
   <post id="36c9ccfb-db46-4fc5-b05c-3eab75b45e1e" section="AMD Processors" discussion="Anyone ever have any luck with Chinese/eBay &quot;AMD-only&quot; RAM? (xposted from Memory sub)">"Crossposted from Memory sub - Legacy RAM question - 512Mx64 "AMD-only" RAM If crossposting/reposting from one subforum to another is verboten, I do apologize - but I wondered if maybe this sub would be better suited for the question at hand. If one thread or the other needs to be deleted I understand, but if they can be merged that would be OK with me. My dilemma: I went cheap and tried some of the "too good to be true" Chinese/eBay RAM that says it is for AMD motherboards only, and it is not going very well. ASUS and Crucial both claim that this board will take 512Mx64 modules (also known as "high density", I believe), but I can t get this PC to boot at all. The whole reason for doing this is that I have 4GB installed as of now and I recently acquired a Gigabyte 7970 3GB GPU...does the old rule of "at least 2X more system RAM than graphics RAM" even still apply anymore? Did DX12 take care of that with the way it shares/pools memory resources?"</post>
   <post id="097c4ecd-9a20-468a-9056-8c0d33510147" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"The crew at TechFrag have been digging around in what is believed to be a leaked Linux patch and have come to the conclusion that AMD Zen based processors will feature up to 32 physical cores. A leaked Linux patch on LKML.org, first spotted by The New Citavia Blog, suggests that AMD Zen based processors will feature up to 32 physical cores. The patch also hints at the similarity of parts of the &amp;#8220;Zen&amp;#8221; and &amp;#8220;Zeppelin&amp;#8221; codenames. The Zeppelin codename was first mentioned back in August last year, and parts of the patch identify it as a &amp;#8220;family 17h model 00h&amp;#8221; CPU."</post>
   <post id="1c95ca04-8dd5-4b55-b40f-78abf6d12930" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Here s hoping for 8-core consumer desktop chips."</post>
   <post id="ab4fce7b-8bcb-4e79-8a96-54718662de05" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"I think this is just setting the future upper limit to the number of cores per socket for the server socket. And certainly not that in 2017 you will be able to purchase a 1GHz 32 core / 64 threaded AMD server chip costing over 10 thousand dollars."</post>
   <post id="865cfdd1-958e-4b60-b5ef-b7dfd9d67b85" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"are people running AMD in virtualization? If not, what would you need so many addressable cores for?"</post>
   <post id="446c32f7-3ced-4554-82c9-b9b17c04ca93" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"I am still waiting to see the next revolution in Mantle technology"</post>
   <post id="0871b772-b865-44b0-a0aa-cd10aa31ee09" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"drescherjm said: ↑ I think this is just setting the future upper limit to the number of cores per socket for the server socket. And certainly not that in 2017 you will be able to purchase a 1GHz 32 core / 64 threaded AMD server chip costing over 10 thousand dollars. Click to expand... Same thought went through my mind as well theoretical number rather then 32 core Zen when AM4 arrives . Since 16 cores for the desktop already makes little sense (due to software not written well enough) it would only end up on the server side of things ...."</post>
   <post id="16f11c38-95b3-4c32-b19b-2aa31e62497d" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"UnrealCpu said: ↑ I am still waiting to see the next revolution in Mantle technology Click to expand... This comment colours so nicely next to your system spec"</post>
   <post id="ed2d818c-7ada-404a-811a-3e6024a16cbe" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"UnrealCpu said: ↑ I am still waiting to see the next revolution in Mantle technology Click to expand... It s called Vulkan. You might have heard of it."</post>
   <post id="3f8936ca-4f5f-4acd-a028-c9231df1b4d7" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"This seems to suggest there will be server versions of Zen. I was under the impression that Zen was the desktop/mobile model, and K12 was going to be the next server arch..."</post>
   <post id="522f295b-e25a-459a-95fa-6ff0713a84fb" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Zarathustra[H];1042119106 said: This seems to suggest there will be server versions of Zen.I was under the impression that Zen was the desktop/mobile model, and K12 was going to be the next server arch... Click to expand... K12 is ARM ..."</post>
   <post id="c51bc921-4ba3-4a42-b6bd-4797d6442496" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Pieter3dnow said: ↑ K12 is ARM ... Click to expand... Ahh, I knew K12 included ARM, didn t know it was 100% ARM."</post>
   <post id="32180b76-1af9-481d-9ac3-7dcad541b8ab" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Orddie said: ↑ are people running AMD in virtualization? If not, what would you need so many addressable cores for? Click to expand... Yes and AFAIK is actually quite popular for that. We currently have 8 AMD virtualization servers. 8 cores/cpu are quite good for the price."</post>
   <post id="59b5c0b2-929e-4dca-ac2d-cc487b040d9e" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Seems about right. I read somewhere (rumors) that the mainstream CPUs were going to be focused around 8 cores but they might have some monster special APU with CPU/GPU with 16-32 cores. Not sure if this article is just regurgitating that same info or if this is a second source. I personally still use the 8 core 8350 and I like the extra cores because I do a lot of work from home that involves virtual machines so its nice to have the extra cores to run my VMs and not have it bog down my system in general."</post>
   <post id="dd3a8732-9cad-40c3-8ee3-17aa23877836" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"This does not bode well for the single threaded performance."</post>
   <post id="fa01083b-8390-4ac5-a188-ace563ceb817" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Creig said: ↑ It s called Vulkan. You might have heard of it. Click to expand... And I m still waiting for that one too."</post>
   <post id="e0c1aeaa-5c86-4f4b-8d06-5bd688e6746b" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"dgingeri said: ↑ This does not bode well for the single threaded performance. Click to expand... So what did 8 ball tell you then ?"</post>
   <post id="833c05f1-36b0-4f48-9fd1-fe0f4669f9bc" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Stoly said: ↑ And I m still waiting for that one too. Click to expand... But that is not going to take of until they are able to run some engines and even then game development cycle will have some impact on this as well. Vulkan is really good but the thing is that the Khronos group takes their time with things..."</post>
   <post id="014e8530-a5a4-446c-bad1-b838a4d05d8a" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Pieter3dnow said: ↑ So what did 8 ball tell you then ? Click to expand... Outlook hazy, ask again later."</post>
   <post id="80c1d76a-4f94-409a-b48b-4528dd5d1aca" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"Stoly said: ↑ Yes and AFAIK is actually quite popular for that. We currently have 8 AMD virtualization servers. 8 cores/cpu are quite good for the price. Click to expand... I ran my home ESXi server on an FX-8120, later upgraded to an FX-8350 for years. great low cost application of these chips, especially since they support ECC (provided your motherboard BIOS does) Biggest limitation - for me - and why I eventually switched to actual server hardware was the fact that 4 DDR3 slots effectively limited me to 32GB RAM (unless you get some ultra rare, and very expensive 16GB unregistered ECC DDR3 sticks), and if virtualization likes anyhting more than many cores, it is lots of RAM. The power use also wasn t stellar. My current dual 6 core (with HT) Xeon board uses about the same amount of power as my octacore AMD FX chip did."</post>
   <post id="182129bc-9c3a-441f-91ac-53448e7ec18a" section="AMD Processors" discussion="Leaked Patch Confirms AMD Zen Will Have 32 Cores Per Socket?">"I m not the only one thinking it."</post>
   <post id="5ddde2ef-08ed-4bbd-93d9-e72b0d112d6d" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"I see a lot of low cost name-brand CPU s available from China/HongKong. CPU s I woudn t think could be faked, but would they likely be factory discards, underperformers or? Anyone know about this?"</post>
   <post id="cb78d866-0ec9-4e05-a793-9957152fad31" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Fakes or stolen goods maybe. Faking the cpu would just require writing a bios that just lies to OS about what chip it has."</post>
   <post id="4a4cdaca-95f2-4bab-b0e0-eb0634087aa9" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Darakian said: ↑ Fakes or stolen goods maybe. Faking the cpu would just require writing a bios that just lies to OS about what chip it has. Click to expand... I would think for CPUs that might be a little more difficult. Video cards on the other hand. There used to be quite a few fakes on ebay, I don t know if there still is."</post>
   <post id="f44e3011-0679-4539-a51a-bbb17b605051" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"i have purchased some chips from china and they were exactly as described. The price was right but the only problem was the time it take to get here and if there is a problem then they are a long way off. I go by rep and if they have a lot of good feedback then i would say its prob what they say it is. But i only have gone for some of the real good deals (cheap), lol still buyer beware, do you homework"</post>
   <post id="2457ea92-4353-4123-84fd-df7ddab1dac5" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Darakian said: ↑ Fakes or stolen goods maybe. Faking the cpu would just require writing a bios that just lies to OS about what chip it has. Click to expand... You mean a motherboard bios? or youre saying there is a bios contained in a CPU?"</post>
   <post id="579afaae-1214-4fd8-8f14-f33ca3bd678d" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">".oO said: ↑ You mean a motherboard bios? or youre saying there is a bios contained in a CPU? Click to expand... Motherboard bios. I believe the mobo bios can be made to lie about what cpu is plugged in."</post>
   <post id="5304f372-c016-460c-b7c9-a520f9affd33" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Wasn t there a big issue about 10-15 years ago where they would show you a real processor, but would ship a counterfeit processor box with either nothing in it, some old processor, or some dead weight? I think it was about the time when socket A and socket 478 were mainstream. Then I think history repeated itself with iPods and iPhones - similar scope of scammage. I know Asia is the placed to order from if you want to end up with counterfeit Jordan shoes.."</post>
   <post id="35a19c75-944e-4bf2-839e-e95afb04ab4c" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"4330thgink said: ↑ Wasn t there a big issue about 10-15 years ago where they would show you a real processor, but would ship a counterfeit processor box with either nothing in it, some old processor, or some dead weight? Click to expand... Happens in the US too: http://www.hardocp.com/article/2010/03/05/newegg_selling_fake_intel_cpus"</post>
   <post id="2eb93f77-fb21-46a2-92dd-6d1539d700ce" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"You need to ask yourself this question: What happens if I get a CPU that s DOA? At least in the USA, if you bought it from a reputable vendor, you can request a RMA, and you stand an excellent chance of getting your money back, or an exchange. If it s from China, you re really taking a crap shoot. Maybe it s fine, and nothing bad happens, but we ve all run into defective CPU s on more than one occasion. Furthermore, shipping the CPU overseas is going to cost a lot. Even if they agree to ship you a replacement, they could easily demand that you pay return shipping as well. Of course, they could also simply tell you to go fly a kite, and unlike reporting bad companies in the USA, I doubt you ll get much help from the Chinese."</post>
   <post id="029a3468-7692-48de-9227-488d5b3e9fdf" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Track Drew said: ↑ Happens in the US too: http://www.hardocp.com/article/2010/03/05/newegg_selling_fake_intel_cpus Click to expand... I forgot about that one.. Good catch! Did they ever figure out where Newegg got those fakes from?"</post>
   <post id="226f1764-3af6-497d-86ab-d15fadf074de" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Darakian said: ↑ Motherboard bios. I believe the mobo bios can be made to lie about what cpu is plugged in. Click to expand... So if its just a CPU being sold (that actually works and is not paired with a motherboard) there is no way to fake it? systemvipers said: ↑ i have purchased some chips from china and they were exactly as described. The price was right but the only problem was the time it take to get here and if there is a problem then they are a long way off. I go by rep and if they have a lot of good feedback then i would say its prob what they say it is. But i only have gone for some of the real good deals (cheap), lol still buyer beware, do you homework Click to expand... If the CPU s are basically legit but have other deficiencies or? (having to do with why they are cheaper and from China/HongKong) what would those issues likely be, if any? Unabomber said: ↑ You need to ask yourself this question: What happens if I get a CPU that s DOA? At least in the USA, if you bought it from a reputable vendor, you can request a RMA, and you stand an excellent chance of getting your money back, or an exchange. If it s from China, you re really taking a crap shoot. Maybe it s fine, and nothing bad happens, but we ve all run into defective CPU s on more than one occasion. Furthermore, shipping the CPU overseas is going to cost a lot. Even if they agree to ship you a replacement, they could easily demand that you pay return shipping as well. Of course, they could also simply tell you to go fly a kite, and unlike reporting bad companies in the USA, I doubt you ll get much help from the Chinese. Click to expand... Reasonably safe through ebay if they have good ratings?"</post>
   <post id="73dde660-7a20-4b7d-ad8f-6540dedb556c" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">".oO said: ↑ So if its just a CPU being sold (that actually works and is not paired with a motherboard) there is no way to fake it? Click to expand... If there s a will then there s a way."</post>
   <post id="9e6000fa-2e0a-49a2-b542-ec82b5b3a127" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Anyone else remember when there was an issue with places overseas sanding the top of some CPUs and laser etching/printing different info on them? Or something like that, it s been a while LOL."</post>
   <post id="cc344e84-9e00-463c-af7a-f25a44ec3a8e" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">".oO said: ↑ Reasonably safe through ebay if they have good ratings? Click to expand... My advice is to simply take those ratings with several grains of salt. After all, it s not unusual for many an unwholesome vendor to have several sock puppets "buying" their wares, and giving them 5 star feedback. I m not saying that they re a bunch of shamming crooks, or that they re ripoff artists. They could very well be honest, legitimate vendors. I simply saying that the risks aren t worth saving just a handful of dollars, especially since you can probably get the same advertised CPU for just a few dollars more from the reputable vendors."</post>
   <post id="39fd7830-8d76-4de4-aa3e-73519f705c52" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"Kinda sounds like all the cheap Intel ES samples you find on eBay? Possibility the same? If that s the case, I know many people have great luck with them, but at least with Intel chips some mobos don t work with ES chips. Or are these being sold as new boxed items? Most of the Intel listings state they are ES and sold as bulk or tray items."</post>
   <post id="4c6ea844-ca90-4354-a795-bd2237289f6f" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"if you need a low cost CPU try the legit re sellers sites .. i like star micro inc and you may find many on e bay that are just trying to recycle old stock or pulls from systems they refurbish .. i always buy from a vendor in the US that has a good reputation i have had a problem with one from that site i mentioned .. they sent a new CPU within days..same with a ram order .. but that was my mistake for ordering the wrong ram ..the RMA was painless both times"</post>
   <post id="dafeb79a-6c30-4738-b9cd-4a90b6b0acc1" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"ir0nw0lf said: ↑ Anyone else remember when there was an issue with places overseas sanding the top of some CPUs and laser etching/printing different info on them? Or something like that, it s been a while LOL. Click to expand... I m not sure what is so funny about fraud?"</post>
   <post id="0fc0018d-98c3-45ee-b0cb-f84a0dd9516e" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"ZodaEX said: ↑ I m not sure what is so funny about fraud? Click to expand... Never said fraud was funny?"</post>
   <post id="e500bea1-bbec-40d3-bbb8-12420abbd668" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"ir0nw0lf said: ↑ Never said fraud was funny? Click to expand... You laughed out loud about it. Usually people laugh out loud when they think of something funny am I right?"</post>
   <post id="eee4c8b1-7abb-466b-a8b6-2cca30d505fd" section="AMD Processors" discussion="Low cost CPU s from China or Hong Kong?">"ZodaEX said: ↑ You laughed out loud about it. Usually people laugh out loud when they think of something funny am I right? Click to expand... Ah. I was LOL ing at the fact that I was trying to remember the info from way back then, it s been quite a few years since the re-etching thing happened. Apologies if you thought I was laughing at fraud."</post>
   <post id="0ba16355-ccde-473c-bd17-a4b5924e22ce" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"I used to be an AMD guy all the way but for the past few years I ve been rolling intel since the FX series never really took off and AMD shifted focus to APUs. Is there a viable AMD counterpart to the Skylake i5s for top-end gaming right now?"</post>
   <post id="4d3c7ffe-6590-411d-ac96-2767751416d3" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"Not even anything close to it, AMD s top end CPUs offer i3 - tier of gaming performance. Wait for Zen and that should change (hopefully) Buying a new FX chip today will be a really really really bad investment."</post>
   <post id="394fc433-eb77-40d7-ae7f-269a364600bf" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"Wait 4 to 6 months for Zen."</post>
   <post id="68e16808-b27f-47b9-bc9d-aae08f85878e" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"Pickup a Skylake PC and enjoy it. AMD hasn t shown anything in the CPU space to indicate they will be able to compete with Intel. They are many generations behind Intel on not only CPU tech but also chipsets."</post>
   <post id="98f9cdca-8550-48e1-945b-9bc5efc74504" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"Ocellaris said: ↑ Pickup a Skylake PC and enjoy it. AMD hasn t shown anything in the CPU space to indicate they will be able to compete with Intel. They are many generations behind Intel on not only CPU tech but also chipsets. Click to expand... I was looking at your specs are you running an OC on that 6500?"</post>
   <post id="2609f95e-b542-45f2-9780-f7c7dc68d6b2" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"a3venom said: ↑ I was looking at your specs are you running an OC on that 6500? Click to expand... No just stock speeds. Don t both trying to overclocking with a non-K chip, it is really ghetto."</post>
   <post id="1f0209b3-03f9-4251-8f70-812380c94262" section="AMD Processors" discussion="Is there currently a viable AMD alternative to Skylake i5?">"Thank y all. Sounds like Skylake is the way to go for a build today. Thanks."</post>
   <post id="5f200d49-3253-459d-9a55-b1aaf7a71c92" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"AMD Zen Rumours Point to Earlier Than Expected Release. http://www.eteknix.com/amd-zen-rumours-point-earlier-expected-release/ Saw it on WCCFTECH first. http://wccftech.com/amd-am4-motherboards-launch-q2-2016-for-bristol-ridge-apus/ Motherboards in March?"</post>
   <post id="ce762e58-3f15-4130-adfe-ffd2e0c313be" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"I ll believe it when I see it."</post>
   <post id="36f99299-fe08-4bf0-8952-c259a785b0a3" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Zen is a good name for it...all AMD fans need to meditate and pray that it doesn t suck"</post>
   <post id="07abaee5-1f87-491b-be90-34603c80be11" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"polonyc2 said: ↑ Zen is a good name for it...all AMD fans need to meditate and pray that it doesn t suck Click to expand... Hey I still get 60 fps in all my games. I wish I had USB 3.1 though. I still have USB 3.0 so I guess it s not so bad over here. There are new 990FX chipsets with USB 3.1"</post>
   <post id="0c541e9c-f7d5-4ae9-812b-871fa1261542" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Quix said: ↑ I ll believe it when I see it. Click to expand... I bought my Bulldozer motherboard in July 2011 and the processors didn t release until October 2011. Back then we could plug our old AMD processors into the mobo without issue though."</post>
   <post id="bdb43c86-3d7a-4559-abfc-01f1a2e88908" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"The eteknix.com article says Zen was originally scheduled for Q1 2016, which is wrong. It was originally scheduled for sometime in 2017, but was moved up in the schedule at the expense of delaying K12 which was scheduled for Q1 2016."</post>
   <post id="4013a619-60d9-413a-a395-2dfba71773f4" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"cageymaru said: ↑ I bought my Bulldozer motherboard in July 2011 and the processors didn t release until October 2011. Back then we could plug our old AMD processors into the mobo without issue though. Click to expand... I remember that, but I take any piece of Zen news with a grain of salt. A whole new architecture is a lot of work and it s not going to come easy. AMD fans haven t had any new performance chips since 2011 so everyone is just straining for some news about Zen."</post>
   <post id="7411bde9-7a5a-4f5a-bd7f-d5f416bf7835" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Roughly lines up with Nintendo s NX release which was rumored to use Zen/Artic islands. Nintendo was claiming a goal of 20m units for next year, so if they are using something Zen-like the earlier the better to hit that goal. Also rumors that Zen was hitting all its performance goals. The irony of naming it Zen (Japanese rock garden) and pushing them out through Nintendo (Japanese company that made gray consoles)..."</post>
   <post id="a6cc8b23-49a2-4691-8371-e8ae7e980c42" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Hoping to see AMD make a good comeback, they ve really fallen behind in some key areas. For gaming they remain a fine choice, but they re left way behind for almost any other compute task, ie content creation."</post>
   <post id="58a3c099-b940-462b-9fb3-e8a683dc29d9" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"It may be the excavator APUs in march with zen later in the year."</post>
   <post id="d31bb5e9-46d1-484b-9739-62e7251fd1d2" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"I doubt it. AMD themselves stated zen itself was only going to be paper launched in q4 and that they don t expect actual revenue from it until q1 2017 at the earliest."</post>
   <post id="c425e878-d234-4e79-8d16-f00cdc51cf90" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"When was the last time AMD ever put out a CPU on time, let alone ahead of time? This picture summarizes just about every AMD rumor regarding release dates. If they get it out in Q1 2016 it will be a miracle. I don t doubt they can, I just sincerely doubt all the rumors. I would think if they were going to launch in 3 months, there would be something...anything by now that AMD was in production."</post>
   <post id="efbee031-1c6f-4470-8269-e21e6e4b1bbf" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Will see, maybe they ll finally be a reason to upgrade my trusty 920 by whatever time Zen does come out. Still, doubt they ll be a need to upgrade, but who knows."</post>
   <post id="b871323c-60ca-49cc-8893-3903dca8b750" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"I m more concerned about pricing. If AMD thinks they can get away with Pricing the Fury and Fury-X/Nano at $550 and $650 respectively in a world of $530 GTX980-Ti s, then I m worried that they ll price a chip the performs like an i7-6700k as if it were an i7-5930k."</post>
   <post id="880fc6bc-c08d-4f96-808a-9d550815e04b" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Rauelius said: ↑ I m more concerned about pricing. If AMD thinks they can get away with Pricing the Fury and Fury-X/Nano at $550 and $650 respectively in a world of $530 GTX980-Ti s, then I m worried that they ll price a chip the performs like an i7-6700k as if it were an i7-5930k. Click to expand... Most of the fury cost can be attributed to new tech or limited availability, whether because of HBM stock levels or their own GPU cores. As of this moment, HBM only exists in the Furys and that alone will add a premium. By the by, the 980Ti is a $650 card MSRP. You cant use current sale prices you have to use release sale prices."</post>
   <post id="4ed76b68-cb9b-4782-9e3a-e1b2bf750a76" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"Rauelius said: ↑ I m more concerned about pricing. If AMD thinks they can get away with Pricing the Fury and Fury-X/Nano at $550 and $650 respectively in a world of $530 GTX980-Ti s, then I m worried that they ll price a chip the performs like an i7-6700k as if it were an i7-5930k. Click to expand... I expect AMD to price Zen to be a little cheaper than the processor they believe they are competitive with although at first they may overcharge eventually they will get the price right."</post>
   <post id="182f7ce9-370c-48ec-912a-5c3bbc560f7b" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"I find it hard to believe they could jump the schedule by a good 6 months that would mean for the first time in a long long long time they had zero problems with the manufacturing process. I m not to bothered about the price as long as it is something with 8 cores or more."</post>
   <post id="ffc23585-f9ae-4415-977c-ef924191f618" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"It s not unusual for AMD motherboards to be released months prior to the CPU. If anything this rumor might point to Zen being on track for a Q3 or Q4 2016 release."</post>
   <post id="2d542f41-9da0-44a5-b7a6-bacd57aa4e38" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"variant said: ↑ It s not unusual for AMD motherboards to be released months prior to the CPU. If anything this rumor might point to Zen being on track for a Q3 or Q4 2016 release. Click to expand... But still if mobos are ready chances increase for leak of ES cpus and someone posting benchmarks And getting to know if it s competitive or not could save a lot of time for people waiting for Zen."</post>
   <post id="0d5c72b4-7a2d-419d-9bc2-8aba2e899457" section="AMD Processors" discussion="AMD Zen Rumours Point to Earlier Than Expected Release">"JustReason said: ↑ Most of the fury cost can be attributed to new tech or limited availability, whether because of HBM stock levels or their own GPU cores. As of this moment, HBM only exists in the Furys and that alone will add a premium. By the by, the 980Ti is a $650 card MSRP. You cant use current sale prices you have to use release sale prices. Click to expand... Ther are no 980 Ti s on sale at $530 either."</post>
   <post id="0d5ad6cc-5868-4532-9e38-6a5b4be83128" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"AMD: The Good News Continues http://seekingalpha.com/article/3968349-amd-good-news-continues Sorry about the headline. Seeking Alpha had done another article with that title and it cracked me up so much that I had to use it. You can see the link to that article on page one of this article. Anyways this article explains why AMD is going to profit from the China deal and why the stock will climb in 2017."</post>
   <post id="73450b5a-104e-49e4-8e1b-7edab6f6fe5c" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"cageymaru said: ↑ AMD: The Good News Continues http://seekingalpha.com/article/3968349-amd-good-news-continues Sorry about the headline. Seeking Alpha had done another article with that title and it cracked me up so much that I had to use it. You can see the link to that article on page one of this article. Anyways this article explains why AMD is going to profit from the China deal and why the stock will climb in 2017. Click to expand... Must register to read.... no way."</post>
   <post id="d58e48d7-95bf-44f0-90bf-f0f98dde4a4c" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Spirit_Retro said: ↑ Must register to read.... no way. Click to expand... Agreed. Even shitty speculation sites like Motley Fool don t require registration, so why should I pony-up for an even bigger unknown player? It s almost as bad as handing Charlie money for his idiotic "insights""</post>
   <post id="5dedf8bb-42a6-4f7a-bdaa-833dafc8b341" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Thanks. I already had an account. I will take a look at that later."</post>
   <post id="a5a1f3cf-46f7-4488-b652-5ef9ec859ac4" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"You can sign in with google? but they want to know stuff about you and that is where I said no thanks ."</post>
   <post id="83c57d7f-f973-41d6-87a8-5eaf74f6758e" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"All you have to do is turn off scripts. Use No Script for Firefox add on and you can read the whole thing. It s their script that is stopping you from scrolling down. " Conclusion AMD s latest earnings release was the most positive I have seen from the company in years. New semi-custom contracts are being readied for production, IP and licensing is generating revenue, Zen is sampling, 2016 will be cash flow-positive and earnings will be positive in the second half. The company is not completely out of the woods yet, but if the Nantong deal does close this quarter, then I would be very confident 2017 will be a very big year for AMD. My $10 price target for AMD does not require $1 per share earnings, even though I do think the company will reach that target easily. All the market needs to see is Zen taking market share in desktops and servers, and the stock will rise accordingly. And that will happen because big customers like HP (NYSE:HPQ), Dell and Lenovo (OTCPK:LNVGY) are eagerly awaiting for competition in those semi-monopoly markets. AMD does not need a superior product to make that happen, but just a competitive one. After all, the company is selling millions of chips with inferior capability (28NM GPU and CPU products). How many more millions will it sell when it has competitive 14NM products? I think a lot more, and at higher margins too. Another positive for the stock is that it is uncorrelated to the market. If the doomsayers are correct and the market falls 20-30% in the next two years, it will not affect AMD much if at all. Cloud and enterprise servers in China and elsewhere will continue to sell and upgrade, desktops have a renewal cycle all of their own and VR is headed up no matter what. Disclosure: I am/we are long AMD. I wrote this article myself, and it expresses my own opinions. I am not receiving compensation for it (other than from Seeking Alpha). I have no business relationship with any company whose stock is mentioned in this article.""</post>
   <post id="67cd36dc-638e-4b3c-bbc5-460012ed5f5a" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"I m cautiously optimistic. I will believe it when I see actual results and numbers on paper. They ve burned people too many times for them to be given benefit of the doubt anymore."</post>
   <post id="52aea227-5909-4d30-a460-da44a66e985b" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"I am buying ZEN for desktop whatever happens. It has to be better than FX so I see no issues. And I think that is what stock holders are thinking - that there is a large crowd that avoided FX and either defected to Intel and want to come back, or held off upgrading, and it is these people who are ready to buy."</post>
   <post id="38266d5a-836d-44de-9c42-c3f2b39d8af5" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"CaptNumbNutz said: ↑ I m cautiously optimistic. I will believe it when I see actual results and numbers on paper. They ve burned people too many times for them to be given benefit of the doubt anymore. Click to expand... You mean that you have links to reviews/articles where AMD said they would beat Intel with Piledriver, Steamroller &amp; Excavator cores because those I would like to see ? You are talking about an event in 2011 as if it scarred you for life."</post>
   <post id="d5af2fa3-fb21-486e-a648-eb1a827f5e33" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Pieter3dnow said: ↑ You mean that you have links to reviews/articles where AMD said they would beat Intel with Piledriver, Steamroller &amp; Excavator cores because those I would like to see ? You are talking about an event in 2011 as if it scarred you for life. Click to expand... Pulling out the fanboy kneejerk defense are we? What are you talking about this "event in 2011" or anything regarding Piledriver, Steamroller or Excavator? Where did I mention any of that or even the year 2011? Guess what? I didn t, nor did I even imply it because this article has nothing to do with anything you just ranted about. You are just pulling this crap out of thin air and creating an argument where there was none. You might want to read the article to figure out what the actual topic of conversation is first. The article in OP is about profits and new markets, not individual products. AMD has not been hitting their profit goals for a long time, losing money nearly every year. Yet somehow they keep getting investments and loans to stay in business. This has been the story with them since the ATI aquisition, if not even further back. When I say "burned people too many times" I m referring to the investors who keep losing money quarter after quarter."</post>
   <post id="9bc9c67a-d4a9-45a9-8662-b21f476a1c81" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Sorry, if there is one thing AMD is good at: it s failing spectacularly. I really want to have AMD  Back in the game , but lets face it: their track record doesn t really merrit a lot of faith."</post>
   <post id="6f64571b-d863-41ed-90f9-779c00fa3928" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"KazeoHin said: ↑ Sorry, if there is one thing AMD is good at: it s failing spectacularly. I really want to have AMD  Back in the game , but lets face it: their track record doesn t really merrit a lot of faith. Click to expand... I know, being in all of the gaming consoles is so fail"</post>
   <post id="d5a0d404-5d24-4e30-9dbb-f9ad6f4d5fb3" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"JHefile said: ↑ I know, being in all of the gaming consoles is so fail Click to expand... It s a win but if you don t know silicon and margins you don t have the whole story. Those console SoCs are huge, they don t fit very many on a wafer and the margins are VERY low. Sony and Microsoft need lowing pricing because they know they cannot charge a ton for consoles."</post>
   <post id="078e54c1-6389-462e-8ae6-e52390164069" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"CaptNumbNutz said: ↑ Pulling out the fanboy kneejerk defense are we? What are you talking about this "event in 2011" or anything regarding Piledriver, Steamroller or Excavator? Where did I mention any of that or even the year 2011? Guess what? I didn t, nor did I even imply it because this article has nothing to do with anything you just ranted about. You are just pulling this crap out of thin air and creating an argument where there was none. You might want to read the article to figure out what the actual topic of conversation is first. The article in OP is about profits and new markets, not individual products. AMD has not been hitting their profit goals for a long time, losing money nearly every year. Yet somehow they keep getting investments and loans to stay in business. This has been the story with them since the ATI aquisition, if not even further back. When I say "burned people too many times" I m referring to the investors who keep losing money quarter after quarter. Click to expand... So how can you get burned exactly ? Your stock sets on fire then transforms into napalm explodes on to you ? Or do you mean that this report is like the many other reports where AMD paints a certain picture that profits are on the horizon (not that uncommon). KazeoHin said: ↑ Sorry, if there is one thing AMD is good at: it s failing spectacularly. I really want to have AMD  Back in the game , but lets face it: their track record doesn t really merrit a lot of faith. Click to expand... The idea is that there are 2 playing fields you need to keep track of and the one that is for investors you should leave it for what it is. AMD is now starting with this VR campaign, it is trying to create a market for themselves where there is growth and they can project it to people in the financial industry ... I would say that with Zen and Polaris maybe some good fortune it might work out nicely for them."</post>
   <post id="ef8c0a0c-fb6b-4887-9fe6-e918c94191ca" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"OFaceSIG said: ↑ It s a win but if you don t know silicon and margins you don t have the whole story. Those console SoCs are huge, they don t fit very many on a wafer and the margins are VERY low. Sony and Microsoft need lowing pricing because they know they cannot charge a ton for consoles. Click to expand... Aren t the new consoles supposed to be running 14nm APUs? I guess they could still use the old node; I don t keep up with APUs and consoles much."</post>
   <post id="9c8a782b-7306-40b9-8a3f-ee6246e9e700" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Spirit_Retro said: ↑ Must register to read.... no way. Click to expand... Firefox -&gt; left click on pop-up -&gt; Q -&gt; press delete -&gt; F12 to hide FF console. Click text, Ctrl-A to select all and defeat blur, Arrow keys to scroll. Use URL bar to navigate to pages 3, 4, 5, 6. Works on so many sites ..."</post>
   <post id="6c47cb3f-be24-49fa-ab7b-b77d370697cc" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Pieter3dnow said: ↑ So how can you get burned exactly ? Your stock sets on fire then transforms into napalm explodes on to you ? Or do you mean that this report is like the many other reports where AMD paints a certain picture that profits are on the horizon (not that uncommon). Click to expand... Since reading comprehension isn t your strong suit, I will answer your question with what I have said already. CaptNumbNutz said: ↑ AMD has not been hitting their profit goals for a long time, losing money nearly every year. Yet somehow they keep getting investments and loans to stay in business. This has been the story with them since the ATI aquisition, if not even further back. When I say "burned people too many times" I m referring to the investors who keep losing money quarter after quarter. Click to expand... I m not only referring to AMD "painting a picture" of profits. All companies do that. They obviously have to sell themselves to get investors. I am referring to their inability to live up to these goals and provide profit, time and time again. For most investors, AMD s inability to be profitable over the course of the past decade is why investors feel burnt. They sell stock, and as a result the stock price goes down to where it is now: a pathetic $3.54 per share today 4/29/16. Compare that to a decade ago, their share price was at $40.54/share in February 2006. It s got a lot of potential to grow if AMD can follow through with this ambitious plan. I will repeat myself. I feel cautiously optimistic. I m cautious because at best, AMD has been inconsistent when making profit. I m optimistic because branching out into new markets like this is exactly the change in strategy they need."</post>
   <post id="646a6493-03a5-4a09-8148-9ad1de9f40e6" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"CaptNumbNutz said: ↑ Since reading comprehension isn t your strong suit, I will answer your question with what I have said already. I m not only referring to AMD "painting a picture" of profits. All companies do that. They obviously have to sell themselves to get investors. I am referring to their inability to live up to these goals and provide profit, time and time again. For most investors, AMD s inability to be profitable over the course of the past decade is why investors feel burnt. They sell stock, and as a result the stock price goes down to where it is now: a pathetic $3.54 per share today 4/29/16. Compare that to a decade ago, their share price was at $40.54/share in February 2006. It s got a lot of potential to grow if AMD can follow through with this ambitious plan. I will repeat myself. I feel cautiously optimistic. I m cautious because at best, AMD has been inconsistent when making profit. I m optimistic because branching out into new markets like this is exactly the change in strategy they need. Click to expand... Actually the last bit has always made sense. But I m still dismayed by the lack of physical burning or spontaneous combustion."</post>
   <post id="628d5513-268c-4173-b27c-17483916755a" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"Pieter3dnow said: ↑ But I m still dismayed by the lack of physical burning or spontaneous combustion. Click to expand... It s a figure of speech. The only spontaneous combustion occurring here was your first over-zealous reply. Before you get bent out of shape again, that too was a figure of speech."</post>
   <post id="116946e0-9f5c-45e3-989e-08b8cf0360f5" section="AMD Processors" discussion="AMD: This Intel Ankle-Biter Is On Its Way To Substantial Profits">"CaptNumbNutz said: ↑ It s a figure of speech. The only spontaneous combustion occurring here was your first over-zealous reply. Before you get bent out of shape again, that too was a figure of speech. Click to expand... I do not have any AMD stock so it won t happen ..."</post>
   <post id="29df63bf-06bf-4c58-bb0d-96bbd34d57c8" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"I built my wife a computer many years ago with an Athlon II 445 triple core @ 3.1 ghz and a single 4 GB stick of memory. This week I upgraded it to a Phenom II 945 @ 3 ghz and added a second 4 GB stick so it s now dual channel. What an upgrade in regard to system responsiveness. Searches are much faster, Chrome feels faster, startup is quicker, and user switching is quicker. This is just an internet machine but I really thought it was good enough before and was surprised by the difference. 3 cores to 4. Lost 100 mhz clock speed No L3 cache to 6 MB L3 cache. Single channel to dual channel DDR 1333 4 GB to 8 GB memory. Same Biostar 880g motherboard Same 840 EVO SSD. Same Windows 10 Pro 64 bit install. This was one of those times when I had to correct my perception of what s fast enough. I d say it s just as fast as my i7 2600k in basic desktop usage now."</post>
   <post id="0d748d0d-ac80-48e6-92be-4b3934f1d99e" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Interesting feedback. I have a feeling a lot of the perceived change is the effect of the massive increase in memory capability (both the cache and 2x RAM bandwidth/capacity). I have used both Athlon-II Tri-cores and the exact same Ph-II 945, albeit in Win 7, and didnt find the difference to be extraordinary in most cases, Haven t used W10 with AM3-socket hardware, though."</post>
   <post id="8b64f9df-d222-4498-a420-447ac2238e1a" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"i was thinking of upgrading to an athlon II quad (630, 640, etc) for my sisters computer, running a 7750 dual core. I think the 4GB is enough for her (dual channel) since she mainly does internet browsing."</post>
   <post id="66e0a887-0c83-43f1-9608-b28d1b21486b" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Heh.. used to own a AX2 7750, too. I think those were basically Phenom I badged as dualies, which is to say  not stellar . But I m not 100% confident about that. 7750 to a PH2/A2 quad should be quite a jump, and I am 100% confident about that because it was the exact path I took ( 7750 -&gt; 945)."</post>
   <post id="717fa8f6-b395-4825-a115-d78a777bd498" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Cool, I m upgrading a client from a Phenom 1 to a Phenom 2 next week for cheap too."</post>
   <post id="6eb6360e-cfed-4de1-8c63-1b4fa03e63be" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Here s the ATech bench of a A2 X3 445 vs. a Phenom II 940. W10 (and even W8+) really enjoy caching stuff into memory, so i imagine that the extra channel of ram + L3 cache is providing a specific boost to responsiveness that may not necessarily appear in a less-cached OS environment and/or pure bench numbers."</post>
   <post id="4ec8726b-133d-4d5d-9643-b8e3a062605f" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"mnewxcv said: ↑ i was thinking of upgrading to an athlon II quad (630, 640, etc) for my sisters computer, running a 7750 dual core. I think the 4GB is enough for her (dual channel) since she mainly does internet browsing. Click to expand... 4 extra GB of RAM wont hurt, especially now are so cheap"</post>
   <post id="23968be4-f9e5-467e-933e-d933414defea" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Single channel vs dual wasn t as big of a deal in noticeable performance when those chips were new, but it became more important over time. That alone probably helped performance a lot."</post>
   <post id="80627c59-b785-442e-b92f-e00d2afbcd59" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"IceDigger said: ↑ Cool, I m upgrading a client from a Phenom 1 to a Phenom 2 next week for cheap too. Click to expand... that would be a huge change going from a terrible processor to a pretty good one. personally, my change wasn t as dramatic as well. perhaps it was the extra 4gb? i noticed with windows 7, post-updates, 4gb is really pushing the minimum. with 8gb, my machines got much more responsive."</post>
   <post id="4f4df5f2-f14d-4186-8ad5-6789b8654aa5" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"4 GB of memory in 64 bit Windows is adequate, if you re not doing more than a few light things at a time. Then again, that would exclude about 99% of the people on this forum... Going from 4 to 6 GB on a 64 bit system (My mother s laptop) made a very noticeable difference, especially when cutting down on thrashing. I suspect that the OP gained the most benefit from the upgrades by upping the RAM."</post>
   <post id="1ca58c46-b79e-45d7-a5ad-3ce32c5dd627" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"I been rocking my Phenom II x4 955 BE on W10 since it was released free. No problems at all."</post>
   <post id="a1d79b22-ad03-4ba5-8ac0-31ead77ca9a1" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Unabomber said: ↑ 4 GB of memory in 64 bit Windows is adequate, if you re not doing more than a few light things at a time. Then again, that would exclude about 99% of the people on this forum... Going from 4 to 6 GB on a 64 bit system (My mother s laptop) made a very noticeable difference, especially when cutting down on thrashing. I suspect that the OP gained the most benefit from the upgrades by upping the RAM. Click to expand... ditto. my htpc had 4gb on w7 64-bit was fine most of the time, but when i streamed w/chrome and watched 1080 .mkv shows w/MPC, occasionally MPC would stutter and lag. Even with only 1 tab+1 stream and MPC, my RAM usage was hitting right under 4gb. After getting other 8gb to replace one of the 2gb sticks, i havent had any issues."</post>
   <post id="6b4ca57b-5bff-4476-b70b-e7a3fe1dee25" section="AMD Processors" discussion="Athlon II to Phenom II in Windows 10">"Just last week I went from a Phenom x2 550 to a Phenom x4 945. I do enjoy the extra 2 cores, not HUGE OMG difference but still noticeable for me. For me, when I kept same processor but changed from old DDR2 based AM3 mobo, to a newer DDR AM3+ chipset i gained HUGE increase there imo. Prior to that the system was sluggish running Win 7 or 10 Pro. Just my two cents, DDR2 vs DDR3 made major difference on my end."</post>
   <post id="96a64245-f44c-41ac-9e8a-0765755b101f" section="AMD Processors" discussion="Someone explain Thermal Margin to me.">"Got an 880K on an Asrock A88M-G/3.1 . Using AMD Overdrive. At idle I get between 50C and 55C. Is this my actual temp?"</post>
   <post id="10300b84-b73d-4cd3-ba2c-d1b3013719be" section="AMD Processors" discussion="Someone explain Thermal Margin to me.">"No, that is the distance between your temp and the maximum temp. If you start seeing less than 10C margin you re very hot."</post>
   <post id="57cd9e1b-a86e-4fe0-b3d6-2795e874ed90" section="AMD Processors" discussion="Someone explain Thermal Margin to me.">"LigTasm said: ↑ No, that is the distance between your temp and the maximum temp. If you start seeing less than 10C margin you re very hot. Click to expand... Ok thanks. I was thinking that was correct but, wasn t entirely sure. Google just turns up a bunch of rubbish searching."</post>
   <post id="da4b5b18-45c6-4c2e-a390-aa6546449234" section="AMD Processors" discussion="Someone explain Thermal Margin to me.">"Private_Ops said: ↑ Ok thanks. I was thinking that was correct but, wasn t entirely sure. Google just turns up a bunch of rubbish searching. Click to expand... Yeah, in that board particularly I found HWinfo to be very accurate (not all AMD boards - especially FM2- work with other programs than AOD) as well if you prefer the normal temp reading, but margin is just fine, its basically distance to "too hot"."</post>
   <post id="cb4383a2-9672-4ad2-83bf-97ec3f8d6820" section="AMD Processors" discussion="Someone explain Thermal Margin to me.">"If you are overclocking ... Some people say 10% margin I would suggest you never go there. And go between 15%-20% (load) unless you know what you are doing ..."</post>
   <post id="a34c7058-af58-4c7f-adec-a71298f21d9e" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Ok, here s my issue. I ve got several 8-core Bulldozer and Vishara boxes up and running for video editing and rendering. I even have an 8150 black w/ factory watercooler in the box. Most of them are based off of MSI-970A-G43 boards. I m debating in my head if it s finally time to give up the ghost and go intel, since it s doubtful that they ll have thunderbolt support, and that s the best in connectivity to video drives. Plus, I d love to take advantage of a board with PCIe 3.0 M2 slots. My choice right now is to either... a) stick with what I ve got and use some PCIe 2.0 based add-in cards to get an M2 drive going (which I haven t ruled out things like hp s turbo drive quad to get more space over speed) or even go to a storage server. b) get a newer motherboard with a PCIe 2.0 M2 drive after zen comes out on the cheap, and deal with it from there c) scale down hardware now, sell, and wait for zen and upgrade all at once, hoping for a decent motherboard solution. d) sell out and *sigh* finally go intel. I feel so dirty after holding out for so long, but the performance/connectivity gap is starting to become very real for me. Let me know your thoughts."</post>
   <post id="0a14c72f-6ddd-4ddc-aeb9-2ce312e915d9" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Voted D. You can get what M2 support you want right now along with much better performance. AMD has done nothing to indicate Zen is worth waiting for."</post>
   <post id="7d4e10e1-f4ba-424d-9f1a-f08e41d63653" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"I d hang in there until October as see where Zen is. If the first rev is competitive, then you can make a good decision. 50% of people who predict the future (one way or another) are wrong. So the best bet is to wait. So you can be right"</post>
   <post id="43ba6ced-4f49-4ea9-8c55-d97c4e51622c" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"You could get an i3 skylake setup and hold for zen and then decide if get an zen cpu or upgrade to an i5"</post>
   <post id="a7b39b21-3192-4241-9e28-0e1e5ec71b3d" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"PontiacGTX said: ↑ You could get an i3 skylake setup and hold for zen and then decide if get an zen cpu or upgrade to an i5 Click to expand... Why? OP is rendering video. Any i3 would be a downgrade even with the better IPC. I d go with Option A personally. Just no point in upgrading unless you move to the Intel 6+ core chips, and that s a lot of money."</post>
   <post id="26460134-3239-4327-9bce-3fb563405ac7" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"DeathFromBelow said: ↑ Why? OP is rendering video. Any i3 would be a downgrade even with the better IPC. I d go with Option A personally. Just no point in upgrading unless you move to the Intel 6+ core chips, and that s a lot of money. Click to expand... Then I didnt see that part and then an i7 Haswell/Ivy Bridge/FX-83xx (if mobo can oc) and hold for zen"</post>
   <post id="d7d337cd-9a72-4352-9262-d234fd6cfe2f" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Thanks for all of the input. So far, you guys have given me a lot to think about. Right now, I may try throwing a second video card into play or moving one over to a used i7 combo for the next six to eight months, then see how Zen pans out. I m hoping for Big Red s sake, it s a whopper of a launch."</post>
   <post id="0d2dae6f-9a6c-49fd-b9b3-afb8f1d861bb" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Lothar the Lotharian said: ↑ Thanks for all of the input. So far, you guys have given me a lot to think about. Right now, I may try throwing a second video card into play or moving one over to a used i7 combo for the next six to eight months, then see how Zen pans out. I m hoping for Big Red s sake, it s a whopper of a launch. Click to expand... The is a bottleneck with 8 core FX Chips with dual GPU configurations depending on what you use - i think atleast 2 x 390s won t work to their full potential because of that bottleneck."</post>
   <post id="e0551077-65e9-47f5-a243-960735cc1337" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"a3venom said: ↑ The is a bottleneck with 8 core FX Chips with dual GPU configurations depending on what you use - i think atleast 2 x 390s won t work to their full potential because of that bottleneck. Click to expand... maybe would work better on DX12"</post>
   <post id="b602499f-bd6f-4861-8dc4-936eadcce93d" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Lothar the Lotharian said: ↑ Thanks for all of the input. So far, you guys have given me a lot to think about. Right now, I may try throwing a second video card into play or moving one over to a used i7 combo for the next six to eight months, then see how Zen pans out. I m hoping for Big Red s sake, it s a whopper of a launch. Click to expand... Krenum posted this video a couple of days ago. You can get the mobo for $80 and the processor for $40. There are more modern Xeon solutions also where the processors are around $90, but the motherboards are getting expensive. I think you would get good use out of a 8 core Xeon until whatever Intel (10 cores) and AMD (Zen) come out with their new consumer lines."</post>
   <post id="3802788d-09ed-4544-a18f-2daf57494da7" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"PontiacGTX said: ↑ maybe would work better on DX12 Click to expand... pure speculation at this point"</post>
   <post id="8c313997-8da5-49c9-9d2d-3f85f9ac05c6" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"a3venom said: ↑ pure speculation at this point Click to expand... it is a fact that DX11 is the biggest limited factor on games with CPU bound scenarios it has been tested DX12 helps the CPU bound scenarios. Ashes of the Singularity DirectX-12-Leistungsexplosion (Seite 5) Hitman Benchmarks mit DirectX 12 (Seite 2) depending on how the game is using the resources the CPU isnt an bottleneck anymore except it is an RTS game or other cpu bound game"</post>
   <post id="19d42b82-e450-466b-8a5e-c46974b9ae53" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"PontiacGTX said: ↑ it is a fact that DX11 is the biggest limited factor on games with CPU bound scenarios it has been tested DX12 helps the CPU bound scenarios. Ashes of the Singularity DirectX-12-Leistungsexplosion (Seite 5) Hitman Benchmarks mit DirectX 12 (Seite 2) depending on how the game is using the resources the CPU isnt an bottleneck anymore except it is an RTS game or other cpu bound game Click to expand... As far as I ve seen it is turning out to be it is not using CPU more effectively, it is just using less CPU than before to do what it needs. Like the multicore i7 or FX gains from DX 12 are not even close to the pentium / i3 gains in these games. But i havent seen any dual GPU testing yet"</post>
   <post id="8ac7212b-5262-4cdc-87f8-a0307b3e988f" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"a3venom said: ↑ As far as I ve seen it is turning out to be it is not using CPU more effectively, it is just using less CPU than before to do what it needs. Like the multicore i7 or FX gains from DX 12 are not even close to the pentium / i3 gains in these games. But i havent seen any dual GPU testing yet Click to expand... if should be using less CPU to be more effective if the game isnt using the extra cores for some tasks and the CPU load is higher the problem is the coding for the game and DX11 problems with ST and the gains are higher on low end/slower part because they are supposed ot be CPU limited by those tasks which need more than 2c 4t/4c 4t about dual gpu testing I asked to the review editor on hardforum and he wanst helpful at all."</post>
   <post id="b2d15452-1d2e-4d56-a227-a33885bf1f44" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"Option A. Wait for Zen (and possibly Intel s Kaby Lake) to emerge and then make an informed decision which platform is the best choice based on reviews with real-world usage results. I ve been itching to upgrade to Skylake, but I m going to hold out until at least Zen hits resellers and figure out which route to take...so I give you the same advice I m giving myself."</post>
   <post id="b8770782-d65d-48a4-a7c0-2f552773e242" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"I have 4 amd gaming machines, i just read an article comparing i5-2500k against an i5-6600k and its pretty huge step. Mind you im running about the latest amd chip, 860k overclocked to 4.3ghz and it doesnt match a stock clock i5-2500k in about any benchmarks. at my work lenovo M91p are starting to be scrapped out. I took one home, bought a replacement motherboard ... got it up and running i5-2500 3.3ghz , put in a video card and it wont boot. Drats! apparently lenovo lock the bios down so it wont boot with any video card better then a geforce 750ti or so i read. Thought i was going to have a sweet $24 i5 gaming pc... Anyway, im waiting for Zen, but i voted D. AMD is killing us, not even updated motherboards to drool over and it still feels like zen wont be shipping for 5-6 months yet."</post>
   <post id="3078bf3c-f481-4c02-b5f7-b061994cbd8e" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"buttons said: ↑ I have 4 amd gaming machines, i just read an article comparing i5-2500k against an i5-6600k and its pretty huge step. Mind you im running about the latest amd chip, 860k overclocked to 4.3ghz and it doesnt match a stock clock i5-2500k in about any benchmarks. at my work lenovo M91p are starting to be scrapped out. I took one home, bought a replacement motherboard ... got it up and running i5-2500 3.3ghz , put in a video card and it wont boot. Drats! apparently lenovo lock the bios down so it wont boot with any video card better then a geforce 750ti or so i read. Thought i was going to have a sweet $24 i5 gaming pc... Anyway, im waiting for Zen, but i voted D. AMD is killing us, not even updated motherboards to drool over and it still feels like zen wont be shipping for 5-6 months yet. Click to expand... You mean no updated AM3+ motherboards ? Because there are some Kyle used one in his DX11 VS DX12 review. The AM4 stuff seems to be in June when Computex along with the new APU based on Excavator ...."</post>
   <post id="9b6bc055-4766-414b-8288-ea5fdd0c5b05" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"DejaWiz said: ↑ Option A. Wait for Zen (and possibly Intel s Kaby Lake) to emerge and then make an informed decision which platform is the best choice based on reviews with real-world usage results. I ve been itching to upgrade to Skylake, but I m going to hold out until at least Zen hits resellers and figure out which route to take...so I give you the same advice I m giving myself. Click to expand... Kaby lake is skylake,there is no need to wait."</post>
   <post id="aa971b85-48ee-4018-9ca3-8fef9bdb98ed" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"PontiacGTX said: ↑ Kaby lake is skylake,there is no need to wait. Click to expand... I assume there will be at least some IPC improvement with Kaby Lake."</post>
   <post id="470b5ae6-0103-4025-9fde-35daf95e3521" section="AMD Processors" discussion="Need Recommendations from Die-Hard Red Fans...">"drescherjm said: ↑ I assume there will be at least some IPC improvement with Kaby Lake. Click to expand... It is a refresh of skylake,intel already stated how they are going to release their cpus,like they did with lga1150 cpus New architecture,refresh(higher frequency,barely improved TIM,slighly different thermal interface,new mobo chipset) and node shrink"</post>
   <post id="b7377292-e1e7-452d-a1bf-99fa6bc34b0d" section="AMD Processors" discussion="Compulab fitlet-XA10-LAN Review: A Fanless AMD UCFF PC for Networking Applications. (AMD vs Intel)">"Compulab fitlet-XA10-LAN Review: A Fanless AMD UCFF PC for Networking Applications. Compulab fitlet-XA10-LAN Review: A Fanless AMD UCFF PC for Networking Applications So the fanless PC in this case is using an AMD A10 Micro-6700T. It is benchmarked against similar and much more expensive Intel Bay Trail and Braswell based passively cooled NUC. Here is a quote from the article. PCMark 8 provides various usage scenarios (home, creative and work) and offers ways to benchmark both baseline (CPU-only) as well as OpenCL accelerated (CPU + GPU) performance. We benchmarked select PCs for the OpenCL accelerated performance in all three usage scenarios. These scores are heavily influenced by the CPU in the system. It was very surprising to see that the AMD A10 Micro-6700T with unlocked TDP can easily outperform Bay Trail and Braswell-based passively cooled NUCs. In fact, only the much costlier and larger Logic Supply NUCs are able to perform better than the Compulab fitlet-XA10-LAN in the Futuremark benchmarks. Cool stuff. Hope they keep it up!"</post>
   <post id="08b9a229-0ee7-45de-9e5c-dffa235838c7" section="AMD Processors" discussion="Compulab fitlet-XA10-LAN Review: A Fanless AMD UCFF PC for Networking Applications. (AMD vs Intel)">"Yeah, at twice the price of any of it s competitors. So if you want to play games on your router, you re covered The only real angle of this is the quad gigabit. Another comment: Intel Atom quad cores are not hard to find, just depressingly absent from those benchmarks. And without those network ports it has no value over a Core i3 Nuc. Intel NUC NUC5i3RYH, USB 3.0, Supports M.2 SSD card, Intel HD Graphics 5500, 2.5" Drive Support - Newegg.com"</post>
   <post id="36949acd-4d1a-4594-9bb7-8d5602c2331b" section="AMD Processors" discussion="AMD A10-7890K, A10-7860K, and Athlon X4 880K Review">"The crew at LanOC have the AMD A10-7890K, A10-7860K, and Athlon X4 880K strapped to the test bench today. The results were mixed overall, with pricing being a plus and performance versus Intel processors being a minus. About two months ago AMD did a large product line refresh that focused around the newly introduced Wraith Cooler, at the time we took a look at the cooler. Then closer to our LAN event they sent out samples for some of the other CPUs and APUs introduced. In their FM2+ mainstream line they refreshed the Kaveri APUs as well as an Athlon X4 CPU. Well with our LAN event keeping my schedule tied up I’m just now finally getting a chance to see what the new A10-7860K sample and Athlon X4 880K that they sent out a that time."</post>
   <post id="5d6fc70c-761f-4b17-8025-12a911537c3b" section="AMD Processors" discussion="AMD A10-7890K, A10-7860K, and Athlon X4 880K Review">"So nothing has changed then?"</post>
   <post id="b9f1a839-03a7-4da9-b1a1-54072bab591d" section="AMD Processors" discussion="AMD A10-7890K, A10-7860K, and Athlon X4 880K Review">"I think "...performance versus Intel processors being a minus" is quite an understatement... I d like AMD to succeed, but I wonder if they can survive with these numbers."</post>
   <post id="6b32a169-b95f-4506-8bba-2b057397c212" section="AMD Processors" discussion="AMD A10-7890K, A10-7860K, and Athlon X4 880K Review">"Yup, Intel finally is within spitting distance of AMD with Skylake desktop graphics, so they have AMD running scared. The Core i3 6100 should be about 15% slower (10% lower clock, half the L3 cache), so still within kicking distance. And now that Intel s shipping some high-end Pentiums with HD 530, the race is on. Would have been a much better review if 6100 had been involved, and one of these! Intel Pentium G4500 Skylake Dual-Core 3.5 GHz LGA 1151 65W BX80662G4500 Desktop Processor Intel HD Graphics 530 - Newegg.com"</post>
   <post id="51accf52-f221-411f-b9e1-dea704c5b66f" section="AMD Processors" discussion="AMD A10-7890K, A10-7860K, and Athlon X4 880K Review">"Memory: 8GB"</post>
   <post id="ffe76d22-2a9a-4398-86c3-ad8956e9fa95" section="AMD Processors" discussion="Final post on 990FX">"Dear FoXie, It s been a fun ride. You ve served me well over the years, but you just don t cut the mustard any longer. Sky comes tomorrow, and you ll retire to the boxes. Maybe I ll sell you, maybe I ll give you to a friend or my nephew. I would love to say that it s me... but it really isn t. You re the problem. You re so greedy with all of your power requirements. You lied to me when you said you were eight-cores. I should of have known that you being a cheap gal was going to make me regret you. You haven t been a big fan of speed, either. You really are quite slow. I did everything I could to get you to move a little faster! I rubbed you gently until you were buffed like a show car with a mirror finish! I put you under a magnificent water fall, hoping that by keeping you cooler, I could motivate you to move along quicker. You just haven t lived up to my expectations. I know, I know, I should have Googled you more before I bought in, but that s what excitement gets you. On a plus, you have been a really stable partner over the years, and you haven t given me any problems. For that, I thank you. However, now it s time for your blue-haired sister to move in. She s been very impressive, and proven herself quickly. She s fast, cool, and thin. She s extra small in the places that count, and really, what man doesn t like some things to be smaller? Can you really blame me? Her name is Sky, and she s beautiful. She s a little flat on the rear, but oh well. She makes up for everything that you ve been unable to provide me over the years. Again, you ve been a good and stable partner, but I yearn for more. Perhaps one day I ll meet your family again. I hear that Zenah could be interesting to look at. It s time to put you back into your place, remove my tubes from your fittings, and remove my power. Maybe I can find someone new for you. Until then, it s been... ok. P.S. When Sky gets here, and we ve had a proper mert and greet, I m gonna cut her top off and squirt some of my grease on her chest."</post>
   <post id="54146e1d-9754-4439-a4ec-5f2f406c473e" section="AMD Processors" discussion="Final post on 990FX">"HaHa... I know this feeling."</post>
   <post id="88751909-a94a-49e9-99cd-cc8ef2e78d70" section="AMD Processors" discussion="Final post on 990FX">"Wow, best platform breakup written - especially the end. Lol"</post>
   <post id="cd8e748d-8a97-4502-a31a-2f77f0dc1add" section="AMD Processors" discussion="Final post on 990FX">"Thanks I shoulda posted this under GenMay. Perhaps a mod can relocate?"</post>
   <post id="c75f6c80-8d4b-4810-a2bd-c1bea681ccaa" section="AMD Processors" discussion="Final post on 990FX">"haha, nah it s fine here. good write up. I like benchies, so don t forget to post your feelings with your new girl.. =)"</post>
   <post id="f8c6bb6f-d846-42ed-b494-c1b2b97883ef" section="AMD Processors" discussion="Final post on 990FX">"Oh I will! Ripjaws decided to stay in California an extra day, so now I have to wait till Monday to get it all together"</post>
   <post id="bfc6141c-2b98-4f9b-823d-751a9d276cc3" section="AMD Processors" discussion="Final post on 990FX">"Great post! I felt sort of dirty reading it lol"</post>
   <post id="415cf1e9-c05e-4fac-8fa9-503b62f8f3ff" section="AMD Processors" discussion="Final post on 990FX">"Man, 990FX is actually a great platform. I went from 990FX (955BE), to 2500K, to 3750K, to 990FX (8320FX) to 4690K. All using top of the line motherboards like Maximus or Sabertooth. To be honest, there isn t really much difference in day to day or even gaming usage. If I had to do it all over again I would probably be on either the 2500K or the 8320FX."</post>
   <post id="23ef20fd-6291-43e3-8cd8-c89816bd6e07" section="AMD Processors" discussion="Final post on 990FX">"Geforia doesn t get along with Foxie at all. Foxie isn t driven enough to fulfill Geforia s desires for providing the most amazing of play sessions. Not to mention, Foxie just didn t react as well as I thought she would when it came time for water sports."</post>
   <post id="b30828b6-0488-4fdf-b5dc-edcf809fb488" section="AMD Processors" discussion="Final post on 990FX">"Well, hope you are not planning on playing at 4k. FoXiE and Sky are both equal to the task there. I should know, I upgraded and it ended up being anything but at 4k. Oh well, I will continue with Sky since she did not come cheap. Oh, and I have a Kabini coming to serve me some files, it should be great."</post>
   <post id="52af6a49-c830-4779-a478-f3e2d8123ff9" section="AMD Processors" discussion="Final post on 990FX">"No 4K for now. I m not going to return to SLI/crossfire, so I m going see how that pans out for single GPU. I m extremely happy with 1440p. In the mean time, I am making eyes at that 34" curved ultra wide Asus released recently. Susie has very nice curves!"</post>
   <post id="ca88c6f9-2e45-409a-a679-5a7fed56e062" section="AMD Processors" discussion="Final post on 990FX">"alxlwson said: ↑ No 4K for now. I m not going to return to SLI/crossfire, so I m going see how that pans out for single GPU. I m extremely happy with 1440p. In the mean time, I am making eyes at that 34" curved ultra wide Asus released recently. Susie has very nice curves! Click to expand... Not me, I could not resist the 4k way of things. Now, I have a reason over the years to upgrade but, since I got a 980 Ti last December, I will not be getting anything new for at least 2 years from now or more. I like to game but, I do not game enough to worry about maxing everything out immediately."</post>
   <post id="bda14638-ce1c-49f7-8a25-7409874ed28b" section="AMD Processors" discussion="Final post on 990FX">"ManofGod said: ↑ Not me, I could not resist the 4k way of things. Now, I have a reason over the years to upgrade but, since I got a 980 Ti last December, I will not be getting anything new for at least 2 years from now or more. I like to game but, I do not game enough to worry about maxing everything out immediately. Click to expand... Poor, poor ManofGod. I feel sorry for your wallet. Read the article about HDR I linked here."</post>
   <post id="c1b74e21-515f-40a8-b0fa-1add2b25a349" section="AMD Processors" discussion="Final post on 990FX">"cageymaru said: ↑ Poor, poor ManofGod. I feel sorry for your wallet. Read the article about HDR I linked here. Click to expand... Lol! Naw, my wallet is fine but, I am going to get my moneys worth like I did the R9 290 I had before it for 2 years. Have to admit, as far as tech goes though, my heart is with AMD but, I just wanted to try something new. In fact, at least at 4k, the 980Ti is almost twice as fast as the R9 290 reference I had before which is why I bought it. (That and doing crossfire, as fast as it was when I tested it, ran way, way to hot and this was during the winter months."</post>
   <post id="ecd02da9-57d0-45f7-a837-64bc75479c10" section="AMD Processors" discussion="Final post on 990FX">"I m slowly piecing together a custom water loop. Well I have everything as I bought a used kit from the a member here on the forums. I keep seeing cool stuff and adding on. Thinking about getting a second R9 290, but I really want the new H.265 encoding engine on Polaris."</post>
   <post id="3ebca5c6-9874-47bb-85b1-b5b5efe8e2b1" section="AMD Processors" discussion="Final post on 990FX">"I would like to see the H.265 as well."</post>
   <post id="6771b001-1e75-46b1-ba34-0ef91bae50af" section="AMD Processors" discussion="Final post on 990FX">"I know your pain. I wanted AMD cpus to work, I really did. But Since the Phenom II era, it s just not been what I was looking for. I mean they do have their market, I just don t think they are a part of it. I want to believe that the next gen will be better, but we all know better now than to listen to the hype just to get bulldozed."</post>
   <post id="f288de9d-fb24-4fc2-a905-17bb68fc96eb" section="AMD Processors" discussion="Final post on 990FX">"I think Zen is going to be spectacular. There is no other option. They brought Keller back to assist, and then he left, wiping his hands in a "my work here, is finished" kind of way. AMD knew from the onset when they started on Zen that they had to deliver, and deliver big. The engineers sound extremely confident, and we don t hear from those guys, EVER. We know they pulled out all stops for a fresh product. I am very excited for the end of this year. Shit s gonna go down come October, and I m excited for it. At worst case, it s gonna a +/- game at Broadwell level. Thats gonna be enough of a stone in the pond to stir the pot, and get us back to the good ole old days, at least for a year or two. Then tweaks and refreshes come around. Either way about it, the end of this year is going to be exciting."</post>
   <post id="9d4780a8-a885-4622-8c3c-06075a51a07a" section="AMD Processors" discussion="Final post on 990FX">"alxlwson said: ↑ I think Zen is going to be spectacular. There is no other option. They brought Keller back to assist, and then he left, wiping his hands in a "my work here, is finished" kind of way. AMD knew from the onset when they started on Zen that they had to deliver, and deliver big. The engineers sound extremely confident, and we don t hear from those guys, EVER. We know they pulled out all stops for a fresh product. I am very excited for the end of this year. Shit s gonna go down come October, and I m excited for it. At worst case, it s gonna a +/- game at Broadwell level. Thats gonna be enough of a stone in the pond to stir the pot, and get us back to the good ole old days, at least for a year or two. Then tweaks and refreshes come around. Either way about it, the end of this year is going to be exciting. Click to expand... If they can meet or exceed Sandy Bridge IPC (which from the numbers they claim, it very well should) it will be great. That means they are finally back into the same ballpark as Intel. The difference between SB and Skylake isnt really much, which would give AMD a fighting chance with further improvements to IPC."</post>
   <post id="dbcb7164-243c-40fc-a8ae-1404dede42fb" section="AMD Processors" discussion="Final post on 990FX">"Shame on you for ditching an 8 core and not at least getting a 5820k."</post>
   <post id="0dcc08e0-80c2-44ea-be3a-0ee965f0e39a" section="AMD Processors" discussion="Zen hype getting over the hill now">"Call me a flamer, but don t get me wrong because I d be glad if it turned out to be true, but some of this hype from certain sites is getting a bit "over the hill". I just spotted this while reading the news this morning: AMD Zen: A serious Challenge to Intel And it ain t even from WCCFtech. What i like about this one the most, is that they mention Skylake and Kaby Lake is being under threat. Where do these journos get their bloody news?"</post>
   <post id="baadb02a-9599-4f7d-b547-321a4f858617" section="AMD Processors" discussion="Zen hype getting over the hill now">"You re a flamer! I kid, but the article is nothing but blind speculation. We ll all see what AMD has to offer in a few months time. Until then zen is Schrodinger s core."</post>
   <post id="2d938f01-b326-46e8-b591-3eb878a2215c" section="AMD Processors" discussion="Zen hype getting over the hill now">"AMD sure has been quiet about ZEN lately. I ve had a number of AMD processors dating back to the 386-40. The "hype" surrounding the Bulldozer and then Piledriver (I owned the 1090T? at the time) was at fever pitch. When it arrived I bought a 8150, 8350 and 8320. The 8320 OC d is still running in my son-in-law s machine. I remember venturing into the Intel camp with an I5-2500k and, quite frankly, despite the AMD hype over the Bulldozer/Piledriver, once I OC d that 2500k and compared the performance to my OC d Bulldo0zers/Piledrivers, I never looked back at AMD. Since then the journey has been a 3770k, 3930k and my present rigs below 5960x and 4790k. ZEN needs to have that "something really special" to make me take a leap at it."</post>
   <post id="d56e5aab-2dde-432f-8169-2deab86e8d8d" section="AMD Processors" discussion="Zen hype getting over the hill now">"You mean as special as the 3 to 5 percent increase as Intel does every generation If you look at the gap Intel has with AMD then you know that is not going to vanish, call it hype maybe not it is pretty important for AMD , they left AM3+ in the cold soon after Piledriver where they could not see it being profitable platform for them. The original article has a question mark behind it , that the article Url does not reflect so hype ? For AMD this is a giant leap new process new cpu and hopefully new market share"</post>
   <post id="f38c23bd-57a1-4095-9b15-e26b49eb80bc" section="AMD Processors" discussion="Zen hype getting over the hill now">"I don t expect the gap to vanish. What I hope for ZEN is better IPC AND better memory utilization."</post>
   <post id="7d95bee2-a8d8-4b72-8dbb-21200bd1669e" section="AMD Processors" discussion="Zen hype getting over the hill now">"That article reads more like a Christmas Wish List than a reporting of facts. Everyone wants AMD to do well, however based on past performance and overhyped garbage there is no evidence to indicate AMD can hang with Intel."</post>
   <post id="9a615fac-3e16-4423-b2a1-81739c1ac686" section="AMD Processors" discussion="Zen hype getting over the hill now">"Well, in their defense, the title is a QUESTION even though it does not pull the link that way. The only thing I keep finding of interest is this, "A goal AMD claims it has delivered on, promising consumers an astonishing 40 percent increase on instructions per clock (IPC) over its predecessors." Has AMD publicly stated this exactly???"</post>
   <post id="9770bc50-42a3-4f67-b49d-c223a4bb388e" section="AMD Processors" discussion="Zen hype getting over the hill now">"Kyle_Bennett said: ↑ Well, in their defense, the title is a QUESTION even though it does not pull the link that way. The only thing I keep finding of interest is this, "A goal AMD claims it has delivered on, promising consumers an astonishing 40 percent increase on instructions per clock (IPC) over its predecessors." Has AMD publicly stated this exactly??? Click to expand... uh yeah, couple of times even with their appreciated slides =) AMD "Zen" Offers a 40% IPC Increase Over "Excavator" AMD announced that its "Zen" CPU core, will offer a massive 40 percent increase in IPC (instructions per clock) or in other words, performance/clock, over the existing "Excavator" CPU core architecture. Zen will introduce features such as SMT (simultaneous multi-threading), a brand new low-latency cache system, and will leverage the 14 nm FinFET process. Click to expand..."</post>
   <post id="68edecf6-7364-4658-b78a-934961dbf73c" section="AMD Processors" discussion="Zen hype getting over the hill now">"Araxie said: ↑ uh yeah, couple of times even with their appreciated slides =) Click to expand... Thanks, I know I have heard that number batted around for a while now, but that is the first time I have seen that slide. AMD stopped talking to us about CPU a long time ago. Thanks!"</post>
   <post id="96f24243-dcd7-43b8-80b3-799b98c1912b" section="AMD Processors" discussion="Zen hype getting over the hill now">"skline00 said: ↑ I don t expect the gap to vanish. What I hope for ZEN is better IPC AND better memory utilization. Click to expand... On top of IPC somewhere between IvyBridge and Haswell I expect significantly better efficiency compared to the current AM3 CPUs."</post>
   <post id="3827ad09-2919-49aa-9b8b-234ab66f0032" section="AMD Processors" discussion="Zen hype getting over the hill now">"Lisa Su mention the 40% in the end of quarter/year conference call as being on track. So within last few months it still seems to be the talk."</post>
   <post id="087dddad-202c-4f4e-9ad9-4303bb4ca526" section="AMD Processors" discussion="Zen hype getting over the hill now">"drescherjm said: ↑ I expect significantly better efficiency compared to the current AM3 CPUs. Click to expand... Yeah, I have been doing the same thing for a long time now...."</post>
   <post id="de55a21b-f59b-458a-aa24-ba7c2857d93a" section="AMD Processors" discussion="Zen hype getting over the hill now">"When Zen is released, I ll be interested in the 8 core performance figures."</post>
   <post id="1ab6edaf-2334-406f-a576-eb2d56aba970" section="AMD Processors" discussion="Zen hype getting over the hill now">"skline00 said: ↑ When Zen is released, I ll be interested in the 8 core performance figures. Click to expand... If AM4 is truely an 95W platform (and not like AM3+) I would be way more interested in the server version on the quad channel server socket with a higher TDP limit with options to move to 16 core processors in the future."</post>
   <post id="96a56435-97d4-4ac3-bbba-9d19d326aeb2" section="AMD Processors" discussion="Zen hype getting over the hill now">"Kyle_Bennett said: ↑ Well, in their defense, the title is a QUESTION even though it does not pull the link that way. The only thing I keep finding of interest is this, "A goal AMD claims it has delivered on, promising consumers an astonishing 40 percent increase on instructions per clock (IPC) over its predecessors." Has AMD publicly stated this exactly??? Click to expand... TBH I haven t seen a link with an official statement by AMD, only the slideshows. That and Raja mentioning "2.5x" but thats for Polaris. For all we know the slides are shopped, which wouldn t surprise me one little bit. Unfortunately that 40% doesn t close the gap anyway as previously mentioned, the APUs may get them some share back and perhaps laptop makers and tablet makers might show some more interest in them. In reality the mainstream market is the only place they need to compete to stay afloat, not that they have YET but overhyping it like its an enthusiast grade product can go either way when it comes to that crowd, I suspect that the forming of RTG was a way to satisfy the bankers/investors if it goes sour... I might invest in an APU for my daughters first machine, I d prefer that over an Intel solution, but otherwise I ve lost hope in the market for the moment."</post>
   <post id="2881f6f7-5ebb-486f-8d8c-94f50cfc87a9" section="AMD Processors" discussion="Zen hype getting over the hill now">"skline00 said: ↑ When Zen is released, I ll be interested in the 8 core performance figures. Click to expand... I m sure AMD will find a way to pump 220w through 14/16nm XD"</post>
   <post id="b08f0599-e6d7-41dd-9bd3-46ad7edaa7e6" section="AMD Processors" discussion="Zen hype getting over the hill now">"Zen APU is due in 2017 Even tho IPC is important to certain aspects of computing AMD can get away with not closing the gap for gamers both Vulkan and DX12 should work better with more cores rather then higher IPC since new API allow all of the cpu cores talk to the gpu instead of just 1 core at a time. I would like to point out that different gaming engines might handle things differently so there is no generalization for performance... SsmB_92 said: ↑ I m sure AMD will find a way to pump 220w through 14/16nm XD Click to expand... If you overclocked some of the Intel stuff you get there too"</post>
   <post id="8546b245-c557-42ab-8850-ffff938541c9" section="AMD Processors" discussion="Zen hype getting over the hill now">"Pieter3dnow said: ↑ Zen APU is due in 2017 Even tho IPC is important to certain aspects of computing AMD can get away with not closing the gap for gamers both Vulkan and DX12 should work better with more cores rather then higher IPC since new API allow all of the cpu cores talk to the gpu instead of just 1 core at a time. I would like to point out that different gaming engines might handle things differently so there is no generalization for performance... If you overclocked some of the Intel stuff you get there too Click to expand... Sure, my OC d 5960x (4.4 Ghz - 1.33 vcore) is pushing @205W at max"</post>
   <post id="7b2d2571-bec2-4fde-bef0-f37ae51d3e62" section="AMD Processors" discussion="Zen hype getting over the hill now">"Pieter3dnow said: ↑ If you overclocked some of the Intel stuff you get there too Click to expand... Hehe I m pretty sure mine is pulling about that much on just 4 cores atm and thats a 32nm. I reckon it would probably still blitz a current AMD 8 core offering in multithreaded loads. Lol."</post>
   <post id="55039b2d-67ca-4ca0-81aa-759f28d67de0" section="AMD Processors" discussion="Zen hype getting over the hill now">"Look. whether it s a 3930k, 5960x or 8350, OCing is going to ramp up the power usage."</post>
   <post id="7937f3d7-d9e3-4a38-922c-618b95048c85" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"AMD has announced early availability of its new mobile 7th Generation AMD A-Series processors. The new Bristol Ridge processor is fabricated on the 28nm process using Excavator CPU cores with integrated Radeon R5 and R7 graphics. The company claims general performance improvements over its previous generation of processors as well as gains in power efficiency. AMD also boasts a design win with the HP Envy x360 notebook. According to the company, 7th Generation AMD A-Series processors will begin shipping today in volume. AMD today announced early availability of its new mobile 7th Generation AMD A-Series Processors, timed to support an exciting new notebook design by HP Inc. Equipped with advanced video, graphics, performance, and security features designed to boost productivity and enhance the entertainment experience, 7th Generation AMD A-Series Processors (codenamed "Bristol Ridge") also provide outstanding energy efficiency. New OEM PC designs powered by mobile 7th Generation AMD A-Series Processors – from ultrathin notebooks and convertibles to sleek All-in-Ones – will come to market first with HP in the new HP ENVY x360, and with other OEM announcements expected later in the year. AMD will officially introduce 7th Gen A-Series APUs and showcase a wide range of OEM designs at Computex 2016, May 31-June 4, 2016, in Taipei, Taiwan."</post>
   <post id="f2bfb26f-1010-452a-9624-485b8316b10b" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"Reading AMD promotional material reminds me of reading North Korean propaganda."</post>
   <post id="4c51b21a-a3ca-450e-855c-a500c41b412c" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"Steve said: ↑ AMD has announced early availability of its new mobile 7th Generation AMD A-Series processors. The new Bristol Ridge processor is fabricated on the 28nm process using Excavator CPU cores with integrated Radeon R5 and R7 graphics. The company claims general performance improvements over its previous generation of processors as well as gains in power efficiency. AMD also boasts a design win with the HP Envy x360 notebook. According to the company, 7th Generation AMD A-Series processors will begin shipping today in volume. AMD today announced early availability of its new mobile 7th Generation AMD A-Series Processors, timed to support an exciting new notebook design by HP Inc. Equipped with advanced video, graphics, performance, and security features designed to boost productivity and enhance the entertainment experience, 7th Generation AMD A-Series Processors (codenamed "Bristol Ridge") also provide outstanding energy efficiency. New OEM PC designs powered by mobile 7th Generation AMD A-Series Processors – from ultrathin notebooks and convertibles to sleek All-in-Ones – will come to market first with HP in the new HP ENVY x360, and with other OEM announcements expected later in the year. AMD will officially introduce 7th Gen A-Series APUs and showcase a wide range of OEM designs at Computex 2016, May 31-June 4, 2016, in Taipei, Taiwan. Click to expand... PRE-announced. Sort of Pre-Paper Launch or whatever that means"</post>
   <post id="4fa2bbce-2ff3-4951-98aa-6eb14491ef6f" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"I m looking forward to this generation. Primarily because of the convergence of the socket. From two sockets to one for the APU/FX lines, so people have an actual upgrade path. I m running VMs on FX-8320 s, and I m very happy with the proc. I want the next gen too"</post>
   <post id="c4e46b93-bd94-40f0-8052-cb85308ae887" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"Interesting. If AMD do have it working and in products then that s good news that they are on schedule. I wonder if we ll see a hard launch at computex."</post>
   <post id="72a531c4-39bc-4d19-b9f0-2c8a043ba812" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"It looks like AMD is chugging along with updates for its modular CPU designs. In normal times this would be a good sign, but falling sales of PCs makes it kind of moot. These models will be sweeping up scarce crumbs shrinking market share at best."</post>
   <post id="63fdb1b5-fe4b-4da5-93d8-b0ee25829330" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"improved igpu, but light years behind in cpu"</post>
   <post id="668db7a7-50d6-4074-affa-4e8e98c4b6c3" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"Soooo.... Specs? How is this different from Godavari?"</post>
   <post id="faa14820-eff3-479b-acee-187f061fe42f" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"They re finally getting some design wins on systems that aren t complete crap, thanks to their load power consumption improvements on this Carrizo rev (original Carrizo was targeted at reducing idle power to Haswell levels). I m sure now that they have turbo boost working well, the CPU deficit is less of a factor than most people think. Also, they claim impressive improvements on their 15w parts. Also, the main problem with previous builds (single channel ram) should be somewhat alleviated by the DDR4 support. Who Controls the User Experience? AMD’s Carrizo Thoroughly Tested Interested to see a review...although in AMD speak this soft launch means we ll see products on review in nine months"</post>
   <post id="a48a5c35-0eac-44f9-a757-b48dd2d02356" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"This is not Zen, right?"</post>
   <post id="f624d0e8-bfe5-407b-8fc9-e667c41c1cca" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"This is not Zen, right? Click to expand... Correct, the 14/16nm Zen APUs are a year away."</post>
   <post id="efd96693-a0e2-4bcf-b703-ce9ee53a98b1" section="AMD Processors" discussion="AMD Announces Its 7th Generation Bristol Ridge A-Series Processor">"KazeoHin said: ↑ Soooo.... Specs? How is this different from Godavari? Click to expand... It s a major silicon revision of Carrizo. Which is essentially an idle-power/vampire power reduced version of Godavari with HEVC decode added. These idle power reductions are on the same level as those seen with Haswell (Connected Standby), and they make AMD competitive on battery life for the first time in years. And the overall platform power reduction (vampire power) means they have more watts for the APU to work with, and can finally make a non-castrated 15w part. Since they concentrated on just getting connected standby working in the first rev, they ve been able to tease more performance out of the second rev."</post>
<post id="d3dad7a7-c99c-438f-ba6c-18f1707d1404" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review - Today we review the new computer case from Phanteks, the Enthoo EVOLV Mid Tower Chassis. It brings with it full aluminum construction and promises features such as quick release side panels, top mount radiator brackets, a new data drive mounting system, and lots of pretty LEDs in four different colors."</post>
   <post id="f079f137-b945-4b54-938a-ef7872255910" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Are there any handles or hand-holds on that thing at all?"</post>
   <post id="1221199b-138f-4266-8bbe-e13f6c4a9c6c" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"This looks like it s going to be just right for my needs. I ve been looking for a decent case that isn t the size of a house with a bunch of drive bays I don t use for a long time but really want to get a dual radiator set-up in. FT05 was the right size but just wasted as I intended watercooling. Before I pull the trigger would a 360 on top and a 280 at the front fit do you think?"</post>
   <post id="b29451b8-a455-4ad3-8fe5-0678479a2c8c" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Wowy wow. I hated the look of the other Phanteks cases, but this is a thing of beauty. 10/10 would build."</post>
   <post id="60258554-4ea1-4c25-8954-4efa0072b384" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Twisted Kidney said: ↑ Are there any handles or hand-holds on that thing at all? Click to expand... No handles...BUT...as mentioned in the review, you can now lift the case from the top panel and it won t pop off. Just put your fingers under the lip of the top panel in the front and back and lift the case."</post>
   <post id="456c014a-848e-4643-9159-6ab6759d39a6" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Super sexy, I like it! $179 though is kinda high. $89 is the most I have ever spent on a case (Antec Sonata). Nowadays $50 is my limit. My Antec 300 was $50 maybe 4 years ago and it s totally been my favorite bang for the buck case. But it s not sexy."</post>
   <post id="8c4333e4-d77f-45b6-9fa0-1d42fdb39bb5" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Burticus said: ↑ Super sexy, I like it! $179 though is kinda high. $89 is the most I have ever spent on a case (Antec Sonata). Nowadays $50 is my limit. My Antec 300 was $50 maybe 4 years ago and it s totally been my favorite bang for the buck case. But it s not sexy. Click to expand... But this case will last several install while your 50$ are cheaply made, with bad fans (if you change them, you have to include the price of the new ones), bad wire management, etc I don t regret at all the 180$ I ve spent on my Enthoo Luxe. Never had such an awesome case to work with. It s solid, everything can be unscrewed (no rivets woohoo), great cooling (Phanteks fans are very quiet and have good air flow), unbeatable cable management and will last a long time."</post>
   <post id="ca6d8ff2-7005-4e39-a6c6-2e22894f8e54" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"MrPatate said: ↑ But this case will last several install while your 50$ are cheaply made, with bad fans (if you change them, you have to include the price of the new ones), bad wire management, etc I don t regret at all the 180$ I ve spent on my Enthoo Luxe. Never had such an awesome case to work with. It s solid, everything can be unscrewed (no rivets woohoo), great cooling (Phanteks fans are very quiet and have good air flow), unbeatable cable management and will last a long time. Click to expand... I m with you there, my case labs will last a long, long time."</post>
   <post id="199ef903-b4bc-42ad-96f9-f323b7d33c34" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"That s an attractive case."</post>
   <post id="d2353dcc-32d1-4965-aa27-3275b9ecc756" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"I had no idea this was coming, I want it! I ve been trying to find a new case for a while but unfortunately all the ones I m interested are shown off at some trade show or another and never heard from again after that."</post>
   <post id="d87f3104-40b1-454e-8355-018fcfd4c219" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Sorry I m old school and I still require the use of 5.25" bays"</post>
   <post id="c1713bbc-4d84-43eb-90d4-4534ee6d80e3" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Looks like a great case! Just to be clear, no bottom intake fan location? I need a new case, and this one looks pretty good. Have been primarily considering the Fractal Design Define S. Would love to see the [H] S take on that case."</post>
   <post id="64715d90-65cc-48d3-9ce9-8c8484591a7d" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"BlueSaber80 said: ↑ Sorry I m old school and I still require the use of 5.25" bays Click to expand... Nothing wrong with that. We still love you The only thing I currently use my 5.25" bays for is a single fan controller, which I don t even really need. The rest are empty, so I d happily trade them away for a more spacious interior. Heck, I don t even need 3.5" bays anymore. Just give me a couple of 2.5" SSD mounting locations and I m all set. All my storage is on my NAS. No hard drives in any of my non-server builds for almost 5 years."</post>
   <post id="850bbf96-41dd-4180-8dc0-99774e949af0" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"This makes me kinda salty that I bought matx variant"</post>
   <post id="e08cf1f5-e785-49d0-b5e1-cd968a4fc9ea" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Zarathustra[H];1041707635 said: Just to be clear, no bottom intake fan location? Click to expand... That is correct. Zarathustra[H];1041707635 said: I need a new case, and this one looks pretty good. Have been primarily considering the Fractal Design Define S. Click to expand... I ll work on that."</post>
   <post id="e50a88b5-1e77-41da-b8c7-8b81da36d39d" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Iratus said: ↑ This looks like it s going to be just right for my needs. I ve been looking for a decent case that isn t the size of a house with a bunch of drive bays I don t use for a long time but really want to get a dual radiator set-up in. FT05 was the right size but just wasted as I intended watercooling. Before I pull the trigger would a 360 on top and a 280 at the front fit do you think? Click to expand... This video should give you a pretty good idea of what you can do. I m pretty sure you could do a 360 on top and a 280 in front, but you will have to be cognicant of the rad thickness and limiting 3.5in drives. https://www.youtube.com/watch?v=FfLJfP0XyaE"</post>
   <post id="3e385fed-018d-4049-a41f-71ccc7da6354" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Looks pretty sweet. May have to buy 1 for my skylake build."</post>
   <post id="66d36f65-f3af-4d14-97be-f38d25dfd035" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"In the review, there are "GPU cooling" green boxes pictured at the front of the case. Is this implying that these locations can be used with AIO liquid coolers for GPUs, that these locations are close enough that the AIO CPU coolers  hose length works?"</post>
   <post id="dbfa870b-de35-49ee-bb98-ef070cd314c8" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Sludacris7 said: ↑ This video should give you a pretty good idea of what you can do. I m pretty sure you could do a 360 on top and a 280 in front, but you will have to be cognicant of the rad thickness and limiting 3.5in drives. https://www.youtube.com/watch?v=FfLJfP0XyaE Click to expand... I have no idea what that guy is talking about "you can t do them simultaneously" in that video. If you install a 240mm radiator / A-I-O cooler in the top (see this picture) there is a TON of room for a 360mm in the front of the case. The mounting holes for fans / radiators are slotted so there is no reason at all the jam a 240mm (in the top) that far forward in the first place. Momo said: ↑ In the review, there are "GPU cooling" green boxes pictured at the front of the case. Is this implying that these locations can be used with AIO liquid coolers for GPUs, that these locations are close enough that the AIO CPU coolers  hose length works? Click to expand... Yes, that is exactly what it means. If you have an A-I-O cooler with shorter hoses, mount the rad in a push/pull and that will move the unit closer to your GPU."</post>
   <post id="6ef0cd70-399e-47f6-98da-90c19abfb0f5" section="Cases and case modding" discussion="Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review @ [H]">"Great looking case, it moves to the top of my next new case list. Oh, and nice review....."</post>
   <post id="38af20d8-2adf-4df3-8b7b-6a6b938eb416" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Fractal Design Define S Window Mid-Tower Chassis - Fractal Design is known for utilitarian designs that make installing PC hardware easier and keeping it cooler. Its new Define S chassis makes claims enthusiasts will want to see come to true, namely a "layout, providing a perfectly straight airflow path to the CPU heatsink for air cooling set ups or extensive radiator mounting possibilities for water cooling set ups.""</post>
   <post id="247380eb-3099-43c5-b0d2-ed30721cca86" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Thanks for the review, very well put together. Now THAT, is a nice case! I will definitely be getting one for the next build. I really like where the HDD s sit."</post>
   <post id="8b1fa514-76e2-4510-a40e-67b9464ce030" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Love the case! Roomy, quiet, sexy and inexpensive. Looks great on my desk. I just wish the activity light on the front was white instead of blue. I have my light disconnected. Besides that, I m very happy with the overall build quality of the case. You guys think it s difficult replacing the front led?"</post>
   <post id="67997ab0-0b15-431d-9d3e-720ccc3b606f" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Love Fractal cases, but this one isn t for me. Gotta have 5.25 external bays, but for those that don t, this looks like a another winner."</post>
   <post id="487eab39-1319-452f-923e-f7375d15ec66" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"itsGEE! said: ↑ Love the case! Roomy, quiet, sexy and inexpensive. Looks great on my desk. I just wish the activity light on the front was white instead of blue. I have my light disconnected. Besides that, I m very happy with the overall build quality of the case. You guys think it s difficult replacing the front led? Click to expand... (Guide) Fractal Design R4 Power LED Change"</post>
   <post id="627a62ab-b7fd-4ed1-a4e0-6947c1c814c1" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Just a note. On page 5 you mention the Suppressor F51. Are you testing this too?"</post>
   <post id="f483f017-89fd-435a-a48a-a7702f1315b6" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"fwiler1 said: ↑ Just a note. On page 5 you mention the Suppressor F51. Are you testing this too? Click to expand... Typo fixed. That review can be found here"</post>
   <post id="28e4dd55-f128-401c-a5e2-7d4655946c68" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Nice price, real simple case, I like it. There are a few issues, which were mentioned in the review. 1. Filters removing from the back, several companies are doing this and it is annoying. Side/Front removal for filters is much preferred, hard to remove them from the back/bottom when it is sitting on the floor near a wall. 2. Hard drive temps, it would be better for cooling if the vertical stand for the hard drives could be pushed almost to the one side of the case and then mounting the drives on the inside and visible. This would allow air to hit them and provide access to them from one side of the case. Additional SSDs can still go behind the motherboard as they run cooler."</post>
   <post id="4ae030d9-edbc-4faf-8641-3bcbbf864dd4" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Awesome review! lots of options."</post>
   <post id="3062f2f0-0476-447f-a663-48cdbbf1fa0e" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Hey Kyle, I ve been using the Fractal case for the last 2 years on customer builds, only because a place here in Kansas City, a huge PC recycler got several pallets of them in that they bought as slightly damaged. So I ve been picking out the good ones for $30 a case new in the box. These are the highly reviewed original Fractals. Anyways, not mentioned is how hard was it for you guys to remove the plastic covers off the top of the case? I found it super tricky and ended up breaking some of the plastic tabs. One thing about the their first model cases is that they included the magnetic edged mesh cover for the top of the case. They no longer do this. Also, the fans used to snap in, now you have to screw them in. I still like the case but was thinking I might seek out something else since they ve started to cut corners. Did they bring these features back in this case? Thanks for the review. Appreciate it."</post>
   <post id="3af8fda8-29b0-4d2a-90fa-8c4a2ea517d4" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"I recently built in the Fractal R5, which I believe to be a better case for those of us using air or all-in-one water. It has a number of advantages, including a latching main side-panel, the bottom air filter slides out from the front, it can handle a crapton more 3.5" drives, the 3.5" drives are cooled properly, has a dual 5.25" bay, and its front door and side-panel are insulated for better noise absorption. All the 3.5" and 5.25" bays are removable and movable so you can essentially turn it into an S by ripping them out or position them in a ton of different configurations. The R5 is a couple bucks more expensive, of course. But I believe the additional flexibility is worth it. (In case it wasn t clear, I LOVE my fractal R5!) Note the S does have one advantage; the slats/slots in front of the motherboard are designed to easily position custom water loops/reservoirs/etc in that giant empty area. Beyond that, it s an inferior and slightly cheaper version of the R5."</post>
   <post id="f8fb8251-a8dd-4fa9-82a7-07d0d4195435" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Great review! But I dislike this style of HDD mounting, not that I wouldn t give this case a fair shot, I would much rather have a mounting tray and one side to open. I like what they are doing here though."</post>
   <post id="1f886252-7b0b-44e2-997c-34c8ed7aa0ec" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"I own this case and love it... Only issue I had is (like others) with the power led... I found that it leaks ALOT of blue light into the interior of the case... Great if you want blue lighting... I however created a small piece with cardboard that sections that light away leaving the case interior dark and thus better able to utilize my own lighting..."</post>
   <post id="cd8da3b6-ce20-49c0-9a32-d8aaa19910b8" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Love the 2.5 and 3.5 mounting options but would like to see a PSU shroud/cover. I can t be the only one who likes to hide their PSU."</post>
   <post id="00866642-159a-4477-82de-11e4ba1f3500" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Been eyeing this and the s340. I currently have a CM Storm 430 so anything is an upgrade"</post>
   <post id="bdeaaf31-4709-4333-98bc-cb58d5e4c85e" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Looks nice as always from Fractal. Might pick up a Node 202 soon."</post>
   <post id="33f3f3d9-4019-4094-add8-25afaea0513a" section="Cases and case modding" discussion="Fractal Design Define S Window Mid-Tower Chassis @ [H]">"Anyone else have issues with the standoffs stripping the holes that they go into in the case? I can t tighten the mobo screws into the standoff since they keep spinning. I ve contacted Fractal, but assume I could fix this myself if I got longer bolted standoffs and used washers and nuts."</post>
   <post id="013027cb-88a6-4552-9d60-7782f7f56f24" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Thermaltake Core W100 Super Tower Chassis Review - The W100 SUper Tower Chassis is not small and it is not cheap. It even comes fully unassembled. It does however look to fit the needs of the most hardcore water cooling enthusiasts however. The W100 is likely the most versatile case we have ever reviewed in terms of fan and radiator compatibility."</post>
   <post id="b18d0916-f164-4a68-8e49-c53321f75a54" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Your case/psu/mb reviews are always very good, thanks for the effort. FYI, I bought my Phanteks Enthoo EVOLV ATX case based off of your review. Introduction - Phanteks Enthoo EVOLV ATX Mid Tower Chassis Review"</post>
   <post id="25231888-d35b-42a3-b90c-23c7cb707521" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"So how would this compare against CaseLabs?"</post>
   <post id="b868c258-d929-4404-b6ef-63ffb826b66b" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Im a bit underwhelmed for $300. The 5.25" slots for burners are a joke for the install method. It doesnt support SSI EEB mobos, only E-atx. So good luck running a workstation dual cpu setup. 6+ hds, but no backplane or hot swap bays. That is gonna be a nightmare if you were going for a media server route. So for an extra $150-200, you get a case that can fit a massive amount of fans. Do $100 with a 200mm side fan not support 2-3 titans?"</post>
   <post id="42755997-4926-421c-8a5a-0c421c2b5f12" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"my god, it s full of stars and for that price it had better be"</post>
   <post id="b736c0d5-b9e4-421a-919c-d04220b48107" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"reminds me of mountain mods cases. albeit this should have better reach to end user via the distribution channel of thermaltake."</post>
   <post id="bd2ab10d-6e5a-4fa1-8271-2da36634f84f" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"I like it. I really like all that space behind the motherboard tray. I also like what they did with the drive bays and freeing up the front of the case for a radiator. All that space up top, too. Personally, I agree with Steve when he says that he d prefer to mount the drive behind the motherboard tray - all that space is great for cable management but would also be great for disks, and might allow the case to be a bit smaller yet still fit a sick amount of radiators. No removable motherboard tray at this price is a little meh as well, but sheer cavernousness, cavernosity? makes that less of a problem. If I ever see this thing on the FS/FT forum, I might bite."</post>
   <post id="8fc1678e-a88e-46af-b12d-0bc57fae3791" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Be nice to see a model scaled 75-80% of the W100 as this is to big /heavy IMO for most home users ,even water cooled . I actually like you have to assemble it as long as its quality materials. So where s the W80 coming out"</post>
   <post id="54ed2c48-5242-48c2-8efb-2f8dbc7a86f6" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"MADNOD said: ↑ reminds me of mountain mods cases. albeit this should have better reach to end user via the distribution channel of thermaltake. Click to expand... Yar, that s what I was reminded of too. It seems like Thermaltake has a bit of a knack for being  inspired  by other case designs."</post>
   <post id="f4b6e246-6c5c-4623-a65b-1eb19b843feb" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"It looks like it might be possible to use a 360mm rad on top and in front and still use put in a bluray drive, would that be correct?"</post>
   <post id="891c2c86-b628-4974-83bc-7f60d294e9cd" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Way too much effort for the money or performance. No hot swap backplane in a case like that these days is just cheap &amp; lazy."</post>
   <post id="4287881e-8f46-43fe-9169-283dcbac4f29" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"I think it s pretty sweet case. It would fit my current system in it with a breeze and allow for expansion. It should come with fans at least 2 I don t see why they didn t include any. I m ok with the fact you have to assemble it. Don t see why they didn t include disk mounts behind the tray with that much space back there, but that s ok velcro works just fine for SSDs. Motherboard tray fits just about anything. I dunno that case is massive, probably wouldn t even fit under my desk."</post>
   <post id="8165a366-1cae-43d6-a566-98cf93da00e8" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"hmm 329 -- amazing large and versatile case but that s just too much. on sale at amazon for 299.99 free shipping for prime members. http://www.amazon.com/dp/B01C71Q8WS/?tag=pchound-passthrough-20"</post>
   <post id="4258dc2e-f1e1-4846-be5b-d1820ddd693d" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Yeah. Just not what I m looking for. Moderately happy with my Core V9 case though. More flexible..."</post>
   <post id="4b33529b-a1c4-4ec1-89de-53db8de24746" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"That is quite a hefty price for the case and with no case fans included and other points mentioned by other users, it s understandable why there s some negativity regarding this case. This case fills that niche of users who want that amount of customization with all the watercooling possibilities and if the price point was lower, there would be more individuals interested. I currently have a Rosewill Blackhawk Ultra which I purchased years ago and if I was looking for a new full tower case, this would be on my list. That said, I really like the reviews that you guys do here on HardOCP and a majority of my purchases are based on them. Keep up the awesome job."</post>
   <post id="0a9e303d-3442-49ff-b56b-2f3e62f8134b" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"They want me to build the case myself after spending that kind of money? Not gonna happen."</post>
   <post id="e64bd996-288f-42b1-8d72-b69967a6e340" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"I m of the mind that there should be no wasted space in a good, clean build. You would have to REALLY fill this thing up if you wanted to follow that philosophy. Though, I would LOVE to see what someone would do with this thing fully built up with quad CFX or SLI and packed-to-the-nose with 80mm thick radiators with fans in push-pull..."</post>
   <post id="6391fccc-95c1-47b8-838c-92b9375d6ddf" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"give me 5k and i will ;-)"</post>
   <post id="a95fc1ff-8832-47b2-9380-bc914d05e33a" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"However however."</post>
   <post id="da97573f-875f-4e24-a0c0-613fb930df50" section="Cases and case modding" discussion="Thermaltake Core W100 Super Tower Chassis Review @ [H]">"Been waiting for ever for this, at some point I expected to come out disappointed in the case but that wasn t the outcome. Very nice case, I may be buying this soon. Thanks for the great review."</post>
   <post id="297243d6-849d-40a0-94b3-c7ad7f4a0073" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Thermaltake Core P5 Wall-Mounted ATX Chassis Review - The main element that Thermaltake wants you to be able to accomplish with it new Core P5 Chassis, is for you to be able to show off your awesome PC system configuration that you have spent weeks working on so that it is near-perfect. While the P5 checks off more feature boxes than that, it surely does a good job of showing off your rig."</post>
   <post id="450f7ff7-2a8a-4c8b-aca9-154d0e9330ae" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Slightly disappointing but I suppose that is to be expected from an open air case with a distinct lack of airflow."</post>
   <post id="7d4a39b5-35bd-4aaa-893a-02a6fae2b71d" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"I saw one pretty slick build in it the other day. It does look cool...but I bet it ll need constant cleaning. Would be interesting to see a smaller one, like an ITX version."</post>
   <post id="47af8206-c8fe-4c14-91b5-236253370512" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Good looking case, and for specialized hardware, the cost isn t that bad. Disappointing re the lack of simple adapting brackets, as that seems like it would be VERY cheap to offer and a good gesture towards customer support."</post>
   <post id="5ebd377d-482f-47c7-9f21-c736c54733b9" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Squizzles said: ↑ I saw one pretty slick build in it the other day. It does look cool...but I bet it ll need constant cleaning. Would be interesting to see a smaller one, like an ITX version. Click to expand... Lian-Li made a similar but smaller (ITX) wall-mountable, glass-sided case (it looks quite a bit different) called the PC-O5. I think they might be discontinued but you might be able to get one somewhere."</post>
   <post id="00973fa9-3f89-44b1-a410-35d117633e8b" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Pretty cool case! Open air wouldn t fly in my house but pretty cool! I like the PCIe riser option for upright video card mounting."</post>
   <post id="de295947-a3c3-42ff-8598-af24df6ac700" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Quix said: ↑ Lian-Li made a similar but smaller (ITX) wall-mountable, glass-sided case (it looks quite a bit different) called the PC-O5. I think they might be discontinued but you might be able to get one somewhere. Click to expand... They had a whole line. Cool cases. http://www.lian-li.com/en/lian-li-launches-o-series-wall-mountable-chassis/"</post>
   <post id="7f545878-84d1-43c9-80c9-856314bb40d0" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Its an amazing case I ll say, I m really in love with mine:"</post>
   <post id="ac33bad4-64e0-4c07-827b-98c048f3929b" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"FredNotFound404 said: ↑ Its an amazing case I ll say, I m really in love with mine: [/URL] Click to expand... Awesome build! That is just the type of system we had in mind when we said: The Thermaltake Core P5 is a very unique case that gives the end user a great opportunity to flaunt their system building prowess. This chassis truly is a showstopper that turns your PC into a conversation piece and any work space into a showcase for your system build. Click to expand..."</post>
   <post id="b9de78cf-3d89-493b-b929-1c3bfc97ada4" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"FredNotFound404 said: ↑ Its an amazing case I ll say, I m really in love with mine: Click to expand... wow.....thats a very nice build! Was hoping to see a real example You have a more distant picture of how it looks from a room point of view?"</post>
   <post id="10188e5d-7905-4dcc-a01f-72abe8ea29e0" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Quix said: ↑ Lian-Li made a similar but smaller (ITX) wall-mountable, glass-sided case (it looks quite a bit different) called the PC-O5. I think they might be discontinued but you might be able to get one somewhere. Click to expand... Ooh, I had no idea. Well if Lian-li has cases shaped like boats, then they most likely have those."</post>
   <post id="91618bbe-3179-4e04-9ee1-0dd7b75a1056" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"primetime said: ↑ wow.....thats a very nice build! Was hoping to see a real example You have a more distant picture of how it looks from a room point of view? Click to expand... Here you go this is my office. =)"</post>
   <post id="dd2a8b54-47b5-4da8-bc8f-4eb686af1a4e" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Way to expensive for my tastes, but that bracket cable combination turning the graphics card sideways made me do a triple take, it looks so strange / different placed that way. If that cable works, why aren t other case manufactures using it? I can easily see better case layouts for micro itx systems using a cable like that."</post>
   <post id="2a009e2d-09c1-43de-baa7-e141ee300ca5" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"An interesting concept, but I m not sure the coolness factor offsets the extra effort involved in assembly/swapping parts. Not sure I d want to remove from the wall every time to do proper cable routing for a new component, or installing a new cooler bracket. Also, I d think a cat would be looking every which way to exterminate those open fans with extreme prejudice. Nice review, in any case (pun fully intended)."</post>
   <post id="902186f5-4e7d-4ec6-aee0-800286052194" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"FredNotFound404 said: ↑ Here you go this is my office. =) Click to expand... Say, is that a Dell 21+30+21 PLP setup? What monitor arms are you using (links?)? They look awesome."</post>
   <post id="ad6e2767-511b-4226-8de0-d820727d848b" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"More of a rack, less of a case. Niche audience with no pets, small children, or dust."</post>
   <post id="25c76203-7d0b-4181-ac99-abec1e8300d5" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"magoo said: ↑ More of a rack, less of a case. Niche audience with no pets, small children, or dust. Click to expand... Cases really don t stop pets, small children, or dust.....it just hides the truth on the inside. Sorta like a heartless person who only sees the negative of things."</post>
   <post id="e4b83b81-cdb5-4058-9e37-39749edb76a8" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"SpeedyVV said: ↑ Say, is that a Dell 21+30+21 PLP setup? What monitor arms are you using (links?)? They look awesome. Click to expand... yeah it is but the 30" is a crossover not a dell, the 2 20" dell are on some arms I bought few yers ago on amazon, they don t really have a brand, and the 30" is also on a no brand slim wall support, that I bought from amazon."</post>
   <post id="7f9d953a-8332-47c1-bbf2-722a1072d407" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"Excellent article as usual. Throughout I was looking for you to cover the issue of mounting on the wall. And then you did it in the conclusion. Tease! Seriously, though, this does not seem to be a major failing of the case - you don t expect your TV to come with a wall-mounting unit, do you? I would have liked you to go into slightly further detail on this - is that a VESA mount on the back, for instance? The position of the USB ports and power and reset buttons seems a little dubious to me. While they re in the standard place for a standard tower system, they seem awkwardly placed for something that s put on a wall. Would the front USB ports not be better placed on the bottom facing down? And the power and reset buttons better placed in the bottom right corner?"</post>
   <post id="c3a59fce-de6b-46eb-81d1-e2994d470033" section="Cases and case modding" discussion="Thermaltake Core P5 Wall-Mounted ATX Chassis Review @ [H]">"I saw this case at Fry s the other day. Dust is not a problem, just haul it into the backyard once in a while and hose it off with the shop vac, but that Ribbon video card thing... I don t know."</post>
   <post id="b2216fab-4fda-4ea9-a9a7-a35974c2bbbe" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"be quiet! Silent Base 800 Full-Tower Chassis Review - With a company name like be quiet!, you likely know what to somewhat expect. This German company strives to build some of the best designed computer chassis on the market. Its new Silent Base 800 series cases certainly look good on the outside. How does it perform when it comes to being cool and quiet?"</post>
   <post id="586c536e-99e5-4d2a-b729-e2516179c673" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Wow, great case, I think they could have squeezed those HDD s together a bit more but I like this a lot!"</post>
   <post id="b7672637-8ef1-444e-af2d-9e5d97c73726" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Any plans to do the TT W100 case? Fully modular, massive, very very open. Looks like a cool case."</post>
   <post id="893ed06b-25e0-4647-b84e-3b5100bfbf40" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"If be quiet sells replacement parts, you could get a second 3-drive cage and fit ten 3.5" drives in the case."</post>
   <post id="771e2766-3bd7-42eb-8b1a-862da98a1880" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Trimlock said: ↑ Any plans to do the TT W100 case? Fully modular, massive, very very open. Looks like a cool case. Click to expand... We have one here in the review queue."</post>
   <post id="777e4f4c-3d7b-498d-8578-36ae56fae196" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Steve said: ↑ We have one here in the review queue. Click to expand... Well, color me excited!"</post>
   <post id="6d24375b-879d-43c8-892f-f9a81dbbe21f" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Not sure if it was mentioned in the review but the be quiet! Silent Base 800 can come with a see through panel (EU at least) and that one seems to be different in sound dampening , supposedly it is a lot louder. I m happy with my purchase never the less tho"</post>
   <post id="32b91fb9-50d0-4f6a-8f2a-b4d19a647102" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"I had a customers Intel i7 Extreme based machine in with one of these. It is a lovely case. The best made one by far I have seen in well over 20 years. Makes every other case feel like a $30 one."</post>
   <post id="5b8286ec-dd18-466f-b733-accb8a0d12bf" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"This seems like a really nice case. When i first saw it I was about to comment that orange really isn t my thing, but then I saw that there are many color options, and that is great. I like my Corsair 750D Airflow, but if I were shopping today, I might choose this instead."</post>
   <post id="1ba27525-a1a8-4c23-ad77-21be9cc67de6" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Pieter3dnow said: ↑ Not sure if it was mentioned in the review but the be quiet! Silent Base 800 can come with a see through panel (EU at least) and that one seems to be different in sound dampening , supposedly it is a lot louder. I m happy with my purchase never the less tho Click to expand... doesn t surprise me, if you look at the last picture of the door in the exterior page you ll see why having the see through panel would make it loud. it becomes the only exit for any sound from the case."</post>
   <post id="29ab4051-8afa-466d-a134-59e925d013cc" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"Nice review! I ve used Antec Performance One P193 tower cases in the past and they re nice because they re coated with some kind of plastic layer and are very quiet, but they always have weird or poorly designed power buttons. I ve been on the lookout for an equivalent in terms of quiet without the weirdness."</post>
   <post id="a21a6579-1fea-49a1-9547-837eba962f39" section="Cases and case modding" discussion="be quiet! Silent Base 800 Full-Tower Chassis Review @ [H]">"sirmonkey1985 said: ↑ doesn t surprise me, if you look at the last picture of the door in the exterior page you ll see why having the see through panel would make it loud. it becomes the only exit for any sound from the case. Click to expand... Supposedly there are cases which do use the better materials with the see through panel that will make it less noisy."</post>
   <post id="bc6e3ef9-26d3-4906-b5c8-becb8a5d01ed" section="Cases and case modding" discussion="Phanteks Eclipse P400s vs NZXT S340">"Hi, looking for a good budget case that is of good quality, has a side window, has good cable management, uses an open case concept, and looks modern and stylish (not like a transformers of sorts, if you know what I mean. So far I am interested in the following cases: http://www.newegg.ca/Product/Product.aspx?Item=N82E1681...(Computer+Cases+-+ATX+Form)-_-Phanteks+Company-_-11854028 http://www.newegg.ca/Product/Product.aspx?Item=N82E1681...(Computer+Cases+-+ATX+Form)-_-NZXT-_-11146198 I am more interested in the P400s atm, what do you guys think? Any of you got experience with these cases? What are other alternatives in the price range? Btw, I am upgrading from a HAF 912 which I bought back in mid 2011."</post>
   <post id="11353522-ca68-46b3-9bec-1c1c1a7c5d1c" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"I am designing a modular CPU/GPU case system where the CPU case is designed to be as small as possible with the GPU case large enough to hold the beefiest of GPU s. The CPU case (19 by 19 by 6.5cm ) will be powered by a PICO PSU with a Power Brick (12 by 6 by 3.5cm) for portability and will connect via a 90 degree PCI Express Riser card that is built into the case. The GPU case is about 19 cm high, 19 wide, and 36 cm deep and has a straight PCI Express Riser that goes to the top of the case (see Renders) In the renders that you can see I have not yet gone into such detail as to fix the screw holes, or the tabs to fix the PCIE Risers too. It is more to allow me to gather feedback from people. The GPU case will have perforations for a 140mm fan on the front and 140/120mm fan perforations on the side panels for optional watercooling, while the CPU case has room for a low profile CPU cooler (such as Noctua L9i) and a 50mm case fan. Are there any obvious mistakes/concerns or possible tweaks and improvements? Let me know what you think. Any observations are appreciated, cheers. PS: I have not yet found a passable solution for the I/O plate in the back (Will also cut a power connector hole here). I don t want any connectors extruding past the case so had to set the MOBO back but that leaves me with a hole. Any suggestions welcome."</post>
   <post id="87c936ac-8e3e-499a-8109-a7651c7dc0a1" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"I still think it looks like a cartridge console! I like it! I/O is simple. make the cut out the standard size that way the back plate that comes with the mobo can be used."</post>
   <post id="7ba7f62a-32e3-4187-9f37-a2680a4c5aac" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"Will that work even if i have set back the MOBO? Its meant to be a fixed distance from the edge of the mobo too the i/o shield? In my case it would be some distance between the hole in the shield and the actual connector"</post>
   <post id="aa129898-c35f-4fa3-8032-cf336a7cee47" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"yeah you d have to move the mobo back a bit to align with the edge of the case. or make a slight recessed area to attach the I/o shield. otherwise you re left with that gapping hole."</post>
   <post id="65bb609a-3881-46c5-bab3-9bfb42ba8bbe" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"upbeat1 said: ↑ Will that work even if i have set back the MOBO? Its meant to be a fixed distance from the edge of the mobo too the i/o shield? In my case it would be some distance between the hole in the shield and the actual connector Click to expand... What if, instead of cutting a rectangular hole for the IO shield, you left enough material there to bend four tabs inward, and use those tabs to hold the IO shield? Speaking for myself, I wouldn t care too much about the DVI connector sticking out the back of the case, but the PCI-E interface sticking out of the two cases would bother me. A magsafe-like connector with magnets and spring pins might be the answer there, if such a thing exists."</post>
   <post id="5ea6e920-80b6-4089-aaf7-4c1034027f74" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"That will work for two of the sides of the I/O plate (either top and bottom, or right and left), but there isn t enough material in that space to bend it back on all 4 tabs. Unless I misunderstand your suggestion. The PCIE interface would only stick out of the  stationary  GPU enclosure, while it sits flush with the case in the CPU enclosure. But you are right. The entire thing hinges on getting a stable and robust connection between the two cases without the possibility of the CPU case falling over (although with the current design all that would be damaged is a roughly 10 dollar PCIe riser card."</post>
   <post id="6d3584ad-0288-4f9e-9d82-5d3cccc77d38" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"That is a pretty cool concept, I like it! I don t see why you d have to move the mainboard into the case, having it at the back makes the I/O shield work, which is a must with a case that s supposed to be transported, and if you want to protect protruding I/O it would make sense to just extend the side panels past the back edge of the case. There s a few things that aren t really clear yet or could be improved: Mounting tabs for the GPU sticking out like that is ugly, you could use a second straight riser to make them disappear. The base case is unnecessarily large. I understand that it looks better if everything is centred, but I think it would look a lot better if you put the PSU in a different location and made the whole thing narrower What sort of use will the main CPU case see? If you re planning to use an AMD APU to play games at LAN parties, you should look into making it larger to gain space for a better CPU cooler. How will the PSU in the bottom be turned on? ATX PSUs have a signal called PS_ON# that is normally drawn low by the Mainboard to turn the PSU on. You ll either need some sort of switch or a connection from the mainboard to the PSU to make that work. What would be very cool is if you didn t need the power brick when the top case was connected to the bottom one, but that would require quite a significant amount of effort."</post>
   <post id="e6bd57fe-0a0d-4392-a98b-346bc9eda907" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"So this is a standard PCIe slot: so you will need a riser which does not have this and yet somehow secure the two together very precisely. I am not 100% that s (easily) doable."</post>
   <post id="826d6280-7f8c-45ee-a2b0-2c2b6b19cb83" section="Cases and case modding" discussion="Small portable CPU case with home based modular GPU case">"that tab is very easy to remove but I also think a lot of risers and extensions don t have it(see below). the parts are out there for what he wants to do it will take a bit of fiddling to get it all working."</post>
   <post id="f1c6e982-e85f-4a89-b297-47c4c58ddf04" section="Cases and case modding" discussion="ENERMAX Launches The Ostrog ADV LED Gaming Chassis">"ENERMAX, a leading manufacturer of computer hardware products, is thrilled to launch a new mid-tower computer case: Ostrog ADV. Built to be the ultimate LED fortress for gaming systems, Ostrog ADV capitalizes on ENERMAX’s latest innovation, MaxBriteTM LED Technology, to make the chassis stand out vividly from its peers. ENERMAX is constantly pushing the development with cutting edge product designs that feature the latest technologies to help gaming enthusiasts create a personalized look that matches their styles. The most charming feature of Ostrog ADV is the ultra-bright LED strips. Leveraging years of experience and knowledge in developing and manufacturing circular-type LED fans, ENERMAX’s R&amp;D team has successfully utilized the MaxBriteTM LED Technology and Nano Diffusant to create ultra-bright LED effects, delivering consistent and uniform luminance. The incredible smooth and even lighting effect with no visible LED spots makes it hard not to indulge."</post>
   <post id="eaf5441d-7dd1-48b3-aabd-e0d0ecf23f01" section="Cases and case modding" discussion="Looking for Quiet Replacement Fan for Supermicro 45 Bay JBOD Chassis">"Hi, anyone have experience with quiet, efficient and powerful 80mm fans that could be a drop in replacement into Supermicro s fan housing for server chassis? Looking to replace: FAN-0126L4 7 80x80x38 mm 7K RPM Chassis Middle Fan w/ Housing The housing I ll most likely reuse, but I need a quiet fan to replace it with, wondering if someone knows of a good fan. I d have gone the Noctua route, but they only offer fans 25mm wide and I m not sure if that s going to fit into the housing holder/work or be strong enough for this application. Looking for replacement fans for SC847E16-RJBOD1"</post>
   <post id="cd63d6bf-f4cd-46d0-bd0d-279453f618b6" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Greetings and salutations to all the fine folks on the Hard Forum! I’d like to formally introduce myself as your official Fractal Design hardware rep for the North American region. Starting today I’ll be maintaining a regular presence around the forum, offering advice and assistance wherever the opportunity presents itself. If anyone has questions on or needs help with a Fractal Design product, please don’t hesitate to send me a pm and I’ll make sure you’re taken care of. Likewise, if you have any ideas, praise, grievances or other thoughts to share then I’d love to hear it. Customer and community feedback plays a central role in everything we make and do, and as such we hold opinions such as your own in the highest regard. So feel free to reach out anytime, and I’ll be seeing you guys around! Cheers, Fischer Fractal Design North America"</post>
   <post id="aedb6123-29f9-489f-b9bb-d3f8b15695cd" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Welcome to the [H]!"</post>
   <post id="3f391577-0341-4c64-ab9a-1339861fa41c" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Any plans to offer a micro atx version of a Node case in an HTPC friendly format such as the 202 and 605?"</post>
   <post id="ce3f6539-bb46-4c12-b6b1-88946b02fbe7" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Welcome! Do you happen to know if there are any plans for a Define XL R3? Many thanks!"</post>
   <post id="c56710d7-335d-4f68-ae27-1118193cae77" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"KrylonArt said: ↑ Any plans to offer a micro atx version of a Node case in an HTPC friendly format such as the 202 and 605? Click to expand... The Node 605 supports Micro ATX and ATX. I have one with a full ATX board installed in my own home theater setup right now, actually. You might also consider the Node 804. It might not be the traditional shape for going on a shelf or tabletop, but as a floor installation it will blend in just like a high-end subwoofer. It s a personal favorite of mine for having a crazy amount of expansion capacity including support for a dozen drives and three radiators. Camberwell said: ↑ Welcome! Do you happen to know if there are any plans for a Define XL R3? Many thanks! Click to expand... I m not able to comment on unannounced products, so unfortunately I wouldn t be able to say one way or another."</post>
   <post id="67ba0128-f803-47c3-9577-55d7d3411d47" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Is the Fractal Design R5 White window version ever going to go on sale? I never see it below $120. I see all the other cases go on sale but not that one. Like ever"</post>
   <post id="dc664b78-455a-454f-a66b-e8fd4144f031" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Edgar said: ↑ Is the Fractal Design R5 White window version ever going to go on sale? I never see it below $120. I see all the other cases go on sale but not that one. Like ever Click to expand... Both the windowed and non-windowed versions were on promo for $99 and $89 respectively just a few weeks ago at NCIXUS.com. The white versions don t go on special quite as often as the others, but they certainly do get their turns. Just gotta be vigilant."</post>
   <post id="d682e55c-2a8d-4ae7-be17-8a2d8a44bc5d" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Fischer, Glad to see an official Fractal Design presence here at [H]! I have an opinion to share. I bought a Fractal Design XL R2 for a build. I love it. So much so, that I bought a second XL R2 for a second build. That s the first time I bought a second, identical, case. Based on my experiences with those two builds, I have a very short wish list. 1. See Your reviews keep missing... In that thread, I discuss how my Corsair 280mm radiator cannot fully mount on the XL R2 due to hole spacing. (TL;DR: Some 280 radiators have spacing of 140mm, 20mm, 140mm, others have 140mm, 16mm, 140mm. Some cases have both sets of holes. Fractal does not.) 2. The door. PLEASE make it so the door can be swapped to either side...AND that it can be opened 270^ so it can be opened, like Antec does, fully flush to the side of the case. 3. A few more millimeters of space on the backside of the mobo would be appreciated. It s not needed, but it would make it a bit easier to route some of the big connectors and cables back there. Edited to add number 4. The bottom fan filter tray is only accessible from the rear of the case. Having it slide out the FRONT would be an improvement. I love the aesthetics, the quietness, and the quality of these cases. There is plenty of room for all sorts of work on the inside. If you have a prototype which fixes some of the issues I mentioned above, I m willing to test it. Thanks, Ken"</post>
   <post id="736873e9-906c-423c-bc80-be8b2f1cd43d" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Thanks for all the feedback, Ken. I actually ran into the exact same issue with the rad mounting when I built a server in the Define XL R2 a while back, so I know exactly what you re talking about with the spacing not quite lining up on certain models. I can also totally get behind the idea of having more space behind the board and a more flexible door mount with a wider swing. I ll get these added to the R&amp;D wish list."</post>
   <post id="438e982e-1095-44d4-b32e-0f566dcc7c64" section="Cases and case modding" discussion="Fractal Design Official Hardware Rep">"Send me that prototype XL R3, and I ll let you know if it s any good!"</post>
   <post id="ee7cea8f-0bda-4fb6-a75b-31b83f5c0739" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"A very quick question for you guys. I hope someone knows the answer! I want to superglue two pieces of metal together but the metal may get toasty (60-65C). Does standard superglue still hold at those temperatures or will the bond break?"</post>
   <post id="341e2f5c-6f01-4bd9-995c-d3dc73c6f159" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"The melting point of set superglue is 368°F/187°C. No piece of consumer hardware is likely going to reach that temp."</post>
   <post id="e30ece3f-7330-439d-957c-fbc971835987" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"If it were to meet or exceed those temperatures then I would say you have a more important issue to worry about"</post>
   <post id="1e9ed45a-e41e-46d6-8132-cad3f2fbc476" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"undeadxwarlock said: ↑ If it were to meet or exceed those temperatures then I would say you have a more important issue to worry about Click to expand... this"</post>
   <post id="240b81ff-cf0e-41ef-8cc2-52e81a8effeb" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"undeadxwarlock said: ↑ If it were to meet or exceed those temperatures then I would say you have a more important issue to worry about Click to expand... Yes, such as what you are going to use to roast your turkey in for thanksgiving, your computer, or your oven..."</post>
   <post id="62b83f2c-27b8-4630-8724-009dc8038bb7" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"Cool. Guess I know what I ll be cooking my Thanksgiving turkey in. They say smoking silicon adds flavor. Thanks guys."</post>
   <post id="1f223f55-67d8-4946-849b-87aca7801350" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"Hi. I hope you ca help me. I just glued two pieces of metal, with crazy glue, on a espresso machine. It s exactly where the water comes out before passing through the coffe. My question is, is it safe to make coffe and would the heat and hot water realize toxins into the coffee? I run it a couple of times and the glue seems to hold, for now. Thank you in advance."</post>
   <post id="e523da32-9707-451c-aa79-3bc1ab9df1e1" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"Hi. I hope you ca help me. I just glued two pieces of metal, with crazy glue, on a espresso machine. It s exactly where the water comes out before passing through the coffe. My question is, is it safe to make coffe and would the heat and hot water realize toxins into the coffee? I run it a couple of times and the glue seems to hold, for now. Thank you in advance."</post>
   <post id="3dba344a-449e-4b6f-a446-4c7b51eea98a" section="Cases and case modding" discussion="Superglue Temperature Tolerance">"if the super glue package says non-toxic on it then you should be safe, might get a hint of a glue taste though."</post>
   <post id="811dc600-9d8c-4d8d-bfc3-11cb77bbdd1b" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"I am tinkering with the idea of selling my MacBook Pro, now that I m getting a Yoga 260 through work. OSX did nothing for me, and while I loved the hardware, it s 2.5 years old, and it s got 14 cycles on the battery. It just doesn t get used. I m thinking that, if I do this, I d like to build another tower. My previous systems over the past decade have either been Chenbro SR10769 based servers, mini-ITX cubes, or thrown together hodgepodges. The only things I have to put towards a new tower are a 24" monitor, and a couple SSDs. Everything else is starting from scratch. And everything apparently sucks now. I can t find any interesting cases that I hadn t looked at a decade ago, or wouldn t touch in a thousand years. I ve had a TON of cases. Lian Li PC60, PC61, PC65, 7323b, v2000b, PC42 CoolerMaster ATC-111, ATC-111B, ATC-410, Praetorian, Preatorian (black) MountainMods U2-UFO Chenbro SR10769 , Genie, NET, Ultra, Junior But these days? I can t find anything that s simple, refined yet unassuming, and yet not full of glaring flaws (like ports on the opposite side of where I sit, or a window slapped on it). Something like the Lian Li PC-Q10 would be great, but the window ruins it. Silverstone has a case that might fit my needs, but I want something longer than the SG05 chassis I just gave up. And, I d honestly prefer something in aluminum to steel/plastic. I m not opposed to MicroATX, although I ll have a motherboard, 2 sticks of RAM, a 970 (I m guessing), and 2 SSDs. I don t need anything big, I won t be watercooling, overclocking, etc. I just want as minimalist a machine as possible."</post>
   <post id="38da26e8-a213-42b9-ac64-6f6992fb956a" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"NODE Series or DEFINE Series"</post>
   <post id="cefe8e9e-0a58-4d8e-9f77-5321105ac37a" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"maybe you ll like silverstone fortress ftz01 black or alu colour... i have the black one, bought it over the silver one because it works great and is understated (black always works), not flashy at all, and looks very well constructed... in youtube there s this guy that makes some very light "review" but is useful to appreciate the looks of it .... and you can look for minilake skywalker (name of the build) in pcpartpicker ... very nice looking case with pretty good r&amp;d (in my opinion ofc)"</post>
   <post id="b8c42627-52c6-418f-903e-5e59c991bb6b" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"If you want quality, Inwin makes some amazing stuff. Not easiest to build, but great results with effort and looks amazing to boot."</post>
   <post id="c6b63d85-f712-4c32-a62b-1f4c0d297294" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Inwin s V523 was the basis of about 80% of the computers I built for other people. That FTZ01 and Node 202 are very close to what I m looking for, thank you! I d never really thought about a "thin" system, but I see no reason whatsoever that they wouldn t be perfect."</post>
   <post id="1af7cb67-52eb-4219-8e7e-d9cb33808b6e" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"I previously was using a Lian Li PCB-10 which I loved. I just got a Fractal Designs Define S, and out of the box everything seemed great (design, included parts, packaging). However, my mobo standoff brass screws got stripped and I can t even fasten my board down. I never had this problem with Lian Li (had 2 of them prior to this)."</post>
   <post id="70f8a9c8-acc8-4b70-882a-af6c5ad8c269" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Silverstone RVZ02 This has some really thought out points. SFX PSU, but current low-wattage Intel processors and Nvidia GPU s, I don t see an the need for much more than 500W anyway."</post>
   <post id="631524a4-d42a-4834-b335-7bf412e1465f" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"I have the exact opposite preferences. I want more features, customization, windows, etc. A case that stands out and does everything, basically. Ive seen some old-school PCs at places like Goodwill and Salvation Army for super cheap. Maybe hit those up if you have any near you. Garage sales are also super lucrative for old gear."</post>
   <post id="7ae20844-5b5a-4112-aab0-f86289ebcd82" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"NZXT makes some good cases, and phanteks cases are semi plain looking but amazing interiors. was looking at nzxt site. They have some nice minimalist cases. I really wanted a h440 or s340 and would have gotten it if I didn t find the phanteks. heres a couple Looks kinda neat. Manta Matte Black PC Gaming Case - Manta Mini ITX PC Case - NZXT this one I was close to getiing because of price. S340 PC Gaming Case - S340 Computer Case - NZXT The awesome h440, also have a non windowless version. H440 PC Gaming Cases - H440 Computer Gaming Cases - NZXT I really like the case, though I wanted atleast one 5" drive bay."</post>
   <post id="3711ed1a-6136-4de3-8ff2-6acfb9e722ea" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Check out Corsair s Obsidian line. Simple, clean leans, no stupid bling and mostly matte black. I have been using a 550D for 4 years now and it s great. Cools well, quiet and has filters to keep dust out."</post>
   <post id="c8c51252-64c3-49b8-bde7-2722926184cb" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Phanteks Evolv ATX Lian Li PC-A75 (Simple &amp; Elegant) like those old ATC cases you remember. Fractal Design Define Series Corsair Obsidian Series Cooler Master Master Case (Master Case Pro version has window)"</post>
   <post id="ff28cb9d-d149-40ec-b972-40b518acc31c" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"I always go with lian-li. You know they make a million different models, you really can t find one you like?"</post>
   <post id="e4f287de-3733-4e87-a047-733c62478457" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Did a Corsair 350D build last week, mATX with full size PSU and can fit a damn dual GPU card + full WC setup for CPU/GPU in there, not a bad case, fits in a suitcase and you can fit a big ass rad in the top and or front if you really want."</post>
   <post id="c17516e9-cb82-4289-a717-b564d76493b6" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Lets see... Fractal Design, Corsair, Phanteks, NZXT - All of these have a variety of high quality cases for their price ranges, some more so than others but still generally good buys. Of the 4, I place Corsair and Fractal as being superior and closer to what you re seeking. Lian Li, Silverstone - These are often (some, most, all) aluminum and more costly than the above. They have some nice offerings, but I find them often not worth the price anymore because the above offer better prices for very similar/better features and the below are superior for the high-end... Case Labs - If you have the money to spare, CaseLabs offer some of the best cases around. They re notable for being full aluminum, made in the USA with a boutique level of craftsmanship, and most uniquely - are very modular and customizable. You can get parts and accessories for whatever you need for most of their cases. Changing from 120mm to 140mm spaced radiators? Easy. Need to add more HDD/SSD racks? Done. It varies a little bit depending on particular models, but you can customize them as you like from the start, and then just buy the parts you need (including new tops, motherboard drawers, sides etc.. ) if you need to make a change later on. The only downside is the price, but considering what LianLi and Silverstone charge for their high end super towers, its a better use of your money in the $250+ arena. Oh, they recently launched the "Bullet" small form factor cases, made for air or AIO liquid in all board form factors, which are a bit cheaper than their predecessors. If you can afford to do so, this is certainly one of the companies that seems worth supporting; I ll likely be buying my next two cases from them."</post>
   <post id="1c9aa292-3a3f-46c0-9ced-4ad3a8c6a5c6" section="Cases and case modding" discussion="Does anyone still make them like they used to?">"Still got an old battered Coolmaster ATC 110 myself - doors fallen off - it s seen better days. Seriously lacks any of the convenience features and (easy access) filters found in newer cases now (apart from some thumbscrews) I always wanted the Silverstone offerings personally either the FT02 or the RV02-E but never did get one. Those were kind of the successors weren t they? But times have changed and we certainly don t need tons of 3.5" &amp; 5.25" bays now, not with NAS drives around. Video cards will soon get even smaller/cooler, SSDs, etc. I think the Fractal Define R5 / S is closest to what I d like but it s not quite right. Give me a Define R5/S with a 90  rotated layout. Proper aluminium front panel 2-3 x Air Penetrators across the bottom Slot loading optical drive 2 x 3.5" drive bays around the back (like on the Define S) so they don t block the fans as they do on the FT05 2+ 2.5" SSD bays And I d be sold. Could always get the Define S and use an external optical drive I suppose. Not quite willing to lose that yet - but don t want the ugly drive covers on show either - as would be the case with the Corsair 450D, etc. I suppose the rotated board design doesn t have the same appeal it once had now that people are using Corsair liquid coolers on the CPU/GPU - don t like thought of mixing liquid and electric."</post>
   <post id="90e3283b-a2f1-477b-a3c7-3af77a9248ed" section="Cases and case modding" discussion="Case to fit Arctic cooling 120">"Looking for a mid tower atx case that fits the new liquid cooler I bought. I have 4 hard drives, single gtx 760, gigabyte ud3h. Any suggestions?"</post>
   <post id="ee7d5d03-5ec2-4f98-8a54-cd0214ad84fa" section="Cases and case modding" discussion="Case to fit Arctic cooling 120">"How big is the radiator? As long as it s not something massive (over 420mm), the Define R5 s a good all around pick with a huge amount of flexibility in terms of cooling and drive mounts. The proper sound dampening s a big plus too if silence is a priority for you. Full review here if you re interested: Fractal Design Define R5 Review Comes in four different color combinations of black, white, and brushed metal: fractal design define r5 - Newegg.com"</post>
   <post id="a3e671b9-8570-4350-b0b0-7bf66c277850" section="Cases and case modding" discussion="Case to fit Arctic cooling 120">"That s a pretty middle-of-the-road system you describe, and assuming your cooler has a 120mm radiator, basically any case with facility for a 120mm fan either on the back or in the top should work. Most cases have this, these days. Antec, Corsair, Phanteks, Fractal Design, and NZXT all offer options that should work fine for you. Just pick one that appeals to you aesthetically, and you should be covered. This is going to be subjective, so it s hard for us to tell you what the absolute best case is, as that may be determined by what the furniture in your den looks like. If you want a specific recommendation, I really like the look of the NZXT S440. It s a little toward the bigger end of the "mid tower" segment, but it has some nice features, and I like the white color. NEW NZXT H440 STEEL Mid Tower Case. Next Generation 5.25-less Design. Include 4 x 2nd Gen FNv2 Fans, High-End WC support, USB3.0, PWM Fan hub, White/Black - Newegg.com"</post>
   <post id="37c14deb-bb73-4ec6-aea8-a6f937d61c90" section="Cases and case modding" discussion="RIOTORO Prism CR1280 Review">"The crew at Overclockers Club have posted a review of the RIOTORO Prism CR1280 today that is certainly worth checking out. The case has a huge side window and has an RGB function that allows you to change the color of the fans. ”I ll start with what I like about the CR1280. The style - while it doesn t break the standard mold for tower cases, it does have a fresh, clean look, and the large side window does it for me. The layout of the top I/O panel is nice too, with adequate spacing of the USB ports (a typical peeve of mine), the separation of the start and reset buttons (another peeve), and the top-facing angle (no USB drives sticking out to get bent over when you walk by). And then there is the size - the CR1280 can handle an extended ATX (eATX) motherboard, supports liquid cooling and long GPUs, and it has decent hard drive capacity."</post>
   <post id="6db4f070-4fa5-43d1-857e-37b5991c202b" section="Cases and case modding" discussion="RIOTORO Prism CR1280 Review">"The case seems functional. I m still old school when it comes to optical drives. Seems weird to me now to see bay-less cases."</post>
   <post id="3b1928a8-85c0-4f22-8e07-ec6ac1e80955" section="Cases and case modding" discussion="RIOTORO Prism CR1280 Review">"Not bad looking at all. I like the input panel. At the same time, I do still use my PC as a Blu-Ray player and probably will for at least a few more years. I can see many other people not needing that, though. Especially with no sign that dedicated 4K Blu-Ray drives for the PC are on the horizon."</post>
   <post id="f4058ccf-cf67-4011-a2df-e49139e06751" section="Cases and case modding" discussion="RIOTORO Prism CR1280 Review">"I can t stand how all these steel cases have the honeycomb fan exhaust going. I feel like they block a lot of airflow. Lian Li for example all there fan ports are open."</post>
   <post id="d7023ed6-172b-4be0-bbda-4a1fbefd1292" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. I m here again with another project. This time will be participating Thermaltake casemod Invitational Season 1. I ll be using the COREP 5 and the chosen theme this time is the Ant-Man. I hope you like the result. I would love to thank Thermalatake and all the sponsors for the chance to participate in grand event along with excellent casemodders. I ll try to use all my creativity and experience to be able to transpose the maximum my ideas on this project that will start soon. I will thank you in advance to all who will follow this wonderful event. Good luck to all friends and competitors. Theme of project The theme of time is the Ant Man. A Super Marvel series of Hero. Your outfit will be my biggest inspiration for this project. I hope to do a good job with that so incredible character . Specs Case:ThermalTake Core P5 PSU: Thermaltake Toughpower 1250W DPS G RGB Titanium Motherboard: Asus ROG MAXIMUS RANGER VIII GPU: 2 x Asus 980 Matrix CPU: Intel Core i7-6700K SSD: Samsung 850 EVO 2.5 "500GB SSD MEMORY: 4x4G Avexir Blitz RED DDR4 Water Cooling: Thermaltake Components"</post>
   <post id="53725a81-d416-42cc-9232-5db013d35cd3" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. Bow down here today photos Hardware kindly provided by Newegg. Many thanks to ASUS, Intel, Samsung and Avexir !!"</post>
   <post id="359021cd-5fe7-4e2a-915a-9db16d58392c" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. This week I ll post some pictures of the mod progress. I ve tried to make the back of the case like the ANT MAN clothing. I hope you like the result. Many thanks to all the sponsors and followers of this forum. Painting The case"</post>
   <post id="8b3e6bc1-edcc-42b1-a5a8-477dc5ab5f96" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. This week I m with a few more mod progress . They are small changes made to the position of the radiator and the acrylic support base. Many thanks to all who follow this topic."</post>
   <post id="a555a561-499b-49e1-a228-2098f09acf3d" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"It s coming together nicely! Looking forward to seeing the finished build."</post>
   <post id="53e6dc51-b243-49d5-a8fd-0dbce63332ce" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Nice build!!"</post>
   <post id="730057ee-fb29-4146-8766-bc9349df711c" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"WiLLiSTER said: ↑ It s coming together nicely! Looking forward to seeing the finished build. Click to expand... Thank you fro follow this topic. tracer11LB said: ↑ Nice build!! Click to expand... Thank you Hello everyone. This week I m with small updates Mod. I made the assembly of the GPU block and other minor modifications."</post>
   <post id="709b9a4a-748f-4c34-ad98-46cacb960d6c" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. Today I post some more updates to the case. Many thanks to all who follow this topic"</post>
   <post id="48f88171-e50e-4d0f-a7c6-a450ac6db063" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello all. This week I have a few more mod progress photos made this week. Thank you all."</post>
   <post id="e69c5fe1-7f9c-40df-b07c-0d26843876c9" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Hello everyone. Today more I post some work I have done today in case the front acrylic. I hope you like the result Acrilic made By X-Zone !! Thank you !!"</post>
   <post id="fe6a1d10-bbee-49e7-85a6-11b3c883f8e6" section="Cases and case modding" discussion="Thermaltake CoreP 5 ANT-MAN">"Thank you forall . More photos of the mod progress"</post>
   <post id="2c49c7f6-2ef3-40b6-9e57-c295c6036551" section="Cases and case modding" discussion="Installed some Cable Combs">"I ve seen these used on a lot of builds to keep the wires nice and straight but didn t know what they were called. Found out earlier this week what they were called and ordered some for my machine."</post>
   <post id="09026b01-65b2-4337-81f9-3e8677b46bcf" section="Cases and case modding" discussion="Installed some Cable Combs">"Yeah these are great to have for thin or individually-sleeved cables, I printed some out the other day to help manage the mess of USB cables behind my computer at work and it turned out better than I expected."</post>
   <post id="648d40a7-b8c2-41f9-ab9c-2ef38335e47f" section="Cases and case modding" discussion="Installed some Cable Combs">"Whats a good site to order sleeved cables &amp; combs from?"</post>
   <post id="5230d6c1-c595-4584-b7f2-a2ff8a13ea68" section="Cases and case modding" discussion="Installed some Cable Combs">"I ordered the sleeve cable extensions from Amazon, they are Silverstone branded. the cable combs I got from an Ebay vendor, Cable Combs for PC - 24 20 16 14 12 8 6 5 4 Pin - Black White Blue Yellow ATX"</post>
   <post id="116bcdba-f8a6-496d-aac1-eee0ca4d7321" section="Cases and case modding" discussion="Installed some Cable Combs">"Thanks"</post>
   <post id="6bb4df4a-0114-4888-8317-52267850255c" section="Cases and case modding" discussion="Compact, cheap ATX case recommendations">"I ll be upgrading an X58 system to Skylake some time next month. I m looking to migrate the ATX-size board of the X58 into a cheap, compact case to act as a backup. It doesn t need USB 3.0. Anyone have recommendations in the $30 and under range if buying new?"</post>
   <post id="daad32db-6946-4e08-b64f-a222b4ec28ee" section="Cases and case modding" discussion="Compact, cheap ATX case recommendations">"ZALMAN T5 Black ATX Mini Tower or APEX SK-386-C Black ATX Mid Tower my recommendation would be to put just a little more money into than $30 unless you get a good used case for that. anything new in that price is pretty low end. so maybe start at this: Fractal Design Core 2300 Black Steel ATX Mid Tower"</post>
   <post id="bbb8b4c5-a85b-4e57-abfb-472513e2017f" section="Cases and case modding" discussion="Compact, cheap ATX case recommendations">"Yeah the T5 was my first choice. I think it s plenty good for the price. Thanks."</post>
   <post id="53cfacf1-afa6-4601-8224-571a2f25955f" section="Cases and case modding" discussion="Compact, cheap ATX case recommendations">"For $30... nothing you want."</post>
   <post id="420b6a68-56aa-4995-968e-735cc5563914" section="Cases and case modding" discussion="Compact, cheap ATX case recommendations">"silent-circuit said: ↑ For $30... nothing you want. Click to expand... Haha I m sure. I ve never bought a case under $100 unless it was on some fluke sale. But this is just an enclosure for a retired system that may never even see any use again, so it really does not matter. The fact that it even has a USB 3.0 port exceeds my expectations already."</post>
   <post id="62f3d76e-0e1f-4d84-b963-277f028cb7e8" section="Cases and case modding" discussion="Phanteks Eclipse P400S Case Review">"There is a review of the budget friendly Phanteks Eclipse P400S case posted today at ThinkComputers. The case scored high marks for its sleek design, sound dampening properties and roominess. Here s a quote from the full review: Phanteks knows this and has launched the Eclipse series. Right now it is comprised of two cases, the P400 ($69.99) and P400S ($79.99). Today we will be taking a look at the P400S, which is the silent version of the case so it has many sound-dampening features. The case also has room for long graphics cards, water cooling support, easy installation, and lots of room inside."</post>
   <post id="1da1f78b-5ad7-4ed9-906d-4e876efae0a8" section="Cases and case modding" discussion="What is the current go-to site for cables and connectors?">"Not sure if this is the right section, I ve always thought it fell under case modding but it could fit under PSUs as well... Anyways, I ve been out of the loop for a few years and coming back I ve found quite a few things have changed. Last time I was building, MDPC was the go-to place for cable-related goods, but they apparently disappeared. Is there another site that offers similar products? I m specifically looking for cable, pins, pin removers, SATA, PCIe, CPU, and ATX plugs."</post>
   <post id="8a4e3330-ef9e-4a09-95c6-49e265ea9f4e" section="Cases and case modding" discussion="Looking for a case &lt;$50 that will fit a...">"I m using some old spare parts I have lying around to throw a computer together to stick in my (non-home) office so I can stop dragging my laptop around. Doesn t have to be (nor do I expect it to be at that price) an amazing case, just something that works. The thing is, the old parts I have lying around include a Thermalright Ultra 120 heatsink (160.5mm tall) and a Radeon 7970 (reference/stock cooler). Plus an ATX motherboard. Wouldn t mind something that might dampen the noise of the 7970 a little, won t be using it a lot but it ll be nice to have the option for when I get stuck at the office. The case has to be sufficient to cool a 2500k, maybe with a minor OC but nothing fancy. I was considering Corsair Carbide Series SPEC-01 but it doesn t look like it ll fit the Thermalright. A lot of the other cases in that price range look like they might be in the same boat (not only that but quite a few of them look to only fit micro ATX). Was wondering if anyone had any suggestions?"</post>
   <post id="4f73ca6e-70d4-4fbc-9753-0f56c033cd91" section="Cases and case modding" discussion="Looking for a case &lt;$50 that will fit a...">"If you re looking for something basic but sturdy, the Fractal Design Core 2300 is a pretty sweet deal right now on Newegg at $39.99 (reg. $49.99). That s actually what I ve got under my desk here at the office right now. I m naturally going to be a bit biased, but IMHO it s a pretty spiffy looking case for the price. Sale at Newegg: Fractal Design Core 2300 FD-CA-CORE-2300-BL Black Steel ATX Mid Tower Computer Case - Newegg.com Review at eTeknix: Fractal Design Core 2300 Mid-Tower Chassis Review"</post>
<post id="4343c85f-5ad0-4597-9b87-04db28b3ec35" section="Computers and Gadgets" discussion="Guidelines For This Forum - Read BEFORE Posting.">"1) All HardForum rules apply to this sub-forum. 2) NO "I can build it myself for $$$ less!" posts. NO "I priced checked at Newegg/ZipZoomFly/ClubIT/etc and can build it for $$$$ less!" threads. These posts will be deleted and your account will be permanently banned. 3) This forum is for prebuilt, OEM systems that you would buy from companies like Dell or Falcon Northwest. If you are looking for a venue to discuss or recommend home built systems, General Hardware is where you want to be. 4) One thread per purchasing decision. If you re looking to purchase a new pre-built PC, please do not start a new thread each time you find a new builder to choose from. Start one thread, and update it each time you have a question."</post>
   <post id="8867b145-ea47-4d29-bd7b-bd5463a0244f" section="Computers and Gadgets" discussion="Yahoo Weather Widget stopped working after Win updates">"This happened on both my Win7 and Win10 PCs. ESET Smart Security is set correctly the the Windows Firewall is disabled since ESS is running. Any ideas? Miss this widget."</post>
   <post id="e093c3f2-385b-4d40-be3a-1026cc399dff" section="Computers and Gadgets" discussion="Yahoo Weather Widget stopped working after Win updates">"I m having the same problem with my Rainmeter weather widgets. I ve seen quite a few similar problems online, but no solutions, yet."</post>
   <post id="a720c565-3b35-4643-9df9-72b9f6d3aaa8" section="Computers and Gadgets" discussion="Yahoo Weather Widget stopped working after Win updates">"Bummer.."</post>
   <post id="2086ac9d-7bb2-41f0-8509-e868d87844fa" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Remember those steel cases 15 yes ago? Mom s FalconNorthwest Talon finally stopped working and I m looking to reuse that same case with mini-IT case set up. Just need for her Facebook and shopping. Can you guys recommend some parts? Budget: maybe under $500? Thanks"</post>
   <post id="6cd2147c-a55a-4425-99b1-cd1a300a5910" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Did you ask if she prefers silent or is okay with whatever fan noise she has listened to?"</post>
   <post id="d656fc1f-e0a9-42fa-9579-41ccdd882e3c" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"the_servicer said: ↑ Did you ask if she prefers silent or is okay with whatever fan noise she has listened to? Click to expand... She s okay with that tiny fan. If I wasn t tide up this summer, I d bore a 120mm fan to it but, it s for FB and Amazon. She keeps her gaming on the iPad. Thanks for your reply"</post>
   <post id="14cecf3b-a351-49d6-bbd1-05f9b71b12e0" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Someone who actually knows will need to address your actual question. Meanwhile you might just consider starting over."</post>
   <post id="4ec9abad-f9fd-44e2-82d7-82de1db299c9" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"the_servicer said: ↑ Someone who actually knows will need to address your actual question. Meanwhile you might just consider starting over. Click to expand... That d what I was going to do, but, not sure about sizes mobo will fit, hence, considering mini-ITX, which I have zero knowledge"</post>
   <post id="a5f28f33-9206-4362-858f-3b2d5e08d99f" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Try checking the links in his post..."</post>
   <post id="f247b8a6-af5f-4882-bf9c-0e57bb91fff4" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Any chance you can take a picture of the inside of that case? A lot of the Northwest Talon pictures I m seeing are from 2014 and newer. I m not seeing any from 2000 to 2001. With that said, just start over. Look at the_servicer s links. I can t think of a single case, consumer or server wise, from 10+ years ago that s worth reusing."</post>
   <post id="abe8af32-52b3-4187-bcb5-bdf943be8d9d" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Will do. I just need to chase out some dust bunnies"</post>
   <post id="3a310076-1ad9-4d27-aded-f986df5f3a3b" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Took pictures but, not sure why it would not upload. Here are some of the culprits:"</post>
   <post id="c06fb614-1b2a-4771-9d22-2539e9410284" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"CPU cooler I think I ll busy for a few hours."</post>
   <post id="f359a837-8980-407e-a779-b5f90309a94d" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Not working. Need a Chromebook for Mom. Please make a suggestion. She wants a printer too so, it had to be WiFi ready. Thanks"</post>
   <post id="092c5175-abc0-4b19-9eda-6102e579b6da" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Pfft. Why dick with an old, obsolete case at all? If she s just using the PC for general productivity stuff, get her a NUC and be done with it."</post>
   <post id="e4c93b3d-4d6c-4ecf-abe5-674a25d0479f" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Chas said: ↑ Pfft. Why dick with an old, obsolete case at all? If she s just using the PC for general productivity stuff, get her a NUC and be done with it. Click to expand... Can you recommend which nuc and what parts"</post>
   <post id="77cf3e06-384b-4f8f-8136-f55343500f17" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"What do you think of that Zotac unit with this RAM and practically any storage drive? (Please note I have never used it myself.) There was mention of Chromebook but not Chromebox -- something else to consider. I recently saw a refurb ThinkCentre Chromebox on Lenovo Outlet with 4GB RAM at under $120. Some recommend Toshiba Chromebook units but I am less impressed with those than with competing models from Samsung and Lenovo. (I think Toshiba might be going out of business anyway.) Another term to add to your Google searching is "mini-STX". New motherboards that conform to that spec may be more standardized and upgradeable than most NUC units, though slightly larger in physical dimensions. Many Dell OptiPlex units are also physically compact, even with an optical drive, and can be found in Dell Financial s official store on eBay."</post>
   <post id="5e4cdf2b-ff45-44cd-9a5a-5742acbf62aa" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"raygan_gamer2 said: ↑ Can you recommend which nuc and what parts Click to expand... Intel NUC6i3SYK Kit with 6th Generation Intel Core i3 Processor - Newegg.com G.SKILL Ripjaws Series 8GB (2 x 4GB) 260-Pin DDR4 SO-DIMM DDR4 2400 (PC4 19200) Laptop Memory Model F4-2400C16D-8GRS - Newegg.com http://www.newegg.com/Product/Product.aspx?Item=9SIA12K3UA7510 Use the remainder for keyboard, mouse and maybe a display adapter from the NUC s HDMI/Display Port to whatever your mom s current monitor is. Even though it s using an i3 processor that s essentially a mobile CPU, with the SSD and better memory subsystem (not to mention better USB), this system that s only slightly larger than a standard mouse will suck the doors off her old system. Note: One thing I DID forget to include. An OS... This will push it outside your $500 budget unfortunately if you obtain a retail copy. You may be able to pick up a license around the forums here cheaper... But if you ve got a little flex, it s how I d roll with this."</post>
   <post id="fe98f1e7-c3a1-4f91-b086-6401e1ea68a6" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"That case should be nuked from orbit, just to be safe. Just an observation."</post>
   <post id="f511c7b2-a441-45fa-9b32-f0873880e651" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"How likely is it that Windows is required to browse Amazon and Facebook anyway? Chas said: ↑ One thing I DID forget to include. An OS Click to expand..."</post>
   <post id="b262c5ea-6eae-40e7-a320-1ea3926f6d4f" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Well, you COULD load Linux on there. Free. So, technically, it s not required."</post>
   <post id="1e06e587-28de-49c9-a2ec-409b4ab040f2" section="Computers and Gadgets" discussion="13 yr old FalconNorthwest Talon upgrade Help">"Others recommend NUC and that is their privilege. They seem to have too many problems for me to feel comfortable recommending them. (Here s the latest.) Or rather than having more problems, is it possible they simply receive more attention?"</post>
   <post id="6405b632-001b-4d2c-b618-d70dbe37f85f" section="Computers and Gadgets" discussion="External Harddrive Issues">"I have an External Hard drive that I had for a very long time. Today when I plugged it into my computer, I cannot get the access icon to show up on my screen. I haven t dropped it or anything, not does it appear to be damaged in any way. I can hear the motor running inside, and there are two blue LED lights that are normally on at a steady rate. Now they alternately blink once every minute or so and nothing else happens What do you all think the problem may be?"</post>
   <post id="53701007-c956-42ba-a8dc-679304b9242e" section="Computers and Gadgets" discussion="External Harddrive Issues">"What do you all think the problem may be? Click to expand... The drive could have died. The expectation is 4% or so should fail each year. It could also be the power supply of the external or the controller. If the drive is a 3.5 inch model you can try removing it from the external and putting the drive in a desktop PC. Although if it is larger than 2TB you may not be able to read the drive because some externals fake 4K sectors to allow &gt; 2TB drives to work with XP and other OSs that do not support GPT partitions."</post>
   <post id="1b736f6d-7262-4893-8511-ace1dd7ca2a1" section="Computers and Gadgets" discussion="External Harddrive Issues">"drescherjm said: ↑ The drive could have died. The expectation is 4% or so should fail each year. It could also be the power supply of the external or the controller. Click to expand... When I plug it in to the computer, it makes a little "ding" noise to let me know that the computer has made the connection, only the icon wont show on the screen and the LEDS alternate blinking every minute or so. If the power supply was bad, nothing would work at all correct?"</post>
   <post id="16c5daad-24a7-4922-99cc-0954a38e7739" section="Computers and Gadgets" discussion="External Harddrive Issues">"If the power supply was bad, nothing would work at all correct? Click to expand... Power Supply issues are not always as black and white."</post>
   <post id="d331a6d4-1085-4853-b3e9-e94c5dd9f9c5" section="Computers and Gadgets" discussion="External Harddrive Issues">"Also does the drive show up in device manager at all? If so have you tried CrystalDiskInfo?"</post>
   <post id="100554f9-ea5a-428e-bd57-cc9e05ff7b60" section="Computers and Gadgets" discussion="External Harddrive Issues">"drescherjm said: ↑ Also does the drive show up in device manager at all? If so have you tried CrystalDiskInfo? Click to expand... No and No.(not yet anyways) I took a voltage measurement on the Power supply and it seems to be working fine.. I put it up to my ear, and I can hear it running, but its also hear it clicking This makes me wonder, Lets say (by chance) that someone has made telnet access into your computer. I believe that there is a way to obtain the MAC address of any device that is plugged into a port and block access . Is there any way that someone can somehow configure the drive itself so that it will not work in ANY port that its plugged into regardless of where its being plugged into?"</post>
   <post id="8911163c-ac81-40b3-acc0-09a56128f034" section="Computers and Gadgets" discussion="External Harddrive Issues">"but its also hear it clicking Click to expand... This could be a problem with the heads."</post>
   <post id="82d2a674-144c-48d4-8dae-e3452579efc2" section="Computers and Gadgets" discussion="External Harddrive Issues">"Lets say (by chance) that someone has made telnet access into your computer. I believe that there is a way to obtain the MAC address of any device that is plugged into a port and block access . Click to expand... Check your router logs. If possible. Is there any way that someone can somehow configure the drive itself so that it will not work in ANY port that its plugged into regardless of where its being plugged into? Click to expand... I say this is highly unlikely but possible."</post>
   <post id="1a1a0e81-25ab-4221-8177-a7960323093f" section="Computers and Gadgets" discussion="External Harddrive Issues">"I m still scratching my head over this. I haven t the slightest idea what could have caused this to happen. This drive is like almost 5 years old and I have never had a problem with it"</post>
   <post id="9ac620db-d634-4e70-8fa9-c1968093300b" section="Computers and Gadgets" discussion="External Harddrive Issues">"Remember a drive can die at any time, between the shipping before you get the drive or up to its 5 year expected lifetime and beyond. It does not matter if you use it or not. And they need not show any signs that they are going to die. You can leave a working drive unplugged then plug it in and it may not work. This is why you always must backup your important data."</post>
   <post id="f109be55-0ccb-419d-a72c-7b10a8352b32" section="Computers and Gadgets" discussion="External Harddrive Issues">"drescherjm said: ↑ Remember a drive can die at any time, between the shipping before you get the drive or up to its 5 year expected lifetime and beyond. It does not matter if you use it or not. And they need not show any signs that they are going to die. You can leave a working drive unplugged then plug it in and it may not work. This is why you always must backup your important data. Click to expand... Thanks"</post>
   <post id="6eaeea7a-4d81-4709-9846-15bce6dd7889" section="Computers and Gadgets" discussion="External Harddrive Issues">"I ve had a VERY similar issue with several drives in the past. Pretty much identical situation. In one case a drive magically seemed to work after sitting a few weeks, but I couldn t bring myself to trust it with any data. Drives are so cheap these days, why bother messing around with a questionable drive?"</post>
   <post id="f9516e90-7c27-4969-9938-e25b04126124" section="Computers and Gadgets" discussion="External Harddrive Issues">"Try a different usb port and cable. I have an external that didn t like to show up on my computer upon first plug of the usb. I has to plug, unplug, replug (real fast) for things to appear. Otherwise the drive sounds like it s on its way out."</post>
   <post id="4a3caec5-9afa-4ea2-a138-df82236d515f" section="Computers and Gadgets" discussion="PC stalling when powered up">"Win7Pro 32-bit/ ABIT IP35 Pro v1.1 BIOS v.16beta09/ Intel C2D E8400 Batch Q748A223 /Xigmatek HDT-RS1283/ 4GB Corsair CM2X2048-6400C5DHX 5-5-5-18 1.80V ver4.1/ CORSAIR 850AX/ CM Stacker 830SE/ ZALMAN ZM-F3RL 120mm Red LED/120mm Yate Loon D12SL-12 Red LED/ Creative Labs Fatal1ty ProGamer/ MSI R7870/ Dell UltraSharp 2407FPW-HC... The CPU fan is spinning, the case fans turns and stops...try by itself then fails...I m try to remove the rest of the case fans (4) and see if this is a power supply issue. Then try resetting the RAMs...not sure where else to check. Thanks for your help"</post>
   <post id="4f60de85-4cb1-43a1-87b6-b13054a7546e" section="Computers and Gadgets" discussion="PC stalling when powered up">"Looks like a bad PSU"</post>
   <post id="10258144-1ba6-4f86-bd8d-3e3dfe3217dd" section="Computers and Gadgets" discussion="PC stalling when powered up">"letulechuga said: ↑ Looks like a bad PSU Click to expand... Shame...I ll have to find a similar or better PSU at a good price then. Thanks I guess it s time anyway for this PSU"</post>
   <post id="cdff1b8d-b157-48f4-8907-47f14003c1f1" section="Computers and Gadgets" discussion="PC stalling when powered up">"This is a Core 2 era computer, so I d imagine the CMOS battery is gone at this point. It means your memory configurations and such are susceptible to corruption. I would simply try fitting a new battery and shorting the  reset  pins to make sure the motherboard has a chance to reconfigure itself."</post>
   <post id="7fd09bb0-16c7-4732-912e-a74e7b099ce5" section="Computers and Gadgets" discussion="PC stalling when powered up">"michalrz said: ↑ This is a Core 2 era computer, so I d imagine the CMOS battery is gone at this point. It means your memory configurations and such are susceptible to corruption. I would simply try fitting a new battery and shorting the  reset  pins to make sure the motherboard has a chance to reconfigure itself. Click to expand... wow, didn t even considered changing battery...cheapest diagnostic tool. Thanks."</post>
   <post id="267c5655-c1d6-4253-aecc-7a332a63055c" section="Computers and Gadgets" discussion="PC stalling when powered up">"raygan_gamer2 said: ↑ wow, didn t even considered changing battery...cheapest diagnostic tool. Thanks. Click to expand... But, did it work?"</post>
   <post id="289fc85f-ac5d-4b71-bb07-fd6bb247f22e" section="Computers and Gadgets" discussion="PC stalling when powered up">"Reporting back. The changing of battery worked. Thanks a lot"</post>
   <post id="03742fc6-60b9-4055-bbe4-7fa5b90bf4eb" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"Is it possible for a hacker to Telnet into a computer that is powered off and remotely turn it on? If so, how?"</post>
   <post id="691de324-f28e-4d2d-87d4-f7e6578d7a2a" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"No. Not unless you hook up the power switch to an x10 module. Why ask questions? The entire movie is a joke Turn your brain off and enjoy the dream sequence!"</post>
   <post id="0ac2d2de-b35e-4db5-aefa-d414e13beef1" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"It s theoritically possible if the computer in question has IPMI. It s a server thing, though. It s basically a computer within your computer. You hook up a specific network port on the back panel to the switch, setup the IP/netmask in CMOS setup, and then basically you re able to access your server via a HTTP browser and power it on or monitor voltages, see the screen and such."</post>
   <post id="7ab5b218-0a07-4c00-b0e9-1b8fa10ca672" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"If you have your PC setup to wake on LAN, in the BIOS and in Windows, then theoretically they could get the PC to turn on by sending a "magic packet", but that would require them getting the packet to the PC. If you are behind a hardware firewall that would be had to do and usually getting Wake on LAN to work is a huge pain in the butt, and its off by default in most BIOS."</post>
   <post id="b2997b02-2688-4c6d-ae6c-8b0b4d35a6bb" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"It is not"</post>
   <post id="9717bf58-0cae-4cb3-8ce5-141049e678c5" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"Too many requirements for it to be realistically possible."</post>
   <post id="014683df-0916-48b5-b823-97721e14102f" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"Why not?"</post>
   <post id="fe82c0d1-54bd-43c1-aa0d-b422b877f7d5" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"liquidathor said: ↑ Why not? Click to expand... Because read the thread... The only realistic way to power on a PC that s off is Wake on Lan and that s already been covered: 1: It has to be enabled, it s basically never enabled out of the box on modern motherboards. 2: WoL is an ethernet packet so it won t make it past NATboxen, routers or anything like that."</post>
   <post id="a289e382-622e-41ad-88ab-c4e4bf870a4e" section="Computers and Gadgets" discussion="Question about the ability of Hackers">"And you re all forgetting the most important part. Said hacker has to have fairly intimate knowledge of the device existing on your network (he needs to know it s there). The chances of this are essentially "slim to none"."</post>
   <post id="3d524446-f034-478a-be84-bcc7f55390c5" section="Computers and Gadgets" discussion="Wanted some opinions on computer setup">"With my wife going back to school I was looking to consolidate my computers. One option I have is to go with an Alienware 15/17 and when at home use the graphics amplifier for more horsepower. The other option is to just build a mid-range skylake setup. I already sold off my X99 monster desktop so was looking for other options. I guess having the Alienware with graphics amp [already have the gtx 980ti sitting at home] is appealing since I can also game on the go or go to a buddies house. I guess the only 2 reservations I have with this option are price and thoughts that the portability would only come in play 4-5 times a year. Going with the skylake setup obviously would be a cheaper solution, but I loose the versatility. So I come to my Hardforum brethren for some advise."</post>
   <post id="923a1597-8cf3-4b3a-8f86-3bf2680bbbdd" section="Computers and Gadgets" discussion="Wanted some opinions on computer setup">"AthlonXP said: ↑ With my wife going back to school I was looking to consolidate my computers. One option I have is to go with an Alienware 15/17 and when at home use the graphics amplifier for more horsepower. The other option is to just build a mid-range skylake setup. I already sold off my X99 monster desktop so was looking for other options. I guess having the Alienware with graphics amp [already have the gtx 980ti sitting at home] is appealing since I can also game on the go or go to a buddies house. I guess the only 2 reservations I have with this option are price and thoughts that the portability would only come in play 4-5 times a year. Going with the skylake setup obviously would be a cheaper solution, but I loose the versatility. So I come to my Hardforum brethren for some advise. Click to expand... Skylake is probably the best choice for your budget if not a 5 generation or high end 4th generation core i-series with OS guard and all the other new security features. If your a gaming that will improve tremendously coming from an Athlon XP as well, so getting this or a newer AMD equivalent if there is such a thing will definitely be noticable and will improve your gaming experience significantly. All other options like 2011 might be to expensive if you have a low budget too, so consider that as well and that your getting similiar security features for far less being spent. Max Memory shouldn t be to much of a problem either as systems in this range can support plenty at up to 32 GB unless you actually need more then get a 1356 or 2011 i7 or Xeon and if you want it to last a few years longer."</post>
   <post id="30f6e279-7bce-4a01-acb0-51e6e5456b51" section="Computers and Gadgets" discussion="Wanted some opinions on computer setup">"Man I am writing you from Alienware 17 R3, with Gefore GTX 970 and Skylake 6th gen. It is the best notebook I ve ever had for games and work. It s battery holds 4,5 -5 hours."</post>
   <post id="551c4f6d-44af-47f2-befc-4bec1ffd7f9e" section="Computers and Gadgets" discussion="Setting up email for Windows 7">"Does Outlook Express run on Windows 7?"</post>
   <post id="0bc110bf-38f1-478e-a19e-e7d3b3c10d21" section="Computers and Gadgets" discussion="Setting up email for Windows 7">"Starguard said: ↑ Does Outlook Express run on Windows 7? Click to expand... Nevermind. I found it How to Download Outlook Express for Free (and by the way.. its NOT free)"</post>
   <post id="894a918b-0460-488b-85e8-cfe50157ab72" section="Computers and Gadgets" discussion="Setting up email for Windows 7">"Only in mode of compatibility of different hacks"</post>
   <post id="2c68cc87-b1d7-4c2f-9934-ee3891aeec4e" section="Computers and Gadgets" discussion="Need help getting my clock back">"I am running Windows 7. Down in the lower right hand corner of my screen (on the bottom bar) I had a clock that somehow has disappeared and I cant remember how to recover it. Anyone here know how to bring it back?"</post>
   <post id="7aab48ab-f5fc-41d8-8be6-0b97c80847d8" section="Computers and Gadgets" discussion="Need help getting my clock back">"does this work? How to display time/date on bottom task bar windows 7"</post>
   <post id="3875b082-cd6a-4c82-b669-34b9669582a1" section="Computers and Gadgets" discussion="Need help getting my clock back">"Yes it did. Thanks"</post>
   <post id="d590adb3-b613-4a82-b54b-b7b910f6d9b1" section="Computers and Gadgets" discussion="Need help getting my clock back">"I sure read that headline different"</post>
   <post id="c20e508b-a608-4bfb-9ab7-37e923a25943" section="Computers and Gadgets" discussion="Device to monitor temperature, humidity, etc which can send alerts to my phone?">"My IT guy recommended that I get a device to mount in our small server room to monitor temperature, humidity, maybe even snap pictures if someone enters the room, which can be set up to send email or sms alerts. Anyone have suggestions? Edit: I couldn t remember the exact name of the thing which he mentioned but i just stumbled across it... a NetBotz. But it doesn t really look like they re being made anymore."</post>
   <post id="9791d07f-2d16-47ff-ae0b-ccdb23d71c8f" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"Hi. My name is Chase and I am twelve years old. I came here to see if I could get an old computer fan from a Windows 97\98 computer. Here are the specifications: DC 12V DC 0.14A I was wondering how many double or triple A s it would take to power it up to cool down my computer. I will need this because my computer gets pretty hot when I play MineCraft and I need to cool it without having to point the Tower Fan towards it and having to wear a jacket. Also, I am not allowed to use anything that can hook up the the wall. Please reply and help me! I am also building it out of cardboard and putting it under my computer and I hope that will work! Thanks for reading and Helping!"</post>
   <post id="b5599742-8c06-49ea-a219-6d1f20db5c90" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"Any computer fan you get is going to have a small 2, 3, or 4 pin connector on its cable. This plugs in to the motherboard of the computer. You can also get an adapter to make it a 4 pin "molex" plug that can hook up to your computer s power supply if you do not have any open "fan headers" on the motherboard. Since the power supply plugs in to the wall, maybe ask your dad for help? If this is just a fan you found that you intend to use with the computer, it may not work. Still possible, though. You do not want to use batteries -- you will go through a lot of them and they will get expensive very fast."</post>
   <post id="40271f97-83ee-4c88-85e1-57ebdc5904f2" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"silent-circuit said: ↑ Any computer fan you get is going to have a small 2, 3, or 4 pin connector on its cable. This plugs in to the motherboard of the computer. You can also get an adapter to make it a 4 pin "molex" plug that can hook up to your computer s power supply if you do not have any open "fan headers" on the motherboard. Since the power supply plugs in to the wall, maybe ask your dad for help? If this is just a fan you found that you intend to use with the computer, it may not work. Still possible, though. You do not want to use batteries -- you will go through a lot of them and they will get expensive very fast. Click to expand... hey, I wanted to say that I have a laptop but thanks And I have a LOT of rechargables"</post>
   <post id="93017b54-c1e7-4aee-8ad5-2301b5786748" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"I am a nOObie ;-;"</post>
   <post id="08501053-b446-4cb9-bf6a-e7ffd935d550" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"If you have a laptop what you probably want to do is get one of those cooling pads with fans built in that hook up via USB. It sounds like that is what you re trying to do here though, kind of build your own?"</post>
   <post id="cce4d73e-ac1b-41ae-9cc7-2ed8fc92437e" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"silent-circuit said: ↑ If you have a laptop what you probably want to do is get one of those cooling pads with fans built in that hook up via USB. It sounds like that is what you re trying to do here though, kind of build your own? Click to expand... I am building my own, and I did not work at the flea market today so I missed out on $30 :\ I work at a fruit stand and he did not open today. Also, I am trying to occupy my time."</post>
   <post id="a5a9ba64-d834-4b29-ad31-f2019e858632" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"Saw your video. 12v fan, 1.5v (more like 1.45v since it s rechargable) battery assuming it s charged. You need to run quite a few in series. Since it s a 12v fan, you need 8. 1.5v per battery, 1.5x8=12. Ideally you d want 16, two stacks/series of 8 in parallel. This would give you more amp hours (same voltage, more capacity) and let the fan run longer between charges. If "=" is a single AA battery, and other shapes ( "|" "-" "/" "\" ) are connecting wires, with (+) and (-) being where you want to connect the fan wires.... Code:"</post>
   <post id="(-) ----|--========--|---- (+)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="\--========--/" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Something like that." section="##2##" discussion="##3##">"##4##"</post>
   <post id="1aeec960-96e2-4502-a480-6b25d6ef2587" section="Computers and Gadgets" discussion="[Computer Hardware] Computer fan">"I ve run 12V case fans off of basic 7.5V and 9V power adapters. They just ran at slower speeds than when I powered them from higher voltage adapters. I d guess you might be able to get away with running your fans from 9V, so 6 in series. I d go with AA over AAA, but if you have C or D cell rechargeables, I d use those if possible. Assuming they re not just a AA in an adapter sleeve to make it the size of a C or D cell, they ll give you more time between charges. I wouldn t waste non-rechargeable C or D cells, though."</post>
   <post id="2259dcf5-bb20-4881-8396-1d4e6e2419aa" section="Computers and Gadgets" discussion="Need Concept Design For Revised Steam Controller.">"I am a head member of a small group called SCTO. We have been working on a revision for the Steam Controller and have come up with the additions that we want to be included in the revision. We need someone who will design the controller based on our input. We are all working on this idea voluntarily and would like whoever is willing to design the controller to understand that we will not be able to provide compensation until we turn a profit. We are still discussing the percentages, but we promise compensation for the final sketch. Our immediate goal is to create a working prototype within the next 30 days. Any additional inputs or concerns that you may have can be sent to a link that I will send you after you can verify your participation with the project. Extra details will be provided after verification as well. Thank You, SCTO"</post>
   <post id="debe0b24-ffa1-4517-9be7-2bb5df3446ad" section="Computers and Gadgets" discussion="HTC Vive Pre shipping in April for $799">"So, the cat s out of the bag. Pre-orders begin on February 29th for $799 and include the HMD, two controllers, two lighthouse sensors and two games (Job Simulator and Fantastic Contraption). It seems they ve also added Bluetooth integration for phones so that you can take calls while in VR.... Like I m really going to bother answering a phone while in VR. Ha! Anyway, I ve already got the Rift CV1 on order. Now considering ordering the Vive Pre as well and then simply selling the one I like less at a small loss, if any due to the demand/buzz. I still think the Oculus is going to be the overall winner, but hardware wise, they are pretty evenly matched. (I doubt the Touch controllers will arrive at more than a $200-$250 add-on, and to be honest, for what I want to do, I have my HOTAS setup and a Leap Motion controller.) Kyle_Bennett I think it s about time to add some dedicated [H]ard|Ware sub-forums to [H] for VR! I m thinking that VR is going to take off like crazy this year - especially where gaming is concerned."</post>
   <post id="82da11b4-c8bb-4777-9215-1bcc0dd988e0" section="Computers and Gadgets" discussion="HTC Vive Pre shipping in April for $799">"I was "meh" about VR and all that stuff, until like a few days ago when I suddenly got excited (probably because I got some money over, lol). Now I m thinking about picking up one of them. I can t really decide which one. Hardware wise both seem fine, but HTC Vive is partnered with Steam, which is a rather powerful ally. Oculus looks nicer though, but I read it s more for a stationary gamer, while Vive is if you want to move (and requres a bigger room). Kinda hard to decide..."</post>
   <post id="9fcdfe1b-1fcc-48a7-b71c-0e5eb80af47f" section="Computers and Gadgets" discussion="HTC Vive Pre shipping in April for $799">"Yes, they both are fairly evenly matched - from what I ve researched it seems the Rift has a very slight edge in display quality (better lenses perhaps) and the HMD is a bit lighter and slightly more ergonomic, with a more comfortable fit. But overall, it seems a pretty close toss up. I like the design of the Touch controllers better, but they won t be out until mid-summer at the earliest and will probably run an extra $200-250 with the extra tracking camera, whereas the Vive Pre will be complete with controllers and the two tracking sensors right from the get go. I plan to simply get both. Evaluate them, keeping the one I like better based on the HMD s performance and comfort... Should be able to offload the other without much loss if any due to demand once the hype peaks and supply dries up. As to the stationary vs. room VR, what I am reading is that once equipped with the Touch controllers and the extra tracking cameras, the Rift does room VR as well. It just isn t starting out that way from the get go."</post>
   <post id="26216aab-0017-4297-8865-4aef1ec1a30b" section="Computers and Gadgets" discussion="HTC Vive Pre shipping in April for $799">"Got my Vive pre-order in as well now! Have both the Oculus Rift and the HTC Vive pre-ordered - both with an expected April delivery date. Will do a side by side comparison/evaluation for all my fellow [H] s once I get them and have had a chance to play with them for a bit."</post>
   <post id="5fe70ecc-de07-4a93-9531-4f25596c91a3" section="Computers and Gadgets" discussion="HTC Vive Pre shipping in April for $799">"Yeah. I saw the comparison video on Verge."</post>
   <post id="107faa05-98f8-413c-84fc-57e21798e68b" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"Looking for an i7 Quad Core Laptop under 13.3" Is this even a possibility?"</post>
   <post id="168917c6-8b4b-48c4-b278-0affa84393f6" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"Surface Pro 3 or 4? *I guess those aren t really quad core, they re dual core with HT"</post>
   <post id="e7c56d52-72b6-46e8-b4ab-4a47f1b6d7ca" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"cortexodus said: ↑ Surface Pro 3 or 4? *I guess those aren t really quad core, they re dual core with HT Click to expand... Yep, they do not fit what I m looking for."</post>
   <post id="7ebb4659-bd5e-4b14-abe7-8e00c3716755" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"Looks like your options are slim. MSI GS30 (open box, no longer made) http://www.newegg.com/Product/Product.aspx?Item=N82E16834152736R Same one but new: http://www.adorama.com/MSIGS30SHA45.html and this "Aorus X3 Plus" whatever that is... http://www.newegg.com/Product/Product.aspx?Item=9SIA25V31M6859"</post>
   <post id="2722b47d-28db-4473-9586-5e8caa275af5" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"I just asked a similar question a few days ago. In my case I was asking for a device WITHOUT discrete graphics. Anyway, yee245 linked me to this video: https://youtu.be/XbowuAFbslI?t=2m58s If this ever becomes a thing, which I seriously hope."</post>
   <post id="ba548f77-6130-4a7e-b3bb-7be90c2e6091" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"If I wanted a small workhorse I would go for one of these: http://pro-star.com/index.php?r=product/detail&amp;model=N155RF http://pro-star.com/index.php?r=product/detail&amp;model=P643RE-S They are rebranded Clevo laptop models. The genericness might worry you, but pro-star support is terrific, and Clevo build quality is comparable to MSI laptops imo, maybe a bit behind. Ask if they re loud though. That first model ran a hotter card, the gtx 765M, and was loud. I think they fixed that though in later models. But ask. That open box MSI is a good find. I saw the Aurus s recently and I m surprised they actually made it to market lol"</post>
   <post id="dc473f88-1e00-401b-a6ec-fbe0afb768bc" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"maybe this too http://pro-star.com/index.php?r=product/detail&amp;model=N240JU"</post>
   <post id="ae935d92-5b5f-4bd5-8c46-1bd1a7cb6045" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"http://www.xoticpc.com/msi-gs30-shadow045-p-8034.html MSI 13.3" w/Iris Pro Bumping up the size to 14 gives you a bit more options: http://www.xoticpc.com/custom-gamin...der=price&amp;size=15&amp;p=clear&amp;processorseries=123 I was in the same boat looking for a SFF laptop w/just a quad, but ive decided to stick to a thin profile 15inch w/dedicated gpu."</post>
   <post id="d7a4303c-9080-4f7f-b8fe-da986a494cc4" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"dell 7000 series would be a good option"</post>
   <post id="7f4ceee7-2d9a-48fd-a86c-31bac12cc6cf" section="Computers and Gadgets" discussion="Looking for an i7 Quad Core Laptop under 13.3&quot;">"Dell XPS?"</post>
   <post id="ff2c871a-6a18-493f-99f3-fc6aecefaabc" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Hi! If there are threads about this I am cool to get some links. I was just wondering what apps people are running to get the most out of the lcd display. Regards"</post>
   <post id="b1f484b1-1a1e-45c6-9f07-12ef77de9419" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Riva Tuner was the most useful for me (CPU TEMPS, GPU TEMPS, CPU LOAD, GPUs LOAD, Memory usage, Video Memory Usage)."</post>
   <post id="1b309ddd-6e62-4342-aac6-bce4f68862dd" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Yeah I use evga precision but have never done anything for games for example...I am pretty much wasting my G15 right now LOL"</post>
   <post id="95579536-74f5-4d31-8c89-b3de29158d03" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"I like the built in BF2 app, typically I just have the time and performance monitors."</post>
   <post id="7648a9d6-cbf2-40aa-ac38-a246b103588b" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"I will run Vent when Im playing to see whos talking and the app for whatever game Im playing."</post>
   <post id="ca687953-3063-4c5f-9b28-ded5fe3cf944" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Vent, Rivatuner, World of Warcraft s stock gui. There was a really good temp monitor out there that I really loved. Told me my fan speed and supported my multi-zone thermometer. Since the fan controller and thermometer went tits up, its just not been the same."</post>
   <post id="b34569ec-6784-475c-9205-b0949e21bf8e" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Everest displays a wealth of information on the LCD...you pic what you want, and display it just like you want...I monitor selected cpu and gpu stats. Also use it for music. ."</post>
   <post id="fadf0f2f-6850-4524-8e31-fdc5995a8de3" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"i like vent, its cool the display is pointless IMO, anythign i need is on my second screen, i love the keyboard though"</post>
   <post id="b3c120c7-bc05-4d88-8d16-84c837e90162" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"P!rate said: ↑ i like vent, its cool the display is pointless IMO, anythign i need is on my second screen, i love the keyboard though Click to expand... Same here. There are a few games i play that work with it but in most cases most of my stuff is on my second screen. Hell a better question would be what to do with the g keys in a fps?"</post>
   <post id="a7cd10c3-0a92-4124-9503-a230223f781b" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"check out lcdsirreal great app... along the same lines, if you feel like wasting more than a few hours, check out lcdstudio, which can plug into alot of the other programs listed here (riva and rain meter i beleave, its been some time since i messed with it) to give you customizability beyond what these app s are capable of on thier own."</post>
   <post id="d2ba4b9c-7f1d-44d9-ada3-3d550bacf63c" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Ender1183 said: ↑ Same here. There are a few games i play that work with it but in most cases most of my stuff is on my second screen. Hell a better question would be what to do with the g keys in a fps? Click to expand... i map them to help requests and such... say BF1942...  need less people in the air, more in tanks" or... "you suck at sniping, grab a bazooka" ect, or in say UT on capture the flag maps, mapped as G2"incoming north"-G5"incoming south" ect. in WoW ill set up G7 G8 and G9 as, /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes /y tomatoes and spam it during a raid on a city once we have been found out. keeps the other side from forming a raid, and communicating via chat, it dosent totally stop them, but it helps."</post>
   <post id="fa02edae-bb62-49b4-ba94-0217cb0e5b92" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"I use Everest on my G19. Its been pretty cool. I haven t used the built in apps since i started using it. My trial version is up though. I ll buy the full version when i rebuild. When i had my G15, all i used it for was just the clock. The only game I had that supported it was FEAR 2 and even then all my info was already displayed on screen."</post>
   <post id="3baf1113-9874-4970-b1c4-4227c6efc404" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Rivatuner and the used app I use is G15Netspeed http://www.g15mods.com/mods.html"</post>
   <post id="9be129a2-634d-458e-b363-1fb02cbff189" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"Checking some of this stuff out guys. Yeah I am not using the G keys either...that is why I am like, wth I bought this for if I am not going to use it! LOL"</post>
   <post id="b488e7d7-bded-4858-af88-e0d860a17042" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"LCD SirReal"</post>
   <post id="608ba412-9c3e-42ae-8e34-1895d475cd0d" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"shaolin95 said: ↑ Checking some of this stuff out guys. Yeah I am not using the G keys either...that is why I am like, wth I bought this for if I am not going to use it! LOL Click to expand... This, LOL, and I just bought the Razer Naga mouse, so I guess more buttons=win?"</post>
   <post id="9c5f2b44-b582-4e94-a101-5f3783495880" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"I m using Core Temp, ATI info from the link above, and FRAPS."</post>
   <post id="6feab21c-f3ce-4413-9aba-dd59fd817635" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"LCD Sir Real is all I used when I still used my G15!"</post>
   <post id="33b22527-50f4-4419-8208-a68c08d74d57" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"lol i dont use the lcd for anything except to see what song is playing (easier then waiting for it start so i can hear what it is - good for when playing a game) for the g keys i use them for quick commands in css. like rebuy. different weapon sets. also use them for shortcuts to calculator and media player."</post>
   <post id="1704a526-2b2d-41ee-8d59-1a37c67d02a3" section="Computers and Gadgets" discussion="Logitech G15 users..what apps do you run on your LCD?">"i only run Coretemp in my display its a handy program that shows me the cpu load and the temp of each core."</post>
   <post id="0e5c3808-2304-41f7-9f51-f5366561b9bc" section="Computers and Gadgets" discussion="Steam Stream Server Spec Question">"I recently decided to setup a dedicated computer to run Steam stream. I had an older HTPC setup that I added a GTX 970 to and so far so good, but I am curious if I will run into a bottleneck based on the CPU and memory I have running in the box. The box is running an Intel i3-2105 with 4GB of RAM I presume the majority of the required horsepower is being provided by the video card, but wanted some feedback."</post>
   <post id="0e8dba53-9673-458a-b25f-5134ba70c7f5" section="Computers and Gadgets" discussion="Steam Stream Server Spec Question">"Really depends on the game, Steam will use NVENC to do streaming so the video encoding gets largely handled by the video card. But on some games or if it doesn t work on one particular game that processor will be a serious bottleneck."</post>
   <post id="085869b2-ea09-4cf5-b4e4-51f19db58855" section="Computers and Gadgets" discussion="Steam Stream Server Spec Question">"So looking at a new i5 may be a good idea then, to have a broader level of support for games?"</post>
   <post id="23db9746-33b8-4fb1-9078-22af04fdc533" section="Computers and Gadgets" discussion="Steam Stream Server Spec Question">"I can t tell if you re streaming from or to the "older HTPC". If it s too, then that should be plenty - you can always show the statistics to see how things are going. I stream from my desktop to an E-350 APU box - no discrete GPU at all. If this can handle it fine, I sure hope an i3 w/ a 970 would... If you re streaming from, then it s really game dependent - some folks might think an i3-2105 won t be enough to play locally, let alone stream."</post>
   <post id="054cb2bb-fee7-45f5-9e75-c547bc72100a" section="Computers and Gadgets" discussion="Inexpensive Laptop Selection Assistance!">"Hey all, So my Fiance has started dropping hints that she could really use a laptop and since I handle the IT in the house, I ve started looking around. We are trying to save up for a down payment on a house, so this can t be something expensive, and she knows that too (she s been looking at the Groupon Goods deals in the $200-300 range and sending me links). I ve been looking through those listings too, but it s been an exercise in frustration, as I can t seem to find what I am looking for. Her requirements: 13" or 15" class Not too heavy/thick My requirements: Absolutely must have upgradeable RAM and replaceable 2.5" drives Must have 802.11ac WiFi. My thoughts are this. I have zippy 2.5" SSD s I m not using I want to apply to make her happier with the speed of the laptop. Since I already have these drives, and low cost is the interest here, I have no interest in models replaceable eMLC or M.2 drives. It s 2.5" sata or bust. I guess I d be OK with soldered on RAM in a pinch, if there were at least 4GB of it, but I really hate that, and would prefer to have long term upgrade-ability in mind. the 802.11ac is a requirement as I don t want the laptop to sabotage the house wifi by dropping it down in speed. CPU power is not a huge deal within reason. I d prefer to not get an Atom, but anything above that, I d be OK with. I have no issue at all with hacking a Chromebook if I need to, as long as it meets the rest of the requirements. So, my issue is this. All the laptops I seem to be finding are either thicker/heavier higher powered models with 2.5" SATA drives and replaceable RAM, OR thinner, lighter models with soldered on flash storage and RAM. Older Ultrabooks/netbooks and chromebooks used to have 2.5" drives and replaceable RAM, but these days everything thin seems to be consumer-deviceified. Are any of you aware of any that still are made this way, and won t break the bank? To sum it up, looking for: 13" to 15" class Ultrabook / netbook / chromebook type thickness/weight (I m fine with hacking a chromebook) Screen resolution at least 1366x768 CPU power not a major issue. I d take AMD or Intel, as long as its not a Atom type weak deal. Replaceable RAM Replaceable 2.5" storage 802.11ac $350 max Is this a possibility, or am I dreaming?"</post>
   <post id="9c5fb65a-7cd1-4c1d-8d97-973954ddc979" section="Computers and Gadgets" discussion="Inexpensive Laptop Selection Assistance!">"Hmm. So I ve been poking around and thinking. I ve always thought very highly of Dells enterprise Latitude laptops. I could pick up a Dell certified remanufactured like-new Latitude E6430s, pop in the SSD, replace the WLAN card with an 802.11ac capable model. This would meet all of the requirements, except it would probably be a little thicker and heavier than she had in mind. Still, very solid hardware though. To me it feels like just yesterday these things were new, but apparently that was 2012. That s 4 years ago now. I wonder if $275 for a 2012 laptop (albeit a great 2012 laptop) is silly at this point..."</post>
   <post id="459afb9d-2855-4fe9-a6c0-f98f386623da" section="Computers and Gadgets" discussion="Inexpensive Laptop Selection Assistance!">"Not long ago I set a friend up with a 6330 that I tweaked in a similar fashion as what you mention. It was indeed bulky, especially with the extended battery protruding from the back. The 1366x768 display was poor but they didn t seem to mind, and in every other respect it was a killer laptop for their needs. The upside of all that bulk? It s since been dropped and abused without any issues."</post>
   <post id="4053d6eb-b9f2-493c-9fed-92b71aa2b2f5" section="Computers and Gadgets" discussion="Inexpensive Laptop Selection Assistance!">"project86 said: ↑ Not long ago I set a friend up with a 6330 that I tweaked in a similar fashion as what you mention. It was indeed bulky, especially with the extended battery protruding from the back. The 1366x768 display was poor but they didn t seem to mind, and in every other respect it was a killer laptop for their needs. The upside of all that bulk? It s since been dropped and abused without any issues. Click to expand... I wound up pulling the trigger on the 6430s. The 14" 1366x768 screen could be higher resolution, but for work I find that the more muted colors and matte display work better than many of the newer more vibrant and shiny models. Factory refurbished 14" Latitude e6430s w. i5-3320m (Ivy Bridge dual core, HT, base 2.6Ghz. turbo 3.3ghz) and a single 4GB module: $260 Samsung 840 Pro SSD from my leftover parts bin in the basement: $0 Extra 4GB DDR3 Sodimm for a total of 8GB: $20 Intel 7260 802.11AC WLAN Card: $25 Total Cost: $305 That is cheaper than most Chromebooks, and a hell of a lot faster and sturdier too. She seems happy with it. I m sure she wouldn t mind it being thinner and lighter, but at this price I don t think we could have done any better overall! Personally, for my own needs, I would probably have gone this route even if it were double the price."</post>
   <post id="a32c1f5a-c73e-4a52-a547-022b201d49e0" section="Computers and Gadgets" discussion="Inexpensive Laptop Selection Assistance!">"Just be aware that factory refurbs often don t come with the best life from the included battery, so you may have to pay for a replacement. And don t forget that Haswell basically increased battery life by 50%, so don t expect miracles from Ivy Bridge. But if all she wants is a laptop to use around the house and mostly keep tethered to a wall, it should be a winner."</post>
   <post id="3ff48514-dcaa-4c66-8056-91e4835d4db9" section="Computers and Gadgets" discussion="Best Bass headphones">"Hi...everyone, which one of your pick in best bass headphone category - NAD - VISO HP50, Beyerdynamic T51i, HIFIMAN HE400S and PHILIPS X2/27 Fidelio..in under $300 category.? Thanx"</post>
   <post id="1ca5647c-f15f-41de-8eb2-de5391a8ea5e" section="Computers and Gadgets" discussion="Best Bass headphones">"Everyone says Bayerdynamics tend to be bass heavy without being shit from what I ve seen, so that s the route I d go."</post>
   <post id="b5eff14c-56e9-4ca9-b66c-9d344b9dc2ac" section="Computers and Gadgets" discussion="Best Bass headphones">"yep..that s pretty close to my observation..how about Hi-Fi Man.?..thanxx"</post>
   <post id="b01b7fde-756b-4036-b7ac-2e08e52f4a04" section="Computers and Gadgets" discussion="Best Bass headphones">"just bought some Denon AH-D600 s and they are bassy and sound great. They used to be $400+ but they were recently discontinued and I got a new pair for $279. Beyerdynamics are good but you also need a good headphone amp to drive most of their headphones."</post>
   <post id="4ab4546b-a6b1-43c7-a455-59bcd7e8df27" section="Computers and Gadgets" discussion="Best Bass headphones">"I was absolutely amazed by these headphones Panasonic RP-HTF600-S specially by the ridiculous low price, even compared to other mid range headphones I have. this is a good review Panasonic RP-HTF600-S Step Monitor"</post>
   <post id="4fc779b3-918c-456d-8bd1-f5b2327a8bf0" section="Computers and Gadgets" discussion="Best Bass headphones">"That s cool..Panasonic is a worthy product, what is yourmopinion about Hi-Fi Man headphones.?"</post>
   <post id="c840cc8f-195f-4d45-8c29-fd500f6e7ed9" section="Computers and Gadgets" discussion="Best Bass headphones">"HE400S review with measurements. Are you looking for emphasized quantity of bass or quality or both? If you re just looking for bass cannons, these guys might be your best resource. All sorts of crazy things going on in that thread, like the sheer bass from headphones blowing around paper. The V-moda M-100 is a well liked basshead can that s within your budget. Now, if you re after something more balanced, I d say Oppo PM3 or the Fostex TH-X00 - both of which are a little over your budget. The more moderately priced ATH M50X might be a good option as well."</post>
   <post id="5acaee56-ed31-46ac-9599-a70e2b27affa" section="Computers and Gadgets" discussion="Best Bass headphones">"That s pretty well landscape...definately bass with quality going to create the right desired effect..the ATH &amp; OPPO are in consideration and the Fostex need a view. The suggested thread is quite good, most of brands math the expactations, but bit more on price. HiFiMan could also be in scheme.thnx"</post>
   <post id="6f75dced-a4aa-46c7-aa96-431386d3cd65" section="Computers and Gadgets" discussion="Best Bass headphones">"i want headphones of jbl is anyone there to sell it..,,..,please contact to me"</post>
   <post id="31e86310-2e88-415d-93ea-58727af08481" section="Computers and Gadgets" discussion="Ive got a problem">"Today I come home from work and power up my computer. The Gateway logo comes on the screen, then it goes black and I get a message " Reboot and Select proper boot device or Insert Boot Media in selected device and press a key" . Problem is I can t find the backup disk that came with this computer. Any suggestions would be greatly appreciated."</post>
   <post id="bc75d301-e3da-4023-afd0-3d7a12edb793" section="Computers and Gadgets" discussion="Ive got a problem">"Makes sure that the hard drive is connected to the motherboard. If that doesn t work, remove the hard drive from the PC and hook it up to another PC to see if that hard drive still works."</post>
   <post id="46ca2390-ba3c-4939-8228-d6a531272962" section="Computers and Gadgets" discussion="Ive got a problem">"You have access to another PC to make a boot disk so you can see what is going on? Which OS version is it? One bootable tool you could use is Gparted and then see if the boot flag is set on the correct partition."</post>
   <post id="d709e147-5003-4ebf-94cd-2fda3ca3e3de" section="Computers and Gadgets" discussion="Ive got a problem">"She s a goner. Thanks anyways for the replies"</post>
   <post id="4996ad80-9cf4-4a2d-99a1-9badc082861b" section="Computers and Gadgets" discussion="Ive got a problem">"Starguard said: ↑ She s a goner. Thanks anyways for the replies Click to expand... If the hard drive will mount use the dd command in linux to clone or someother cloner and perform forensics on it by data carving what you can find in hexedit. If that s to complicated for you try rstudio and make the image with that as you will not be able to read an image created with anything else. Remember not to format the drive before you do any of the previous tasks mentioned. If it won t mount it s a goner for sure."</post>
   <post id="dbe493ba-08e8-45ad-9baf-83bf4b9879fb" section="Computers and Gadgets" discussion="Ive got a problem">"Question: Just out of curiosity, what do you guys think made this happen?"</post>
   <post id="a1adbbd8-8628-4c66-bc10-964b5f75b927" section="Computers and Gadgets" discussion="Ive got a problem">"Aliens."</post>
   <post id="500a24c2-0771-488b-b3ca-8d1b277c3846" section="Computers and Gadgets" discussion="Ive got a problem">""</post>
   <post id="b7ca4016-4c38-4454-b969-b417946c352b" section="Computers and Gadgets" discussion="Ive got a problem">"Kyle_Bennett said: ↑ Aliens. Click to expand... You know, I never thought of that"</post>
   <post id="33062c9f-5820-4f63-9691-a2de7405710e" section="Computers and Gadgets" discussion="Ive got a problem">"Kyle_Bennett said: ↑ Aliens. Click to expand... So you are saying that playing the movie Aliens on his computer caused this? That is oddly specific. Plus how did you know?"</post>
   <post id="d5195280-3373-4515-9839-10c1c167353b" section="Computers and Gadgets" discussion="Ive got a problem">"Kyle_Bennett said: ↑ Aliens. Click to expand... lol."</post>
   <post id="8fd5a5dd-7e5f-4fe7-b5cf-3db81d085a95" section="Computers and Gadgets" discussion="Ive got a problem">"Yep Alien gamma beams and nerd rays. They cause drives to develop faults. On a more serious note, not all dead drives are dead... yet. And some can be recovered. But it will take someone with more time than I have to help. If you want to get it sorted, answer the guys above."</post>
   <post id="47209fe1-8dd0-4467-bf46-f603f2c05845" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"This thread is about mirroring, extending, and casting your screen to a TV. I think this falls under Computers &amp; Gadgets, but if not, mods please move to the correct sub forum.. Hardware-wise, I have a old custom PC, hooked up with ethernet. Old laptop, planning on upgrading to Microsoft s SP4. PS4 over wifi, and a regular LG HDTV (not  smart tv ) I have been simply using an HDMI cable to connect my laptop to the TV. But what is the best solution to connect my desktop (in another room) and future SP4 to the TV? Miracast, Chromecast, roku, and what not..I m fairly unfamiliar with how powerful these devices can get. Is there any strong software I can use to do this over my private network? Is it necessary to get additional hardware (like a chromecast/miracast) and which one? I m looking for a simple solution that would allow me to either extend or mirror my screen on either device (desktop or SP4). Any suggestions? Thanks. edit: From what I understand about devices like Chromecast (maybe they ve gotten better since release), it will send whatever you want to cast(youtube videos, etc) to the device and the chomecast itself will connect to wifi and stream to the TV. I m looking for a more straightforward device that simply copies what I m doing on my desktop/laptop and sends it over to the TV. Something that I can support not just the Chrome browser or youtube player, but anything I bring up (VLC, media player, documents, streams, etc..)"</post>
   <post id="5038faf8-c90f-477a-9f64-5429f7aa1f76" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"You "can" stream your desktop to a chromecast by casting a tab in chrome, hitting full screen, and minimizing the browser. Works ok, can stream vlc by doing this with little to no lag, but I use an app called localcast to stream things off my nas to the chromecast. Easier to use and the quality, especially the audio, is better. I m sure there is a device that would work better for streaming the desktop."</post>
   <post id="5f8868b4-3ff4-4221-ab94-6e28d4078416" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"interesting, did not know the chromecast can do that. Would you recommend I wait for the chromecast 2? Any other suggestions?"</post>
   <post id="2c4f4cc5-a59b-46b9-9840-cf3396aa6113" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"bump"</post>
   <post id="a034ff18-d0d7-4462-99b3-4cf593182571" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"How do you plan on controlling the desktop PC that is in another room from the TV?"</post>
   <post id="ab9579ab-8244-4424-8b9e-f103896b3a03" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"Ideally, I d have an SP4 to control and play videos/movies. And this "solution" would work for both my desktop in another room, and the SP4. Walking to another room to start a movie or stream wouldn t be an issue for me though.."</post>
   <post id="c178a32b-38b7-4d5a-a6c7-c474be1ba7d3" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"Miracast is exactly what you want, based on your description. It comes built into Windows 8+ as long as your hardware supports it. I use my Amazon Fire TV Stick as a Miracast receiver for my TV, but there are many devices that support Miracast streams."</post>
   <post id="0a29b90d-a051-4ec7-9744-919c18648392" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"..as long as your hardware supports it. do you mean as in a Fire TV Stick? and I have Win 7."</post>
   <post id="38244560-41a9-42a6-a3f5-9bd8aca8c537" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"dragnandy said: ↑ ..as long as your hardware supports it. do you mean as in a Fire TV Stick? and I have Win 7. Click to expand... If your machine supports the Intel WiDi Drivers, you can use Miracast on Windows 7. You might also consider Steam In-Home Streaming if you re mainly streaming games, though it can stream XBMC and other media players as well."</post>
   <post id="b62cbfea-47e6-424a-8dac-81a82fc67c03" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"I think the chromecast/fire stick is definietly going to be the cheapest choice at this point. Considering you have older hardware and not a newer that would certainly have Intel WiDi Drivers compatibility."</post>
   <post id="471e06c8-9ab0-490b-90a5-3ed2548d67fd" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"hmm, sounds like I ll go with chromecast/fire stick. I ll do research and pick between those 2. I m a bit confused about Miracast. Do I need a  miracast compatible  device like the Surface Pro 4 (win 10) along with a  miracast compatible  TV ( HDMI dongle )?"</post>
   <post id="c1d02571-949e-4d69-b299-40da86578681" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"dragnandy said: ↑ hmm, sounds like I ll go with chromecast/fire stick. I ll do research and pick between those 2. I m a bit confused about Miracast. Do I need a  miracast compatible  device like the Surface Pro 4 (win 10) along with a  miracast compatible  TV ( HDMI dongle )? Click to expand... Your hardware needs to be compatible with Miracast to use it. You need a server (a PC with Miracast-compliant casting software installed) and a receiver (a standalone media device like FireTV or Roku, or a PC with a Miracast client installed). You can find out if your Windows 7 hardware supports Miracast by installing Intel s WiDi drivers. If not, Chromecast (which requires no special hardware on the PC casting side) is probably the way to go."</post>
   <post id="b6c2d013-7357-4bae-a590-fca2890b800e" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"You can use a doongle ezcast,it is analogue chromecast."</post>
   <post id="472f8089-be77-4248-8798-356106a1e50c" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"I use a chromecast and it s the best thing you can get for $35, get the first gen and it s $20 (not that much of a difference anyways) As someone mentioned, you can cast your desktop on it as well"</post>
   <post id="658b9bbe-f5ea-4a98-8203-377170e84fbc" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"those steam links are basically just remote control stations that plug into your tv for $50"</post>
   <post id="ab478080-dcac-4054-8b6f-bf5c2e9ff7c9" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"BTW your SP4 will come with windows 10"</post>
   <post id="5270dffc-02b0-4589-9c19-11fa5a00ead6" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"Yeah, chromecast is a good one. I have 3 in three different rooms and I can basically cast anything on my phone."</post>
   <post id="34df2a37-b833-47bd-8dad-c3456cab3397" section="Computers and Gadgets" discussion="[help] Best way to &quot;cast&quot; device to TV">"Personally I d use a HDBaseT HDMI over Ethernet extender. Monoprice has a good one. But then again, my entire house is already wired with Ethernet, making this easy."</post>
<post id="0335f42a-2ca8-47bb-b412-0386be96b74e" section="Displays" discussion="Show Your LCD(s) setups!!!">"UPDATED 04/16/2015"</post>
   <post id="dccb41ea-05c4-4b32-bc17-23f78ce5b3f1" section="Displays" discussion="Show Your LCD(s) setups!!!">""</post>
   <post id="340f132a-5e61-49b5-9c77-636ff9e980cd" section="Displays" discussion="Show Your LCD(s) setups!!!">"Anyone have projectors? Anyone dare to start a tread to show your projectors off, unfortionately I am too poor to own one. Ive always dreamt of having 2 dell 2001FP s"</post>
   <post id="c646fb88-6dc6-48e9-89d3-c5d8e079c512" section="Displays" discussion="Show Your LCD(s) setups!!!">"DaRkF0g said: Anyone have projectors? Anyone dare to start a tread to show your projectors off, unfortionately I am too poor to own one. Ive always dreamt of having 2 dell 2001FP s Click to expand... this is a show your LCD not projector. get you own thread"</post>
   <post id="6861bda5-1e4a-46b9-96b1-8c17f43070a7" section="Displays" discussion="Show Your LCD(s) setups!!!">"Nope, I m not lucky to have three, 2 are replacements. I ll eventually have just one 2005fpw and a 15inch LCD on the left. One of the LCDs is running off a laptop not shown."</post>
   <post id="4bb6ad41-5f79-4f9e-b1aa-5d76ed507c7f" section="Displays" discussion="Show Your LCD(s) setups!!!">"Zardoz.... any way i can get a link to that background you re using? it s freakin awesome!!"</post>
   <post id="8b91421b-4dca-4133-a4b7-172ba7000f16" section="Displays" discussion="Show Your LCD(s) setups!!!">"Great idea for a thread. I ll post my setup when I get my camera back from my sister."</post>
   <post id="c079a605-dcb5-4bef-890c-c97b26ed1a24" section="Displays" discussion="Show Your LCD(s) setups!!!">"shocksyde said: Zardoz.... any way i can get a link to that background you re using? it s freakin awesome!! Click to expand... Click here for goodness!"</post>
   <post id="1d326b59-ca03-4319-a0a7-600cedd9e7bc" section="Displays" discussion="Show Your LCD(s) setups!!!">"sweeeeeet thanks dude"</post>
   <post id="de7e3293-a637-4c0c-89b2-3ce90aafd018" section="Displays" discussion="Show Your LCD(s) setups!!!">"Benq Fp937s"</post>
   <post id="befcfeaf-e38c-434d-9395-43fabbded05c" section="Displays" discussion="Show Your LCD(s) setups!!!">"Bleh, nothing fancy.. FP791 on a ti4600 s DVI. My wallpaper and windows theme are constantly changing."</post>
   <post id="874dbdaf-d873-48bf-95a7-c31b5420df57" section="Displays" discussion="Show Your LCD(s) setups!!!">""</post>
   <post id="7a2c3a0f-6fac-45cd-884a-99dfc5e49cee" section="Displays" discussion="Show Your LCD(s) setups!!!">"nancyboy said: Click to expand... I d rotate the rear speakers away from you in an attempt to bounce off the walls, just a slight 45 degree turn. Then maybe mount the center speaker above the monitor on the wall with a nail. Or maybe take the stand off the center speaker to try and fit it nicely in the middle of the monitor stand instead of in front. But I guess the controls are on it so that might not work."</post>
   <post id="9eb305e4-1f9d-4d1b-8181-bc2f13297a44" section="Displays" discussion="Show Your LCD(s) setups!!!">"i wouldnt suggest buying any of the new NEC displays though. the 1765 on the left has been awesome, the 1735 on the right (which was about 4 hours old in that picture) crapped out a few hours after i took the pic, and NEC has been a bunch of assholes about replacing it."</post>
   <post id="67bc5c82-3196-45de-bc20-de9dd64458c6" section="Displays" discussion="Show Your LCD(s) setups!!!">"i really like the look of the NEC displays with the black shiny bezel, they re slick"</post>
   <post id="7ff721df-8ea4-4e39-9cef-4f5a7545c106" section="Displays" discussion="Show Your LCD(s) setups!!!">"Shocksyde, where did you get that wallpaper. It s one of the member only wallpapers at Digital Blasphemy isn t it? How much does it cost to be a member? Or can you get it elsewhere....?"</post>
   <post id="2602a62d-02dc-4d3b-aa76-2bb8e6d17bef" section="Displays" discussion="Show Your LCD(s) setups!!!">"it s not in the member only section anymore, but you can only get it at 1152x864. i just stretched it to 1280x1024 and it looks great to me. here s a link: http://www.digitalblasphemy.com/dbgallery/2/anen.shtml"</post>
   <post id="1d6237cf-8d3c-4cf1-820d-1e225cd5e6c6" section="Displays" discussion="Show Your LCD(s) setups!!!">"2 EIZO L685 1 PowerBook 1 iMac G5"</post>
   <post id="53e3a342-df29-45f3-8487-023a4ecf9763" section="Displays" discussion="Show Your LCD(s) setups!!!">"Sweet, thanks. I wanted to see if my LCD was that vibrant, and it is haha."</post>
   <post id="3eb7b2c4-b41c-4b6e-a06d-508619c3b6d7" section="Displays" discussion="Show Your LCD(s) setups!!!">"nice lcds"</post>
   <post id="5606a80b-0d93-469b-9082-03456e0650bb" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Revision 2.1 Revision History: 1.0 07/22/2015 - Initial Revision 1.1 07/23/2015 - Corrected several embarrassing typos 2.0 07/27/2015 - Changed color mode recommendation from YCBrCr mode to RGB Full, Added Cyph s window resizing issue fix, Added 4:4:4 Chroma test image,clarified One Connect Box, other misc, minor corrections/clarifications. 2.1 07/28/2015 - Minor Typos. Moved Revision History to top of document. So you bought a new fancy 2015 model 4K Samsung TV to use as a monitor and want to know how to set it up? Well, I m here to lend a hand. First let me point out, that I in no way came up with all of this myself. It has been a team effort with different people figuring out different things and posting them in the mammoth 200+ page New Samsung 4k for everyone thread. As with all these threads, over time things get difficult to find when they are a hundred or so pages back, so here is a quick guide to get you going. I will mention the term Chroma, 4:4:4 and 4:2:2 a bit. Their exact definitions are not really important to this writeup, but if you are curious, you can read up on the topic here. Assumptions/Disclaimers: This guide was written based on my JS9000 model. All of these models (JU6500, JU6700, JU7100, JU7500, JS7000 JS8500, JS9000) are very similar, but there are slight differences. This guide should still be mostly applicable for all of them. This guide assumes you have the TV assembled already, have powered it on for the first time, and gone through the initial setup (setting date, time, network settings, etc.) but have not yet gotten to picture modes, color configurations, and other things which really make these TV s shine as monitors. This guide assumes you have a HDMI 2.0 capable video card. These TV s are only equipped with HDMI ports, and this means that if you want the full 3840x2160 resolution at 60hz, and full 4:4:4 Chroma, HDMI 2.0 is the only interface that is going to work. At the time I am writing this, this means a GeForce GTX 9xx series card. While these ports will likely be available on all kinds of GPU s and computers in the future, right now GeForce GTX 9xx cards are the only game in town. TV picture settings are VERY subjective. There may be recommendations in this guide you disagree with. That doesn t mean either of us are wrong, it just means we prefer things one way or another. Wherever possible I intend to identify which of the recommendations are particularly subjective ones, and which are fairly objective. Before Connecting to Your Computer: On the JS9000 and other higher end models the inputs are all in an external "One Connect" box, which connects to the back of your TV using a proprietary cable. The different ports on the box are labeled for different purposes. Some models do not have a one connect box, but rather connect straight to the back of the TV. Some have only one HDMI 2.0 port, in which case you ll need to use that port. On the JS9000 all the ports are HDMI 2.0 ports. They are labeled for different purposes, but for PC use with a video card that has an HDMI 2.0 port, any one of them should work. In this guide, I will be using HDMI1 as the computer interface. While many of the early articles about HDMI 2.0 claimed you could use all your existing HDMI cables, this has sadly proven not to be the case. In order for this to work properly, you will need a good 18 Gbps HDMI cable, otherwise you might experience random dropouts, failure to connect at at high chroma (and thus poor image quality), or no signal at all. Keep the cables no longer than you need them, preferably 10ft or shorter. Even with cables rated for 18Gbps, many have reported that longer cables cause all sorts of problems. So, now that we have the screen physically set up, there are a few settings that make sense to do before connecting it to your computer for the first time. Nothing will have been harmed if these steps are done later, but now is a good convenient time to do them. Updating to the Latest Firmware -- Objective, but Debated Samsung has made many improvements to the firmware in these TV s in a very short period of time, and they affect the exact type of things that we as PC users of these TV s care about, namely image quality and input lag. I say this is debated above, as some of the early firmware updates on lower end models with 4 core processors (the JS9000 has an 8 core CPU) actually had negative impacts on input lag. On my JS9000 - however - I have found that every update I have received has improved input lag in PC mode without worsening quality, and improved quality in Game mode without sacrificing input lag. While some users of lower end 4 core models still use older firmware revisions as a precaution, posters in the thread who have installed more recent firmware suggest that anything 1207 or later on lower end models are a safe upgrade without bad input lag. The latest firmware at the time I am writing this is 1217. So there is a judgment call here, you can choose to keep the existing firmware for fear that updates will increase input lag, but on the JS9000 I wouldn t . Every firmware has been a clear improvement. On the lower end models, I still probably wouldn t based on what I have heard in the thread about 1207 and on, but it is worth keeping in mind. Time to get started. Turn on the TV and press the MENU/123 button on your remote. You should see the screen below: Using the arrow buttons on the remote (or the fancy WII-like accelerometer controls if equipped/desired) to navigate to the top left where it says "Menu". You should now see the menu below: Navigate down the list and select the "Support" menu. Once there, select the "Software Update" option. Now select the "Update Now" option. It goes without saying, but you ll need a network connection (wired or WiFi) for this, set up in the first time setup screen. The update will be downloaded, unpacked and installed, and the TV will reboot. Updating the Remote Firmware While we are updating firmware, why not do the remote as well? I have honestly not noticed any difference at all from this, but why not be current? Go to the menu again, as above, but this time choose the "System" menu. Now navigate to "Smart Control Settings" Select firmware update. This will also require a network connection, and should be quick. Enabling UHD mode -- Objective This one is important! In order for your TV to receive the full color signals from your computer, at 50/60hz refresh rates, you need to enable this option. (It makes no sense to me why this wouldn t just be on by default, but I didn t design the thing) Navigate to the menu again, like we did above, but this time select the "Picture" menu, and then scroll down to the second page, and select the "picture options" menu. Select the "HDMI UHD Color" menu. You will be greeted by the options below: Select the HDMI port you are using for your computer (I am using HDMI1), and change the setting to ON. This will restart your TV. Disabling stuff we don t need/want -- Semi-Subjective So this one is a little subjective, but here is the theory. Anything that performs image processing on the computer output before it hits your screen is going to take time, and this will directly translate to input lag, and we don t like input lag, so any unnecessary image processing needs to go off. Furthermore, these TV s have CPU s in them that perform the functions set in the menus. Lower end models have 4 core CPU s, while the higher end ones like the JS9000 have 8 core CPU s. If the CPU is busy doing other stuff it might just slow down the processing of your image, and we have more of the dreaded input lag. So, lets start with the Picture menu (you should know how to get here by now) If you scroll down to the second page, the things we are interested in start popping up: Lets start with 3D. I believe this is disabled by default, but lets just make sure it s set to "off" Back to the main menu again, and it is time to navigate to the "Smart Hub" menu. This one is important. Smart hub is what Samsung calls its smart TV entertainment apps platform. Make sure app auto update is off, so it doesn t start messing with you in the middle of doing something, and also disable Auto-Start. Don t worry, you can still launch it by pressing the colorful "Smart hub" button on your remote, even when auto-start is disabled, it just takes a tiny bit longer. At least this way it doesn t load every time you turn the screen on, pop up in your face, and hang out in the background doing stuff, and slowing the screen down. Now let s go back to the main menu, and navigate down to the "System" menu. Scroll down until you see "ECO Solution" and select this menu. Here I have disabled everything except "No signal power off". Firstly the ECO auto sensor is highly annoying when it randomly changes brightness on you, especially when you have multiple monitors, and now the brightness is suddenly very different between your screens. It also might just use some CPU cycles, so I d rather have it off. Lets return to the system menu, and now move down to the "General" menu. We ll come back to "Game Mode" later, lets just turn everything here off for now. Samsung Instant On SOUNDS good, but in reality it can be a problem and is better off. The light effect is subjective, but I prefer to not have a LED shining in my face when I am looking at the screen, so I have it set to only come on when the TV is in standby mode. Configuring Windows: We want to make sure we set this up before we set up any picture settings on the TV, as the TV tries to be smart, and can tell when we ve changed things, and will identify the changed output settings as a different device, and use a different picture mode profile. If we change the picture mode settings first, we will lose them all, and have to do them again. Now is as good a time as any to make sure you have fairly recent Nvidia drivers. Once installed, pull up your Nvidia settings and go to the "Change Resolution" tab. You ll want to choose 3840x2160 as your resolution, and 60hz as your refresh rate. (These might already be selected.) Next we want to make sure that our output color is correct. In the "Output Color Format" drop-down, select "RGB", and in the Output Dynamic Range dropdown select full. (Previously YCbCR444 was recommended due to a TV firmware bug preventing RGB mode from working properly, but this has since been fixed. Once setting RGB and Full in windows we will need to make sure that we have also set the correct "Full" level in the TV, or the colors will be compressed. I will cover this below in the "Setting up PC mode" section. Once the settings are applied, we can move on to our picture settings, and not worry about having to redo anything. Setting up PC mode: Press the "source" button on your remote, and you will see the following screen. Navigate over and select your input (in our example HDMI1) and click the select button. Push the down button on the remote (or long press the select button) to reveal the semi hidden input options menu. Select "Edit Device Type" Choose PC, and select OK. You are now in PC mode. We have one more last setting before you can finally see the colors and quality of this screen in their full glory. Since we are using RGB mode and FULL colors, we need to make sure that we have the corresponding full mode on the TV side. Navigate to the picture settings menu (you should know how to get here by now) Scroll down to the second page, and select "Picture Options". Here we need to make sure that HDMI Black Level is set to "Normal". (Ignore the fact that menu option is greyed out in my screenshot above, it shouldn t be in yours) If you want to make any preference adjustments, we can go back to the picture menu and make them there. By default there are two separate picture modes in PC mode, "Standard" and "Entertain". I don t know what s so entertaining about the "Entertain" mode, it just kind of scorches my eyeballs, so I leave mine in Standard. This is where we start getting into very subjective territory though. As for contrast, brightness and sharpness, I feel all of these hit it pretty well with their default settings. If anything is too dark or too bright for you, make adjustments to the backlight, before touching the brightness setting, as changing brightness from its default values can compress the color space. I found the default backlight (I think it was 12?) much too bright for my tastes and my office, so I turned it down to 7. At this setting it matches my Dell 2007FP side monitors pretty well in brightness. If you have any side monitors, you have probably noticed by now, that compared to the Samsung TV, they seem kind of yellow.This is due to an effect called "white balance". Our eyes adjust to the white balance of the light around us automatically all the time, and it ranges from warm to cool. While there technically is no such thing as a correct white level, CCFL backlights like in traditional LCD monitors are probably closer to normal light. The LED backlights like in this Samsung TV tend to skew a little blue/green. TV purists hate this, and tend to stick to their plasmas, but most peoples eyes adjust very quickly, especially with a large screen up close like this, and suddenly everything else looks yellow, including that supposedly highly color accurate IPS panel sitting right next to your TV. If you are just using one screen, I suggest leaving it as it is. If you want the whites to better match the other screens you have hanging around we can make a white balance adjustment. Scroll down in the Picture menu to "Picture Options" Here you ll find a "Color Tone" menu. Options are "Cool", "Standard", "Warm1" and "Warm2" I found even the warmest setting (Warm2) to be cooler than my IPS side monitors, but at least now they are pretty close. I should note that this is the simple way to try to control white balance. If you know what you are doing, there is an advanced White Balance menu under "Menu -&gt; Picture -&gt; Advanced Settings" which allows further white balance tweaking, but it is beyond the scope of this writeup (and quite frankly, beyond the scope of my full understanding) Next we are going to set up Game mode, but first a note, the TV will remember picture mode settings individually for the different input modes (PC, Game, etc) which is great, because you can tweak them separately, and simply switching between the modes will remember how you last had them set up, so feel free to tweak the picture mode here, without any concern for how it will impact game mode. Setting up Game mode: The PC mode looks gorgeous, but it has some ~46ms of input lag, which wile OK for desktop use, and some types of games (I m not bothered in Civ 5, for instance) would be kind of bad in a fast paced first person shooter. Once we have properly set up game mode, we should be able to get that input lag down to ~24ms, which quite frankly, is better than any non-CRT monitor I ve ever owned. Again, lets press the "source" button on your remote. Navigate over and select your input (in our example HDMI1) and push the down button on the remote (or long press the select button) to reveal the semi hidden input options menu again. Select "Edit Device Type" This time we are selecting "Game". This is where you gasp and say, "Oh my god this looks horrible, is my gaming really going to look this bad!?" The Answer, No. Game mode DOES reduce the color level a little bit down to 4:2:2 (I think) which is enough that if you are staring at certain colors of text on certain backgrounds it might look bad, but in any game I have tried thus far, I can t tell the difference in image quality. I CAN however tell the huge difference in input lag, which is much much better. The reason it looks terrible right now is because the default settings are really bad for some reason. First things first. Simply setting the input to "Game" does not fully enable game mode. As of right now, you still will have kind of high input lag. We need to enable it in the settings menu too. Lets navigate to the System settings menu. (You know how to get here by now) Scroll down to the second page, and select "General". Here, select "Game Mode" and enable it. Make sure everything else is still off. Now we need to go fix that horrible looking picture. Go back to the Picture menu. At first glance, nothing will look different except that the Picture Mode up top says "Game" and is grayed out, but here s the trick: For whatever reason, maybe intentional, maybe a bug, the sharpness setting is different in game mode than it is in PC mode. You will find that it is still set to 50, just like in PC mode, but it s not the same 50. This 50 is really (REALLY) high. So the solution is simple. Turn that sharpness setting all the way down to 0, and you will find that Game Mode actually looks pretty good now. On the desktop, especially with a lot of text you can tell the difference between this and PC mode, but it s difficult as the difference isn t huge. In games, you can t tell the difference at all. At least I can t. And don t worry about the picture mode settings being different, as we mentioned before the TV will remember them for each input mode. Switching between Game Mode and PC Mode: Some people are not very lag sensitive, and they say they just stick in PC mode all the time, even in games. Others are not very Chroma Subsampling sensitive, and they say they stay in Game Mode all the time. Personally, I can tell the difference in both, so I switch the modes all the time. Luckily, all the settings we changed are one time deals. The TV remembers them when you switch modes, so going forward we only have to change the input, and everything else is remembered. Just to repeat, this is how we do it from now on: Press the "source" button on your remote, and you will see the source screen. Navigate over and select your input (in our example HDMI1) and push the down button on the remote (or long press the select button) to reveal the semi hidden input options menu. Select "Edit Device Type" Choose PC, or Game and choose OK. That s all there is to it. Everything else is remembered. If you ever notice that everything else is NOT remembered, you probably did something silly, like changed the input, changed the output mode in the Nvidia control panel, plugged in a different PC, etc, etc. The TV is too smart for it s own good, and recognizes these things as new devices, and starts new profiles for them, so you need to go back and change the settings under "Setting up PC Mode" and "Setting up Game Mode" again. Final thoughts and some issues/fixes Window Resizing Fix: If you use certain connections to your TV, and notice that your windows resize when you switch inputs, this is apparently a bug in Windows, which Cyph posted a solution to over in the aforementioned mammoth thread. His solution is as follows: Cyph said: ↑ Not a firmware issue but a Windows one: https://support.microsoft.com/en-us/kb/2625567/ To fix. In Regedit, go to HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\COntrol\Graphics Drivers\Configuration Find the entries that starts with SIMULATED and your monitor string. If you don t know which one, change all of them. Go to the first subfolder 00, and find the keys: PrimSurfSize.cx and change to hex "f00," and PrimSurfSize.cy hex value "870." That should change the default monitor size to 3840 x 2160 which will no longer resize and move your windows to the upper left corner. Click to expand... Verifying that you are actually in 4:4:4 Chroma mode. The TV will never actually tell you in any menu which Chroma mode it is currently displaying in. If you are uncertain if your results are 4:4:4 Chroma (in PC mode, Game mode only uses 4:2:2 Chroma) the only way to check is using a test image and looking for artifacts. This image is the preferred test image, as lower chroma shows up most noticeably in colored text. Display this image at 1:1 pixel size on your TV and look to make sure the fonts are clean and crisp. With lower chroma modes you will either see what looks like slight dithering effects, or in the worst case something that is completely illegible (usually in the red text with blue background and blue text with red background) Now go enjoy, I know I will! If you think I got anything wrong, or missed anything, please feel free to comment."</post>
   <post id="fbe2d0aa-2386-4f41-a766-6057b39bae9f" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Good stuff. I m thinking of going this route. Any reason to pay more to get the higher cost models for monitor use?"</post>
   <post id="7eedd6bc-5a0f-4eae-8adf-73c6d066559a" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Awesome, thanks for doing this. It will definitely help out new owners."</post>
   <post id="7aed7b67-26de-46e0-9fcf-8e193eac8e6f" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Oh wow, this was a great article. Overall it will give me an idea if I want the 6700 or 7500 40 inch model myself. What is the ms response rate on these guys as well?"</post>
   <post id="00d2b91a-195b-48b6-b727-cdbc41fc1c3b" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Thanks! WoW! I have the JS9500 and returning it for the JS9000, I find it odd in PC mode that we cant change certain settings for Movies (Dark / smooth / 3d options). In Game Mode it seems we can, should we keep all of the Advanced and picture options off? Is there a way to verify settings? Color Tone in Game mode do we keep it at standard? I find Warm 2 to be really warm and yellowish. This could be due to me being just used to Standard at this point. My other main issue on the 65" JS9500 / 55" 9000 is that text is so hard to read in game."</post>
   <post id="279c393b-cbeb-45e2-81b5-49597d2d6a34" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Momma...... I gotta get one of these here deals. Great guide. Thanks for the info. I think it s time to put the Surround away."</post>
   <post id="f031799e-ed68-48ed-bc82-bcfbb401880b" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Nice! Very well done guide. Time to set aside some monies...."</post>
   <post id="3443a870-fb14-414d-8091-c1c163b2711e" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"dpoverlord said: ↑ Thanks! WoW! I have the JS9500 and returning it for the JS9000 Click to expand... I am curious, the JS9500 is reportedly a fantastic screen, even better than the JS9000, with full matrix dimming for much better blacks, among other things. Why do you feel the need to switch? dpoverlord said: ↑ I find it odd in PC mode that we cant change certain settings for Movies (Dark / smooth / 3d options). Click to expand... yeah, Samsung made some strange decisions in how to let you configure these TV s. (Like, how you need to enable game mode twice, and that the default mode is to have higher color modes disabled... Makes no sense. That being said, if you are watching a movie, why not switch it out of PC mode and into one of the movie modes? The benefit here is that it will save all your specific movie picture settings, and they will be called up every time you switch the input, so you can have specific settings saved for movie watching, including AMP if that s your thing. dpoverlord said: ↑ In Game Mode it seems we can, should we keep all of the Advanced and picture options off? Click to expand... This is really a matter of judgment and taste. Everyone has different preferences. I ahve mine set up the way I do because I like it that way, but if I were setting it up for someone else, and didn t know their preferences, I d use the "everything off" as the starting point, and then one by one add in the things they wanted, simply because each thing you add can and will add input lag. So turn everything off, and then only add what you want, and you will be adding less input lag than if you immediately add all the bells and whistles, whether you need them or not. If you enable AMP mode for frame interpolating, things will look VERY smooth, but at the cost of a lot of input lag. Firstly, it will add another frame to the queue, since if you are interpolating, you need to have two frames to interpolate between, and then there is the interpolation processing time to account for. Depending on your tastes, this will look either great, or odd in movies, but in anything interactive the lag might be a bit much to stomach. dpoverlord said: ↑ Is there a way to verify settings? Click to expand... You can push the OK button on the remote to get a very cursory summary of current resolution, etc, but it is very low on details. It will not confirm anywhere I have found if it is actually in full 4:4:4 Chroma mode or in a lower mode, but this ought to be pretty easy to just see, as the quality on screen will be rather heavily affected. If you suspect you are not in the right mode first make sure you are in 3840x2160 at 60hz and look at a screen with lots of colorful small, text. (colored text on black background is a great test). Now drop it down to 30hz, and see if the text becomes clearer. If it does become clearer, something is off, as this means you are in 4:4:4 mode when in 30hz, but not at 60hz. At this point I would verify you actually have everything hooked up to HDMI2.0 ports on both ends, check your cable (and test with others) etc. dpoverlord said: ↑ Color Tone in Game mode do we keep it at standard? I find Warm 2 to be really warm and yellowish. This could be due to me being just used to Standard at this point. My other main issue on the 65" JS9500 / 55" 9000 is that text is so hard to read in game. Click to expand... This is one of those that is 100% subjective. Do what you think looks best. As I described in the guide, I set it to Warm2 simply because I was trying to match the whites of my CCFL backlit IPS side screens, but I recommended leaving it at standard for those of you who only have the one screen, or who are using it together with another LED backlit panel. The beautiful (and confusing) thing about human vision is that we ahve evolved the ability for our eye sight to adapt very quickly to different white levels. Walk outside on a bright day after having been inside for a long time, and all of a sudden everything will ahve a bluish hue for a while until your eyes adjust. Go back inside to a room lit by lightbulbs, and everything looks yellow until your eyes adjust. Same thing with the screens. If you were to use an instrument to measure the light levels, you d probably find that the CCFL backlit screens are probably closer to full white RGB levels (R255, G255, B255) and that the LED backlit screens err a little bit to the Blue/Green side, but your eyes adjust quickly, and there is no reason to change the white level unless you are trying to match it to nearby screens, IMHO."</post>
   <post id="8e5619f9-2f05-4cdf-9eb8-abb809bb715b" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"AthlonXP said: ↑ Oh wow, this was a great article. Overall it will give me an idea if I want the 6700 or 7500 40 inch model myself. What is the ms response rate on these guys as well? Click to expand... I only have the JS9000, so can t speak with authority on the other models, but they are all pretty close. All have fantastic input lag in game mode, and somewhat higher (but usable for desktop apps) input lag in desktop mode. For measured specifics, I think rtings.com is probably the best source right now. Just go over there and type in the model number, and you should be able to find all the data you need."</post>
   <post id="06b6db1b-55e4-4f54-9228-968f365a004a" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"xp3nd4bl3 said: ↑ Good stuff. I m thinking of going this route. Any reason to pay more to get the higher cost models for monitor use? Click to expand... It depends very much on what your preferences are, and what you are sensitive to. If you want to compare specs tables there are websites (like rtings.com) where you can do that, so I m not going to be your Google bitch but here is my qualitative take on what those spect mean: If you are PWM sensitive (screen dimming, not fans) it seems best to avoid the lower end models, as their PWM dimming scheme uses a lower frequency, and some people are very sensitive to it. I ve never seen it myself (I must not be sensitive), but apparently it can show up as an annoying flicker. The lowest end curved model (JU6700) is a semi-gloss screen. Move up one step to the JU7500 and you get full gloss. Some like it, some actually prefer the lower model. As you go up the model numbers, the actual panels in the TV s move from 60hz to 120hz (don t believe the official specs here, as they overstate the figures and use electronic trickery to compensate). This list helps explain it. 120hz panels are preferable, but keep in mind that this doesn t mean you can set 120hz in windows and actually use it. The display output will still be 60hz. The reason they up it to 120hz is to reduce ghosting and response times. Because of this the higher end models fare better in this regard. Lower end models have a single HDMI 2.0 input, higher end models ahve more of them. Lower end models have 4 core CPU s, while higher end modes have 8, which can make the interface more responsive, especially if you want to use smart TV features. Higher end models are 3D compatible, whereas lower end models aren t. Keep in mind that there is no way to transfer more than 60hz at 4k resolutions to the screen (HDMI2 bandwidth limitation), and 3d alternates frames left-right, so in 3d you ll be maxing out at 30hz. There are more differences, but these are the big ones I can think of right now."</post>
   <post id="a84bef62-19a4-4a2b-9123-e23f5a280ebf" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Nice guide. I may get one of these Samsung 4k s."</post>
   <post id="a661e25e-e118-47cc-b40f-90fd6abe2697" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Best buy has the 40" I think for around $700 which is a pretty smoking deal."</post>
   <post id="edbd4c36-3ba2-4ff1-ad37-51fb75c7ea5d" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Great guide. I am considering one of these."</post>
   <post id="4be19643-dce3-48e7-a80e-12d8e9d4484f" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Picked up a 48JS9000 and am having issues with 4:4:4 at 4k 60hz. It looks to be a driver issue, as I ve got 3 GTX780 s and I m not able to get 4:4:4 displaying through HDMI (which reportedly may only be 1.4, which makes sense), DP1.2 -&gt; HDMI (passive adapter so in theory it should easily push it), or DL-DVI -&gt; HDMI (also should be able to push). At 60hz with any connection, I lose the color options when setting the resolution as you screenshotted above. At 30hz, it shows back up again and kicks into 4:4:4. Any ideas? Maybe a way to force it through an EDID profile? Thanks"</post>
   <post id="dc00304c-dde8-4e84-b07b-1b330650ad5e" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Glorious post, Z. Bravo!! First time ever that I ve bookmarked a thread on [H]. I prefer PC to Game mode for everything on my 7500, but you ve given lots of good tips/tweaks to try. I so wish Samsung had a 40" JS9000. Sadly, I suspect the 7500/7100 were the last of high end 40" TVs. I think everything going forward will be 48" and bigger."</post>
   <post id="15b958fc-8f73-4895-8386-6a71c051ad20" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"I forgot to ask: 48 inch? Is your screen curved?"</post>
   <post id="36e2caf4-376b-4781-9722-92d5f2eb9122" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Homer said: ↑ Picked up a 48JS9000 and am having issues with 4:4:4 at 4k 60hz. It looks to be a driver issue, as I ve got 3 GTX780 s and I m not able to get 4:4:4 displaying through HDMI (which reportedly may only be 1.4, which makes sense), DP1.2 -&gt; HDMI (passive adapter so in theory it should easily push it), or DL-DVI -&gt; HDMI (also should be able to push). At 60hz with any connection, I lose the color options when setting the resolution as you screenshotted above. At 30hz, it shows back up again and kicks into 4:4:4. Any ideas? Maybe a way to force it through an EDID profile? Thanks Click to expand... Unfortunately I don t think this is possible without an active HDMI2 adapter, if one of these even exists yet.(This will also add input lag) My understanding is (and I might be wrong) that DP passive adapters are similar in capability to DVI passive adapters, which limit you to single link DVI type capabilities. Unfortunately I have to date not heard anyone suggest that getting 3840x2160 at 4:4:4 chroma and 60hz works on any GPU without native HDMI2, and the only ones on the market right now are the GeForce 900 series, not the 700 s"</post>
   <post id="d6d7caa7-8902-4e70-a789-d784c7c47104" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"magoo said: ↑ I forgot to ask: 48 inch? Is your screen curved? Click to expand... Yes, and yes. The JS9000 s are all curved, and start at 48". This was the main reason I went 48". Prior to deciding on the JS9000, I was shopping for 40" screens, as I felt that was closer to the size I was looking for for desktop use."</post>
   <post id="d1ab9a21-541f-4cb1-960c-a42b58c8ec8a" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Tyler-Durden said: ↑ Glorious post, Z. Bravo!! First time ever that I ve bookmarked a thread on [H]. Click to expand... I m flattered I had all these thoughts in my head, the sources of which were scattered all throughout the 230+ page thread. I figured they needed to all be in one place. Kyle and I spoke about it, he suggested adding pictures, and I thought why not, and here we are!"</post>
   <post id="83803064-2417-4139-9f61-538baaf8638d" section="Displays" discussion="2015 Samsung 4k TV as a Monitor Set Up Guide">"Great post! now to decided which 48 inch TV to buy."</post>
   <post id="5d053643-f5bc-4d51-a819-cdc60123cc09" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"LCD Panel Technology Type and Characteristics TN film (Twisted Nematic) - low manufacturing/retail costs - restrictive viewing angles - fast pixel response times - dead pixels display white. Stuck pixels display RGB colors - lower contrast levels means blacks are not as dark as VA based panels - lower color reproduction IPS (In Plane Switching) - improved viewing angles over TN - very good color reproduction - slower pixel response times than TN - dead pixels display black - lower contrast levels means blacks are not as dark as VA based panels Super-IPS (S-IPS) - same as IPS except ... - likely best color reproduction of all TFT - less expensive to produce than IPS - improved pixel response​ VA (Vertical Alignment) Technologies MVA (Multidomain Vertical Alignment) - compromise between TN and IPS technologies - superior color reproduction over TN but not as good as IPS - very good viewing angles but less than IPS - higher contrast than TN or S-IPS means very good blacks - dead pixels are black - slower pixel response than TN or IPS - details can be lost when directly viewing dark areas Premium-MVA (P-MVA) - same as MVA except ... - "overdrive" technology increases pixel response but still slower than TN - may have slightly degraded color reproduction due to "overdrive" process​ PVA (Patterned VA) - same as MVA except ... - larger viewing angles - higher contrast levels means darkest blacks​ Super-PVA (S-PVA) - same as PVA except ... - “Magic Speed” (the Samsung equivalent to Overdrive) improves pixel response - slightly improved color reproduction - slightly improved viewing angles​ Purchasing Considerations TN Gamers Considered a "gamers" panel due to it s fast pixel response times which reduces trailing images know as "ghosting". However, this advantage has been reduced by new technologies to accelerate pixel response times in other panel types. Colors and contrast tend to be weak and blacks are not truly dark. Viewing angles are significantly limited. However, monitors based on this technology tend to be inexpensive. IPS / S-IPS Graphics Work or Web Browsing Considered to have the best color reproduction of all panel types, these panels are well suited for graphics work or web browsing. Pixel response time is also good but slower than the TN "gamers" panel. Contast and blacks are also less dark than VA panels but viewing angles are excellent. MVA / P-MVA / PVA / S-PVA Compromise for All-Around Use These panels are a compromise between the fast pixel response times of the TN panel and the excellent color reproduction of the IPS panels. Contrast and blacks are best of all the panel types. Viewing angles are similar but slightly inferior to IPS. Model/Panel Index Acer Acer AL1951Cs - 19" TN Film Acer AL1916ws - 19" WS TN Film Acer AL2016ws - 20" WS Chunghwa Picture Tubes TN Film Acer AL2032wa - 20" WS AU Optronics P-MVA (M201EW01 V0) OR LG.Philips S-IPS (LM201W01) BenQ BenQ FP202W - 20" WS Chunghwa Picture Tubes TN Film Dell Dell 1905FP - 19" Samsung PVA (LTM190E4-L02) or AU Optronics P-MVA (M190EN03 V0) Dell 1907FP - 19" TN Film Dell 2001FP - 20" LG.Philips S-IPS (LM201U04) Dell 2005FPW - 20" WS LG.Philips S-IPS (LM201W01) Dell 2007WFP - 20" WS LG.Philips S-IPS (LM201W01) Dell 2007FP - 20" LG.Philips S-IPS (LM201U04) Dell 2405FPW - 24" WS Samsung PVA (LTM240M1-L01) Dell 2407WFP - 24" WS Samsung S-PVA (LM201W01) Dell 3007WFP - 30" WS LG.Philips S-IPS (LM300W01) Gateway Gateway FPD2185W - 21" WS Samsung S-PVA (LTM210M2) HP HP F2105 - 21" WS Samsung S-PVA (LTM210M2) Hyundai Hyundai L90D+ - 19" Samsung TN (LTM190EX-L01) NEC NEC LCD20WGX2 - 20" LG.Philips AS-IPS (LM201W01) Sceptre X20G Naga II 16ms 20" P-MVA Sceptre X20G Naga II - 20" WS P-MVA Samsung Samsung 930B - 19" Samsung TN Film Samsung 940B - 19" Samsung TN Film Samsung 940T - 19" Samsung PVA (LTM190E4) Samsung 940MW - 19"WS Samsung TN Film (LTM190M2) Samsung 204B - 20" Samsung TN Film (LTM201UX) Samsung 215TW - 21" WS Samsung S-PVA (LTM210M2) Samsung 244T - 24" WS Samsung S-PVA (LTM240M2) ViewSonic ViewSonic VA1912W - 19" WS Chi Mei Optoelectronics TN Film (M190A1) ViewSonic VP912B - 19" AU Optronics TN Film (M190EN04 V1) Viewsonic VX922 - 19" AU Optronics TN Film (M190EN04) Viewsonic VX924 - 19" AU Optronics TN Film (M190EN04 V5) ViewSonic VP920 - 19" TN Film ViewSonic VP930 - 19" AU Optronics P-MVA (M190EG01 V0) ViewSonic VA1912W - 19" WS Chi Mei Optoelectronics TN Film (M190A1) ViewSonic VA2012WB - 20" WS Chunghwa Picture Tubes TN Film ViewSonic VX2025WM - 20" WS AU Optronics P-MVA (M201EW01 V0) Much information gathered from TFT Central. Please visit their excellent site for detailed information on TFT technology and manufacturer models."</post>
   <post id="335cc13c-7cbd-44e8-876d-7fd5a7a9d6bb" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"great sticky!"</post>
   <post id="517fab86-95a7-44fd-9018-a72633f74f95" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"oh cool"</post>
   <post id="249985ae-7535-4122-b663-2f60c13b556c" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"thanks for the info"</post>
   <post id="f890036c-e80f-490c-bfe5-0a43c8043d48" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Great information! This definitely deserves the sticky."</post>
   <post id="afb5b8ae-a6a9-4aa2-9c5f-47759d42b5bb" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Are you sure about the Samsung 930b and 940b? The viewing angles and contrast ratio seem to high to be a TN..."</post>
   <post id="c612e9a1-2857-4cea-9e06-ebbb1fb12dcc" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Unknown-One said: Are you sure about the Samsung 930b and 940b? The viewing angles and contrast ratio seem to high to be a TN... Click to expand... yeah, both are listed as 700:1 contrast ratio and 160/160 viewing angles, but this is Samsung s 8ms LTM190EX-L01 TN Film panel as used in a large numer of their range and in other models too (Samsung 913N, 920N, Hyundai L90D+ etc)"</post>
   <post id="8ef7ff68-2fbf-4145-9b5a-16609f2b3459" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"NEC NEC LCD20WGX2 - 20" LG.Philips AS-IPS (LM201W01) Click to expand... whats the difference between AS-IPS and S-IPS"</post>
   <post id="207d1272-9e19-414b-8702-65b9a14d8638" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"AS-IPS is "Advanced Super In Plane Switching", but S-IPS is "Super In Plane Switching". It s just an extension of the same technology but a new generation with a new name."</post>
   <post id="64b394e0-7c1a-498b-839f-d523e8d5fb18" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Hate to burst the bubble, but it seems the site you linked has very little hands on and relies on other sites reviews to make its desicions. I would recommend anyone wanting to buy an LCD look around oin the [H] forums, plenty of users have posted their experience over time with hands on. I know my reliance on the reviews I read led me to a certtain choice and after some hands on I changed it... I can also say that there is no substitue to actually seeing the LCD in use before you buy it(if possible). Good luck to anyone looking for a new LCD!! And as I said, read forums and Newegg User reviews and even PM users here if you want the most info possible b4 you spend your cash."</post>
   <post id="3a227b24-e740-4271-8a59-63e05a24466a" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Badd said: AS-IPS is "Advanced Super In Plane Switching", but S-IPS is "Super In Plane Switching". It s just an extension of the same technology but a new generation with a new name. Click to expand... I m not sure about this, but I think AS-IPS is a buzzword for a S-IPS display that has extra electronic gimmickry to boost contrast ratios based on colors present in the scene, and perhaps use pixel overcharging as well to achieve slightly better response times."</post>
   <post id="26757ee2-7223-4fe3-a678-d6349cf153d0" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"placebo said: I m not sure about this, but I think AS-IPS is a buzzword for a S-IPS display that has extra electronic gimmickry to boost contrast ratios based on colors present in the scene, and perhaps use pixel overcharging as well to achieve slightly better response times. Click to expand... oh, it s very much a marketing word certainly. The panels are still based around S-IPS panel technology, and the AS-IPS terminology seems to be so far exclusively used by NEC. It might be their way of identifying their "boosted" range. LG.Philips have developed their next gen of S-IPS as well, called Enhanced S-IPS. At the end of the day, there s a lot of different names floating about. fundamentally the panels are IPS underneath"</post>
   <post id="5db60421-9be0-46fb-85f1-933aa66560ea" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"what about adding the Acer AL2416W and AL2423W to the monitor list?"</post>
   <post id="3075bf70-1aa5-43c9-91cc-6e6d16eca614" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Nice work a good guide for the many newbs on this forum."</post>
   <post id="03adeb9f-12b6-401e-aa64-dce46cec05fe" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"Time to update sticky with new info."</post>
   <post id="58278029-937d-4e38-844e-4927fe2fe376" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"LostStorm said: Time to update sticky with new info. Click to expand... I agree, this is great info I had no idea it was here but I would like to see additonal monitors listed as well as the LG l204wt"</post>
   <post id="e778f5d5-8b25-4e2f-8ddf-584e8b4d2056" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"full panel database can be found here: http://www.tftcentral.co.uk/, but might be worth updating the sticky itself at some point too"</post>
   <post id="03cd998d-4195-4812-997d-4b0b172b1935" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"According to the Egg Samsung has a new 22" widescreen LCD the SAMSUNG 225BW. It also lists it as a TN LCD. Also it seems a bunch of new 1680x1050 panels are around the corner from Acer, Sceptre (which has HDMI and a claimed 1200:1 contrast ratio!!) and all seem to be TN, but I am not sure about the Sceptre."</post>
   <post id="3528ac0e-306a-44a6-944a-6248b20437f6" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"kool"</post>
   <post id="e35134fd-95b0-40e0-ba14-60c503df5037" section="Displays" discussion="TFT Technology Breakdown and Model/Panel Index">"damn it, i bought a 1907FP without reading this. The TN blows compared to my 2001FP."</post>
   <post id="e4f6551f-299a-4f92-a272-f9b5b247aa79" section="Displays" discussion="Make Shopping for Displays Easier with Hover Hound for Chrome &amp; FireFox!">"I would like you guys to give this new Chrome Extension, NewZon or here for FireFox a try. This extension was built by BD Inc, a sister company to HardOCP. We built this extension with the computer hardware enthusiast in mind. It makes shopping at Newegg and finding and comparing prices at Amazon and Tiger Direct, and soon NCIX as easy as clicking a button or simply hovering over the Hover Hound button to LIVE CHECK prices immediately. Find and compare prices for Amazon technology products easily while shopping at Newegg. Shopping at Newegg has been a staple for the computer enthusiast for years, and comparison shopping those same exact products at Amazon can sometimes be difficult. Built with the computer hardware enthusiast in mind, our Hover Hound&amp;#8482; extension for Chrome makes comparison shopping products at Amazon while at Newegg.com very simple. Hover Hound can accomplish this in several ways, while keeping your privacy and browsing experience at the forefront. 1. The Hover Hound extension will place an &amp;#8220;[N]&amp;#8221; icon in your URL bar. This icon will stay here while you are browsing Newegg pages and will allow easy access to Hover Hound options with a right click. Left clicking the [N]&amp;#8482; icon while on Newegg product pages will search for that item at Amazon and open a new browser tab with the product that Hover Hound finds. 2. Hover Hound can also add a more accessible Hover Hound button to your browser that will allow you to search for the product at Amazon as well. This can easily be turned off by the user at any time in the Hover Hound extension options found by right clicking the [N]&amp;#8482; icon. 3. Hover Hound Hover for Price&amp;#8482;! When you have the Hover Hound browser button enabled, you can also hover over the button and Hover Hound will provide a real time price and shipping cost for the item at Amazon. Hover Hound Hover for Price will also let you know if the real time pricing includes a rebate, be it instant or mail in. 4. For our Amazon Prime members, we allow you to filter Hover Hound search results to return only those items at Amazon that include Prime Shipping. This will also apply to the Hover Hound Hover for Price as well. 5. Hover Hound Cart&amp;#8482;! Hover Hound will also take your entire shopping cart and search for matches and return you to a Hover Hound Cart Conversion page. From here you can add all matched items in your Hover Hound cart to your Amazon shopping cart with one click if you wish. Additionally, your Hover Hound cart link will stay live for 3 months, so you can bookmark this URL and easily refer back to this at any time or share your Hover Hound Cart with friends. We also very much value user feedback! While we do our best to not ever mismatch you with a product you are not looking for, we do get one wrong every once in a while. If we do, please simply right click on the Hover Hound button on the original product page and you can tell us what we have gotten wrong. Once we know that, we can fix the mismatch or any other issue you might be seeing. Thanks for any help, feedback, or ideas for new features you would like to share. The enthusiast computer hardware community has helped shape Hover Hound tremendously and we are very thankful for this. Hover Hound and BD Industries LLC. respect your privacy and have NO access to any of your tab information, browsing information, or any website data besides unencrypted data on newegg.com pages open in your personal browsing window. Changelog: http://extension.HoverHound.us/changelog.txt TRADEMARKS - The company, product, and service names used in Hover Hound are for identification purposes only. All trademarks and registered trademarks are the property of their respective owners. Newegg® is a registered trademark of the Newegg Inc. in the United States and in other countries. Amazon®, Amazon Prime®, and its affiliated Prime logo are registered trademarks of the Amazon.com in the United States and in other countries. All other trademarks or registered trademarks are the property of their respective owners. Click to expand..."</post>
   <post id="1cc4b4da-1611-47ee-abaf-f20763a092f8" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Philips BDM4350UC 43 inch  4K  UHD IPS monitor - PC Monitors Biggest difference here is that this new monitor is now IPS instead of VA. I ve been waiting for this kind of monitor for over a year that is 40+ inch 4k, PWM-free, non Korean ebay brand, 4:4:4 chroma, and has input lag much better than a TV. Will be getting this day one."</post>
   <post id="6f2eefe5-fcf0-4f0c-86fd-27c99f691cbd" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"I love the contrast of VA, but this monitor looks BAWS."</post>
   <post id="c2669274-992f-4e2e-9184-0c60014023e5" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Looks very very nice for content creation"</post>
   <post id="25ddb63d-6d58-444b-851e-f47a2a9fb757" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"KazeoHin said: ↑ I love the contrast of VA, but this monitor looks BAWS. Click to expand... Same. I would ve just loved to see an updated 2016 version of the 4065UC that s flicker free but I guess the 1200:1 contrast ratio (IF that s even really true) is better than most IPS panels and will have to do."</post>
   <post id="6afa4132-9e30-441b-8e7d-e5b7ecae4d74" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"subscribed: Tied the 40" philips...will be waiting anxiously on this one."</post>
   <post id="15ad56fe-30c2-42f5-ba4c-a77368bdddbd" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Didn t see anything in their specs about input lag so no evidence yet it will be better than a tv. Will need to see actual reviews first."</post>
   <post id="31157ebd-67fb-4df3-8f6e-5caddd3762d2" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Skott said: ↑ Didn t see anything in their specs about input lag so no evidence yet it will be better than a tv. Will need to see actual reviews first. Click to expand... I had the 40" Philips. I dont game...but for general every day use the lag that the 40 had (for me) was totally acceptable. Actually, I did not even notice it."</post>
   <post id="83744d65-060f-499a-adbd-7136b5cf8892" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"You can already buy this monitor. It s called Sony KD-43X8305C."</post>
   <post id="6cbaea77-9fed-40b9-b471-a9683d40e0d1" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Darwin3232 said: ↑ You can already buy this monitor. It s called Sony KD-43X8305C. Click to expand... I suspect this monitor could be using the same panel as that Sony TV. Hopefully I m wrong and the claimed "1200:1" contrast ratio holds up to be true, otherwise if it s the same crappy 700:1 panel as the Sony then I m just gonna return it."</post>
   <post id="fa2653b0-7ac1-4045-8b56-8b002e9c25a8" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"I cant wait, this will be perfect for 4k without scaling."</post>
   <post id="3823822b-d4c8-45bc-ab44-affeefd47122" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Awesome to see a follow-up to the BDM4065UC. I love VA panels for their blacks and contrast but this one should have superior color and no weird color overlap lines like the 40" version had. Subbing because I want to see what early adopters of this monitor have to say (particularly if they owned the BDM4065UC)."</post>
   <post id="07dae94d-1255-47e3-9603-215a5cd6b25b" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"My worry is the IPS glow / bleed at this size..."</post>
   <post id="e89f6333-adc5-403e-a8f6-41ddb53b4e08" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"kabobi said: ↑ My worry is the IPS glow / bleed at this size... Click to expand... Well TBH I m not too concerned about that because if it was a VA panel instead then we d have to worry about gamma shift from sitting so close to such a large screen. I m more bummed out about the lost of contrast."</post>
   <post id="5266c0bb-a3e4-4b77-816b-7e014d6e037c" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Darwin3232 said: ↑ You can already buy this monitor. It s called Sony KD-43X8305C. Click to expand... That doesn t have DP or HDMI 2.0, so right there, personally, I can t consider it an option. But thanks for the heads up though. My dream screen is a Sony 50" 4K something. Sony s TV interface and particularly post-processing features are unrivalled imho, so a Sony version of this 43" Philips could have been awesome. Opportunity missed."</post>
   <post id="1078dc96-4066-425d-aaa3-9f39ba780cb6" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"spine said: ↑ That doesn t have DP or HDMI 2.0, so right there, personally, I can t consider it an option. But thanks for the heads up though. Click to expand... Sony does have HDMI 2.0, but indeed does not have DP, so you need a Nvidia card."</post>
   <post id="10c8046c-cd36-449c-b3ba-994d94f0c13d" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Darwin3232 said: ↑ Sony does have HDMI 2.0, but indeed does not have DP, so you need a Nvidia card. Click to expand... Or the DP to HDMI Club3D adapter."</post>
   <post id="4d25820b-3b49-4e39-8146-86baa6220571" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Wow nice. 4K 43" IPS PWM-Free This will be in stores by the end of April in my country but I am not sure if I will be an early adopter, it all depends how much I can get for my current monitor, can t afford to spend much cash."</post>
   <post id="a56e8a7e-b4c6-4fa6-b17a-ebe48bc2d0b6" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"This may finally be the 4K monitor I buy, depending on the reviews. Unfortunately I have a feeling that variable refresh rate technology for monitors this size will be a long time coming or not at all, so I ll bite if the price and quality are right."</post>
   <post id="97f28741-d7ed-4f3f-9de0-ed9c4ffc5720" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"Wow! Now if only it was already available and got some reviews for it. Yesterday my 8-9 years old HP 30" 2560 X 1600 bit the dust and I am now left with a Samsung 32" HDTV (1080p) as a monitor so I need a new good display ASAP. I don t mind gaming but I will use the monitor for productivity applications (Photoshop, Illustrator, 3Ds Max, Autocad and Web authoring) I was ready to order the 40" Version of this monitor but now I am puzzled. What would you do? Buy the 40" now or wait till this one is available. I live in Europe so I guess it might be available within the next 40 days."</post>
   <post id="7c094e6f-0a45-44c6-987d-1bc404f0def9" section="Displays" discussion="Philips BDM4350UC 43 inch 4K IPS PWM-free monitor">"I would wait."</post>
   <post id="c087eaa9-66ed-46d7-949e-5bfb10f99c7c" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Well guys, I went to some type of 3rd dimensional hell to get this but it s here I ll leave some pics and impressions I actually discovered this monitor here. Some people were trying to get it but didn t go through the hassle. I went through 5 stores and 4 of them were horrible for various reasons. Specs: (These i tested and confirmed) -Sharp Panel 23.5" 1080p 10 bit (well no source and gfx to confirm this but its stated) VA panel 5000:1 144hz, 1ms Adjustable height, tilt, portrait mode -English menu was found after fiddling yay The Hell First I tried Shop China (as in the first thread of HKC x3). Their shipping rates seemed too unbelievable, but since their monitor price was a little higher than taomall, I figured it was added on. But seemed like a lot less hassle to just click, buy and wait. NOT! They told me that the item is fragile and won t guarantee its safety. Second I tried Yoybuy.com . They told me through chat that they first said they could ship it to me , then they changed their mind after I paid it and said "Do you agree that this item is fragile and if it breaks you will pursue getting a refund ?" I quickly cancelled that but I had to wait for my money back Then I tried taobaoring. This time I went to the chat online and they just flat out said NO we will not ship the item. The price The next one was Taobaocart. Well the price was high compared to the rest, but then again I thought no one would ship it to me. The man through email agreed so I went through the process. He would NOT choose any of the Tmall stores that I chose, but chose his. $250 for his choice. The DHL shipping (not including extra packing) and paypal fees, Dhgate fees, commission added up to $397. I tried to pay anyways, but my bank, Western Union and Paypal, DHGate all alerted me that night that this seller was a fraud and they didnt charge my bank. Then I tried Yoycart. I just inquired and they said they would deliver, but their commission and service wasn t as good as what was already under way at the same time... DOT DOT BUY. A Chinese only website. I thought I had no hope in working this one out! But praise God, it did. I went through the tutorial on reddit and saw they had some decent reviews. I just linked the page to the top bar, hit add to cart and buy. The price of the Monitor base price was a very l ow $133usd. I then chatted thru the online chat and asked for English and they were nice that they could do that. They said they didn t have bubble wrap, but they could double box the item and find something to put inside. After I had clicked buy, It took me to pay via paypal (all in Chinese again) But thank God for Google translate page! Then I received an email where I translated as they asked me to confirm that its a monitor and would need special care. I said OK and they had it shipped to their warehouse. I just went to the main page to get updates daily after this email. After 2 days they got it in and packed it up. They gave me the DHL quotes. Now take note that if u go on DHL yourself, it would cost $433 usd without a business account. Typically, these taobao sellers ask $162 for this size of package. However, DDB asked for $142 as a complimentary discount. A few hours later, i saw that it was 0% commission rate weekend and I would receive NO fees whatsoever. They had this packed up and it asked me if i wanted special care extra box packaging. Usually this is an extra charge but they didn t ask for that either, and they absorbed both paypal fees for the 2 transactions. I then received the Monitor 3 days later and the whole process of completion was 7 days. For $277 I received a TN price panel for what is basically the younger brother to Eizo Fg2421 After almost getting swindled, I got a good deal. They even threw me in an Extended Razer mouse pad, those things don t go cheap here so that s nice. Now, NVidia driver had reset the values to 16-235 and it looked horrible. I had changed that back in both areas of the Nvidia Control panel to 0-255 and we re doing good. I don t know how to really calibrate and test this since i don t have the Calibrator . But if you want to guide me, please do. I ll be responsive"</post>
   <post id="906689b6-f61c-4a52-8414-07ad1d9c58c6" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Console gaming works out quite nicely here, the fast reaction time really helps pulling off those kills. Note: My 24" Korean IPS monitor could not show the PS3 menus but could only play the game itself."</post>
   <post id="6ca07b80-7673-48e4-9ccb-d056f562fa9c" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Looking nice. Same semi-glossy coating as the FG2421. How is red colour displaying? Looks good enough on the screenshots. The Eizo had some problems with that Does it accept custom resolutions at anything higher than 144hz? (since SHARP LK235D3HA0S Overview - Panelook.com is listed as 240hz on panelook) Does it have problems with black crush? Black level - Lagom LCD test Does it produce any trails on the Ufo? Blur Busters UFO Motion Tests (for a pursuit photo 1/36 sec exposure at 144hz)"</post>
   <post id="73dc0af6-df7c-42f2-8063-a288e149ca94" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"igluk said: ↑ Looking nice. Same semi-glossy coating as the FG2421. How is red colour displaying? Looks good enough on the screenshots. The Eizo had some problems with that Does it accept custom resolutions at anything higher than 144hz? (since SHARP LK235D3HA0S Overview - Panelook.com is listed as 240hz on panelook) Does it have problems with black crush? Black level - Lagom LCD test Does it produce any trails on the Ufo? Blur Busters UFO Motion Tests (for a pursuit photo 1/36 sec exposure at 144hz) Click to expand... I really need a calibrator. If i put it on Gamma 2, then it will show all the squares, but the temp will be slightly too blue. I can t adjust it since I m using the WARM preset, not the user. The Warm preset i+Gamma 1 is ALMOST perfect but it needs tweaking. ..but you can t tweak it in presets mode. In User, i can tweak the values to be identical to any preset, but I get eye fatigue and my eyes don t adjust quickly enough to change the the colors appropriately. A lot of bright monitor lights into y our eyes will do that to you! In the Blur busters, I don t have a camera, just a cell phone. But I finally can see the dudes eyeballs clearly! There is some slight artifacts around the end of his ufo, but definitely no trails. This is an OD monitor so there s some artifacting. Not noticeable at all in CSGO or Bf4 though."</post>
   <post id="d0440f22-ff6a-4d83-9504-24146f8a8233" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Sounds pretty good so far. Maybe you will eventually find good User values, otherwise you could also try to tweak gamma parameters per colour channel with Nvidia driver."</post>
   <post id="78a0b706-ebe1-4b56-812d-e667be3e0a08" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"igluk said: ↑ Sounds pretty good so far. Maybe you will eventually find good User values, otherwise you could also try to tweak gamma parameters per colour channel with Nvidia driver. Click to expand... Oh I forgot to answer. It only goes up to 144hz and that s overdriven. You can t turn off OD though. This info needs to be updated or it may be a different panel. Take note the AG coating on this screen is like holographic polarized. It seems to be contributing to the "tunnel" vision gamma shift. My Vizio also has Semi gloss coating but the screen uniformity is better due to the coating. Well this is a theory. I think if it was removed it might be better. I guess its a small price to pay. I mean with the IPS I have, you don t have this issue, but you have other issues. yea good idea, I may use the Nvidia software EDIT: OH yes and NO DEAD or stuck pixels!"</post>
   <post id="feef62d0-f9bd-413f-a862-8d2f019ac272" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"does this have some kind of blur reduction or no?"</post>
   <post id="6463c2dd-7cda-4580-9fce-1eeeeb2bd7cf" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Odellus said: ↑ does this have some kind of blur reduction or no? Click to expand... It does not have ULMB or Blur reduction. Be nice if it did but alas it does not. There is no Gsync/Free sync either but I haven t seen a single frame tear yet. I don t know why I don t see tearing, do you? I didnt get tearing anymore even on my 60hz monitor. It suddenly stopped happening a few mos ago. Maybe Nvidia driver update?"</post>
   <post id="03e96758-71d9-44bf-966b-ef6999557fb1" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"tearing is impossible to notice at 120 Hz with sample and hold. i use ULMB though and it s extremely noticeable (microstutters, too), only downside to it really."</post>
   <post id="a618d10e-2c99-489c-b273-247d05db6df7" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Odellus said: ↑ tearing is impossible to notice at 120 Hz with sample and hold. i use ULMB though and it s extremely noticeable (microstutters, too), only downside to it really. Click to expand... Ic, that helps to know! BTW, I m not sure yet since I had too many variables during my use, but It seems that using 120hz instead of 144hz reduces artifacts and product less central headache when viewing. I ll turn it back and make sure it wasn t some other setting."</post>
   <post id="927e597a-ab27-403e-b031-df0f06db7f21" section="Displays" discussion="My HKC X3 144hz 1ms hi contrast VA panel is in!">"Congrats for the monitor I have a FG2421 (no fault unit) and I love it. It doesnt do 144hz, but it does 120hz with storbing. I would love if someone releases a mix between yours and the FG2412 with freesync/gsync."</post>
   <post id="a7774f7c-65aa-492f-8191-c40309137be5" section="Displays" discussion="My new Vizio 43&quot; 4K screen is here">"VIZIO m43-C1 I actually got this a few weeks ago, but I ve been too busy working my butt off paying for it Anyways, this purchase did not disappoint. I got it on Ebay (new) for $450 total when the screen was still $529 at Costco and Sams before taxes. Pros: The colors and resolution, and gaming speed is much improved. Sharpness and detail is quite unbelievable. There s color gradations that can t be seen with my 24" IPS for the same pictures. Viewing the same pictures , which are both 4k, it is evident how much detail is gained on the Vizio even with the higher source image to the 1080p IPS screen, It is also pretty lightweight compared to my 2007 -40" Sony Behemoth. Confirmed I can set this screen to 1080p 120hz from my PC, but I set it back to 4k. Cons: The viewing angle color shift is not as nice as our Sony KDL55w900 1080p. For my room size, this flaw isn t notable, but if you re gonna put it in a living room and the walls are not close enough to the sides, this will bother you. The other flaw is only the 5th HDMI can output 60fps 4k, but this and the meh speakers can be remedied by sending it all to a receiver . This is my first NON big brand purchase. I have no regrets   Attached Files: 2016-03-13 08.27.00.jpg File size: 100 KB Views: 0 2016-03-14 13.18.23.jpg File size: 72.1 KB Views: 0 2016-03-14 13.19.13.jpg File size: 99.5 KB Views: 0 2016-03-16 23.03.20.jpg File size: 158.1 KB Views: 0 2016-03-17 00.56.51.jpg File size: 114 KB Views: 0"</post>
   <post id="def9cccd-8239-4000-837b-a97f58cfcbcd" section="Displays" discussion="My new Vizio 43&quot; 4K screen is here">"I ve tried hard to look what kind of panel this is and what other TV s are sharing this, but I couldn t find anything. Anyways, I m loving it for games. Response time is great and no noticeable trails in most games."</post>
   <post id="d19081f7-e8f8-4c20-802b-513ecc821763" section="Displays" discussion="My new Vizio 43&quot; 4K screen is here">"It uses AUO T430QVN01.0 as far as I know. The Sony KDL55W900A is VA, the KDL55W900B is IPS."</post>
   <post id="ef03a3dc-b809-442c-a893-98623199dcc6" section="Displays" discussion="My new Vizio 43&quot; 4K screen is here">"Vizio is a big brand -- so far as TVs go they re probably trading blows with Sasmsung at this point, as far as number of units out there. They also tend to make descent stuff. Glad you re happy with it, and yeah, that s a good price you got. Sadly won t work for my purposes since it won t do 4:4:4 for monitor use, but as a TV it s nice."</post>
   <post id="f5391fb7-6eeb-438e-95dd-9bd52ae992f6" section="Displays" discussion="New Samsung 4k for everyone.">"http://www.samsung.com/us/video/tvs/all-products Stats &amp; Reviews: Only PC mode with UHD color-enabled gives you uncompressed 4:4:4. JU6500 REVIEW FLAT. Edge-lit. Input lag: 26.5ms (GAMEMODE) 48ms (PC MODE) JU6700 REVIEW CURVE. Edge-lit. Input lag: 27.8ms (GAMEMODE) 44.2ms (PC MODE) JU7100 REVIEW FLAT. Direct-lit. Input lag: 26.1ms (GAMEMODE) 44.3ms (PC MODE) JU7500 REVIEW #1 Review #2 CURVE. Direct-lit. Input lag: 21.0ms (GAMEMODE) 36ms (PC MODE) JS7000 REVIEW FLAT. Direct-lit. Quantum dots and wider color gamut. Input lag: 27.4ms (GAMEMODE) ??? (PC MODE) JS8500 REVIEW FLAT. Edge-lit. Quantum dots and wider color gamut. HDR. Input lag: 36.9ms (GAMEMODE) 37.7ms (PC MODE) JS9000 REVIEW CURVE. Edge-lit. Quantum dots and wider color gamut. HDR. Input lag: 23.6ms (GAMEMODE) 55.8ms (PC MODE)"</post>
   <post id="743e28d7-1465-41e3-82ab-f265559e2777" section="Displays" discussion="New Samsung 4k for everyone.">"Your link shows them, but can t find any announcements. Quiet release... Nothing on European availability or 60Hz 4:4:4 either. So not yet sure if these can replace the Philips BDM4065UC"</post>
   <post id="5c340974-2dbe-41ad-a844-f101c3a110f0" section="Displays" discussion="New Samsung 4k for everyone.">"Well the 21ms input lag figure has only been confirmed for the top JS9500 model, which is $6500. I would hope the lag improvements trickle down to the entry models, but not a sure thing yet, unless you ve seen reviews for these?"</post>
   <post id="3fbc84f6-7843-4b05-abae-7e00939894da" section="Displays" discussion="New Samsung 4k for everyone.">"Samsung also likes to use low frequency PWM which renders 4K pointless since it destroy motion clarity, and the motion compensation features are disabled when using the gaming friendly modes. The Philips BDM4065UC also uses PWM if not set to an eye scorching 100% brightness, and stretches images too."</post>
   <post id="a1217cbd-14bd-472d-a90e-cce019997b53" section="Displays" discussion="New Samsung 4k for everyone.">"I could just see me with 3 x 55" monitors on my desk......."</post>
   <post id="c37752a1-1cd4-448c-bbb7-b58fb6bcfa72" section="Displays" discussion="New Samsung 4k for everyone.">"If that 40" does 60hz 4:4:4, I ll be hitting that up for my next computer monitor."</post>
   <post id="e2ed265e-f448-4865-871e-510008de279b" section="Displays" discussion="New Samsung 4k for everyone.">"Do they have direct LED or edge LED ?"</post>
   <post id="f1c6fda4-b841-4d87-90d7-94ab6f94d3bf" section="Displays" discussion="New Samsung 4k for everyone.">"munkle said: ↑ If that 40" does 60hz 4:4:4, I ll be hitting that up for my next computer monitor. Click to expand... Samsung is supposed to make a 34" 21:9 144hz curved g-sync monitor but it probably won t be out until 2016. They recently released a 34" 60hz 3440x1440 non g-sync one that is VA type panel (Samsung S34E790C) and it pretty pricey at ~ $1300. I m wondering if they will make their 34" 21:9 144hz g-sync gaming one VA rather than the ips that the Acer Predator XR341CK 34" 144Hz Curved Gaming Screen with G-sync will likely be. If samsung releases such a high rez 3440x1440 21:9 gaming panel that is VA like the eizo fg2421 (but with better panels + QC) and fast enough I will be all over it. So one way or another I ll likely be on 21:9 gaming monitor in 2016. 4k would be nice for desktop/app real-estate and as an additional monitor would be nice just for those tasks. Otherwise not for gaming for me until they are running off of dp 1.3 - 1.4a input at 120hz with g-sync. Preferably 144hz but I think dp 1.3 only mentioned being capable of 4k at 120hz (if someone makes one, and off of displayport 1.3 gpus as well). So that is quite a ways off for me considering release time of such a monitor and me being on dp 1.3 - 1.4a gpus in sli. 4k will be over-demanding on gpu for high frame rates even after all of those other considerations. You could probably run 1080p gaming pixel doubled cleanly since it divides 3840x2160 evenly however. You could prob alternately run 21:9 mode with bars on a 4k for much wider aspect ratio game viewport and less pixels to render by gpu. GPU power will increase over the next year though as well, and there will be some directx12 improvements supposedly. By the time I move from a 21:9 3440x1440 gaming panel it will probably be to a VR setup and then a high hz with screen blanking 4k gaming desktop oled. Oled for living room also in the long run but hopefully 21:9 there too."</post>
   <post id="e76fa862-697c-4bbc-881b-5416a2e4a6f5" section="Displays" discussion="New Samsung 4k for everyone.">"petzz said: ↑ Do they have direct LED or edge LED ? Click to expand... All are edge aside from the flagship JS9500 unfortunately, which is also only available in 65" and above size. For that reason I think the Vizios will be a much better buy for most people, assuming they get 4:4:4 support nailed down in this year s models."</post>
   <post id="28464faf-87ae-46f7-9993-2cd5cc1c7064" section="Displays" discussion="New Samsung 4k for everyone.">"As others have mentioned, the 4:4:4 issue is probably the biggest deal breaker here. Last year none of the Vizio P series and only a small few of Samsung s high end models like the HU8550 had 4:4:4. Let s hope these guys can get it right this time around."</post>
   <post id="0e2b6e09-2be7-44f6-bda9-ed38cebdcb07" section="Displays" discussion="New Samsung 4k for everyone.">"Well Samsung usually always had a 4:4:4 support when you renamed the input as PC so I am hopeful."</post>
   <post id="ae77cb34-404c-4366-a25e-5f7e95548ac6" section="Displays" discussion="New Samsung 4k for everyone.">"Looks like the 40" models are $849 and $949 for the 6500/6700 respectively. I don t see why these wouldn t do 4:4:4 60p unless for some cost-cutting reason they omit HDMI2.0- the manuals mention nothing about displayport. EDIT: Just had a little chat with support, cliffs on the 6700 FWIW: N: I have checked the information for you. This TV supports HDMI 2.0 ports, for color mode it supports 4:4:4 Response time is 6 ms GTG and dynamic contrast ratio is of 1,000,000:1 It accepts a 120hz input Click to expand... Might just have to be a guinea pig for this, after DHL decided to smash my Phillips"</post>
   <post id="ef9c5719-2e2b-43a9-90a1-e64e28ddebf9" section="Displays" discussion="New Samsung 4k for everyone.">"seanclayton said: ↑ Samesung JU6500 Shamesung JU6700 Sauce: http://www.samsung.com/us/video/tvs/all-products Click to expand... Intentional or not, the typos on your post made me spill coffee all over my monitor!"</post>
   <post id="37ad36e7-1994-4a28-a861-b3d2c71bb363" section="Displays" discussion="New Samsung 4k for everyone.">"Any idea when this will be available?"</post>
   <post id="47e63c5c-89fa-4934-98c3-697d40986a42" section="Displays" discussion="New Samsung 4k for everyone.">"The 40" curved panel retails for $949. I looked at the instruction manual and it s quite poor. It doesn t say if it s HDMI 2.0/HDCP 2.2 or if any of the HDMI ports are HDMI 2.0 at all. Edit- I found a French website that gave this info for the flat panel: Connectors: 4x HDMI 2.0 (HDCP 2.2), Component, Composite, Optical Mini-jack, 3x USB, Ethernet, RS-232, CI + ... Click to expand... So it should be the same for the curved model. It says 120Hz refresh rate. It looks good. If it is a 4:4:4 display, I just might buy the curved panel and use it with my Titans until I upgrade to a card that supports HDMI 2.0."</post>
   <post id="09209bff-1041-444c-b03b-201bb419fc5f" section="Displays" discussion="New Samsung 4k for everyone.">"Wag said: ↑ It looks good. If it is a 4:4:4 display, I just might buy the curved panel and use it with my Titans until I upgrade to a card that supports HDMI 2.0. Click to expand... Read up a bit before you post. petzz said: ↑ Any idea when this will be available? Click to expand... Rep says expected ship date is between March 16th-20th for the JU6700, but this is tentative"</post>
   <post id="812720c5-2e6d-4e59-9671-ea5803a158a2" section="Displays" discussion="New Samsung 4k for everyone.">"thanks"</post>
   <post id="40017297-4679-47f4-8fae-ef31529aaf5a" section="Displays" discussion="New Samsung 4k for everyone.">"Chat InformationPlease wait for a Samsung Agent to respond. Chat InformationYou are now chatting with  Michelle . There will be a brief survey at the end of our chat to share feedback on my performance today. Chat InformationYour Issue ID for this chat is LTK1125603293528X Michelle: Hi, thanks for reaching out to Samsung pre-sales support. We appreciate your interest in Samsung products. How may I assist you today? Visitor: On the Samsung UHD JU6700 Visitor: does it support 4:4:4 subsampling? Visitor: HDMI 2.0 and or have display port? Michelle: Hello, could you give me a few minutes while I gather the information for you? Visitor: And is this product in stores now? Visitor: of course and thank you kindly Michelle: They are not yet in stores. This model does have HDMI 2.0 but just a moment as I look into your other questions. Visitor: ok thank you Michelle: You re very welcome. Michelle: I apologize for the delay. Unfortunately, I was not able to verify that the JU6700 has a displayport and supports 4:4:4 Chroma. We have a dedicated team to assist you further. Do you mind holding for a moment while I transfer your chat to a specialist who can further assist you with your questions? Visitor: yes Visitor: that would be fine Visitor: I am ready to make a purchase and these specs are very important to me. Thank you Michelle: I understand, they are very important specs. Just one moment for the transfer. Chat InformationPlease wait while I transfer the chat to the best suited Samsung Agent. Chat InformationAll Samsung Agents are currently assisting others. Thanks for your patience. A Samsung Agent will be with you shortly. Chat InformationAll Samsung Agents are currently assisting others. Thanks for your patience. A Samsung Agent will be with you shortly. Chat InformationAll Samsung Agents are currently assisting others. Thanks for your patience. A Samsung Agent will be with you shortly. Chat InformationYou are now chatting with  Vain K . There will be a brief survey at the end of our chat to share feedback on my performance today. Chat InformationYour Issue ID for this chat is LTK1125603293528X Vain K: Hi, thank you for reaching out to Samsung technical support. Your chat was transferred to me and I will be glad to assist you. Please allow a couple of minutes, while I review the previous chat to assist you better. Visitor: Hi, I am ready to make a purchase within the next few days on the UN48JU6700FXZA Visitor: I understand it has HDMI 2.0 but doe those ports have 4:4:4 chroma? Visitor: aka 4k@60hz Vain K: I understand that you want to know if the TV mentioned by you has 4:4:4 chroma. Is that correct? Visitor: yes Vain K: Thank you for confirming. Vain K: Could you give me a few minutes while I check the information for you? Visitor: sure Vain K: Thank you. Vain K: Just to confirm, from which country did you purchase your TV? Visitor: Its presale now it ships the 9th of this month. USA Vain K: Thank you for the information. Visitor: I have to step away from my PC but if you could leave me a yes or no answer as to if this set does support 4:4:4 chroma I would be very appreciative Vain K: I have checked the information for you Vain K: I see that the UN48JU6700FXZA does not support 4:4:4 choma. Vain K: The 4:4:4 chroma is supported by only HU model TVs. Visitor: ok thank you Vain K: You re welcome Vain K: I just wanted to make you aware of some really good support pages that are available to our customers. Samsung SPOT (Smart Personal Online Training) offers real-time Samsung support with a product expert through live video chat. visit us at Samsung SPOT Our hours of operation(currently) are: Monday to Friday / 10am to 7pm EDT. If you are looking for more details on the functionality of a product or would like to find answers to some of the questions, visit us at SamsungSimulator for an interactive review of some of our Samsung products. Vain K: Is there anything else I can assist you with?"</post>
   <post id="fcf538ff-fbc7-4b02-9c51-860a0a358b10" section="Displays" discussion="New Samsung 4k for everyone.">"It might be worth asking what HDMI 2.0 brings to these TVs. If not 4:4:4, what do they support?"</post>
   <post id="015caea5-1b16-419c-9faa-1320bd0ea038" section="Displays" discussion="New Samsung 4k for everyone.">"Well, apparently all of Samsung s new 2015 Ultra HD 4K sets ... DO NOT support 4:4:4 chroma You ve been warned."</post>
   <post id="3e76418c-e8a4-4fe9-8a9b-4b01bf370d54" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Finally received my FW900 from Ebay, The box was packed extremely well with a very thick barrier of bubble wrap around it. The front of the monitor casing has a little scratch (Update: I was able to cover up this scratch using a silver colored sharpie) but the glass/screen itself is in perfect condition. Picture quality on this thing is AWESOME I was very pleased to find the Geometry and Convergence in near perfect condition after looking at various test patterns.Also the overall Focus is excellent corner to corner. It seems as if this monitor wasnt used very much or it just aged very well, I cant see any notable flaws in the picture quality, I havent really messed with it gaming &amp; movie wise but I was just playing FarCry @ 1900x1200 and it looked amazing, I think I got an excellent deal @ $400 shipped,especially considering this monitor retailed for $2,300 new. Few pics I took, digital camera doesn t really do it justice tho: CRT Calibration Guide (courtesy of atwix): http://hardforum.com/showpost.php?p=1039320979&amp;postcount=8742 WinDAS White Point Balance guide for Sony Trinitron CRTs (courtesy of spacediver): http://hardforum.com/showthread.php?t=1830788 A big Thanks to Hurin for putting together the following information from this lengthy thread: Monitor Information Sony Product Page (product datasheet, user s manual, driver). Service Manual. Aspect Ratio and Resolutions The monitor is 16:10 aspect ratio. The following resolutions are 16:10: 1280x800 1600x1000 1680x1050 1760x1100 1840x1150 1920x1200 2048x1280 2304x1440 (Max resolution listed in the FW900 product datasheet) If you can t select these resolutions, make sure the monitor driver is installed (included with Windows XP or you can download it at the link above). If certain resolutions are still not available, you can add custom resolutions easily via NVIDIA s "Custom Resolution and Refresh Rates"control panel. ATi users may need to use a 3rd party application such as "Powerstrip" if their preferred 16:10 resolution is unavailable. Initial Setup Panic? "Image Restore" to the Rescue! When you first unpack and power up your monitor, do not worry if black levels and color are way off. Let it warm up for about 30 minutes. After thirty minutes in the powered-on state (don t let the monitor enter "sleep" mode), the "Image Restore" option becomes available under the "Expert" and "sRGB" color settings menu. Set your preferred color temperature in the Expert area and then activate the "Image Restore" option. Your colors should then "pop" into place. Edit: its also good to turn up the monitors Brightness setting before running Image restore, For example I normally run mine at around 25 but before running Image restore Ill turn it up to 50, Then back down after running it. Doing this normally gives the brightness setting a wider range, especially if you re currently having to run the monitor at a low brightness setting to achieve good black levels. Green Tinge? If you notice a "green tinge" to greys and blacks, do the "Image Restore" procedure above. But first, raise the Brightness setting for your monitor appreciably above where you d normally like it. Then, do the "Image Restore" operation. Discolored Corners? If you have a yellowish (or other color) "tinge" in one or more corners of your display (but the rest of the display is fine), adjust the "landing" setting for the affected corner in the monitor s setup menu. Circles Are Oblong! Sony specs state that the  standard image area  calls for 1/2" of black space on top/bottom and 1/4" total on the sides. This gives a 1.59x :1 aspect ratio. Close enough for government work. So, adjusting your image area completely to the corners isn t recommended if you want a completely pure 16:10 aspect ratio (totally round circles). But really, it s hard to notice either way. BNC Cable? So far, nobody in this thread has noticed any improvement from using them. But, if you want to be sure you re getting the best possible video signal to your monitor, you can try getting this high-quality BNC cable. A high-quality cable has heavily shielded individual signal wires as early as possible in the cable run rather than a standard VGA cable that only breaks out into the five individual wires over the last few inches of the cable. One side-effect of the BNC cable connection is that you will need to manually set up the monitor driver. The monitor driver is built into Windows XP, You can choose it manually or if you have trouble you can download it from here. When using BNC connections, don t be alarmed if the screen "jumps" or "rolls" for a moment every time you right-click certain video files. This is a side-effect of using BNC cables, apparently. Multiple peope have noticed it. Monitor focus seem a little soft / blurry? Over time the optimal focus can tend to drift on CRTs but you can re-adjust it using the 2 focus pots located inside the monitor , Thanks to MightyJoe for the detailed info on gaining access to these adjustments here. Sorry the picture links are currently dead if anyone has them backed up please let me know, Although It might not even be necessary to open your monitor , refer to the Alternate method for adjusting focus below. - UPDATE / Alternate method for adjusting Focus: Apparently you can adjust the focus pots from the outside of the monitor! I recently adjusted my monitor using this method ,Thanks to beast for this info: "The pots are visible from the outside by shining a flashlight into the left rear top of the case, and with a small screwdriver, they were easily accessible thru the ventilation slots. The metal cage inside the plastic case has round holes, and the pots are directly under two holes, which happen to be directly under two ventilation slots. It looks intentional from the outside, but i could just be lucky." uberwurst confirmed that he was also able to adjust it from the outside so it s definitely worth a try before going through all the trouble opening the monitor. When adjusting the Focus I noticed its best to have the Contrast turned up to around 85 and display a white backround with black or blue text (such as cnn.com which has both) if its even slightly out of focus the text will appear blurry ,try to get it as clear as possible with contrast turned up and you ll be in good shape. How Does It Display 4:3 Content? It s up to you! For non-widescreen content, the monitor can show it in all its glory in the proper aspect ratio by simply squeezing the raster area so that it s only drawing in the 4:3 areas of the screen. In other words, there will be black "undrawn" bars on either side of the image. If you don t mind a distorted image, the monitor can also "stretch" the image to fill the entire screen. But then, things look "fat." The proper 4:3 aspect ratio can easily be attained by pressing the "ACS" button on the front of the monitor when any 4:3 resolution is displayed. Opening the monitor If for whatever reason you need to open the monitor for service etc. here s some info on how to do it, Just remember to BE CAREFUL as there are high voltage areas in the monitor even after its been unplugged for days: Link Removing Anti-Glare coating from monitor If you have scratches in the antiglare coating (the dreaded rainbow effect) there is the option of removing the coating entirely, of course it involves tearing down the monitor but people have reported good results: Link and also here. Dynamic Convergence Adjustments With the help of WinDAS you can make Dynamic Convergence adjustments across the entire screen, This allows for picture perfect Convergence compared to using the monitors limited user adjustments, Thanks to Hurin for making this guide! Link UPDATE: Thanks to roberta for spending the time putting together this refrence list of topics from this ever growing thread: Refrence List Last Updated: Jan 3, 2015"</post>
   <post id="6dc0df13-6c39-4d20-94d8-412d68090b9a" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"great monitor, great price. The only drawback is the hefty weight. I can t imagine dragging that thing to a lan game."</post>
   <post id="9444766a-fb17-4ddc-a0d7-fb0853cdff5e" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Oh my back hurts just thanking about it but it is a nice looking Monitor."</post>
   <post id="18e23c77-a708-4027-86f9-989b2f4d5ca1" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"hey, does that person you puchased it from have more. Im looking for a reputable seller and feedback from this forum is better that the BS sometimes Ebayer put out there."</post>
   <post id="e05a5397-78fc-4da4-9a2f-53b7aac19f23" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Got the HP version on the way. Same guy, I saw you mentioned same MA town, noticed it was the same as my ebay. I think you re thread got me to buy this thing. I was kind of in the dark they had 24" Widescreen CRTs. I was ok with LCD drawbacks, but I had to try door number two. So cheap! Picture probably does the monitor no justice. The 2405FPW probably has the best image of any monitor I seen, thing is that image up there doesn t degrade when you start hauling ass on a vehicle or so on. Heh... oh well, I go to the gym, bring on the 100lb dinosaur."</post>
   <post id="5b3acdd3-4588-437b-9fa8-509c060fce46" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Nice mathesar, we both rolling with monitors from the same guys. exept I went for the sony one. It has the metal gray case instead of the beige. And yes this monitor kicks ass."</post>
   <post id="65d0e5a1-bb7e-4e1c-9466-be05bd9aae9d" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"ellover009 said: Nice mathesar, we both rolling with monitors from the same guys. exept I went for the sony one. It has the metal gray case instead of the beige. And yes this monitor kicks ass. Click to expand... Actually mine is the Sony version as well"</post>
   <post id="0e04070f-2180-41e3-91ba-259e7d0171a5" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Pkirk618 said: hey, does that person you puchased it from have more. Im looking for a reputable seller and feedback from this forum is better that the BS sometimes Ebayer put out there. Click to expand... He sure does, Original Sony version here HP OEM version here"</post>
   <post id="cc03dcd6-b217-4a30-a907-225bb37303a1" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"wow i want a 24 inch widescreen SO bad...especially the 2405, but for $400 i would buy this shit in a heartbeat...if i had the $$ Congrats on the kick ass monitor dude, im sure you have many happy gaming hours ahead"</post>
   <post id="2eb708ab-bde2-438a-9478-2d7d9dec4af2" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"well, already looking at this guys stuff. Its reassuring its the same person though. thanks man."</post>
   <post id="8d3ef273-1623-4325-a7d8-7c3f37da0644" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"weight = 92.6 lbs that s more than your average geeky prepubescent teenager"</post>
   <post id="fd34da96-3ee5-4acc-a47c-f7925c17324f" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"I hope my desk can handle this thing. I can though, I eat my vitamins."</post>
   <post id="de446951-33c0-42fd-8ac0-45940c623038" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"What s the depth measurement of this thing? Might want to pick up one to compliment my 2405 :]"</post>
   <post id="2dd2a136-f287-4484-b0ff-6fb0dca0606e" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"i bet its at least 24in wide"</post>
   <post id="859fa597-32b7-42e1-85b5-1c1e497e6291" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"heh, gj mathesar... i bought mine new about 5 years ago... still works perfect. I ve babied this thing everywhere I ve moved... not a scratch on it. It rox for games... Just seeing it available on ebay makes me wanna buy another one... can you imagine 2? Anyway, I m gonna hold out for sed technology and blow some bucks that way... I need more real estate, and I don t want to go to the dual monitor set up... not any good for games. You re gonna love that monitor... if you play cs at all, be sure to play at a resolution that allows you to use 100hz refresh rate. Oh, and be sure to get the program reforce.exe, it allows you to lock the refresh rate at 100( or whatever you want) when you get into opengl or direct3d mode. Otherwise, xp has a nasty habit of lowering the refresh rate to 60hz... it makes it look fugly. PM if you have any questions about video tweaking... again congrats on the monitor... you re gonna enjoy it... I still enjoy mine and haven t regretted plunking down 1800 clams on it. For $300 its a friggin steal. I m tempted just to buy it just to have two lol..."</post>
   <post id="8e256729-4645-46da-a215-1042b0390351" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"Man, I would have a problem keeping up in fast-paced FPS games if I was sitting close to that monitor. I would LOVE to play some flight sims on that thing though. Are there any real differences between the Sony and the HP? His "Buy it Now" Price is $75 cheaper on the HP..."</post>
   <post id="90dc107c-683b-49db-89fe-82efbf82cb0c" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"HighwayAssassins said: wow i want a 24 inch widescreen SO bad...especially the 2405, but for $400 i would buy this shit in a heartbeat...if i had the $$ Congrats on the kick ass monitor dude, im sure you have many happy gaming hours ahead Click to expand... Keep in mind that this screen and the 2405 are not in the same size category and shouldn t be compared to each other when it comes to size considerations. The viewable area on the 2405 is much bigger (24 inches). The 2405 will probably beat the pants off the W900 in some areas (text sharpness in 1920x1200) while the W900 will probably win in black levels and various kinds of color benchmarks (and obviously viewing angle), as well as gaming. I would personally go for the 2405, but I can completely understand why some people go for the W900 instead, especially if they re gamers."</post>
   <post id="760aa5d7-e719-472f-b045-d14de44427d9" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"__Maad__ said: I would personally go for the 2405, but I can completely understand why some people go for the W900 instead, especially if they re gamers. Click to expand... Exactly why I went for the FW900 ..and you d be suprised how clean the text is in 1900x1200 (Not LCD clean of course) but even better I can run it at a lower resolution without worrying about image quality loss,I have the desktop set at 1600x1024 now and text is very clean. So far im blown away by this monitor, I was watching some 1080i clips in Awe with the monitor set at the proper 1920x1080 res (no black bars visible), the color is noticably better on this than my previous 21" G520P wich I already thought had excellent color, and the black level is black as it gets (same as my previous monitor). No complaints here p.s. viewable area on fw900 is 22.5""</post>
   <post id="5056bb31-78b8-47d5-a9d2-4c868f81c98b" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"taht my friend is a sweet ass looking monitor... man if i was out of college right now (lol and i just got in!) i would so get that, since i won t have to move it that much.... MAN that would be sweet for some movies (better blacks than a LCD)"</post>
   <post id="e84be479-609d-4b4f-9d2a-f986df4d4cb7" section="Displays" discussion="24&quot; Widescreen CRT (FW900) From Ebay arrived,Comments.">"How are you setting 1600x1024 on this puppy?"</post>
   <post id="28615b0e-c513-43db-b659-ac3cee99cfe0" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"This thread contains links mostly-in-depth reviews of the best reviewed monitors which use A-MVA panels. Only LED PWM dimming or Flicker Free/Safe monitors and monitors which use very high PWM frequencies are included. Read about the side effects caused by LED PWM Dimming here. Use Google or Chrome to translate reviews. Best 24" Options: BenQ GW2470H BenQ VW2430WH Iiyama X2483HSU BenQ GW2470H: Review by Playwares. BenQ VW2430WH: =DEAD= s Review =DEAD= s Iiyama X2483HSU Review =DEAD= s Samsung S24C750P Review Svete Hardware s Samsung S24C750P Review Best 27" Options: iiyama XB2783HSU (not available in North America) BenQ EW2740L BenQ EW2750ZL HP S270C: The HP is curved and has a 1% haze or "Almost-Glossy" coating which enhances image clarity and colour vibrancy Asus VN279Q =DEAD= s Asus VN279Q Review PRAD s Asus VN279Q Review. [H]ard Forum VN279Q Thread =DEAD= s BenQ EW2740L Review PC Monitor s BenQ EW2740L Review PRAD s BenQ EW2740L Review BenQ EW2705ZL review by PC Monitors BenQ EW2705ZL Review by Playwares The BenQ GW2460HS should perform like the 27," but there are no reviews. =DEAD= s BenQ GW2760HS Review PC Monitor s BenQ GW2760HS Review PRAD s BenQ GW2760HS Review TFT Central s BenQ GW2760HS Review Flat Panel HD s Eizo FG2421 Review Hardware Norway s Eizo FG2421 Review PRAD s Eizo FG2421 Review (Use Google or Chrome to translate) Pure PC Review Eizo FG2421 SWECLOCKERS Eizo FG2421 Review TFT Central s Eizo FG2421 Review [H]ard Forum Eizo FG2421 Thread (check this thread to read about the Eizos many quality control issues/horrible quality control) HP S270C Review by PRAD (Curved VA) =DEAD= s Iiyama XB2783HSU PRAD s Iiyama XB2783HSU-B1 Review (Use Google or Chrome to translate) =DEAD= s Samsung S27C750P Review NCX s Samsung S27C750P Review PC Monitor s Samsung S27C750P Review PRAD s Samsung S27C750P Review Samsung S27D590C review by PRAD Best 28" Monitors: They have less vibrant colours than the good 24 &amp; 27" 1080p options since they cover less of the sRGB colour space (&lt;90% vs 95%+) =DEAD= s Asus VN289Q Review. Read this post. Glossy Digital Versus iiyama X2888H Review. Matte Playwares ViewSonic VX2858SML Review. Glossy Best 32" Options: Top Pick: Crossver 32X2-P &amp; Philips BDM3270QP have better colour presets than the BenQ, are completely PWM Free unlike the Samsung (PWM free down to 30% brightness=135cdm/2 which is 2x too bright for dark room use IMO) and free from obvious overshoot ghosting unlike the Acer. Pick the Philips BDM3270QP if it is available from retailers with hassle free return and exchange policies since the Crossover must be ordered from Korean eBay sellers. Daywalkers Acer B326HUL Review: It suffers from really obvious overshoot ghosting but has better colour presets than the BenQ. Playerwares Crossover 32X2-P Review TFT Centrals BenQ BL3200PT Review Trusted Reviews BenQ BL3200PT Review Philips BDM3270QP Review by Digital Versus Philips BDM3270QP review by =DEAD= Philips BDM3270QP Review by Sweclockers Trusted Reviews Samsung S32D850T Review PRADs Samsung S32D850T Review"</post>
   <post id="09adbd8d-cbc1-4e92-9565-36bb4ccdf369" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"Could this A-MVA monitors be the best substitutes for my old PW201? Better than IPS or PLS? Thanks"</post>
   <post id="061a36fd-3824-440f-8afc-411875b56df8" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"There s also the Dell S2440L: http://www.tftcentral.co.uk/reviews/dell_s2440l.htm"</post>
   <post id="bc85fcc5-7c10-4928-a8e6-027e4d831111" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"The Dell sucks unless one considers very obvious overshoot ghosting, grayish blacks and extreme reflections caused by the glass good things. Some units use LED PWM Dimming."</post>
   <post id="5af159d3-507a-478a-aa8c-fbed29994be2" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"NCX, which one would you choose of those? Except the Eizo (expensive)."</post>
   <post id="fc8d4183-8f2e-496e-ace8-9c08d434edd1" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"NCX what do you think to the BL2410PT? I know it uses PWM but are there any other problems that you know of?"</post>
   <post id="47b38b0e-d895-4b7f-a324-bff948d11425" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"Wow that Eizo FG2421 is intriguing."</post>
   <post id="3ad5087b-4cfb-4fdd-bfb6-f43c5b9d5bd2" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"mathesar said: ↑ Wow that Eizo FG2421 is intriguing. Click to expand... And a major quality control fail. The FG2421 is a design using the rejected panels made for a $6,000 Geographic Info Systems monitor. All of these panels will display one type of visual defect or another. I ve been through 4 of them now and not a single one was "good" enough to pass my IS THIS WORTH 600 dollars test. 3 out of 4 of them would restart themselves for no apparent reason, including the NIB one with a center dead pixel (it literally just restarted itself and it has 0 hours on it) I have left which I m waiting for an RMA form and label from ProVantage to send back. These monitors are also being shipped poorly in very thin manufacturer s packaging with minimal protection and quite a bit of side to side play. My advice: avoid the headache and lost shipping costs."</post>
   <post id="545143d3-5f6e-4690-b0a9-415c51bea98f" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"What about the BenQ GW2255? Or is that the wrong kind of *VA? They were being blown out at my local Fry s for ~$85 and I picked up one for the server cabinet. I forgot a 22" widescreen would have trouble fitting into a spot that barely took a 19" 4:3 (dead, but the server is mostly headless), so... Is it worth keeping, or should I sell it off? I haven t found much on forums about this monitor, either. EDIT: since directly googling the product leads to a dead product link, here is the correct one from BenQ: http://www.benq.us/product/monitor/GW2255."</post>
   <post id="fa60f51b-61b4-440e-a7bd-ede58a126493" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"Read the thread title...best reviewed, there are no GW2555 reviews. Missing the BenQ EW2740L and PCM S other reviews which I will add later. Will also add links to the big [H] threads for a few of these. I like the Asus since it has a nice stand, slightly better overdrive &amp; better sRGB color space coverage than the 750P &amp; GW276HS, but it has 2x.5khz PWM frequency which I am unsure about. The BL2410 has slow pixels response times, uses PWM &amp; is not semi-glossy. The EW2740L is also pretty nice but I need to re-read PCM S review."</post>
   <post id="6a37c1c3-7c22-4af2-96ce-cc5b04bebabb" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"NCX said: ↑ Read the thread title...best reviewed, there are no GW2555 reviews. Missing the BenQ EW2740L and PCM S other reviews which I will add later. Will also add links to the big [H] threads for a few of these. I like the Asus since it has a nice stand, slightly better overdrive &amp; better sRGB color space coverage than the 750P &amp; GW276HS, but it has 2x.5khz PWM frequency which I am unsure about. The BL2410 has slow pixels response times, uses PWM &amp; is not semi-glossy. The EW2740L is also pretty nice but I need to re-read PCM S review. Click to expand... Hence the earlier post. Now I know there are (likely) absolutely no GW2525 reviews."</post>
   <post id="96fcc7f0-7cc4-4488-9727-4552375e3502" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"jeremyshaw said: ↑ Hence the earlier post. Now I know there are (likely) absolutely no GW2525 reviews. Click to expand... I have a GW2255, and this display would seem to be a very good value for the price. The contrast ratio is excellent (as would be expected from a VA panel) and color is as good or better than any low end IPS display. It does suffer from the usual VA contrast shift so that blacks become somewhat lighter towards the corners of the screen. My unit has no dead or stuck pixels, but it does have a minor backlight bleed along the left edge about an inch down from the top. It s not very noticeable even in a dark room looking straight at the screen, but there is a small blob of blue glow if you view the screen at an angle. All in all, I would say the GW2255 is probably a better choice than a low end HP or Dell IPS display. (I m really not sure why people are so high on IPS, given that most IPS displays have a contrast ratio well under 1000:1.)"</post>
   <post id="61ebcdc0-baa8-46f2-b0e5-56221a996213" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"NCX said: ↑ The BL2410 has slow pixels response times, uses PWM &amp; is not semi-glossy. Click to expand... thats not true, the newer models are PWM free!"</post>
   <post id="775b8bdb-8ad2-443e-8444-ce1bccd5967b" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"CyBoS said: ↑ thats not true, the newer models are PWM free! Click to expand... Is there a source for this? And how can you tell if your monitor is PWM free before opening the packaging?"</post>
   <post id="a94f129c-62a4-41c5-a7ae-62f92be080a7" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"http://www.computerbase.de/forum/showthread.php?t=1290495 in this german link you see the partnumbers which are flicker free http://www.benq.de/product/monitor/bl2410pt here is the second title for eye-care, which means flicker free here the same on the global page: http://www.benq.com/product/monitor/BL2411PT/ benq changed a whole bunch of products to flicker free technology!"</post>
   <post id="66723d25-23b2-4513-8299-dc9777b9de09" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"http://www.tftcentral.co.uk/articles/flicker_free_database.htm another link with a complete database"</post>
   <post id="73ecb4f3-32da-4f39-9cbb-a20d608eb7fa" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"Christian88 said: ↑ Is there a source for this? And how can you tell if your monitor is PWM free before opening the packaging? Click to expand... The newer revisions which are PWM free have different model numbers. Those are listed on the outside package. Thus, you can try to contact BenQ for the correct number then contact the retailer to check their product. (And naturally you dont tell the retailer which model number you re interested in before they check it. Cause some of them will just tell you anything you want to hear to make a sale.)"</post>
   <post id="2a634e30-300d-4afa-8c16-92f120034bdc" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"I didn t realize that BenQ updated the BL2410PT, still one would have to verify they are buying a PWM free version &amp; the BL2410PT is not semi-glossy which is why it didn t make the list."</post>
   <post id="d892640f-4129-4691-94be-56b2ecb87d2a" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"how about the iiyama X2483HSU or the XB2483HSU (which is exactly the same but with adjustable height  n stuff)? Anyone have experience with that one? Or some reason it would be good/bad?"</post>
   <post id="a8fd5f6a-e172-4cab-ac09-c69c41041a8f" section="Displays" discussion="Best Reviewed A-MVA Monitor Thread: Read the 1st Post">"From the 1st Post =DEAD= s Iiyama X2483HSU Review (Use Google or Chrome to translate)."</post>
   <post id="03848ff2-41e1-4bbf-993f-c43c494e907d" section="Displays" discussion="Wasabi Mango UHD430 REAL4K HDMI 2.0">"saw this @Linustechtips.com, it seems Wasabi Mango revealed a 43" variant on their website. It is similar to UHD420 Real4K HDMI 2.0 in terms of spec. Not much info besides specs was revealed at this moment, even pricing and availability. http://linustechtips.com/main/topic...with-hdmi-20-and-displayport-12/#entry6048666 http://wasabimango.co.kr/bbs/board.php?bo_table=product_1&amp;wr_id=35&amp;sca=43형&amp;sfl=wr_10&amp;stx= http://prod.danawa.com/info/?pcode=3434200&amp;keyword=uhd430#bookmark_cm_opinion"</post>
   <post id="9cb76cd6-da3a-4c04-a77b-638d597c2e56" section="Displays" discussion="Wasabi Mango UHD430 REAL4K HDMI 2.0">"On Danawa.com pricing of UHD430 was revealed . It was priced around $739000 won to $850000 won,which is around $625 to $719."</post>
   <post id="918461c7-27b2-4f7c-9945-d291cfe31ba2" section="Displays" discussion="Wasabi Mango UHD430 REAL4K HDMI 2.0">"Why is no one talking about this monitor?"</post>
   <post id="e2224f3f-548a-49c1-bdae-c72df0685b50" section="Displays" discussion="Wasabi Mango UHD430 REAL4K HDMI 2.0">"I m guessing because the wasabi units are ebay gambles and shipping a large heavy object back to korea on your dime isn t terribly appealing. If a squaretrade warranty is available that might help but it s still going to be a longer process than popping your screen down to your local bestbuy."</post>
   <post id="f7f67866-fd33-4755-a29b-9f21db6f9407" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Today, on the eve of PAX Prime, we are excited to announce the Dell 27 Monitor (S2716DG) – the first gaming monitor to join our award-winning portfolio. Serious gamers can discover unrivaled gameplay with a smooth and responsive view. The S2716DG is designed to provide an uncompromising gaming experience with sharp and undistorted moving images, thanks to NVIDIA’s G-Sync Gen II technology and the fastest refresh rate at 144Hz. Its swift 1ms response rate offers virtually no input lag. The Dell 27 Monitor is also packed with uncompromising performance features to further enhance gameplay, including: Nvidia’s G-Sync Gen II support feature synchronizes GPU and monitor to minimize graphic distortions and screen tearing Quad HD resolution of 2560 x 1440 with close to 2 times more onscreen details than Full HD A full range of adjustability features, like tilt, pivot, swivel and height-adjustable stand allow for long hours of comfortable gameplay A wide range of connectivity features, including DisplayPort 1.2, HDMI 1.4, four USB 3.0 ports, USB 3.0 upstream, Audio line-out &amp; Headphone-out Starting at $799.99, the new Dell 27 Gaming Monitor (S2716DG) will be available in the US on Dell.com beginning Oct. 20. Click to expand... http://en.community.dell.com/dell-b...irst-gaming-monitor-and-new-27-curved-display Edit 0: What goes unsaid is how the 1ms response time implies TN, which implies the same panel as ASUS SWIFT (or an upgraded version of it). Also gone unsaid is exactly what Gsync 2 is. Dell has linked to a PDF for a workstation expansion card that I ve never heard of before ("NVIDIA® Quadro™ G-Sync™ II is an option card for the NVIDIA Quadro 6000. Featuring frame lock and genlock functionality"). In any case, we know this new gsync monitor supports both DP and HDMI, and we know past-gen gsync monitors did not. Also noteworthy: It s got a premium price ($800 USD), despite launching LONG after the ASUS SWIFT."</post>
   <post id="e8d789ce-1d64-4f12-bcb3-60f80df5a531" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"in a league of their own"</post>
   <post id="0302ff9e-1890-4083-a84c-a507b899b0e9" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Oh good now all the people who cry about Asus s QC can go buy this one instead"</post>
   <post id="e697cb31-f6bc-4aa8-82fe-d45fdb584e85" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Dell are making gaming products now?"</post>
   <post id="2d85564f-ec18-44c7-8700-430f420610a5" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Knowing Dell, this will be hugely discounted a couple of months after release."</post>
   <post id="d1553aa2-60c1-4268-98c4-a7f5ea154f9b" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Nvidia says nope on the G-Sync II http://www.pcworld.com/article/2977500/displays/dells-first-gaming-display-doesnt-really-pack-g-sync-gen-ii-but-it-still-looks-nice.html#tk.rss_all"</post>
   <post id="abccef78-cdfd-47a9-9074-d774969e9f52" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"I m kind of shocked to see that Dell are producing a G-Sync display. Shame that it s a TN panel rather than IPS though."</post>
   <post id="01f05fe7-828c-4762-8485-91a6b8a7aade" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"zone74 said: ↑ I m kind of shocked to see that Dell are producing a G-Sync display. Shame that it s a TN panel rather than IPS though. Click to expand... Well it s either speed or viewing angles. but dell already has plenty of good ips panels so.."</post>
   <post id="3ffa353e-e953-41b5-8888-75a4b63f90c7" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Geforcepat said: ↑ Well it s either speed or viewing angles. but dell already has plenty of good ips panels so.. Click to expand... None of them are gaming IPS screens, and it s not just about viewing angles it s about color reproduction as well, now that IPS and VA gaming screens are starting to come out it seems ludicrous to me to pay 800$ for a TN screen. You can get the Acer XB270HU for the same price..."</post>
   <post id="d3d0c965-f334-4219-ba08-ca0c371cefb2" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"prolifik said: ↑ Nvidia says nope on the G-Sync II http://www.pcworld.com/article/2977500/displays/dells-first-gaming-display-doesnt-really-pack-g-sync-gen-ii-but-it-still-looks-nice.html#tk.rss_all Click to expand... The original g-sync module only allowed a single DP input, so something has obviously changed in the specs that they can now also include an HDMI connection. I would potentially consider this monitor as long as Dell doesn t insist on covering it with some dog shit AG that ruins the image quality."</post>
   <post id="e6493d2a-2ab9-416c-be64-973158830318" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"cybz said: ↑ None of them are gaming IPS screens, and it s not just about viewing angles it s about color reproduction as well, now that IPS and VA gaming screens are starting to come out it seems ludicrous to me to pay 800$ for a TN screen. You can get the Acer XB270HU for the same price... Click to expand... No FUD about TN in this thread please. The Asus Swift panel has better color than some IPS displays. Tftcentral ran the numbers and proved the color accuracy: http://www.tftcentral.co.uk/images/asus_rog_swift_pg278q/comparison_2.png ("If DeltaE &lt;2, LaCie considers the calibration a success; there remains a slight difference, but it is barely undetectable. If DeltaE &lt; 1, the color fidelity is excellent.")"</post>
   <post id="f4a1c4a7-0a50-45fc-a7b2-430ae0bf0ecf" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"bAMtan2 said: ↑ No FUD about TN in this thread please. The Asus Swift panel has better color than some IPS displays. Tftcentral ran the numbers and proved the color accuracy: http://www.tftcentral.co.uk/images/asus_rog_swift_pg278q/comparison_2.png ("If DeltaE &lt;2, LaCie considers the calibration a success; there remains a slight difference, but it is barely undetectable. If DeltaE &lt; 1, the color fidelity is excellent.") Click to expand... Ran numbers from the middle of the screen with a little device. Wake up, you don t stick your eyeballs onto the screen in the middle. I hate IPS glow myself so avoid IPS generally, but TN colour shift is a big issue that only blind people underplay."</post>
   <post id="2ae67ba3-1e86-4446-aa0c-2b717fb6c1f7" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"bAMtan2 said: ↑ No FUD about TN in this thread please. The Asus Swift panel has better color than some IPS displays. Tftcentral ran the numbers and proved the color accuracy: http://www.tftcentral.co.uk/images/asus_rog_swift_pg278q/comparison_2.png ("If DeltaE &lt;2, LaCie considers the calibration a success; there remains a slight difference, but it is barely undetectable. If DeltaE &lt; 1, the color fidelity is excellent.") Click to expand... color accuracy isn t everything and those are default aka out of the box measurements, which are almost always fucking horrible. a modern calibrated tn will never be more accurate than a modern calibrated ips, nor will the color be as pleasing to the eye. so no, "the asus swift panel has better color than some ips displays" is complete horse shit. give me a break. this monitor should either be ips/va or $200 less."</post>
   <post id="fcd84709-af93-4dde-84b6-e2cd9772bc1e" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Surprised they use G-Sync, since AdaptiveSync/FreeSync is a standard which should be pushed forward instead. This thing of selecting a monitor based on Nvidia/AMD is ridiculous."</post>
   <post id="09f9e08f-1c10-4896-8677-ac269ec831c1" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"bAMtan2 said: ↑ No FUD about TN in this thread please. The Asus Swift panel has better color than some IPS displays. Tftcentral ran the numbers and proved the color accuracy: http://www.tftcentral.co.uk/images/asus_rog_swift_pg278q/comparison_2.png ("If DeltaE &lt;2, LaCie considers the calibration a success; there remains a slight difference, but it is barely undetectable. If DeltaE &lt; 1, the color fidelity is excellent.") Click to expand... Color accuracy doesn t mean a whole lot on a TN panel when the viewing angles are like this: It s the same reason that an "accurate gamma" doesn t mean anything on a VA panel. VA on the left, IPS on the right. I wouldn t pay a premium for any non-IPS panel. Geforcepat said: ↑ Well it s either speed or viewing angles. but dell already has plenty of good ips panels so.. Click to expand... The majority of motion blur is caused by image persistence rather than panel response times. IPS vs TN won t make much of a difference if you re using G-Sync."</post>
   <post id="94d0cc30-4f44-418c-bd91-f020dc4ba44e" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"you mean ULMB."</post>
   <post id="4fc7bf8c-1c77-4798-9c03-0cf227d7031a" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Firepc said: ↑ TN colour shift is a big issue that only blind people underplay. Click to expand... Odellus said: ↑ "the asus swift panel has better color than some ips displays" is complete horse shit. Click to expand... zone74 said: ↑ Color accuracy doesn t mean a whole lot on a TN panel when the viewing angles are like this: Click to expand... No IPS trolls in this TN thread, please. It s well documented by real users that Asus Swift is TN and looks amazing when you re sitting in front of it and using it, which is exactly what it s for. And this Dell will probably look similar. If you don t have anything nice to say, don t say anything at all... Especially if you ve never used a $800 TN before."</post>
   <post id="76b2b11d-2f5f-458a-9077-6e330cf6821a" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"Odellus said: ↑ you mean ULMB. Click to expand... No, I meant G-Sync. If you re using G-Sync you have a minimum of 7ms motion blur due to persistence at 144Hz. That extends down to 33ms at 30Hz. Not that panel response times don t matter at all, but on a full persistence display they are not the main cause of motion blur. With ULMB, if the panel response is faster than the refresh rate (85Hz = 12ms) then there should be no panel-based motion blur at all. bAMtan2 said: ↑ No IPS trolls in this TN thread, please. It s well documented by real users that Asus Swift is TN and looks amazing when you re sitting in front of it and using it, which is exactly what it s for. And this Dell will probably look similar. If you don t have anything nice to say, don t say anything at all... Especially if you ve never used a $800 TN before. Click to expand... The photo I posted was taken from the same TFT Central review of the ROG Swift as the image you posted to prove its "accuracy". When there are now similarly specced IPS panels in that price-range, I don t see why anyone would pay that much for TN."</post>
   <post id="0732f5bb-91ad-4c29-aa8c-e445c3bc97a6" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"bAMtan2 said: ↑ No IPS trolls in this TN thread, please. It s well documented by real users that Asus Swift is TN and looks amazing when you re sitting in front of it and using it, which is exactly what it s for. And this Dell will probably look similar. If you don t have anything nice to say, don t say anything at all... Especially if you ve never used a $800 TN before. Click to expand... i don t need to use an $800 TN to to know what a TN looks like. my VG236 calibrates to essentially the same accuracy as a PG278Q and it absolutely looks worse than my PLS QX2710. color shift is visible viewing it head on and it s only a 23" screen, i imagine it s significantly worse on larger screens. IPS is superior and that s a fact, whether the difference is as big as some would like to make it out to be or not is irrelevant. that being said, this being the same price as its IPS competitor makes no sense. not to mention that it s over a year late to the market AND you can buy essentially the same thing sans an HDMI port in the PG278Q for $130 less. dell is either completely unaware as to what s going on in this segment of the market or they think their brand carries more weight than it actually does."</post>
   <post id="9bbd639b-af05-46a9-a325-0b28cc1358df" section="Displays" discussion="Dell S2716DG, 27&quot; 2560x1440 144hz 1ms &quot;G-Sync Gen II&quot;, DP+HDMI">"bAMtan2 said: ↑ No IPS trolls in this TN thread, please. It s well documented by real users that Asus Swift is TN and looks amazing when you re sitting in front of it and using it, which is exactly what it s for. And this Dell will probably look similar. If you don t have anything nice to say, don t say anything at all... Especially if you ve never used a $800 TN before. Click to expand... Breaking news!!! People have different opinions doesn t mean they are trolls. If you can t handle a little debate just don t log on."</post>
   <post id="53e25dd7-a53c-4f6b-a347-50e8866757fc" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Hey folks I have a VIZIO E470I-A0 (47-inch 1080p LED Smart HDTV) that just failed on me yesterday. I purchased it as an open-box item from walmart a couple months ago for less than $300. I know it is a POS compared to most TV s, but it does the trick. Returning it is not an option. Anyway, the screen had some issues with flickering in the top right corner for a couple weeks, then suddenly it got really big dark blotch in the middle. I could still use it, but the entire middle of the display was dim. Yesterday I turned it on and the power indicator LED turned on, but the display did not. Sound was still working. I held a flashlight to the screen and could see the image displayed. I was able to navigate to the menu and reset to factory defaults to no avail. From what I am reading online, it sounds like the issue is the inverter board. I opened the TV and I don t see any blaringly obvious cap bursts. Parts for this TV are really cheap on ebay, but I want to be sure I am replacing the right part. Some auctions use the term inverter board and power supply board together even though they seem to be different parts. Displays are not my cup of tea and this is really foreign to me. I appreciate any advice you folks can give to a fellow [H] member. :-D btw, i can take pictures if that helps."</post>
   <post id="1eff779e-d13b-4c25-aab0-bc97b524f152" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Are there a lot of boards?"</post>
   <post id="cb898ecb-7188-417c-a259-b789ecc74e5b" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Visibly there is a power supply board and a mainboard. From the mainboard, two ribbon cables lead to the bottom of the TV where there are 2 protected LED boards; one for each half of the screen. When I search ebay it seems there are really only a couple things that can be replaced. I dont think the LED strips are supposed to be removed because I have not seen any for sale anywhere. http://www.ebay.com/sch/i.html?_trk...&amp;_nkw=VIZIO+E470I-A0+parts&amp;_sacat=0&amp;_from=R40"</post>
   <post id="1d48ab9b-cf35-425c-bc73-1ffcaaa6d953" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Just bought a power supply from here for a Panasonic plasma tv. Works nice."</post>
   <post id="912af0c2-9590-4109-865e-aa3f636e5aa6" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"King Icewind said: ↑ Just bought a power supply from here for a Panasonic plasma tv. Works nice. Click to expand... Thanks for response. Yea I keep seeing that site. What issue were you trying to resolve by buying the power supply? I just want to know which part needs to be replaced."</post>
   <post id="a2eddfdd-8e8e-4b2a-a600-d900d5034b18" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"The TV made a loud popping noise and would no longer display anything. Upon further research I found that there was actually a diagnostic built into the TV similar to cars. The front LED light that shows whether the TV is on or off will flash so many times when you immediately press and hold the power button for 5 seconds upon plugging the TV in. Counting the amount of flashes tells you what s wrong. The flashing code I got meant the power supply was bad. It was also a common problem with the TV. Replacing it was very easy. I d try to see if there is a similar diagnostic method for your TV. Shop Jimmy actually had a youtube video for my exact TV model explaining it. I suppose I could have gone rummaging around for a popped capacitor, fuse, etc. but replacing it entirely was much easier. Also there was a warranty on the replacement part. I can t remember the exact name but there was a seperate board in the TV that powered just the signal to the display/panel. I d check into that."</post>
   <post id="010db2d0-bb6f-4beb-8311-c669cd38dac7" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Indeed. Anyone have any suggestions?"</post>
   <post id="779c9e0d-5f2c-4cef-90e9-e4ad67eb8706" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Dupe"</post>
   <post id="6f4a466e-6afc-4274-81b3-94c8315f162f" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Posted on wrong thread sorry. Ill post back here if i get it fixed though"</post>
   <post id="66d7bd4e-4ed9-4977-90ed-a037acd98968" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"I fixed these for a few months and flipped them. Basically, unless it s a blown cap or loose wire/connection, you re going to have to spend a good deal of money to replace a part. Troubleshooting the boards is a very time consuming, difficult, and dangerous process. Most of the units I repaired were Vizio or Westinghouse, and when factoring in labor, it was a waste of time."</post>
   <post id="600e0eb4-fa61-4307-9bff-e2c792a7105f" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Damn. That is disheartening. :-("</post>
   <post id="7cbccf93-088f-4bfb-875b-703f0877b1bc" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"I went ahead and replaced the power supply board. The TV turned on once and worked for a few minutes. I was so happy! ...but when I turned it off the same problem started happening. Now if I keep turning it off and on it will work maybe once out of every 20 tries. Once it gets going it is fine, but all the other times the backlight doesn t light up. Anyone? I would seriously greatly appreciate some advice. :-("</post>
   <post id="fb28a9a7-25cd-44b5-bdc8-450e8dc24f22" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Having mario kart 8 withdrawals"</post>
   <post id="ccc046db-6bf1-4cd9-8666-dd6e723031fa" section="Displays" discussion="Trying to repair backlight issue for a Vizio TV - couple questions">"Dark12 said: ↑ I went ahead and replaced the power supply board. The TV turned on once and worked for a few minutes. I was so happy! ...but when I turned it off the same problem started happening. Now if I keep turning it off and on it will work maybe once out of every 20 tries. Once it gets going it is fine, but all the other times the backlight doesn t light up. Anyone? I would seriously greatly appreciate some advice. :-( Click to expand... Hey just wondering if you still have the tv if sowould you be willing to sell it ineedthe led screen for parts i have completetv just the ledis broken"</post>
   <post id="50397c48-7929-4885-92b4-88d378378ecd" section="Displays" discussion="2016 Vizio P Series">"I wanted to start conversation here on the recently announced Vizio P series. It has caused quite a stir in the home theater community due to the features offered, price point, using casting instead of TV apps, and lack of a built in tuner. Brief specs and pricing: 4k, HDR, DolbyVision, FALD 50" - $999 VA, 60hz 55" - $1299 IPS, 120hz 65" - $1999 VA, 120hz 75" - $3799 VA, 120hz HDMI 1-4 support the following: 2160@60 4:4:4, up to 8bit per color 2160@60 4:2:2, up to 12bit per color 2160@60 4:2:0, up to 12 bit per color HDMI 5 is a low latency (gaming) port that supports: 2160@60, 4:2:0, up to 10bit per color 1080p@120, 4:4:4, up to 10bit per color ~15ms latency in game mode Vizio Product Page RTINGS Review of the 65" AVS Owners Thread I m considering purchasing one for monitor use, deciding between a 50" VA 60hz and a 55" IPS 120hz. No word on PWM to my knowledge. Those of you who have used a 50"-55" display as a monitor, how far away do you sit to see it all without moving your neck? Those of you who are good at math, how far away would I have to sit from a 50" VA panel with a 17 degree viewing angle to avoid gamma shift due to sitting too close? Does FALD help contrast on IPS?"</post>
   <post id="b41a7647-3f6d-410f-bf0e-c54b18ed847b" section="Displays" discussion="2016 Vizio P Series">"Unfortunately gaming mode 4K is 4:2:0, which looks horrid."</post>
   <post id="beeb04ab-e8b8-46c9-8c40-183007086055" section="Displays" discussion="2016 Vizio P Series">"Waiting for someone to bite the bullet and test input lag on the non "gaming" ports. (+1 on the fuck 4:2:0 camp here) Granted you still can t really correctly test 4k with any of the current testing gear, but I d still take first hand owner accounts over the home theatre "review" sites. I have brown spots (dead backlight array leds) on my samsung JS which qualifies for a full replacement/credit under the extended store warranty, but I m intentionally waiting a bit to see whether I d want any of the this years screens first. The KS models are actually a downgrade at the same model #s, kinda sad how it reminds me of the nvidia/ati rebranding crap."</post>
   <post id="0be8797b-4679-4ee5-828e-4f232cd9f21a" section="Displays" discussion="2016 Vizio P Series">"Vega said: ↑ Unfortunately gaming mode 4K is 4:2:0, which looks horrid. Click to expand... Rtins says you can do 4K and 4:4:4 60hz But it does say "4:4:4 is blurrier than on other TVs that support it." Whatever that means..."</post>
   <post id="835979f8-fa79-493e-9a8a-719d5d8f3fe7" section="Displays" discussion="2016 Vizio P Series">"Aluminum said: ↑ Waiting for someone to bite the bullet and test input lag on the non "gaming" ports. (+1 on the fuck 4:2:0 camp here) Granted you still can t really correctly test 4k with any of the current testing gear, but I d still take first hand owner accounts over the home theatre "review" sites. I have brown spots (dead backlight array leds) on my samsung JS which qualifies for a full replacement/credit under the extended store warranty, but I m intentionally waiting a bit to see whether I d want any of the this years screens first. The KS models are actually a downgrade at the same model #s, kinda sad how it reminds me of the nvidia/ati rebranding crap. Click to expand... Rtings put it at 37ms on non-gaming ports."</post>
   <post id="8c7966c0-a0b0-4cf5-89b5-04f654187520" section="Displays" discussion="2016 Vizio P Series">"What about this as a PURELY TV watching set? Worth the $?"</post>
   <post id="2c5edfb3-5fc0-4715-9524-ad17954aa826" section="Displays" discussion="2016 Vizio P Series">"bandit390 said: ↑ Rtins says you can do 4K and 4:4:4 60hz But it does say "4:4:4 is blurrier than on other TVs that support it." Whatever that means... Click to expand... Hmm, that kind of worries me, other than the panel quality/type variations there should be no difference in what you see, 1:1 with subpixels is 1:1 with subpixels. This implies they might be cheating or fudging it somehow Fuck, now I really really really want to see someone take a picture of the usual 4:4:4 test pictures from PC output. Worst buy near me needs to get some on the floor I can play with. bandit390 said: ↑ Rtings put it at 37ms on non-gaming ports. Click to expand... Yeah at 1080p, they can t test 4k input lag yet. Some tvs have way worse delay at 4k than 1080p because they don t really turn off all their stupid image processing effects. If they do proper PC/native 1:1 modes that turn off processing it should have equal or possibly even lower latency since no scaling is needed."</post>
   <post id="e97555b4-e283-4678-8893-ffe4b581bd74" section="Displays" discussion="2016 Vizio P Series">"delita said: ↑ What about this as a PURELY TV watching set? Worth the $? Click to expand... The usual AV / home theatre discussion places have 100+ page posts about these as a TV, what I ve read overall seems positive so far. HF is one of the few places that has the rare double-combo of enough people that 1) care about PC input and 2) actually understand the shit that matters behind PC uses. The samsung threads are a good example of this. There are a handful of smart users on AVS and other places but they get drowned out by the 5000 "this shows the red highlights in RandomBlurayMovie#6172 better than OtherBrand blah blah blah"."</post>
   <post id="3c65e182-8e02-4ac4-9e7a-94eba47917bd" section="Displays" discussion="2016 Vizio P Series">"Aluminum said: ↑ The usual AV / home theatre discussion places have 100+ page posts about these as a TV, what I ve read overall seems positive so far. HF is one of the few places that has the rare double-combo of enough people that 1) care about PC input and 2) actually understand the shit that matters behind PC uses. The samsung threads are a good example of this. There are a handful of smart users on AVS and other places but they get drowned out by the 5000 "this shows the red highlights in RandomBlurayMovie#6172 better than OtherBrand blah blah blah". Click to expand... LOL, yeah. I just needed a new 65" for my living room. I game on Gsync but a lot of people on HF only talk about displays from a PC use perspective and I was just curious on how this guy performed as a regular ole TV"</post>
   <post id="74f16cac-b3c1-41e6-ae9e-c7ed72ce4a6d" section="Displays" discussion="2016 Vizio P Series">"According to rtings the P series use PWM, but they don t elaborate on the frequency."</post>
   <post id="2ad81c77-d5a3-4f2c-9b98-2b12b573a4cc" section="Displays" discussion="2016 Vizio P Series">"Purely on the TV aspect of it: no tuner (not a big deal for most people) and it uses Google Cast for "smart TV" content. This is an interesting feature as this means you are using Google s cast TV apps not "native" TV apps. The set comes with a tablet with Vizio s branded "SmartCast" app for the TV, so this is basically a TV with a built in chromecast. The way I understand it, this means your 4K viewing options are limited to whatever 4K is supported by Google Cast. (E.g., no Amazon 4K streaming.) I cannot definitively figure out if Netflix 4K is supported but comments here and there seem to think it is. Does anyone know if Chromecast now works with 4K Netflix? I think it would be crazy for Vizio to go this route if they could not deliver streaming 4K Netflix. The other thing I cannot figure out, if the TV runs on Google cast, can you use wired ethernet rather than stream wirelessly? It has a wired ethernet port, but if it has no apps on the TV and depends on a wireless connection to the tablet and the SmartCast app, I m a little confused how it would all work. I can t find an answer to this on AVS forum or other forums with 100+ page threads. My current set up just runs all my streaming content from my PC to my TV, but having used smart TV s and Roku s recently at other people s houses, these devices have come a long way and the convenience of a dedicated streaming TV app or peripheral, rather than using my PC, is actually something I d like to move over to. For the non TV part of it, the low input lag is intriguing even with the 4:2:0, since for me my "fast-twitch" games are on console, and my casual games are on PC, so I could use one of the 4:4:4 chroma ports for my PC and probably live with 4:2:0 from my console in the "game" port."</post>
   <post id="c0298abe-ba86-4376-af89-91402debeede" section="Displays" discussion="2016 Vizio P Series">"illram said: ↑ The other thing I cannot figure out, if the TV runs on Google cast, can you use wired ethernet rather than stream wirelessly? It has a wired ethernet port, but if it has no apps on the TV and depends on a wireless connection to the tablet and the SmartCast app, I m a little confused how it would all work. Click to expand... I have the P65-C1 and can hook it up to ethernet, but I think then I m limited to casting via the Chrome extension? Is that something you d want tested?"</post>
   <post id="5e66de9d-8642-4657-a678-bf0452f9ffab" section="Displays" discussion="2016 Vizio P Series">"I just picked up the 50". Everything is good so far, but I can t get 4:4:4 to show under nvidia control panel. Any suggestions?"</post>
   <post id="f87b7353-c877-40f3-8d87-f8e9319f3f11" section="Displays" discussion="2016 Vizio P Series">"bandit390 said: ↑ I just picked up the 50". Everything is good so far, but I can t get 4:4:4 to show under nvidia control panel. Any suggestions? Click to expand... What GPU/cables/adapters are you using? Official Vizio 2016 P Series Owners Thread (UHD/HDR/DV) No Price Talk Please - AVS Forum | Home Theater Discussions And Reviews First post has information about how to get it working. Edit: Just saw that you already posted in that thread. Looks like you need to use HDMI1-4 and not 5."</post>
   <post id="2e1d21a6-57ea-44df-b55a-485dff02298f" section="Displays" discussion="2016 Vizio P Series">"Snowknight26 said: ↑ What GPU/cables/adapters are you using? Official Vizio 2016 P Series Owners Thread (UHD/HDR/DV) No Price Talk Please - AVS Forum | Home Theater Discussions And Reviews First post has information about how to get it working. Edit: Just saw that you already posted in that thread. Looks like you need to use HDMI1-4 and not 5. Click to expand... Thanks!"</post>
   <post id="18cbbc6b-5bbf-4591-ba3a-3162fb41f239" section="Displays" discussion="2016 Vizio P Series">"I just got moderately interested in the 55 inch model only to read they don t have built in tuners OTA and streaming are all I use for media."</post>
   <post id="68ca5bfd-21ee-45f8-981e-78897075b30e" section="Displays" discussion="2016 Vizio P Series">"Ocellaris said: ↑ I just got moderately interested in the 55 inch model only to read they don t have built in tuners OTA and streaming are all I use for media. Click to expand... But they basically come with Chromecast-equivalent so you can use Plex or Kodi to stream everything. Take a look at the massive AVSforum thread for more info."</post>
   <post id="f35702d1-98cc-4738-bcf8-f17be84a574d" section="Displays" discussion="2016 Vizio P Series">"kabobi said: ↑ But they basically come with Chromecast-equivalent so you can use Plex or Kodi to stream everything. Take a look at the massive AVSforum thread for more info. Click to expand... "Everything" doesn t include OTA sports though. And I ve yet to see a TV s built in apps be as flexible as something like a FireTV, so what software they build in to the TV (and won t update after a few months) doesn t matter much to me. The software on two Smart TVs I ve had has been dreadful."</post>
   <post id="3c07a380-14d7-4b77-b371-2c01a00f5c9c" section="Displays" discussion="2016 Vizio P Series">"Snowknight26 said: ↑ I have the P65-C1 and can hook it up to ethernet, but I think then I m limited to casting via the Chrome extension? Is that something you d want tested? Click to expand... Awesome. Yeah I guess I d just like to find out if the TV can stream via the wired connection, and you just use the smartcast app to control the TV, or does it actually force you to stream from the wireless tablet (or equivalent). Ocellaris said: ↑ "Everything" doesn t include OTA sports though. And I ve yet to see a TV s built in apps be as flexible as something like a FireTV, so what software they build in to the TV (and won t update after a few months) doesn t matter much to me. The software on two Smart TVs I ve had has been dreadful. Click to expand... On topic with the above...the TV is basically just piggybacking on Google Cast, and ditching its (defunct) TV app partnership (I believe with Yahoo). So as long as Google Cast remains updated, the Vizio will also see the same updates. It s an interesting idea and it basically makes Vizio s smart TV solution on par with the big players like Amazon and Samsung and LG as far as reliability with updates."</post>
   <post id="c51703ff-0371-476c-bc49-62571e5e4db0" section="Displays" discussion="2016 Vizio P Series">"Ocellaris said: ↑ I just got moderately interested in the 55 inch model only to read they don t have built in tuners OTA and streaming are all I use for media. Click to expand... I thought HD tuners were mandated by law."</post>
   <post id="5bb0ef1d-9a27-4482-b78e-3638e8f23e6e" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"As the title says, I m curious about monitors that have been announced and coming out in the next year or so. With Nvidia s lineup launching soon and Amd s Polaris shortly after, I m hoping the 4K experience will be better, especially if Vega ends up launching this fall, which I m sure there would be a Ti variant from Nvidia shortly after that. We should be in for a pretty decent 4k60 upgrade on the high end cards later on even with more current games. As long as reviews hold up, that will get me to take the plunge and upgrade my Lightning 290X and 1440p monitor. With my desk setup I have a 40" 1080p as a secondary monitor, I ve tried putting it in place of my monitor to see if a 40" 4k would fit good, but physically thats just too large for my main screen with how I sit. So I m interested in 34" max. With all that said, technically speaking, I don t have any specific requirements on sync ranges, I would like it to be non TN though, IPS or VA panel. Don t really care about price, just looking for a solid quality 4k sync monitor."</post>
   <post id="4a905aa2-363f-4233-88e1-c82189ac85ac" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"There s already at least one; Acer Predator XB321HK comes in at 32", 4k, 4ms, IPS. However as far as I can tell it is DP 1.2 rather than the newer 1.4 which the new cards supposedly support, that and it is very expensive. there s a 34" ultrawide predator also from acer if you re into that format, not my thing personally, and also very expensive. Or you can wait it out and see when displayport 1.4 makes it into some screens."</post>
   <post id="09ebd4b7-3963-46a8-a037-34178c7b3d29" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"The problem is that none of the video cards are really fast enough to 4k at high framerates yet, and the whole appeal behind DP 1.4 is that you can do 4k @ 120hz."</post>
   <post id="edf26b4a-a360-404a-9aa1-5228db589281" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"As far as I know the 32" Acer is the only one on the market, and we haven t heard anything new about similar displays coming. The market for high-end gaming displays seems to be stuck on 27" 1440p and 34" ultrawide at the moment."</post>
   <post id="47e842d4-050d-48ac-8335-38667bda27d9" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"nvidia has this new tech call FastSync that supports all displays I think. This is more exciting than the gtx 1080 itself tbh."</post>
   <post id="47a240da-a360-4c9e-a76c-a51203201070" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"realworld said: ↑ nvidia has this new tech call FastSync that supports all displays I think. This is more exciting than the gtx 1080 itself tbh. Click to expand... Have a link? I would be very interested in this. To have the sync range and clarity of G-Sync and the compatibility with Adaptive-Sync would be pretty exciting."</post>
   <post id="1ffc39d7-1aa1-4a7f-8be0-d9244ed25ba4" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"There is a presentation. It sounds like FastSync reduces the input lag of Vsync On and removes the tearing of Vsync Off, but only when the framerate is higher than the refresh rate. It s complementary to G-Sync but also works without. It doesn t do anything when framerate drops below the refresh so it s not any kind of alternative. It will also work on cards older than Pascal."</post>
   <post id="8595e5fe-2f78-4838-a234-7d81e81e3a41" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"FastSync is exclusive to 1080 and 1070 I imagine? That s a shame."</post>
   <post id="3cfb2f1f-1d74-4f59-811e-c9cfee61db22" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"No, at 7:48 Petersen says they ll make it available for older revisions too"</post>
   <post id="7b504bc7-ed56-40fe-8bf0-c91e7cf5f0f5" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"igluk said: ↑ No, at 7:48 Petersen says they ll make it available for older revisions too Click to expand... Thanks. Good news for me, then."</post>
   <post id="1c2e1a46-85a7-4654-978a-ef5fe0f78f78" section="Displays" discussion="Any upcoming 30-34&quot; 4k UHD Freesync/Gsync Monitors?">"From earlier in the presentation - it s also intriguing that games start supporting HDR soon already NVIDIA GeForce GTX 1080 full presentation | VideoCardz.com (the leaked slides) http://cdn.videocardz.com/1/2016/05/VC-GTX-1080-73.jpg http://cdn.videocardz.com/1/2016/05/VC-GTX-1080-78.jpg Whenever supporting monitors start to come out - maybe within a year - (TV s have already started to approach the HDR standard), the SDR sRGB gaming displays available now will quickly be outdated. edit: Here is the HDR part of the presentation He says HDR monitors come early 2017 (10:49) Btw. Does FastSync also help with tearing when the framerate is lower than the refresh? Watching the presentation again, I m not so sure"</post>
   <post id="072c7f6b-d234-4753-b637-1084bf460629" section="Displays" discussion="u2711 upgrade">"I have had this U2711 for the past 6 years thanks to an [H] member and my nephew wants an upgrade from his 1080p. I am afraid that without having a 144hz IPS panel side by side I will not be able to discern a difference. For those of you upgrading from a great monitor with 60hz and moved on to 120hz+ --- is it worth it? At this time we have decided upon an Acer Predator xb271hu and a U2715. ($750 vs $510) The Pred x271hu has great reviews compared to the ASUS - but inferior warranty to Dell. The Dell UltraSharp is a newer version of the one I use so I am biased in believing it will be just as great -- plus the warrant exchanges even for 1 dead pixel -- but inferior refresh rate. What would you choose? At this time I m edging to the cheaper u2715 because consistent 60fps at 60hz should be just as smooth as 144hz if you are between 60-144fps due to hardware limitations. I used to have a 120hz crt back in the day and got used to this 60hz panel and never looked for anything more. Am I making the right choice in saving money by not buying into the marketing, that says a 144hz+ stock image vs the Gaussain Blur applied 60hz stock image is superior therefore demand a superior price?"</post>
   <post id="80cfadea-6b9e-4b58-8f9a-8892ea74850f" section="Displays" discussion="u2711 upgrade">"Well I guess there is no interest in this topic which means I just need to buy the 165hz Acer and see for myself."</post>
   <post id="3fc9c504-7d96-4fcb-819b-b14ac5889f88" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"I ve seen rumblings of this 4ms IPS to be released "this quarter" but nothing is shown on there website. Does anyone in here have any "whispering s" of it by any chance. OR we could just discuss among st ourselves. SS"</post>
   <post id="10ed5806-0b2a-4040-851a-1fd8c5128457" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Pics or it didn t happen"</post>
   <post id="f5803e5a-8754-4ad1-bc10-2d00038db6d3" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"KazeoHin said: ↑ Pics or it didn t happen Click to expand... It s hasn t happened which is why I m asking. But here ya go Nancy. Monoprice enters the ultrawide arena with a 34" IPS offering SS"</post>
   <post id="cab039a6-41fd-4079-85cf-ac198205401b" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"I ve heard about this one also and have been in the market. Had my eye on the xr341CK and to be released xr342ck but for several hundred less for the same panel..... My question is what kind of warranty is this thing going to have........"</post>
   <post id="7c806a25-88cd-4806-ac31-2ad3b5839daf" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"scgt1 said: ↑ I ve heard about this one also and have been in the market. Had my eye on the xr341CK and to be released xr342ck but for several hundred less for the same panel..... My question is what kind of warranty is this thing going to have........ Click to expand... The soldering iron and screwdriver warranty."</post>
   <post id="6c00ba69-fdf3-488f-8277-6629132d2744" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"KazeoHin said: ↑ The soldering iron and screwdriver warranty. Click to expand... Yea pretty much fix it yourself after the crap 1 year warranty."</post>
   <post id="95795ea1-e399-4d98-ada0-73ccbc6f74c6" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Looks awesome."</post>
   <post id="e83a627b-2716-4469-a9f5-638711ff23bb" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"scgt1 said: ↑ Yea pretty much fix it yourself after the crap 1 year warranty. Click to expand... You could purchase a contract I m sure to extend it somewhere. Honestly, when a warranty longer than 1 year on electronics is given by a manufacture you are paying for it regardless. Go spend $650 on a wash machine or a dishwasher and tell me what kind of warranty you get. How about your $600 phone? Your $500 watch? IF a major purchase point is a warranty on a "toy" and let s face for 50% (more?) of us this stuff is a toy. You pay for PRO use stuff for more reasons than a warranty. SS"</post>
   <post id="8fabca89-c8e8-4588-8f51-c3fe677224ef" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Anyone seen any release updates? I wonder if Wal-mart will be listing this for sale like they have so many other Monoprice items listed. I should say I wonder if Monoprice will be selling these via Wal-mart. Wal-mart has cheap extended warranties that start after manufacturers warranty. Hell it may be cheaper there also. Redmere cables sure are."</post>
   <post id="c3019e82-284b-43f3-9d29-b7c84f09bd6d" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Yeah, wish this would drop. Curious to see some hand on reviews. This is in my top 3 list. The only thing lacking is g-sync."</post>
   <post id="33740682-b889-4ce4-b65b-f73c01da3c91" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Still on the fence about gsync/freesync My card is getting pretty dated but still plays everything on max and stays a cool 42*C or less under gaming so can t really beat it. I just don t know if I want to fork over $700+ for another gpu to switch to gsync. Been eyeing the XR341CK for quite some time although I like the light effects and extra curve of the 342CK but don t like the street price of it. This monitor will be 75hz either way so your not constrained to any specific gpu for the max potential of the monitor and that s the way all monitors should be designed. The only part of a computer that should have you by the balls is the cpu/mobo."</post>
   <post id="effee635-f0bc-49f1-aef7-ed160b65fa58" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"I think the monitor is the most important component... You don t stare at your CPU &amp; MOBO... at least I hope not"</post>
   <post id="33070d4f-c1f2-4f33-861d-2ba6306ffe75" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Officially ready to pull the trigger with a ready and waiting Bill me later balance that is just smoking on fire. $129.99 for an extended 3 year warranty from square trade also."</post>
   <post id="d2a7cd8d-4923-4c80-84ab-7b1692858e22" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"So at CES they say Q1. On twitter they say April/May. Yet on Facebook Developing? WTF It should be developed and being manufactured if not boxed up and stocked by now."</post>
   <post id="1d284f0b-c0a1-4fda-9b16-7189e462300a" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Monitors are renowned for always arriving late. A company will announce a monitor for Q1 and it wont arrive until Q3... of the next year. The announcement is just to keep a few people from upgrading JUST yet."</post>
   <post id="447e1a6c-e6c1-477b-81bb-d959e29ee2a3" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Something tells me that getting this monitor without g-sync would be a mistake. If it comes out soon I may get it and see how I like it, if I can return it if I don t like it. I mean I d I pay $500 for this I might as well pay the big bucks and get the x34 or the pg348q."</post>
   <post id="9dcd21a8-8402-44b5-a0b7-90e10b2e3a93" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"HardUp4HardWare said: ↑ Something tells me that getting this monitor without g-sync would be a mistake. If it comes out soon I may get it and see how I like it, if I can return it if I don t like it. I mean I d I pay $500 for this I might as well pay the big bucks and get the x34 or the pg348q. Click to expand... Gsync is not a magic bullet. It improves the experience at the given refresh rate. If I were offered a 100Hz Gsynch display or a 144Hz NoSync display, I d go for the 144 and enable tripple-buffer Vsync"</post>
   <post id="4591e39b-cf8b-4f63-8d2b-9eb9556e54b1" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"KazeoHin said: ↑ Gsync is not a magic bullet. It improves the experience at the given refresh rate. If I were offered a 100Hz Gsynch display or a 144Hz NoSync display, I d go for the 144 and enable tripple-buffer Vsync Click to expand... I suppose, but this is 75mhz and doesn t even exist."</post>
   <post id="06628ab6-89fc-4dd3-87e1-b87848477a77" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"Damn glad I gave them the bird and picked up a brand new U3415W for $580 shipped. Move on people and grab up the deals you see because this one probably isn t going to happen. Lame fucks!"</post>
   <post id="9178ffb1-40e3-4a28-9f4b-a4f1e9ff2282" section="Displays" discussion="MonoPrice 34&quot; curved 1440p 75hz">"scgt1 said: ↑ Damn glad I gave them the bird and picked up a brand new U3415W for $580 shipped. Move on people and grab up the deals you see because this one probably isn t going to happen. Lame fucks! Click to expand... Oh well. The Dell is probably a better choice anyway. Who knows what would have happened."</post>
   <post id="611bed4b-a91c-4187-a97f-bab63ca6522e" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"I had been wanting to pick up a new 40-43" 4k display for use as a computer monitor for a while. Looked at quite a few 4k TV models with high hopes for 4:4:4 @ 60Hz, but didn t seem to be having good luck. I had been using a pair of 27" Shimians for over 3 years now, so I decided to look into the Korean offerings for 4K models. Decided to purchase the Wasabi Mango UHD400 model from AccessoriesWholesale. 30 day returns through Ebay for any reason, and 1 year warranty offered on manufacturer s defect. In a different thread I had promised a review on it, so here it is. The monitor was purchased on Friday afternoon (Saturday morning in S. Korea) for $569 and free shipping. I chose AccessoriesWholesale as the shipper as he had over 24K ratings at 99.3% positive. The monitor was shipped Sunday evening local, and arrived at my doorstep Tuesday morning. Monitor arrived less than 48 hours after shipping. The outside of the box was wrapped very nicely in two layers of bubble wrap with "fragile" stickers all over. Box was spotless after removing the bubble wrap, with no signs of damage. Upon opening the box, the monitor was also wrapped in bubble wrap, and placed tightly into six pieces of hard foam. Panel itself and bezel had plastic film on it for protection. Packing was great. Monitor "feet" were very easy to put on, and seems to keep the monitor very sturdy. The "feet" are made out of coated hard plastic, not metal. Panel will wobble if I push it at the top, but seems in no danger of being pushed over. The monitor includes 1 DP port, 4 HDMI ports (2 x 2.0, 2 x 1.4), and 1 VGA port. I have to order a DP cable, so I m testing with a HDMI cable in the 2.0 port. The monitor also includes a nice remote. Most of the labels are in Korean, but as it looks like most TV remotes, it isn t hard to figure out what each button does (menu, select, volume, etc...). Panel came up and was recognized by my Nvidia 970 at native resolution. Tried the chroma test and confirmed 4:4:4 at 60Hz. Changed from RGB to YCrCb444 as the panel looked a bit washed out on the RGB setting. As it s a VA panel, blacks are very black, and contrast is very good. No discernible light bleed noticed. Overall a very solid panel! Seller is claiming a Samsung panel in the listing. Next up was a test for dead pixels. Upon solid color backgrounds, I found 2 stuck/dead pixels. One was at the very bottom where the taskbar is displayed. The other is at the very top. Not noticeable in the slightest. The seller did not have a pixel perfect option, but advertised that each panel would be "checked" prior to shipping. 0-3 dead/stuck pixels are considered "normal" by the seller. I tested out the monitor s menu system. The seller was kind enough to change the language option to English for me, and it looks like the latest firmware has been installed. Freesync is available as a menu option. The brightness was set very high (75). I turned it down to 45. I played around with the menu settings to where it passed my eyeball test. That pretty much means that it now looks very similar in color to my IPS Shimian sitting next to it. I am in no means an expert at color calibration, and have not attempted to do so. Additionally, monitor was changed from the "full" setting to "1:1". Another cool option is that the monitor has PiP (picture-in-picture) and PbP (picture-by-picture). These options are highly selectable and seems like a nice touch as it s more of a TV feature. I"m running Windows 8.1, so scaling had to be turned back down to "small" which is 100%. Next up was trying to load some 4k content from Youtube. Picture looked great, but suffered from stuttering. I have a 150Mb/sec connection which should be plenty to stream in 4k. I still have to look into that. Fully downloaded 2160p samples looked fantastic. I ll experiment with more samples, but from what I can tell, this panel looks amazing. I may have to invest in a Roku 4 now. On other forum post, 10-bit color was selectable. I could only choose 8-bit however. After a bit of research it looks like that is attributed to using an HDMI cable instead of DP. I will look into it once I get an ordered DP cable from Amazon. Next test was for banding. Monitor looked great with absolutely no banding or gradients noted. Final thing I was able to test today is the possibility of PWM flickering. I will explain first off that I can t say that I ve ever really been sensitive to monitor flickering, so I don t know that I m the best judge here. I used the test located at: Inversion (pixel-walk) - Lagom LCD test. At 45 brightness, I only see moderate flickering in box 3. No flickering in any of the other boxes. If I choose the next option down at the bottom and generate the grey background, I do see flickering. It dissipates completely (to me at least) when the brightness is turned down to 0, and gets heavy flickering when the brightness is set to 100. Based on these tests I can t say that this monitor is flicker-free as advertised by the seller, but it definitely does not bother me. It may bother you if you are more sensitive. Lag/delay was listed as 5ms GTG in the listing, but I have not had a chance to test anything out. Other people have said that this panel will not overclock over 60Hz, and will NOT do 1080p at 120Hz. Pros: No backlight bleeding Contrast is very sharp, blacks are very black No color banding 4:4:4 at 60Hz VGA port (at least for me...I still have old consoles to hook up) PiP and PbP Freesync included in the firmware Lots of menu options, remote is easy to use Price Cons: 2 stuck/dead pixels (very minor) If the monitor has problems, shipping back to Korea could be problematic (May purchase a squaretrade warranty for $54). Does not appear to be flicker free. Not overclockable, and will not do 1080p at 120Hz. All in all, I m very happy with my purchase. The price was great for something more akin to an actual computer monitor, and not a television. This is my third Korean monitor purchase, and they have all been great so far. If you can get over the name (Wasabi Mango, really?), then I think it would be a great model to consider. Recommended so far!"</post>
   <post id="976f9f0f-6e4b-45d9-84de-cc0551ae0501" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Thanks for writing this up!"</post>
   <post id="6405b9c1-4802-4e25-9916-a939eccf1fc6" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Glad you like it they really are amazing monitors. The price you paid along with the features it offers is unmatched in the NA market. I have a UHD490 myself (ah-ips) and couldn t be happier. Before this is had a crossover 494k Which went bad. Seller sold me a shipping label for $40 And had me ship to cali. Uhd490 replacement still shipped from korea. I used to have 970 Sli for some reason wouldn t let me select 10 bit. Switched to AMD cards so I can use freesync, 10 bit is an option for the amd cards. Definitely one of the best tech purchases I ever made. Mine has no back light bleeding also, tiny tiny amount of glow."</post>
   <post id="7ac4f8c0-1825-4c36-b31e-069832a68f1f" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Just a follow up that changing the connection from HDMI to DP has enabled the 10 bit color option to appear in the Nvidia control panel."</post>
   <post id="fcc02121-ff78-46f7-aa85-30f011c6407a" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"How about gaming, any lag noticed? Also, how about running at lower resolutions, does it scale well?"</post>
   <post id="384458b6-bcf8-4814-80aa-3dbac68b520f" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"are the "perfect" variants of this worth the extra premium? the claim being that the check the screen for dead/stuck pixels before shipping it to you and won t ship it if something is off. also as I asked in another thread; has anyone noticed any image burn-in on these?"</post>
   <post id="76675645-e02e-4fa2-a49f-49d4132bb3c2" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Just ordered a perfect pixel UHD400 today from Ebay, with 3 years squaretrade warranty. I will do a review on it and report back here."</post>
   <post id="9819df16-8f3b-4252-9c08-7cb12005ae1b" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Has any done a color quality review or used these in production like work? Seems like a pretty decent deal for a 4k monitor."</post>
   <post id="af0c67f3-4d7e-4869-a429-0870a79dab03" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"I m tempted to sell my Dell U3415W and pick up one of these, but I m a little worried about quality control issues. OP, what s the blur like? If you try a FPS or something is the pixel response really feeling like 5ms? I m very sensitive to this sort of thing -- I tried several TVs and returned them all because they were a blurry mess with fast moving stuff."</post>
   <post id="7b5488b3-c08b-4f2e-8f09-bd1fc3492f35" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Sorry all, have been out of town for a few days and hadn t noticed this thread picking up. In terms of gaming, I don t play FPS anymore so it s a bit difficult to comment on response times. The closest I can say is that I ve discovered Geometry Wars 3 over the last couple of weeks, which is (for me) a very fast twitch game. No lag or ghosting noticed at all on my end. Controls are very responsive, which leads me to believe that the response time is very quick indeed. No burn in noticed after 30 days of use. It does indeed scale well, however I changed the scaling from being handled by the television to the GPU (Nvidia 970). Garin: When I ordered on Ebay, I did not see a pixel perfect version listed. If there is one, I don t think it s worth the premium. I have about 3 dead pixels around the frame, and none of them are noticed. With 40 inches of screen at 4k, there are so many pixels, I think you d be hard pressed to notice them unless dead in the middle of your field of vision. Spidey329: Colors are bright. I had to do some adjustment, but I do not use the monitor with any type of professional acuity needed. Blacks are very deep. Colors aren t quite as bright as the IPS panel sitting next to this, but that is expected of a VA panel. I ve had this for just over a month now, and absolutely no regrets purchasing it."</post>
   <post id="ae956a06-4c8e-4104-888d-88c17e62322f" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"joeh_1974 said: ↑ Sorry all, have been out of town for a few days and hadn t noticed this thread picking up. In terms of gaming, I don t play FPS anymore so it s a bit difficult to comment on response times. The closest I can say is that I ve discovered Geometry Wars 3 over the last couple of weeks, which is (for me) a very fast twitch game. No lag or ghosting noticed at all on my end. Controls are very responsive, which leads me to believe that the response time is very quick indeed. No burn in noticed after 30 days of use. It does indeed scale well, however I changed the scaling from being handled by the television to the GPU (Nvidia 970). Garin: When I ordered on Ebay, I did not see a pixel perfect version listed. If there is one, I don t think it s worth the premium. I have about 3 dead pixels around the frame, and none of them are noticed. With 40 inches of screen at 4k, there are so many pixels, I think you d be hard pressed to notice them unless dead in the middle of your field of vision. Spidey329: Colors are bright. I had to do some adjustment, but I do not use the monitor with any type of professional acuity needed. Blacks are very deep. Colors aren t quite as bright as the IPS panel sitting next to this, but that is expected of a VA panel. I ve had this for just over a month now, and absolutely no regrets purchasing it. Click to expand... Have you found it difficult to adjust to the 4k desktop space versus something smaller? I m going to be doing a lot of CAD work soon and I feel the monitor might finally be the 4k worth buying. Just not sure how I d handle the browsers/etc. on such a large screen. Granted, Windows 10 does do split screens better (lock to corner, etc.). I currently have an HP 27" 1440p. I think if I could sell that, I d likely buy tomorrow."</post>
   <post id="4e5125d5-ad50-47ec-a52d-08cb1b81f437" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"Spidey329 said: ↑ Have you found it difficult to adjust to the 4k desktop space versus something smaller? I m going to be doing a lot of CAD work soon and I feel the monitor might finally be the 4k worth buying. Just not sure how I d handle the browsers/etc. on such a large screen. Granted, Windows 10 does do split screens better (lock to corner, etc.). I currently have an HP 27" 1440p. I think if I could sell that, I d likely buy tomorrow. Click to expand... My prior monitor was a Shimian 27" 1440p. No difficulty adjusting to the new size. I don t find myself having to move my head a lot either. The only real change I made is moving my desktop icons from the left to the center for easy readability. One of my 27" monitors now sits vertically next to the mango. Working on a spreadsheet on a monitor this size is awesome. The 40" scaling wise is great as the dpi is very similar to the 27" 1440p monitor. 40-43" is probably the largest size I d go for a monitor though. Anything over that (considering how close I sit) I think would introduce some head movement to see the entire screen."</post>
   <post id="0b005e74-3a3d-450d-abda-e99a7bad55d0" section="Displays" discussion="Wasabi Mango UHD400 40&quot; 4k Display">"4k at 40-43" is close to the same pixel density as a grid of 4 20" screens at 1080P, roughly. So yeah, pretty close density to 27" 1440P, I d imagine."</post>
   <post id="7c11cc79-a84a-4251-81f0-82e924ce1fca" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q : Parts &amp; Upgrades | Dell. Anyone see one of them yet. The site doesn’t even have the VESA specs or panel only weight. I’m guessing no FreeSync but this could be my new work display. Been weighting forever for a 40”+ 4k display, the DPI is just too low on 24” and 27” 4k displays. I wish it was 16:10 though. They just won’t make those anymore I’m guessing."</post>
   <post id="a74bf5e6-85e9-4daf-9684-20416c0fd8a6" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Why is this worth the extra $500 over the 43" Philips 4K?"</post>
   <post id="8d0ea556-bcb9-46a2-80e0-75082a2a02d4" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"We shall see when these things become more available, I guess. I know I ll be waiting to see how things shake out."</post>
   <post id="c172fd3e-8f3f-410c-8227-fd88c6a99832" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"They do not tell us what the panel is it."</post>
   <post id="b1454c76-55cd-45f0-99ce-fbb4d258542d" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Tanquen said: ↑ the DPI is just too low on 24” and 27” 4k displays Click to expand... Your eyes must be better than mine..."</post>
   <post id="688fbe87-4ce3-44b7-af72-4cd313dc875b" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I was anxious for a new monitor and unwilling to continue to wait for the Phillips to make it to the US.. so I pulled the trigger on this.. says it ships in 6-8 days.. will post my thoughts once it arrives."</post>
   <post id="66047ad1-dc88-40cc-ac75-971e332214ae" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"TheGameguru said: ↑ I was anxious for a new monitor and unwilling to continue to wait for the Phillips to make it to the US.. so I pulled the trigger on this.. says it ships in 6-8 days.. will post my thoughts once it arrives. Click to expand... Let us know what the estimated delivery date is once you have an order status. Their site says 6-8 days, but when I added one to the cart it had an estimated ship date of 06/05."</post>
   <post id="5b6e3c0f-6d2e-402a-ae62-b9afa046ff70" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I m waiting for the HDR monitors to come out at this point. But wouldn t one of the Wasabi Mango 4K monitors on EBAY be a better deal? Should be able to add a SquareTrade warranty to the purchase if scared of warranty work from Korea."</post>
   <post id="12f7333c-18f1-4193-bed6-3afac8acc338" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"lucidrenegade said: ↑ Let us know what the estimated delivery date is once you have an order status. Their site says 6-8 days, but when I added one to the cart it had an estimated ship date of 06/05. Click to expand... May 10th"</post>
   <post id="f32ed180-bc9f-4957-ae98-9d10438b27d7" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I ordered one as well, actually earlier than TheGameguru, but my Estimated Delivery Date: 5/13/2016 Crossing my fingers this is gonna be a good monitor. I m currently on 30" HP Zdisplay."</post>
   <post id="0221811c-39e9-48b8-b4a5-3e9d3a19a2b1" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I emailed Dell about the specs on this monitor but I have yet to receive a reply. Do you guys care about panel type or other unspecified features, etc.? I m very interested also in the case the Philips gets canceled or doesn t come though but I m a bit picky on the specifics."</post>
   <post id="83acf975-b73b-4fc2-95cf-d76991a32228" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Lender said: ↑ I emailed Dell about the specs on this monitor but I have yet to receive a reply. Do you guys care about panel type or other unspecified features, etc.? I m very interested also in the case the Philips gets canceled or doesn t come though but I m a bit picky on the specifics. Click to expand... I saw on some site it listed the panel as an IPS.. so I m figuring its the same as the Phillips which seems to be pretty good from what I ve read.. I mean its a 60hz PWM free panel so for the most part I would be happy."</post>
   <post id="a5dbb25d-0455-4439-ac40-edd6801f142c" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Yeah, and based on the viewing angle at 178deg it would appear to be IPS. Probably the same screen as the Philips. Do you guys have some good discount codes? Even with the 15% I can get it still comes out 51%+ over the Philips for me. Seems like a lot for essentially the same monitor. Good luck!"</post>
   <post id="784d0bc5-0300-487f-9b68-592ecb3b1587" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"This 43" Dell monitor will probably be my next monitor. Might wait a few days before I pull the trigger, as I only just found out about this, but man I m tired of waiting for a 40 ish inch 4k monitor (not a TV). The price delta is easier to swallow with Dells excellent warranty and support."</post>
   <post id="be6c598d-faa1-4ce3-a0ad-36d7d30bf9a3" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Triple portrait U2515H would cost less and have 50% more pixels."</post>
   <post id="c5b9ca34-a8b5-4aef-9824-cd89600b6496" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I d pay the higher price if they d actually put a 10 bit capable color backlight on the thing and given it 99-100 adobergb or UHD color depth. Why would you get something that is basically a modern 4K device and with UHD available right now from Roku and Ultra blu ray, cripple a 10 bit fully capable screen by putting only a silly wled backlight on it? Wide gamut is no longer the future, it is here right now and it makes a huge difference in a lot of content. For those who are going for it anyway - don t mean to dampen your enthusiasm. It is in all other ways a seemingly great monitor."</post>
   <post id="0626d0b2-763d-4ea6-99d4-d2aa33386b8d" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"I think you guys are missing the point - Dell is marketing the  multi-monitor  aspect of this, which is a big deal if your work involves looking at 4 screens at the same time (brokers traders coders and what not) - you can do it at 1080p without bezels, but is probably useless if all you want to do is game or watch TV on a large screen at 4K."</post>
   <post id="f605283a-8ad5-4d3b-be7a-b5226601212e" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"couldn t find the manual, does anyone have a link to it? would like to know what the RS-232 connection offers and am not familiar with it."</post>
   <post id="e6389b70-9c15-467a-b065-d63156c28d03" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Is it me or there are no HDMI 2.0 ports on this monitor?"</post>
   <post id="4621d2f3-6b9f-4881-9f23-5941ab0ca870" section="Displays" discussion="Dell 43 Ultra HD 4K Multi Client Monitor – P4317Q">"Doesn t seem like it. I don t think it s really geared toward gamers/enthusiasts. Shame."</post>
   <post id="41c81dce-a55c-4fe1-82c0-e8b62952e38d" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"I believe it has the same panel as the eizo fg2421. The key differences are that it goes up to 144hz, it s not strobed, it s much cheaper, and it s from a Chinese company. It advertises some 10bit something, but as we all know, that doesn t really matter with most graphics cards. Pretty much all the information about it on the internet is in Chinese. Here s one review: http://diy.pconline.com.cn/515/5155296_all.html no idea how the quality control is but I doubt it would be any better than eizo s. the only way of which I know to buying it would be through a taobao agent. the monitor s price on taobao is around 1600 cny (~260 USD). international shipping would be around 150 USD though most taobao agents offer 40% or so of discount for the international shipping. In total, the price to get it to the us would be around 400usd"</post>
   <post id="6148a90c-b484-456c-bd4b-6c90b3e0f5f5" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"you can get Korean 27" IPSes that are 100+Hz for less..."</post>
   <post id="a98d182b-06c5-4a82-a9b3-ae5306c7db2d" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"ya but the va panel has the advantage in contrast ratio and in response time"</post>
   <post id="000586d8-e457-446a-8374-a24594ce74f1" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"back in VA heyday we had screens such as Dell 2407WFP and HP LP2465 that had viewing angles so good that they rival todays IPSes. I recently saw HP LP2465 next to U2412M and from side it was S-PVA that was winner. Straight on not so much but it was holding its ground pretty nicely against much newer monitor. Sure, there was gamma shift but not like this: if they made VA with the same viewing angle quality as those older panels but with similar contrast ratio difference to IPS and speed that was at least as good as it were back then then we would have something with 2000:1 and that would sell like crazy. Instead we have VA panels that are just slow as hell and look worse from side than your typical TN Sad thing is that good VA technology is available, we have good VA panels in HDTV, we just do not get it in monitor that get cheap crap that doesn t even compare to HDTV s VA are not faster. They can be fast with proper RTC that adds input lag, and if it is not used we have very slow transition times from black to dark gray, the same as all recent VA panels exhibit, which make VA panels to  smear . IPS with similar avergage time will nicely blur image and show little smearing if at all. Big win to IPS imho Contrast ratio such as 5000:1 is not really that important without viewing angle to back it up and make it consistent. I had two 3000:1 monitors, one C-PVA and one A-MVA and they had similar viewing angles to this Sharp panel and black levels of those was their most irritating issue. I had less issues with black level on Dell U2410 and it s 500:1 contrast ratio because it lacked gamma shift and black was consistent. Viewing angles are important and they are weakest point of those new VA panels which make them unusable for me."</post>
   <post id="47c6ea30-77f5-4af9-ab2d-f7ae9b9ad5f0" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"XoR said: ↑ back in VA heyday we had screens such as Dell 2407WFP and HP LP2465 that had viewing angles so good that they rival todays IPSes. Click to expand... Oh, yes. I still think that my old viewsonic vx2435wm was one the best multimedia/gaming TFT displays ever manufactured. By image quality, not the response time etc."</post>
   <post id="835002f1-6418-4de0-9fd0-89322109acf4" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"Lol I m still using an LP 2465. The blacks are indeed to die for, and the viewing angles are great. In the past I had the backlight flicker off a few times. Hasn t happened since, but I wouldn t blame it for dying out. How are these high refresh VA monitors compared to TN s?"</post>
   <post id="ffbb802b-0696-4e6c-b1f3-ddf282d0e96c" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"Love the design (except for the red stand neck) and price vs. the ugly FG2421 which costs 900$ after tax in my country from retailers with awful return and exchange policies. Glossy version=instant buy."</post>
   <post id="fa70dab2-32ba-4755-bf94-e9201722c967" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"XoR said: ↑ They can be fast with proper RTC that adds input lag, Click to expand... if you mean like a frame of input lag, that doesn t always have to be the case. for instance the vg248qe has rtc but also only around 2ms of input lag."</post>
   <post id="b06968f1-9506-4bb2-9cdb-54e9195fa988" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"flod said: if you mean like a frame of input lag, that doesn t always have to be the case. for instance the vg248qe has rtc but also only around 2ms of input lag. Click to expand... S-PVA technology uses  DDC-II  to boost response times. It works by pre-tilting crystals by applying small voltage before desired voltage is applied to avoid overshoot when going from fully black to other colors. It successfully solves issue with dark streaking (dark smudges) and boost overall response times but at the cost of one frame of input lag so its not perfect solution. There is possibility to use normal RTC without pre-tilting and added frame of input lag but that will yield worse response times than there could otherwise be with DDC-II there is good paper on this and other S-PVA advantages: URL it covers also improvement in viewing angles, improvement this Sharp panel in HKC x3 obviously does not have... Murzilka said: Oh, yes. I still think that my old viewsonic vx2435wm was one the best multimedia/gaming TFT displays ever manufactured. By image quality, not the response time etc. Click to expand... no it is not even close... typical IPS now beats best S-PVA/S-MVA in multimedia. Not really enought to make IPS inferior. Gamma shift is much more image quality degrading watching from normal watching position than IPS glow. Only from very large angle there is more degradation of image quality on typical IPS from IPS glow than there is on best S-xVA from gamma shift. besides best multimedia LCD/TFT monitors that there is when it comes to image quality are: - my LG Flatron W2420R - HP Dreamcolor LP2480zx - Quatographic Intelli Proof 240 LED excellence - EIZO CX240 - EZIO CG246 - NEC 2490WUXi all have IPS panel with A-TW so no IPS glow there. They also have features such as: - hardware calibration (no need to alter video card LUTs) - brightness homogeneity compensation all but NEC have also wide-gamut larger than sRGB and gamut correction/emulation with proper color-space emulation to achieve perfect sRGB gamut Viewsonic VX2435WM on the other hand have gamma shift and no fancy features. Even with all professional features S-VA screens will look just broken next to any of the aforementioned monitors Anyhow, I looked for some BenQ GW2760HS viewing angles pics and videos and it seems its having very good viewing angles for a VA. Very interesting and cheap monitor. Too bad AUO do not make 120/144Hz version of this panel"</post>
   <post id="20cfab0d-9a7d-4dc6-99ca-88e9190f0602" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"XoR said: ↑ S-PVA technology uses  DDC-II  to boost response times. It works by pre-tilting crystals by applying small voltage before desired voltage is applied to avoid overshoot when going from fully black to other colors. It successfully solves issue with dark streaking (dark smudges) and boost overall response times but at the cost of one frame of input lag so its not perfect solution. There is possibility to use normal RTC without pre-tilting and added frame of input lag but that will yield worse response times than there could otherwise be with DDC-II there is good paper on this and other S-PVA advantages: URL it covers also improvement in viewing angles, improvement this Sharp panel in HKC x3 obviously does not have... Click to expand... really interesting, thanks for explaining. i guess that s why the fg2421 has an additional frame of input lag? could you post the link again? it links to one of your local files"</post>
   <post id="7e7a1a7d-08a8-4af4-b82b-62a114c9a1b6" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"XoR said: ↑ Anyhow, I looked for some BenQ GW2760HS viewing angles pics and videos and it seems its having very good viewing angles for a VA. Very interesting and cheap monitor. Too bad AUO do not make 120/144Hz version of this panel Click to expand... The AMVA+ traded a bit of contrast/black for improved viewing angles, but they re quite good actually. I still own a P-MVA from 2007 and the blacks are obviously better, but it lacks any kind of RTC and the narrow viewing angles don t make it very  multimedia . Anyway AUO are currently manufacturing new AMVA+ panels, I m curious to see if they will make any significant changes (?)"</post>
   <post id="df91669c-ba65-4630-aaa0-19aa42dcebb5" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"Does it use the exact same Sharp panel? Without light strobing its not going to provide the same quality smoothness as 120hz light-strobed. I don t understand what the fuss about IPS is all about. IPS TV s are a different matter. Some of them now beat plasma level blacks, but in the world of monitors - IPS is only good for photo work. Its not good for gaming and viewing angles are sure hell nowhere near as important in games as contrast ratio, response time, and refresh rate (+ light strobing) UNLESS those viewing angles are horrid, which is not the case with Eizo Foris FG2421. That Chinese knock-off has far worse viewing angles. I am not even talking about IPS glow that creates a perception of much lower contrast than the screen actually has. Eizo Foris FG2421 has great viewing angles or angles good enough not to notice any kind of shift during gameplay. It does have that nasty little gamma defect, where 3-5mm from right and left edges, the image is visible brighter, but its visible only on several graysale patterns, and only with full-pattern solid color images. Input lag is really important to those who play online games competitively with a mouse, but when you consider that there are hardcore console players that use TV s with far worse input lag than Eizo s 19ms, then you can t say 19ms is a high input lag. Then there are people with SLI setups who endure much higher input lag, but still play games, even online ones like BF4 and CS:GO. TV s are best for all-around gaming, but so far none are like Eizo Foris FG2421. I have a nice SPVA HDTV right next to me with its 3000:1 contrast ratio, calibration controls, etc. It even has better uniformity, but ultimately, I want higher contrast ratio, higher response times, backlight strobing @ 120hz and decent input lag without the use of any zones. I find it so funny when I watch some people checking out viewing angles, looking at the screen from this side and that side while keeping the game paused, just LOOKING for issues. And then to think some people actually preferred TN screens like ASUS ROG! Makes me want to take another shower... I do agree on one thing - Eizo Foris FG2421 has the most basic design, nothing nice or pretty to it. I dislike it, but I love the screen too much to give it up for anything out there, yet..."</post>
   <post id="5150403b-3104-4c18-a560-269e533bb3d1" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"MonarchX said: ↑ IPS TV s are a different matter. Some of them now beat plasma level blacks Click to expand... Beat? At best the most exceptional FALDs can match some of the lower quality plasma displays qualitatively in certain scenes, but an outright victory is out of the question. I m in the same boat with regards to wanting a high-contrast large-size strobed display. The technology is out there. Unfortunately the profits are not, apparently."</post>
   <post id="c16e1e15-9d7e-4bac-80a4-5ec3d7e9df25" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"XoR said: ↑ Click to expand... I m looking at a LP2465 next to an IPS screen and the gamma shift is so terrible it s not funny. But this is something else."</post>
   <post id="6abe5561-2831-4c19-b7ba-3034866668a1" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"MonarchX said: ↑ I don t understand what the fuss about IPS is all about. IPS TV s are a different matter. Some of them now beat plasma level blacks, Click to expand... no they don t and they never will be able to. TVs with va panel and full array local dimming have very good contrast but they are extremely rare literally every other display technology is better at black levels than lcd"</post>
   <post id="27dcc47f-a360-4739-98f6-f881618ba6c2" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"Has anyone ever bought one of these? Is it truly 10bit and is it matte or glossy/semi-glossy?"</post>
   <post id="027fcb2a-dd17-49b7-bb69-cec4eefb39da" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"You can probably find an eizo fg2421 for close to 400-450 used anyway."</post>
   <post id="c622d713-418f-4c41-b770-d597fcc98a4a" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"All the MVA+ (3000:1) Monitors i had looked all milkish against my 2 old MVA (5000:1) Monitors, i have returned this MVA+ Monitors on the same day. I can t believe that so many people still use 1000:1 Monitor in 2014 in my option the picture quality simply look awful on a 1000:1 Contrast Display, and don t get me started on this IPS glow or the 6-bit TN Panels. And any review site that gives a 1000:1 Contrast Display 5/5 stars should be beaten with a 50" TV. http://www.cnet.com/news/contrast-ratio-or-how-every-tv-manufacturer-lies-to-you/"</post>
   <post id="8ced67bd-19bb-420c-a7ae-a5a9c6896570" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"I have an Eizo fg2421 and it s great. Just wondering how this monitor compares to it since it claims to be 10bit color, same contrast ratio and 144hz with better color uniformity and less gamma shift, 1ms GtG. I wonder if any of those claims are true and if they have been confirmed by any reputable source."</post>
   <post id="4ee7d09f-6187-4f02-954e-c013bb23b908" section="Displays" discussion="HKC x3: 1920x1080 144hz VA chinese monitor">"The panel is not the same as the Eizo FG2421. Eizo uses a Sharp LQ235D1LW03 MVA panel, and this HKC uses a LK235D3HA0S. Sounds like this might be a decent alternative to the FG2421. Personally I can t return to 24", and I d prefer my next monitor to have G-Sync/Freesync."</post>
<post id="56446b9b-1671-44c8-988f-ee5d7447aa4c" section="General Hardware" discussion="Please Give PC Hound a Try When System Building Posting Here">"We have been working [H]ard to make PC Hound a great system builder tool. We even supply markup code for the forums that you can cut and paste like shown below. Give it a try if you get a chance. PC Hound Part List CPU: Intel Core i7-4790K ($329 @ NCIX US) Motherboard: ASUS Z97-A ($144.98 @ NCIX US) Memory: G.SKILL 8GB (2 x 4GB) Ripjaws Series ($69.99 @ Newegg) Video Card: ASUS GeForce GTX 970 STRIX-GTX970-DC2OC-4GD5 ($329 @ NCIX US) Power Supply: EVGA 850W 220-G2-0850-XR ($119.99 @ NCIX US) Storage: SAMSUNG 250GB 850 EVO-Series MZ-75E250B/AM ($124.99 @ Amazon) Case: Fractal Design Define R5 FD-CA-DEF-R5-BK ($109.99 @ NCIX US) CPU Cooler: CORSAIR Hydro Series H100i CW-9060009-WW ($99.99 @ Amazon) Windows: Microsoft Windows 7 Home Premium SP1 64-bit ($89.99 @ TigerDirect) Mouse: Logitech G502 ($67.99 @ Newegg) Keyboard: RAZER BlackWidow Chroma ($159.99 @ Amazon) Headphones: Logitech G430 ($59.98 @ NCIX US) Speakers: Creative GigaWorks T20 Series II ($78.99 @ Amazon) Monitor: ASUS VG248QE ($264.99 @ NCIX US) Optical Drive: LG WH14NS40 ($56.99 @ Amazon) Case Fan: Noctua NF-F12 PWM ($19.25 @ Amazon) Thermal Compound: Arctic Silver AS5-3.5G ($8.99 @ Newegg) Sound Card: Creative Sound Blaster Z 70SB150000000 ($99.84 @ Amazon) Networking: ASUS PCE-AC68 ($94.99 @ Amazon) Total: $2,329.92 Price may include shipping, rebates, promotions, and tax Generated by PC Hound"</post>
   <post id="bf6f020b-3ef6-4bfe-b154-3fc853f2b1fc" section="General Hardware" discussion="Building or Upgrading a Computer (The Detailed [H] Guide)">"The following are the steps you should take when deciding upon building a computer from scratch. You can also use some or all of the following when you are considering upgrading your machine. 0) Please use PC Hound to post your system build. 1) Figure out your budget. Figure out how much you are willing to spend on the project as well as what needs to be covered within the budget. Factor in the costs of all of the actual components to your computer, as well as additional costs for software (particularly the operating system), additional accessories, and shipping/taxes. Many people have added "discounts" received from mail-in rebates into their totals. Don t. The issue with mail-in rebates (or MIRs) is that you still have to pay the full (before rebate) price up front. (Plus, there s no 100% guarantee that you ll even receive the MIR in the end.) BE REALISTIC ABOUT YOUR BUDGET. Theoretically, you could build an entire system, complete with a monitor, keyboard/mouse, and other peripherals, for as low as $400-$500. But realistically, you would be cutting a lot of corners (with the system s overall performance, if not its longevity) in order to get it done. If you have a budget of under $1000 (to include shipping/taxes) and you wish to build an entire computer (including monitor, OS, and/or other peripherals), you may want to consider getting a prebuilt system instead, from Dell, HP, Acer/Gateway, or some other reputable vendor. 2) Figure out which components you would need for your setup. When we re referring to components, we mean: COMPUTER (TOWER): Case Power Supply (PSU) Case Fan(s) Motherboard Processor (CPU) CPU Cooler/Heatsink with Fan (HSF) Memory (RAM) Hard Drive (HDD) Optical (Disc) Drive (CD/DVD/HD-DVD/BR) Video/Graphics Card (GPU) Sound Card Additional Cards -- Wireless (802.11b/g/n) Network -- TV/Cable tuner -- RAID controller -- IDE/ATA/SATA controller Miscellaneous -- Floppy drive -- Memory card reader -- Fan controller OPERATING SYSTEM (OS) - This is important, because most people need new license keys for their new systems. Because of its importance, you might as well consider the OS as part of the system. (Read the EULA of your operating system before you consider transferring an old license to a new machine.) WATER COOLING - Though not mentioned much in General Hardware, water cooling setups are normally used by those who want the most efficient cooling available, for heavy overclocking (OC), very quiet or near-silent operation (compared to an air-cooled system), or for all of the above. PERIPHERALS/OTHER ACCESSORIES: Monitor Keyboard Mouse Speakers Printer Uninterruptible Power Supply (UPS) or surge protector Miscellaneous (Accessories) -- External Drive(s) -- USB/FireWire Hub -- (A/V) Receiver/Amplifier You will need to figure out which components you will need to buy and which, if any, you are transferring from another machine. You may have already purchased/received some components beforehand; include those as things you are transferring to the new system. 3) Determine what the computer is going to be used for. It could be designed for one primary task, or it could be a "multitasking" machine capable of performing multiple/various tasks. SAMPLE TASKS: Gaming Internet/Web Design Office Programs/SOHO Networked Server (e.g., Game, Print/File, Web) Video Editing Photo/Graphics Editing (e.g. Photoshop, Maya) Television/Video/Music FTP/BitTorrent (download/upload) Virtual Machine Multiple OS (Windows/Linux/Mac) 4) Figure out which features you want on your computer. The motherboard could contain many of those features that you want already, but you may have to purchase other components in order to fill in the remaining gaps. SAMPLE FEATURES: RAID Multiple IDE (2+) ports Multiple SATA (4+) ports External SATA (eSATA) ports Multiple video card setup - SLI (NVIDIA) or CrossFire (AMD/ATI) Ethernet/LAN - 10/100, Gigabit (10/100/1000), multiple (2+) ports, wireless (802.11b/g/n) USB/FireWire - internal headers or external slots Serial or Parallel ports Number of RAM slots Heavy Overclocking features Large number of hard drives TV/DVR capabilities The above list is only a sample of many possible features (for lack of a better term) available for your system. It s up to you to determine everything that you would want/need. 5) Determine whether or not you are planning on overclocking any of the components. Overclocking places heavy stress onto the components, so you would need to find parts that can handle the stress or cool everything down. If you are even considering the possibility of overclocking, then purchase components that would allow you to do so safely. Even if you don t do so, some of the components designed for overclocking have the added advantage of enabling you to run your components cooler or more stable than "stock" components. 6) Determine how long you want your machine to last. Depending on how well you take care of your machine, as well as how quickly technology changes during that time, you may or may not hit your self-imposed mark. You also need to consider how often you plan on updating key components in order to allow your machine to last longer. There are two things to remember in regards to upgrades. The moment you buy a new motherboard, you are essentially building a new computer. And though you could possibly replace everything on your system at one time or another, consider the overall costs of doing so. If you spend more than $600 for any amount of upgrades at any one time, you may want to consider building a new system from scratch. 7) DO SOME RESEARCH. Check out various hardware sites/forums (starting with this one), online retailers, and do a few searches (Google is your friend here). Make sure that whatever you choose has the features that you need/want and can perform the tasks that you want accomplished. Also look for and read posts, reviews, and articles about the component(s) you want, so you are aware of any problems or issues that could come up. Many people typically build their systems around one main component; start with the motherboard. Many people build around the CPU, which then determines their motherboard selection. Keep in mind that all of your components will be connected to each other by way of the motherboard. Again, START WITH THE MOTHERBOARD -- it s essentially what the entire system is based off of. Figure out which components the motherboard would accept, find parts that will work on the motherboard, and go from there. If you are overwhelmed by the myriad of options available, or if you re just plain lazy, check out some recent posts (from here as well as other hardware-based forums) for similar configurations (aka rigs) within your budget. You could also look at configurations higher or lower than your listed budget, so you have a better idea of what s available. If you re confused as to whether Part X will work in your system, and you can t find the answer you re looking for in General Hardware, take a look at one of the specialized subforums available at the [H]. Or, perform a search (again, Google is your friend) for the specific item(s) you have questions about. Due to the constantly changing nature of technology, there won t be any "best of" parts listed in this thread. However, don t embrace or dismiss components because they re "the latest and greatest" or because they re "outdated." In fact, if you re looking at a recently released item (within the past year), wait at least six months before jumping on it. For example, waiting six months could help you determine whether the new video card you re looking at would perform great (like the 8800GT) or poorly (FX5600, anyone?). And just because something has been out on the market for a few years doesn t make it outdated; many people have keep their rigs for over five years without any major changes because they built a computer for the long-term that worked for their needs. 8) Come up with a list of what you want. By this time, you have an idea of what you want. List your entire (planned) setup, including what you already have in your possession. Perform some more research to make sure that all of the components that you chose is compatible with each other. 9) Figure out where you are going to purchase everything from. There are many places to shop at, but make sure that you choose at least two or three locations to shop from. Some places overcharge for certain components; NewEgg, for example, have some of the highest prices (in the US) for power supplies. This is by no means a complete list of stores to buy from but it should tell you which stores people usually buy from (please note that the following links are for US-based retailers): NewEgg ZipZoomFly Mwave Mircocenter Buy.com Tiger Direct 10) BUY EVERYTHING! Do you really need our help there? _________ Here are few other things to keep in mind when building or upgrading your machine. DO YOUR HOMEWORK -- RESEARCH! -- BEFORE POSTING A THREAD FOR HELP! There are hundreds of threads in General Hardware asking for help in configuring a system within a set budget. If you don t want people firing off at you a lot of messages or questions -- or telling you to do some research -- do us all a favor and do your homework beforehand. Only post if you can t find an answer to your question(s) from here, other forums, or through a Google search. If you do post a build thread, please include: -- What your budget is (and whether it includes taxes, shipping charges, and/or other costs) -- Which parts you need within that budget -- What the system is going to be used for -- All of the components that you already have and/or are planning on reusing -- Which components you are considering getting (list out your components with model numbers/names along with links to the stores you re getting them from) -- The question(s) you have -- or, the reason you made the thread in the first place -- Be as specific/detailed as possible (without writing a novel -- some of us have short attention spans here...) If you are just upgrading, all of the steps listed above still apply. Pay special attention to the second part of step 6; if you re spending a lot of money on upgrades, or if you re replacing the motherboard (and other important components, like the CPU and RAM), then you might as well approach this as a new build. __________ A Special Note on Power Supplies One of the most common problems with most PC builds on the forum is the choice of power supply. When doing research on power supplies, please read these articles first: JonnyGURU s Power Supply FAQ Hardware Secrets - Why 99% of All Power Supply Reviews Are Wrong If the second link is a bit too technical: If the power supply review does not mention the use of an Automated Test Equipment, or ATE, and a proper test methodology, then that review should not be taken into consideration. A good example of a test methodology is [H]ard|OCP s methodology. The following sites should be your first stop when looking up power supply reviews: [H]ard|OCP JonnyGURU Silent PC Review AnandTech"</post>
   <post id="ea67416a-b08c-413c-b2f6-358da670f2c7" section="General Hardware" discussion="Building or Upgrading a Computer (The Detailed [H] Guide)">"[Space reserved for instructions and pictures on building a computer from scratch.]"</post>
   <post id="74c04d75-e7b6-44f7-a203-548229133544" section="General Hardware" discussion="Building or Upgrading a Computer (The Detailed [H] Guide)">"One more thing: If you have any questions and/or comments about this or any of the other Gen[H]ard-related sticky threads, please post them in the GenHard Sticky Discussion thread. Please do not post anything here."</post>
   <post id="8c138747-eb4d-4f4a-a557-66de88a428fc" section="General Hardware" discussion="Asking for Build Help?: ANSWER THESE QUESTIONS FIRST">"If you re gonna ask us to build/list a PC for you or seek advice about a build, please answer all of the following questions: 1) What will you be doing with this PC? Gaming? Photoshop? Web browsing? etc 2) What s your budget? Are tax and shipping included? 3) Which country do you live in? If the U.S, please tell us the state and city if possible. 4) What exact parts do you need for that budget? CPU, RAM, case, etc. The word "Everything" is not a valid answer. Please list out all the parts you ll need. 5) If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. List make and model. 6) Will you be overclocking? 7) What is the max resolution of your monitor? What size is it? 8) When do you plan on building/buying the PC? 9) What features do you need in a motherboard? RAID? Firewire? Crossfire or SLI support? USB 3.0? SATA 6Gb/s? eSATA? Onboard video (as a backup or main GPU)? UEFI? etc. 10) Do you already have a legit and reusable/transferable OS key/license? If yes, what OS? Is it 32bit or 64bit? By answering these questions you help us help you build a PC that s of better quality, better performing, cheaper or all of the above. Please use PC Hound to post your system build. If you have any questions and/or comments about this or any of the other Gen[H]ard-related sticky threads, please post them in the GenHard Sticky Discussion thread."</post>
   <post id="16aa60d6-cda4-4784-b0d5-4890d687bf21" section="General Hardware" discussion="Asking for Build Help?: ANSWER THESE QUESTIONS FIRST">"====================== Example: ====================== 1) What will you be doing with this PC? Gaming? Photoshop? Web browsing? etc Mainly web/email. Frequent HD viewing from online sources. Light gaming (WOW). 2) What s your budget? Are tax and shipping included? $400 before taxes and shipping 3) Which country do you live in? If the U.S, please tell us the state and city if possible. Canada 4) What exact parts do you need for that budget? CPU, RAM, case, etc. The word "Everything" is not a valid answer. Please list out all the parts you ll need. CPU, Mobo, and RAM 5) If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. List make and model. 2x WD800JB, 1x WD6400AAKS, BenQ DW1640, Antec P160, Antec TruePower 2.0 550W, and 7800GT 6) Will you be overclocking? mildly 7) What is the max resolution of your monitor? What size is it? 22", but may upgrade to 24" within the next month 8) When do you plan on building/buying the PC? ASAP 9) What features do you need in a motherboard? RAID? Firewire? Crossfire or SLI support? USB 3.0? SATA 6Gb/s? eSATA? Onboard video (as a backup or main GPU)? UEFI? etc. RAID, LPT Parallel header or port (for my LJ1100), COM header or port (for my UPS) 10) Do you already have a legit and reusable/transferable OS key/license? If so, what OS? Is it 32bit or 64bit? Yes, XP OEM These are the parts I was thinking about: $85 - Asus M3N78-VM AM2+/AM2 NVIDIA GeForce 8200 HDMI Micro ATX $72 - AMD Athlon 64 X2 7750 Kuma 2.7GHz 2 x 512KB L2 Cache 2MB L3 Cache Socket AM2+ 95W $51 - A-Data 4GB (2x2GB) DDR2-800 ADQVE1B16K You can copy and paste from here, replace *** with your answers: HTML: 1) What will you be doing with this PC? Gaming? Photoshop? Web browsing? etc[COLOR="Orange"]"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]2) What s your budget? Are tax and shipping included?[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]3) Which country do you live in? If the U.S, please tell us the state and city if possible." section="##2##" discussion="##3##">"##4##"</post>
   <post id="[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]4) What exact parts do you need for that budget? CPU, RAM, case, etc. The word &quot;Everything&quot; is not a valid answer. Please list out all the parts you ll need. [COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]5) If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. List make and model.[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]6) Will you be overclocking?[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]7) What is the max resolution of your monitor? What size is it?[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]8) When do you plan on building/buying the PC?[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]9) What features do you need in a motherboard? RAID? Firewire? Crossfire or SLI support? USB 3.0? SATA 6Gb/s? eSATA? Onboard video (as a backup or main GPU)? UEFI? etc.[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR]10) Do you already have a legit and reusable/transferable OS key/license? If so, what OS? Is it 32bit or 64bit?[COLOR=&quot;Orange&quot;]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="***" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[/COLOR] Thanks you enginurd for the recommendation. Note: When you do list out your parts, please provide the names for those parts for speedier assistance." section="##2##" discussion="##3##">"##4##"</post>
   <post id="3c527020-d582-489e-9f1e-4bc66e92dad3" section="General Hardware" discussion="Asking for Build Help?: ANSWER THESE QUESTIONS FIRST">"2.1) Are you including rebates?"</post>
   <post id="0679f93b-077f-4fd9-8612-4ac4ad6f6eb9" section="General Hardware" discussion="Asking for Build Help?: ANSWER THESE QUESTIONS FIRST">"You don t need to bump this thread. There is a link to it on the revised Gen[H]ard FAQ sticky."</post>
   <post id="d1ac3cf6-6d0b-4270-bfe5-5888b88e97f1" section="General Hardware" discussion="Gen[H]ard FAQ">"This is the General Hardware FAQ, where we attempt to answer many of the questions that are commonly asked in this forum. While we can t answer every question or solve every problem you have, this is still a good reference point. A big thank you to Dangman, enginurd, Markyip1, and silent-circuit for their help with assembling the FAQ, and to flipflopsnowman for making the original sticky this FAQ is based off of. __________ Please use PC Hound to post your system build. Quick Links Gen[H]ard WLWC List of Recommended Online Retailers Gen[H]ard FAQ -- Part 1, Part 2 __________ If you need help with building or upgrading a computer, please answer the questions listed here. If you re willing to invest a little more time, here is a more detailed guide. If you re having trouble with your computer, check out the Basic Troubleshooting Guide. If you have any questions and/or comments about this or any of the other Gen[H]ard-related sticky threads, please post them in the GenHard Sticky Discussion thread. Please do not post anything here."</post>
   <post id="42e00b21-1f4c-43c2-84e1-cc3b78d9aa6e" section="General Hardware" discussion="Gen[H]ard FAQ">"NOTE: Some of these links are old, and haven t been updated in a while, but they still offer relevant information [H]ard|Links Video Card FAQ &amp; general references Benchmark/Overclocking software list Case-Mod FAQ ESD: Truths, myths, and flat out lies Electronics FAQ Memory FAQ Motherboard Manufacturer Links Small Form Factor (SFF) FAQ Home Theater PC (HTPC) guides and links Power FAQS &amp; tutorials Uninterruptable Power Supply (UPS)/surge protector FAQ Hard drive FAQ/guides Thermal Paste Shootout - Q209 Other WLWC AnandTech - The SSD Anthology AnandTech - The SSD Relapse EXTREME Overclocking Forums - Ultimate RAM Guide Power Supply Guides BFG Power - Basic Power Supply Troubleshooting [H]ard|Forum - PSUs to avoid -- DO NOT consider any of the brands listed here in a high-end or performance build Hardware Secrets - Why 99% of All Power Supply Reviews Are Wrong JonnyGURU s Power Supply FAQ PC Building Guides Build-Your-Own-Computer.net Driver Heaven - Building a PC eHow - How to Build a Custom PC Computer Lifehacker - DIY: The First-Timer s Guide to Building a Computer from Scratch Lifehacker - How to Build a Computer from Scratch: The Complete Guide Lifehacker - The Best PCs You Can Build for $300, $600, and $1200 MaximumPC Build a PC Section -- Multiple guides on different PCs mechBgon s guide for first-time system builders -- First-time builders start here NewEgg TV - How to Build a Computer -- A three-part video series (also available on YouTube) reddit BUILDAPC -- reddit forum similar to the [H] Tech Report - How to Build a PC (YouTube) Troubleshooting AumHa - Troubleshooting Windows STOP Messages -- Good for interpreting the meaning of BSODs ComputerHope.com - Basic Troubleshooting Steps Computer Repair with Diagnostic Flowcharts Directron - Troubleshooting Tips Microsoft Help and Support page -- For Windows- and Microsoft-related issues PC Hell Part Reviews [H]ard|OCP 3dGameMan AnandTech Bit-Tech Bjorn3D Club Overclocker (Club OC) DailyTech -- Look for their "Daily Hardware Reviews" DriverHeaven ExtremeTech FiringSquad FrostyTech -- Focuses primarily on heatsinks, fans, and other forms of cooling GPU Review -- Compare video card specs with links to reviews The Guru of 3D Hardware Canucks Hardware Logic Hardware Secrets Hexus HotHardware JonnyGURU -- Articles, reviews, and forums on primarily power supplies Legion Hardware Legit Reviews Mad Shrimps Motherboards.org Overclockers Club (OCC) PRAD -- German site that focuses on monitor reviews; English language version SFF Tech -- Focuses on small form factor and Shuttle systems Silent PC Review -- Articles and reviews on making your PC quieter Storage Review -- Articles and reviews on hard drives Tech ARP Techgage techPowerUp! TFT Central -- Articles and reviews on monitors The Tech Report Virtual-Hideout X-bit Labs"</post>
   <post id="13f6d307-22c9-48ed-9f4d-542ff11bdb4a" section="General Hardware" discussion="Gen[H]ard FAQ">"NOTE: Unless specified otherwise, the retailers listed here are based in the United States. Places to Buy - General Amazon Buy.com Directron Micro Center Mwave (U.S. site) NCIX (U.S. site) NewEgg (U.S. site) PCPartPicker -- Price comparison site Provantage SuperBiiz (formerly eWiz) Tiger Direct (U.S. site) Places to Buy - SFF, mini-ITX &amp; Car PC parts Computer Gate mini-ITX store DSL mini-ITX store E-ITX iDOTpc Logic Supply Mini-Box mini-ITX.com store (UK/EU) MitxPC Mobile Computing Solutions Opus Solutions PC Alchemy Places to Buy - Fans, Cooling &amp; Case Mods Case-Mod.com FrozenCPU Heatsink Factory Jab-Tech Performance PC s Petra s Tech Shop Sidewinder Computers Silicon Valley Compucycle (SVC) ThermalFX Xoxide Miscellaneous -- other places to consider for computer systems and components AVADirect Dell Dell Outlet -- for refurbished Dell products HP Bargain Hunting Ben s Bargains dealnews FatWallet Google Shopping Got Apex PriceGrabber.com Pricewatch SlickDeals.net Tech Bargains Places to Buy - in Canada Canada Computers DirectCanada Infonec Computers NCIX (Canada site) NewEgg (Canada site) Shopbot.ca -- Bargain hunting site for Canadian buyers Tiger Direct (Canada site) Places to Buy - in the UK Advance Technologies CCL dabs.com Ebuyer MicroDirect Mini-ITX.com online store MISCO.co.uk Novatech Overclockers UK Pixmania Quiet PC UK Scan Computers UK SpecialTech Watercooling UK Places to Buy - in Europe ARLT Computer (Germany) cool-prices.nl (The Netherlands) Komplett Prodimex Places to Buy - in Australia 9289.com.au ARC Computers Australia Computer Online CCPU Computers Computers &amp; Parts Land (CPL) ITSdirect MSY Technology Pty Mwave (Australia site) PC Case Gear PC Maniacs staticICE -- price comparison site for Australian and New Zealand retailers UMart Places to Buy - in New Zealand Ascent Technology"</post>
   <post id="2542e4d0-f686-48e3-91cd-24b9a9c3d656" section="General Hardware" discussion="Gen[H]ard FAQ">"How much can I get for [my computer/my parts]? Price checks are not allowed in General [H]ardware (per Rule 26); the only place you could get a price check at the [H] is through the General Mayhem forum. The "easy way" to determine your resale value is take 10%-40% off the item s current retail value based on its age, its condition, whether or not it has all of its accessories (including packaging materials and paperwork), and other factors (e.g., where it was used at, whether or not it was overclocked, the time left on its warranty). If you want a more "accurate" estimate, check out what the used computer/part is selling for elsewhere. Check out eBay, Craigslist, and forums (like here) where members sell and trade their used parts. As a warning though: don t expect a huge profit in reselling your part, as many people want a huge discount on used parts. But this (part) is cheaper... it s only $XXX AR... STOP RIGHT THERE. AR means "after (mail-in) rebate," and though a mail-in rebate (aka MIR) can save you money in the long run, it s not the same as an instant rebate (which is, in reality, a price cut). A lot of us here don t like mail-in rebates because it s not guaranteed that you ll receive the rebate check. If you re "including" the rebate amount(s) in the total for your build, DON T. You still have to pay the full amount up front, and the rebate check(s) -- if you even get them -- will likely be the last things that you receive, long after you get your computer up and running. As one wise man said in the past, "Don t count the rebate in your total until you actually have the check in your hand." Again, DO NOT INCLUDE THE MAIL-IN REBATE AMOUNT(S) IN YOUR BUILD COSTS. You aren t saving any money right away. Why do you guys use NewEgg all the time? Because NewEgg offers us the most information about computer parts, sometimes even more than what we could find from the manufacturers  sites themselves. (Plus, in many cases, NewEgg provides links to each item s product page -- straight from the manufacturer s site.) While not everyone can buy parts from NewEgg, we ll occasionally link to parts from there to show the people we re helping greater details (and pictures) about what we re recommending. Why do you guys tell people to not post their (NewEgg) wish lists? Oftentimes people link them wrong, which delays responses. It s simply easier for others if you post the parts list instead, so we don t have to click on another tab just to see your list while we re responding. If you d like us to take the time to respond to your post, please take the time to make it easier for us to respond. Why do you guys tell people not to rely on NewEgg reviews? Most of the reviews posted in NewEgg (along with most online retailers) come from users who don t really know what they re talking about or those who use the review(s) to speak their minds about anything and everything (except, often, the item they were supposed to review). If you want the best information on a certain item, perform a Google search for the item in question, or check out a review of said item from a hardware review site or forum (there s a list available in the WLWC portion of this FAQ). What s the deal with PCPartPicker? A lot of the forum regulars refuse to use it. There are two problems with the site. First, it uses after-rebate totals when it picks out parts, which we don t recommend to anyone trying to stick with a strict budget. Second, some of the retailers chosen through PCPartPicker aren t the best around. Some sites aren t recommended due to shoddy site design, inaccurate pricing (compared to the PCPartsPicker site), or bad customer service. How do I overclock? There are many guides out there to show you, but the basic principles of overclocking are: Slowly adjust the clock speed in the BIOS/UEFI settings. (Ensure that the computer is stable at the current clock speed before you increase it any further.) Increase voltage and/or adjust memory timings, as needed, to maintain system stability. Test the system to ensure that the computer can function properly at the increased speed. There are several tricks and guides to overclocking, based on what you have (Intel/AMD processors, specific motherboard brand/model) and/or what you wish to overclock (e.g. processor, video card, RAM), so do some research before making any attempt at overclocking. As a warning, though: Overclocking could cause system instability, crashes, and damage to hardware, and it voids the warranties of any and all parts that you use. How do I determine which power supply is right for me? With a bit of research. Start by reading the following articles first: JonnyGURU s Power Supply FAQ Hardware Secrets - Why 99% of All Power Supply Reviews Are Wrong If the power supply review does not mention the use of an Automated Test Equipment (ATE) and a proper test methodology, then that review should not be taken into consideration. A good example of a test methodology is [H]ard|OCP s methodology. The best places to go for PSU reviews are JonnyGURU and [H]ard|OCP. They not only use ATEs in their reviews, they also stress-test the PSUs well past their "normal" operating levels. A PSU that they recommend is usually among the best of the best. Remember that wattage doesn t mean as much these days. What matters most is where those watts are being delivered. For current rigs, it s all about how much amps are on the +12V rail since most PC parts draw their power from there. The more amps you have, the more upgrades (hard drives/SSDs, video cards, expansion cards, etc) you can add. You determine the amperage on the +12V rails by first finding out what s the total combined, max load, combined or max wattage aside for the +12V rails/section alone. Then divide that total by 12 and you get how much amps the PSU has on the +12V rail. That s the correct way to find out how much amps a power supply has. Don t add up the amps on the +12V rail to figure out the amperage. If the total combined or max wattage can t be found on the power supply, check the PSU manufacturer s page for that info. If the manufacturer doesn t provide that information, it s generally a good sign for you to drop that power supply from consideration. Which speed of memory do I need for my CPU? (Usually preceded or followed up by, I plan on overclocking my CPU.) It depends on what you re using (and what you can obtain). For most modern systems (anything developed within the past couple of years), DDR3 1600 offers the most bang per buck in regards to performance. RAM speeds? Shouldn t you talk about maximum bandwidth instead? Well... HardwareSecrets  article on Understanding RAM Timings can explain things better than we could. Do I have to use dual-channel RAM? Not when your motherboard supports tri-channel or quad-channel. "X-channel" refers to the motherboard technology that allows sticks of RAM (or DIMMs) to work more efficiently when grouped together. Various benchmarks (both real-world and synthetic) show some degree of improvement per architecture (quad &gt; tri &gt; dual &gt; single) but it s virtually unnoticeable during most real-world applications. (One notable exception is the use of the onboard GPU from a motherboard or a processor. Since the embedded GPU uses the same memory resources as the rest of the system, it is oftentimes recommended to have as much bandwidth as possible.) Having said all of that, however, your motherboard can operate off of one DIMM. Just make sure that you run that DIMM on the first RAM slot (as defined in your motherboard s user manual). Is it true that I have to use the exact same RAM in all of my RAM slots? It s recommended for best performance and guaranteed compatibility to use DIMMs with identical speeds, capacity, timings, and voltage levels, ideally from the same manufacturer (and, even better, from the same model family). In the past, motherboards dealt with different sticks of RAM by automatically adjusting the speed and timings of each stick to a "lowest common denominator" that all of the RAM could operate under. Today, many users find it easier to either buy the same brand and model of RAM they re currently using or replace the RAM that they have with a newer multi-channel set (consisting of multiple sticks of identical RAM). Managing RAM voltage is an entirely different beast. You should ensure that your RAM runs at a voltage level that the processor or the motherboard (whichever holds the memory controller hub, or MCH) can handle before you use it. I want better performing RAM. Should I buy RAM that s faster or RAM with lower latency? If you plan on overclocking, it s better to buy RAM that runs at faster speeds (or greater bandwidth). In most cases, the bus speed/maximum bandwidth of the RAM in question will help determine how far you can push a CPU overclock. Lower latency RAM (the explanation of which can be found here) does offer some improvement, but it s not noticeable in most cases. The simplest explanation, though it doesn t explain everything, is that today s chipsets benefit more from the memory bandwidth available than they do from lower latencies/tighter timings. (Information provided courtesy of Extreme Overclocking Forums.) In short, don t spend more for lower latency RAM unless you can find it for around the same prices as the higher latency variety. What does it mean to have RAM with tight timings? Hardware Secrets has an article that explains what RAM timings are. (CL, or CAS Latency, is one of them.) Having RAM capable of lower/tighter timings was a big deal with DDR1 memory, but they have less significance now with DDR2 and DDR3 RAM and their emphasis on speed. (We haven t heard much on DDR4 RAM yet, but given historical trends....) I want 8GB of RAM. I ve already bought two 2GB sticks of [RAM]. Can I just get two more 2GB sticks? Yes, you can... but you may run into stability issues, especially if you plan on overclocking anything. (That s not to say that it will happen, just that it s a possibility.) So, are you trying to say that it s better to use two sticks of RAM instead of four? Yes... and no. It s harder to OC with four sticks of RAM than with two. Also, two sticks of RAM will be less of a burden on the MCH. As an added "benefit," using two sticks of RAM will gives you the option to add more RAM later on. The "no" part is that you don t need to replace two sticks of RAM with two sticks of a larger capacity, especially if you can t afford to. As long as you ve properly done your homework beforehand, buying new RAM shouldn t create further problems with stability. Does it really matter if [CPU] has a large L2 cache? Not as much as you may think. Here are a few links detailing the performance increase from a larger L2 cache: Influence of L2 Cache Size on Conroe Processors Performance @ XBit UT3 Review: Cache Scaling: 1MB, 2MB, 4MB @ AnandTech 2MB or 4MB Cache? @ AnandTech Does it really matter if [hard drive] has a large(r) cache? Not really. Benchmarks have historically shown that there is little improvement from "doubling up" the size of the HDD cache. Spindle speed (RPM) and platter density (how many platters per drive, and how many GB per platter) play bigger roles in the hard drive s performance than the amount of buffer cache. Which version of Windows is better? Whether you should go with Windows 7 or Windows 8 depends on whether you re willing to use Windows 8 s Start Screen. Eventually, Microsoft will take that choice away from us, but until then.... But all of the reviews keep saying that Windows 8 is better.... Yes, Windows 8 (and 8.1) has some under-the-hood improvements over Windows 7. Many users have reported faster startup (especially with SSDs) and longer battery life (in laptops) with Windows 8. And lately, games have started to be optimized for it. But many people hate the Start Screen with the heat of a thousand suns. Rather than resume the war between Windows 7 and Windows 8 fanboys, I m telling you to go with what you feel more comfortable with. I love Windows 8, but I hate that damn Start Screen! How do I get rid of it? The easiest way is to find a Start Menu replacement. Two of the better ones are Classic Shell (freeware/donations) and Start8 (costs $5 USD). But I thought that Windows 8.1.... It brought back the Start Button, which is now another way to bring up the Start Screen. (That may change in future updates, but I can t tell you when.) What s this about my copy of Windows not working with all of my RAM? Many older versions of Windows had total system memory limits ranging from 4GB to 16GB. That limit includes desktop RAM, GDDR memory from your video card, and whatever else that Windows can find and utilize. Simply put, the component memory, including the video card memory, is recognized first; the RAM is the last type of memory recognized. Today, Windows 7 Home Premium has a 16GB memory limit. Windows 7 Professional, Windows 7 Ultimate, and both versions of Windows 8 (non-Pro and Pro) have a much higher memory limit. If you plan on using a lot of RAM in the near future, avoid Windows 7 Home Premium. Do I need to buy the retail version of Windows? Can I (legally) buy the OEM (System Builders) version? The retail version has a significant advantage over the OEM or "System Builders" version (from here on out, we ll call it OEM): you can transfer that license from computer to computer (on the condition that you remove all traces of it from prior systems beforehand). However, it oftentimes costs at least twice as much (if not much more) than the OEM version. The catch with using an OEM copy of Windows is that it comes with no supporting software and the system builder (read: you) is responsible for all troubleshooting and repair of the system it s installed on. Additionally, for Windows 7 and older operating systems, the OEM licenses are bound to the computer (namely, the motherboard) they were activated on. Though there are a few exceptions, the license dies the moment your computer dies. Windows 8 changes a few of the "old" rules about OEM licenses. Most notably, if you ve purchased the software (versus buying a computer with Windows 8 already preinstalled), you may transfer the license from one computer to another as if you have a retail license. However, as with the retail license, you must remove all traces of Windows from the older system(s). For more details on what you can and can t do with an OEM copy of Windows, perform a websearch for the EULA (End User License Agreement) of the OS you have. OK wise guy, should I buy a retail version or an OEM version of Windows? If you re a cheapskate or you re building a system you know you ll keep for a long time (even while factoring in periodic updates), go with an OEM license. We also recommend OEM license for those upgrading the OS on their laptops. (I mean, how often do you upgrade everything in those?) If you plan on keeping the OS license for several years but you plan on upgrading your entire system (mainly, the processor and motherboard) often during that time, a retail license may be the way to go. In that case, the best time to purchase a retail license is around the time the OS first enters the market. Do I really have to use Windows? Well, there is Linux... and we do have a forum to help you there. What about Apple? Can you use OS X on a PC platform? The Apple EULA prohibits the use of its operating systems on any non-Apple platform. Since the rules here prohibit the discussion of illegal activities, that s as far as we can go in talking about it."</post>
   <post id="73fdfba6-efd4-4802-8c9e-eaf2fb4a5f8a" section="General Hardware" discussion="Gen[H]ard FAQ">"How many [CPU] cores do I need for my system? It depends on what you use your system for. Here s what we generally recommend: Dual-cores and tri-cores (AMD X3 series) are generally fine for everyday "family" systems that aren t in constant use. They can handle some gaming, provided that you use a suitable discrete video card. Quad-cores are recommended for systems that will be used for heavy gaming, photo editing, "light" video editing (using consumer programs like Adobe Premiere Elements) and media (CD/DVD/BD) ripping. Six- and eight-cores work best for professional-level software (e.g., Adobe Premire Pro, Autodesk Maya), CAD (computer-aided design), heavy use of virtual machines (VM), and other resource-heavy tasks. (No, gaming doesn t count.) Dual-processor systems? You either know what you re doing or work for someone who does. You can easily game on an eight-core processor or edit video on a dual-core, but you may not see the performance level you re expecting from them. Then again, processors alone don t determine how well a game runs or how long it takes to encode video. Why should I (not) use SLI or CrossFire? If you have a large resolution (greater than 1920x1200) or plan to play games on multiple screens at the same time, SLI (Nvidia) or CrossFire (AMD) allows you to combine the resources from two (or more) video cards to generate more GPU power than you would from one video card. While you could use SLI/CF at a 1920x1200 or lower resolution, and two mid-range cards in SLI/CF can outperform even one high-end card, the disadvantages of SLI/CF outweigh the benefits at lower resolutions. The disadvantages of SLI and CrossFire all come from the addition of an additional video card. You re spending more money on your graphics and you ll need a good power supply (of at least 600 watts, in most cases) to run everything smoothly. You may also need to check your internal cooling as two video cards naturally run hotter than one card. Plus, some games don t perform well or aren t configured for SLI/CF. Great! So I can buy [old video card] used and get improved performance from SLI/CF, right? Easy there. You shouldn t grab any old card as eventually a newer card will arrive that outperforms your SLI/CF configuration. Plus, the true benefits of SLI/CF come from using your setup at resolutions that single-GPU video cards struggle with. If your old card is struggling with games at your current resolution, a second identical card may not be enough to solve your problems. (Then again, you shouldn t expect to pair two low-end cards together and have them match the performance of a high-end card.) 4K s here! And it s better than HD! So why aren t you cheering about it? 4K (or Ultra HD) is relatively new technology, so all of the kinks haven t been ironed out yet. Plus, the greater resolution requires a new, (comparatively) more expensive display and more GPU power (for example, the aforementioned SLI/CF setup) if you want to play games at a good frame rate. (Remember kids: 4K offers up to four times the resolution, or generates up to four times the amount of pixels, as 1080p.) What the hell is RAID? What is it good for? Why is it good? What does it do? RAID stands for Redundant Arrays of Inexpensive/Independent Disks (or some variant thereof), which integrates, via a RAID controller, two or more hard drives together for greater performance and/or data protection. There are many levels of RAID, with each level having its own strengths and weaknesses. Here are some explanations of RAID and its various levels. Please understand that RAID is NOT a backup solution. Is an SSD (solid state disk) truly faster/better than an HDD (hard disk drive)? Yes. SSDs generally have considerably faster read, write, and random access speeds than HDDs. You can start Windows in less than 30 seconds and load many programs and games even faster than that. Because SSDs use the same type of flash memory as RAM, you also have a storage device that generate less heat, use less energy, and can take more abuse than a traditional multi-platter HDD. SSDs still carry a higher cost per gigabyte (GB) over HDDs. For example, you can buy either a 2TB HDD or a 120GB SSD for around $100. And SSDs, like HDDs, run noticeably slower the closer they get to full capacity. But if you can afford one, the positives from using an SSD far outweigh the negatives. What should I do with my old PC? upriverpaddler said: ↑ Lol, I just dug up one of my old posts to copy into another post. And then I see this one while it was still on the clipboard. So here it is again. #1 Fold - Google [H]orde Team 33 and Google "Folding Farm" #2 Network Attached Storage - Google NAS DIY #3 Mail / Web Server - Google Apache Server #4 Christmas Light Controls - Google Computer Christmas #5 Search for Extraterrestrial Intelligence - Google SETI #6 Learn Linux - Google Ubuntu and DistroWatch #7 Sell it - You should have no need to google ebay. #8 Donate it to a folder - http://www.hardforum.com/forumdisplay.php?f=111 #9 Use it as a backup or second PC #10 Media Jukebox for parties - Google Silverjuke #11 HTPC (maybe you ll want a new case and TV tuner card) - http://www.hardforum.com/forumdisplay.php?f=103 #12 Total Home Automation - Google x-10 #13 Mod it into something new and exciting that will compliment your style - http://www.hardforum.com/forumdisplay.php?f=13 #14 Firewalled router - Google m0n0wall #15 Build an arcade cabinet - Google MAME #16 Build a carputer - Google Car Computer #17 Build a USB controlled Dance floor or Bar - http://web.mit.edu/storborg/ddf/ Click to expand... I ve never built a computer before... how do I do it? There are a lot of guides available, with different variations of the same instructions. Check out the guides from MaximumPC (Part 1 &amp; Part 2) and Corsair Labs, as well as mechBgon s guide for first-time system builders. There is also a series of videos available, courtesy of Expert Village. What are some good programs to run after building a new PC? Though this is the General Hardware forum, we re going to be nice guys and help you out a bit. The following is a sample of the programs used mostly for benchmarking and stress-testing hardware: Belarc Advisor (PC analysis) CPU-Z (CPU identification/analysis) HD Tune (HDD benchmark/analysis) Memtest86+ (RAM stress test/troubleshooting) Orthos (CPU stress test) Prime 95 (CPU stress test) SpeedFan (Temperature &amp; motherboard analysis/fan speed adjustment) This is not a complete list, nor was it ever intended to be one. Check out the General Software forum, the Overclocking and Cooling forum, and/or do a Google search for more answers. Can I use my flash/thumb drive to boot from the BIOS? It depends on the motherboard you re using. Though most motherboards released within this past year allow bootable USB devices (including flash drives), there are many motherboards that don t. If you have a motherboard that supports a bootable USB flash drive, there are several ways to create one. If you re trying to create a bootable flash drive to install Windows 7 or Windows 8, Microsoft offers a tool to help make the process easier. I have an old motherboard with PCI Express (PCIe or PCI-E) 2.0. Do I need to buy a new motherboard for my new PCI Express 3.0 video card? No. PCI-E 3.0 is backwards compatible with its predecessors (PCI-E 1.x and PCI-E 2.0). You may suffer some performance loss by going with a PCI-E 3.0 card, but it normally occurs when you use a high-end card like the GTX 780/Titan or the R9 290/290X or you decide to use SLI/CF with two or more PCI-E 3.0 cards. I ve got the Blue Screen of Death (BSOD)! What do I do now? A BSOD usually indicates a hardware issue. Figure out the code that the BSOD is showing and use AumHa.org s Troubleshooting Windows STOP Messages page to determine what it means. Each explanation of the STOP message has a link to its appropriate page on the Microsoft Developer Network (MSDN). You could also use the MSDN directly if you find a STOP message that isn t listed or explained well in the AumHa page."</post>
   <post id="cf2749e9-ad9d-4a2b-87db-3cc1dfd45ad2" section="General Hardware" discussion="Basic Troubleshooting Guide (Please read before seeking help)">"Ultimate Boot CD: UBCD is a FREE, bootable CD image (ISO) that includes many common diagnostic utilities and more! Ultimate Boot CD UBCD 4 Win (Some of the included software may be outdated) Bart PE Below are some basic troubleshooting steps you should take if you run into problems. While the following steps may or may not solve the problem, they should at least help in narrowing things down. Determine what the problem is... Ensure that the BIOS and hardware firmware/drivers are current (supports your entire system). Check (or recheck) all connections, both internal and external, and reconnect if necessary. Visually inspect all components of your system. Check for any signs of damage or tampering. Ensure that your hardware is free of dust, dirt, or debris. Clean what you can, and replace what you can t. Perform a search, within the forum or on the Internet, to see if others have experienced your problems before. If its a software/OS problem, you could Repair and/or reformat your OS installation (as a last resort). Software FAQ. Repair installation for XP: Boot to CD When you are welcomed to Setup, press ENTER to setup XP Now Press F8 to accept the EULA Select the partition that currently has your existing XP Installation Setup will detect the current installation, and ask if you d like to repair it Press "R" to repair If setup does not detect your current installation, then you either chose the wrong partition or your current installation is FUBAR, sorry. Repair installation for Vista/7: Repairing a Vista or 7 installation is a bit tricky, since MS changed the setup. Setup now copies an entire image over to the drive, instead of a file-by-file copy. Therefore, in order to repair the installation, you must perform an upgrade. In order to upgrade, you will need an image/ISO that is newer than what s currently installed. Download the latest windows updates individually from MS website. Use VLite to integrate new updates with your current ISO. Proceed with the upgrade. Here are some "quick fixes" ... Reset your CMOS and/or replace the battery. (Follow the instructions listed in your motherboard s manual.) Uninstall and/or reinstall the (suspected) hardware drivers. Use Driver Sweeper to remove any device drivers you will be replacing. Driver Sweeper 2.6.5 @ Guru3D If you can, update the firmware/BIOS/driver. A new version may contain a fix for your problems. Return all modified/overclocked parts to their stock settings. Remove the suspected part(s) from your machine. Replace the part(s) if necessary. Unplug any port headers (USB/Firewire/LPT/COM/etc). Try another cable (PATA, SATA, power, etc). Try another slot (PCI, PCI-E, DIMM, etc). Re-seat your CPU. Remember to clean off the old Thermal Interface Material (aka Thermal Compound) and apply a new layer. To clean off the old TIM, use 90%+ Isopropyl Alcohol and a coffee filter (poorman s lint-free cloth; q-tips are also good for cleaning the edges of the CPU and/or grooves in a heatsink). Narrow down the problem... Run stress-test programs, at STOCK speeds, (e.g. Prime95, memtest86+, HD Drive Fitness Test, etc) to narrow down potential problem areas. More details listed below, in post#2: Rule out any basic hardware issues. If you have spare parts, you can swap them in to help. Temporarily replace suspect parts with working ones and/or run the suspected part(s) on a known working system. Run a "minimum" build. Attempt to power the machine using just the motherboard, CPU, one stick of RAM, one hard drive, and the GPU (preferably onboard). Add additional components, one at a time, until the full rig is reassembled or you run into a problem. To rule out a short, remove the motherboard from the case and, on a static-free surface, attempt to power it up. Procedures and more detailed info below, in post#3: Back to basics&amp;#8230; A Barebones bench test. Seeking help... ComputerHope.com - Basic Troubleshooting Steps Directron - Troubleshooting Tips Computer Repair with Diagnostic Flowcharts PC Hell Microsoft Help and Support page (more for Windows- and Microsoft-related issues) Your favorite search engine. Post a thread asking for help.... but only if you were unable to make any progress (even after attempting the above steps). When creating a thread for troubleshooting help, please provide the following info: List what the problem is and/or what you need help with. Please be as detailed as possible. The more details you provide us, the less questions we have to ask, and the more details we can give you in return. Whenever possible, give us specifics like: Temperatures of key components (e.g., CPU, GPU, northbridge) and/or the inside of the case -- also, whether or not you re overclocking and/or using exotic (i.e. water-) cooling The voltages everything is running at How long you ve had your computer for Whether or not you ve tried diagnosing the problem already (e.g., from software, by finding a solution online), and (if so) what the results were If you re getting a BSOD, please post the error code!!! AumHa.org - Troubleshooting Windows STOP Messages (hex codes, given during a BSOD) How to disable automatic restart on error (BSOD) (If using XP, boot to safe-mode first by pressing F8 before the Windows Loading Screen) Be as detailed as possible, but also as concise as possible. We need to know everything, but we don t want to read a wall of text. Tell us what you ve done so far, and also report results of all efforts. Again, please be clear and concise, and keep us updated. =================== The guide was extracted from the Gen[H]ard FAQ, originally compiled by tiraides. Last updated by engiNURD on 2009-NOV-10. NOTE: To keep this thread clean, please do NOT discuss in this thread directly. Instead, please post any suggestions/comments/questions in this discussion thread: GenHard Sticky Discussions..."</post>
   <post id="5be89ab0-abc6-4903-8560-e864ad9143e8" section="General Hardware" discussion="Basic Troubleshooting Guide (Please read before seeking help)">"Updated Links and revisions. To help rule out any basic hardware issues, run these tests and report results in your thread: [RAM] Memtest* (bootable ISO), for at least 15 passes with ZERO errors. Memtest86+ v4.20 @ Memtest.org (2011-01-25) Memtest86 v4.0 @ Memtest86.com (2011-03-28) [CPU] Prime95* Small FFTs test or Intel Burn Test, for at least 12 hours with ZERO errors at acceptable temperatures. Please research the safe temps for your CPU. Prime95 v26.6 @ Mersenne.org (2011-04-8) IntelBurnTest v2.3 @ Guru3D (2009-07-05) [GPU] FurMark, ATI Tool, or 3DMark loop, for at least 6 hours with no visual defects (fragmenting/discoloration/pixilation/etc). FurMark v1.9.0 @ Geeks3D.com (2009-07-03) ATI Tool v0.26 @ TPU (2006-12-08) 3DMark®06 (Build 1.1.0) @ Futuremark [HDD] HD Tune Full Error Scan HD Tune v2.55 (2008-02-12) [HDD] Drive Fitness Test (or any other manufacturer s provided diagnostic test utility, available from their websites). Drive Fitness Test v4.16 @ Hitachi Data Lifeguard Diagnostic @ WD SeaTools @ Seagate/Maxtor ES-Tool @ Samsung [CPU/RAM] Prime95* Blend test, for at least 24 hours with ZERO errors. Monitor all temperatures during testing. These programs are recommended: Core Temp Real Temp ATI Tool Riva Tuner Speedfan Other programs that may be helpful: CPU-Z GPU-Z HD Tach ATTO Speedfan CrystalMark Everest Trialware Sandra Lite More? Tell us here! *Note: This software is included in the UBCD."</post>
   <post id="f0dd2269-624b-4568-965e-fad93ceb9517" section="General Hardware" discussion="Basic Troubleshooting Guide (Please read before seeking help)">"Back to basics&amp;#8230; A Barebones bench test: If you followed a build guide, this should have been one of the first steps to assembling your computer. If you did not do this prior to building, it may help rule out several issues. Possible common symptoms: The system does not POST (ie. the system powers on, but does not complete POST (Power On Self Test)). The system powers on for a quick second or two, then powers off. The system powers on, but you don t see anything on the screen. The system does not power on at all. The system was working fine, but not after you moved it from one location to another. The system was working fine before you cleaned out all the dust. The system was working fine before you installed a new (or replaced an) expansion card. A Barebones bench test - Procedures to follow if your system does not POST: It would help to have spare parts. If you don t have any, try borrowing from a friend. Setup everything OUTSIDE of the case, with the mobo on top of its cardboard box. Plug in only the essentials: PSU CPU w/ HSF Single stick of RAM in the slot closest to the CPU. Video card (if no on-board) along with its molex or PCI-E power connector if needed System Speaker/Buzzer (if no on-board) Monitor Keyboard Clear your CMOS (Reset the BIOS) by following the instructions in your mobo manual. Some boards have on-board reset switches instead of a jumper. Make sure you have an updated BIOS, and that your board supports your CPU. Power on the system using a spare power switch or by shorting the two power switch leads for a few seconds or less (typically done with a screwdriver). Some boards have on-board power switches. Be sure you have a buzzer connected, to hear any POST error beeps. If you have an LCD on-board, it should give you a POST error code either in addition to or in place of a beep error code. Some Asus boards would "voice" these codes via the on-board audio line-out, in which case you d need a regular speaker or headphones. If it won t POST, try different DIMM slots. If it still won t POST, remove all RAM and make sure you get error beeps. If not, then try known working RAM and make sure your RAM is compatible with your motherboard. If you do get error beeps but it still won t POST, try another slot for the vidcard (PCI-E, PCI, or AGP, depending on your card) if another is available. If not, or the other slot did not work, remove the videocard and listen for error beeps. If you get error beeps with a single stick of RAM and no vidcard, try another known working video card. If it still won t POST with known working RAM and Vidcard, remove the RAM and Video card, and listen for error beeps. If no beeps, try re-seating your CPU. Be sure to properly clean and re-apply thermal compound (see above for a few more details). If you do get error beeps, then its either the vidcard or RAM. If re-seating the CPU/HSF does not get the system to POST, then its most likely an issue with your CPU, Mobo, or PSU. CPU s rarely go bad, so try a known working PSU that s capable of powering your system. If another PSU doesn t help, you can try another motherboard (spare or borrow from a friend). Paperclip PSU Trick: On the main ATX 24-pin connector, short (connect) the green wire with any black wire, using a paperclip. How to test with a multimeter @ BFG ​"</post>
   <post id="623776fa-540b-491f-b22e-a705922cf622" section="General Hardware" discussion="Basic Troubleshooting Guide (Please read before seeking help)">"One more reserved spot. Again, PLEASE do not respond in this thread. Please use the GenHard Sticky Discussions Thread."</post>
   <post id="ef88fd6e-49f1-4d50-92be-e76a4cb95901" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"I ve found using my sig system that things like external 3.5" hard drives (2.5" work fine!) and my Xbox 360 controller won t work or be recognized using my front panel USB ports (USB 3.0 spec) but they work no problem when hooked up to the back ports. I ve ALWAYS had problems with front panel USB compatibility on every PC I ve ever built, so I know its not a specific hardware problem with this PC. Is it the front ports not getting enough power or something? This seems to be a common occurrence among front USB inputs."</post>
   <post id="9e95a833-cd3e-46c7-bd04-ec29fbe3cb8e" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"It may have to do with the power output on those front usb ports. Determine if the motherboard has on/off jumpers for those ports and set them accordingly. Also check the wiring. Make sure the wires leading to the front USB conform to proper USB specification. http://en.wikipedia.org/wiki/Universal_Serial_Bus"</post>
   <post id="a2022b6a-8c9d-4572-a4b0-520467f6a97b" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"Holy shit bro, 8 year member with 37 posts?! OK, on topic, I don t know how to check front panel power...I m assuming it works as it can charge devices and power 2.5" external hard drives. Wiring is fine...if anything it should be better than most considering the length of the cable is much shorter than standard...using a mini-ITX case here. As far as specifications go the front ports do achieve USB 3.0 speeds, that I know from testing my Vertex 4 SSD on the front ports using an enclosure. Like I said in my first post, this seems to be an ongoing issue with ALL motherboards and ALL cases I ve used over the years...and I ve used PLENTY (at least a dozen cases and multiple motherboards). So this doesn t seem to be a problem specific to my current build. Also, just to be clear, I m not looking for a fix as I feel none exist...maybe its just the nature of the beast? I mean, if its happened once or twice sure, its a fluke, but for the issue to be normal on every PC I ve ever built I feel that theres a bigger wide spread issue here."</post>
   <post id="d9ca9e4d-35fe-40a6-b800-a5ffbf176d45" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"Some USB 3.0 headers require drivers to work. I know my rear 3.0 connections on my Rampage III and IV needed software installed. I ve never had an issue running front USB, but you need to make sure you have the headers connected according to the case manufacturer schematic that came with the case.....altough most are pretty much all the same...... One thing i did notice on my Coolermaster case, where the wiring enters the front connection.....a big piece of plastic.....the wires connect in the same fashion as they do to the motherboard, and over time they worked loose. It was over an hour to disconnect the plastic thing and reconnect the headers....this time I put superglue on the connections so they wouldn t work loose."</post>
   <post id="b5f1c726-067f-4e86-99ee-90086065c70d" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"Driver are all installed. Cable or connection is not the problem...the connector is properly and securely fastened with plenty of give in the cable."</post>
   <post id="70c56a9a-3d25-442b-bda9-b333580bf959" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"I ve noticed my wireless mouse/keyboard has less range on the front panel compared to the back - sounds like a power issue."</post>
   <post id="e0d5d09f-ae84-41c6-b4cd-b272a4bfbd84" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"geraltofrivia said: ↑ I ve noticed my wireless mouse/keyboard has less range on the front panel compared to the back - sounds like a power issue. Click to expand... That s what I think it is too. My theory is that the connection between the motherboard header and the actual front panel plug drops the voltage down just to the point of not QUITE being able to power a lot of device. I mean, what other explanation is there really? However, I m 100% sure that all motherboard manufacturers are aware of this, so you d think they could pump a little more voltage to the front panel motherboard headers. This I think might fix the problem but it also doesn t explain why some motherboards I ve owned DO pump out more voltage to the front panel ports. A Gigabyte board I had owned used some rapid-charge tech...used more voltage to charge devices quicker, which it did, meaning more power, but still the same issues...so that brings to believe that maybe power isn t the issue after all. I don t know...like I said, not looking for a solution to the problem, just an understanding as to why this problem even exists in the first place. I know its not just me, every PC has this problem whether you know it or not. You just may or may not have come across a device that displays these issues. That I would consider a fact."</post>
   <post id="61d56559-b472-4e7d-918d-e7245196b0e1" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"Any more ideas?"</post>
   <post id="9a5afe99-d2fd-4d41-95a6-034913b70fad" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"I also have had this problem on every PC I ve built, I end up just hooking up everything to the motherboard s USB ports if possible unless I m feeling super lazy."</post>
   <post id="d0758424-14b4-4ae0-9885-b9a2598b75dc" section="General Hardware" discussion="Why don t front USB ports work with a lot of devices?">"Hi everyone, i have been surprised to find how little information there is out there about usb 3.0 ports , how they are powered, and the typical problems we all run into with them. I have spent some time digging around the interweb and found a few tid bits of interest, as well as my own experiences: So to do with the front panel headers on motherboards and adaptor cards for usb 3.0 - the standard output for these connectors is limited to 500 ma , which paired with the front headers themselves being connected with long, high gauge, poorly shielded, and realatively poorly made cables makes a storm of bad communication and under powered front ports, especially when trying to use fast devices like usb sticks and USB  powered  external hard drives! I myself have encountered poor write sepeds on my usb sticks in the fornt usb 3.0 ports, and they periodically drop out, as well as serious drop outs or not even being able to read or power external hdd s that are powered through the usb cable. These problems never occur when im using the back ports directly off my mobo or adaptor card, and going back to the power issue, this is because the usb ports on the mobo provide 900 ma + of power, and the front header ports are only given 500 ma of power (found this out through tech support for one of my cases) Now all this being said, there are other factors at play as well. One big one is poorly shielded internal front panel cables which use high gauge wire and the length of the wire alone creates resistance which slows device communcation down, this problem does not exist on the mobo ports because they are directly connected to the controller with no china made cables in the way to interfere. Another issue commonly run into is drivers. If you have poor drivers or windows drivers they usually always slow things down or lead to the ports not working at all, so make sure if at all possible that you have the correct drivers for your system. Lastly i have read of several instances where computer cases have had defective front panel usb 3.0 cables and or ports/connectors leading to a plethera of issues such as drop outs, no communication and poor communication with devices leading to data corruption. So in conclusion my advice would be to make sure your drivers are up to date and correct, and to really just avoid using the front usb 3.0 ports if at all possible, the rear ones are significantly more reliable and stable Good day eveyone!"</post>
   <post id="7983950e-be74-445a-9aab-3ca2a4821425" section="General Hardware" discussion="wow didn t think the old girl could do it...">"I just loaded Doom 2016 on an old Core 2 quad Q6600 machine witn 4GB, 240 ssd, 1TB hdd,Gigabyte Iram, Ageia card,Gt 740 with win7 64. It runs the new doom smooth as silk... THe only I7 machine I have that won t run doom is an HP laptop with Radeon Hd6770m it only has a gb of vram.. Maybe someone will figure a way......."</post>
   <post id="0f0f30d0-749d-416a-952f-742afbe2122b" section="General Hardware" discussion="Hauppauge HVR-1265 not getting channels">"I tried everything and every option. When I scan for channels nothing comes up, hooked up through the coax connection to the cable box. I tried scanning both digital and analog. Tried with the WinTV software and also Media Center. Tried the Digital QAM hooked directly to the wall and that finds the channels but they are all encrypted and only in SD. I need HD, FOX, NBC, and ABC. Any ideas? I need maximum quality so typical downloads are not going to cut it."</post>
   <post id="42a5494a-e08e-419a-a36f-0aeaada5c356" section="General Hardware" discussion="Remove write protection from pendrive">"Hello: Hoping I am in correct forum to post this question. If not, would a "admin" please move to correct forum. I have a Lexar 16Gb flashdrive that somehow acquired  write protection". I did NOT install this "feature"!!! Now, in order to use the remaining 6+ Gb s on the drive I must remove the "write protection". I have read and followed every operation I could find that deals with Win7. So far, everything has failed to accomplish my goal. I can  read" all the files on the disk, so it is still operable. Could someone suggest a downloadable program, or an  operation" that would either format over write protection or simply remove this "curse". The drive is too new to just throw out. Someone surely must know how to accomplish removing the write protection!! Please do not suggest anything on Win7 for I ve spent countless hours attempting every "fix" I could find and all have failed. Oh, and...there is no physical  switch" on the drive. THANK YOU Rick P.S. I just tried mUSBfixer and cbl-data-shredder. Both "claimed" they formatted the drive, but did NOT. This tells me the drive cannot be written to and/or not "mounted". Now, maybe I need to know how to mount the drive so that it could be formatted/wiped? H-E-L-P!! Could using a Linux machine be the answer?"</post>
   <post id="8baa7b0c-79d2-4bc1-a8ec-45dd701d14f6" section="General Hardware" discussion="Remove write protection from pendrive">"Does it have a physical switch on the drive that puts it in write-protected mode?"</post>
   <post id="fd5df68b-8091-4114-82f5-df62a93cfeb5" section="General Hardware" discussion="Remove write protection from pendrive">"Run Regedit.exe (searching regedit will usually show the program at the top of the list). Navigate to the following key: Computer\HKEY_LOCAL_MACHINE\SYSTEM\ CurrentControlSet\Control\StorageDevicePolicies Double-click on the WriteProtect value in the right-hand pane of Regedit.exe. Change the Value data from 1 to 0 and click OK to save the change. Close Regedit and restart your computer. Connect your pendrive again, and you should find it is no longer write protected."</post>
   <post id="996a4fe0-7c09-489a-8a05-98359545a641" section="General Hardware" discussion="Remove write protection from pendrive">"Skillz said: ↑ Does it have a physical switch on the drive that puts it in write-protected mode? Click to expand... To: aliona In my original thread, I stated the answer to this question. Rick"</post>
   <post id="870c7d9e-9177-4c0c-8234-620acf4cac6c" section="General Hardware" discussion="Remove write protection from pendrive">"aliona said: ↑ Run Regedit.exe (searching regedit will usually show the program at the top of the list). Navigate to the following key: Computer\HKEY_LOCAL_MACHINE\SYSTEM\ CurrentControlSet\Control\StorageDevicePolicies Double-click on the WriteProtect value in the right-hand pane of Regedit.exe. Change the Value data from 1 to 0 and click OK to save the change. Close Regedit and restart your computer. Connect your pendrive again, and you should find it is no longer write protected. Click to expand... To Skillz: In the original thread, I distinctly directed that no replies offer any MSWin suggestions. EVERY one that I ve tried has failed, and believe me, I ve tried everything I could find pertaining to Win7. Rick"</post>
   <post id="eee839b4-a803-4ca9-8c4c-3f353d4282b9" section="General Hardware" discussion="Remove write protection from pendrive">"Well guess you know everything then. Good luck."</post>
   <post id="27fe1997-3f15-4d64-91d0-f81311e59a39" section="General Hardware" discussion="Old Parts for Smaller New Case...Need Help">"Hi! I want to take my current setup (an old HTPC that I only use now for internet and Microsoft Office) and replace as few parts as possible (looking to do this as inexpensively as possible) to fit it into a much smaller case. I only have one 2.5" SSD and no other drives. New case must have at least 4 USB ports. I am open to a new motherboard if I absolutely have to, but I would like to eliminate that expense if possible. My objective is to keep the price down as I really don t do much on this computer, but its just too darn big. I am looking for any recommendations you may have for the smallest case possible that can use as many parts as I currently have and keep my costs down. I understand I may need some other parts other than a case...so thats OK if I do. Please find below a list of my current parts. I really don t know a lot about hardware, so any help is really appreciated. Thank you so much! SilverStone Grandia GD04 AMD A6-3650 GIGABYTE GA-A75M-D2H FM1 AMD A75 (Hudson D3) HDMI SATA 6Gb/s USB 3.0 Micro ATX AMD Motherboard Crucial 4GB 240-Pin DDR3 SDRAM DDR3 1600 (PC3 12800) Desktop Memory Model CT51264BD160B CORSAIR Builder Series CX430 V2 (CMPSU-430CXV2) 430W ATX12V v2.3 80 PLUS Certified Active PFC Power Supply"</post>
   <post id="87b90027-31ee-4264-ad9f-9f0f811af5f6" section="General Hardware" discussion="Bootloop with new Asus Z97 Pro Gamer">"Hello, I just changed my motherboard for Z97 Gamer Pro from Asus, before, I had an MSI. I replaced the CM and kept ALL the same config. Once reassembled everything, I press the power button and the PC reboot loop 3 or 4 times then appears on the screen message that says: "CPU HAS BEEN CHANGED" "devices detected" with a list PRESS F1 TO RUN SETUP. (Ok nothing unusual there), then I went into the BIOS, everything works. I did a Clear CMOS to see if I could reproduce the problem in the boot loop beginning, it did not. I tested with a restart from Windows, no boot loop problem. I tried with a cold start, no problem. I also tried a boot 20 seconds after pressing the power button, disconnect the PC, no worries, the PC started normally. Such testing the strips of RAM in all ports, dual, or with a single stick. No problem. In short, not (for now) to replicate the boot loop I had the very first start. No BSOD either. BUT I have never had this problem after climbing config, it worries me because it might be a concern that could reappear totally random / later. Does anyone has had this kind of boot loop at the first ignition until everything is in order? I hesitate to return the card: ??: Thank you !"</post>
   <post id="d8ed4d25-0def-4b68-ab04-0a52005a1940" section="General Hardware" discussion="Computer wont turn off.">"Basically my computer wont register turning off no matter what, I can fully unplug it from power, fully turn it off, and it registers that it has been on for however long it has been off for. I ve updated BIOS, I ve reset CMOS, and nothing worked. I literally just turned my computer on and this is what it says Gyazo - 1e1ce4dd11651a2ecaec869e036e85e2.png . Why is this affecting me? Oh well, basically its messing up my Memory/RAM. The longer the computer is on the more RAM its using, therefore when its been on for 3 days I can t even open Google Chrome, it lags so bad. Please help. TL;DR My computer won t register turning off no matter what. I need help, thanks."</post>
   <post id="2a90dce6-da98-40d5-a379-da46b14e6d9d" section="General Hardware" discussion="Computer wont turn off.">"Maybe its a mix of driver and bios problem. Try to uninstall all new drivers one by one and Rolling back to the previous driver."</post>
   <post id="3a37139e-46d7-429c-af31-f02ece2ae632" section="General Hardware" discussion="Computer wont turn off.">"When did it start happening? Maybe it s a memory leak bug/virus. If it started recently, try a system restore. Would it be possible to install an OS to it on a separate drive to see if it still happens?"</post>
   <post id="0a88be3d-482b-430b-b302-37460c7ca136" section="General Hardware" discussion="Computer wont turn off.">"Have you tried removing the bios battery?"</post>
   <post id="04a27a30-b19d-480a-a5c0-53623fdebd13" section="General Hardware" discussion="Computer wont turn off.">"turn off all power options in bios and in windows. sounds like it suspending to ram instead of powering off."</post>
   <post id="062a61b1-53b4-4874-98a5-adb6096c7452" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"can someone please explain what does a digital tablet does? does it work like a mouse, can i use one instead of a mouse, is it better/how accurate is it compared to normal mouses? does anyone have one?"</post>
   <post id="135fc504-6e80-42be-842d-58a9dc022040" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"I think those pens are mainly used to write on the tablets, or draw things for art. A mouse should be better for daily activities"</post>
   <post id="c75dca21-a265-4959-9428-d432e9c34ea5" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"Its used for photo editing and graphics design. its more like a digital drawing pad for artists in photoshop."</post>
   <post id="ee7289b4-e5e7-41d8-a493-2f7beae3c259" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"yes, thanks for replying. i was thinking the same thing. how is the accurace of a pen tablet, is it more sensitive than a mouse, can it be used as a mouse? and what about those that have the pad and pen and a mouse, what is that?"</post>
   <post id="2b1a1830-0d45-4254-810e-381fbd3c3acb" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"stopmenow said: and what about those that have the pad and pen and a mouse, what is that? Click to expand... those are most commonly refered to as  WACOM  tablets. check out this link WACOM products"</post>
   <post id="7497c832-482b-4f54-86c6-daec69ea540d" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"You can use it as a mouse, but I would suggest not I have a wacom as I generally do alot of colouring in photoshop, but for everyday use you can t beat a mouse.  tis simple really, if you are going to do alot of digital artwork, a wacom setup will give you a big advantage over mouse once you get used to it. If you don t do any digital artwork then save your money and buy something else you would get more use out of instead... like beer or women"</post>
   <post id="b33937d0-c5a5-4fa5-9207-032bc258e8e7" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"WACOM Intuit3 is awesome. I love mine. I use my pen as a mouse when I am doing a graphic/photoshop session. But when I am done, I just switch over to my G7....No problems. If you work with photoshop or any graphic program, it is worth it hands down...."</post>
   <post id="2ea91623-25cc-4eb5-886a-26c8c935275f" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"i am in complete agreeance with the above posts. my 12x9 platinum intuos 2 has served me very well for a couple of years now. i had issues with the mouse a few months after purchasing it, a quick phone call with no wait time and within 3 days a new one was sitting at my doorstep. for photo editing and graphics work there is no substitute to a grpahics tablet and the wacom ones are top notch. they are however pretty much just for drawing or graphics and i couldn t really see anyone wanting to use it for everyday mousing. im sure you would get use to it after a while but i, like the rest of the posts here, would not recommend getting one for that use. HTH"</post>
   <post id="d60c1e26-6c52-4b83-a0b4-ef7dee948cea" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"You can get alot of good info at The Best Drawing Tablet"</post>
   <post id="536ede20-cea5-496b-a8f2-fbf25959e8c8" section="General Hardware" discussion="digital tablets mouse/pen ? what are those?">"Just stop now."</post>
   <post id="88c0de7e-30c6-4df0-9d27-493cee67eebb" section="General Hardware" discussion="Business Server">"I need some help configuring parts for my office server. Any help would be appreciated. I will se the server for our business software tomrun on. Also will setup the server to run server 2012 with terminal services so I can have outside clients remote into server for there desktop an access to the business software. At most 3 users remoted in at same time. Also setup on the server as ftp server for pulling files while at customer site. Thanks in advance. I already have the server OS. So just need help on hardware."</post>
   <post id="d04b45b3-c37f-4b2a-aa37-a7558b30d017" section="General Hardware" discussion="Business Server">"You should let a big name PC vendors such as Dell or HP handle this. If it s for a business then up time is probably of big, big concern and if it isn t then it probably should be. Therefore, the business class computers from Dell and HP include top notch warranties and repair services. We re talking same day hardware replacement or at most next day hardware replacement. You re not going to get that level of support buying all the pieces yourself from various retailers and putting it together yourself unless you build two identical servers and leave the 2nd in it s packages and hope that if something on the primary fails that your spare parts isn t DOA. I m not familiar with HP s offerings, but I know Dell offers a wide variety of systems from all sorts of price points. If you still refuse to go that route then we re going to need more information from you. So start here."</post>
   <post id="ea618107-4d89-4122-88a3-050289508db0" section="General Hardware" discussion="Business Server">"Yea it s generally not a good idea to build your own business class server. You want the warranty s on all of the hardware... plus the big names like Lenovo (these days), Dell, HP, even supermicro all offer great support for their hardware."</post>
   <post id="d2948f32-fbc1-49a7-84b7-1b63262ff1ca" section="General Hardware" discussion="Business Server">"Go for Fujitsu or Lenovo, I d avoid Dell and HP due to their choices of hardware in general."</post>
   <post id="7fc92ee9-8079-4f0e-b037-2daeaa3a8852" section="General Hardware" discussion="Business Server">"Dell, get in touch with a human business sales rep. You can often save 20% or more off web pricing depending on how hungry they are. (I would do an R730xd)"</post>
   <post id="5f1bce73-a636-4859-85ac-c62e403c5009" section="General Hardware" discussion="Laser printer suggestions?">"My last inkjet died over the weekend. It will be the last inkjet I ever buy. Any suggestions for a decent laser printer with scan/copy functions? Wanna keep it under $150. Tons of reviews over at Amazon and Newegg, but they range so wildly (for the exact same printer, no less) that it s damn near impossible to know what to believe."</post>
   <post id="2ef3c5a4-ccb2-4b7b-9c6f-bdfe248b3ffd" section="General Hardware" discussion="Laser printer suggestions?">"Looking for color or monochrome? I picked up one of these a few months ago, and while it s over your budget, it s a hell of a nice printer and I ve got zero regrets. Photo printing isn t quite as good as my Canon inkjet on photo paper, but I so rarely do that it s a non-issue. Here s what looks like a monochrome version of the same thing for $149.00. I m over inkjets, as well. I m very happy with my Samsung laser printer, it s been great."</post>
   <post id="03eaeef8-7540-4528-b7b2-97ca055634bc" section="General Hardware" discussion="Laser printer suggestions?">"Oh, yeah. Probably would a helped if I specified mono or color. I only need mono, and will check out that $149 Samsung. Tanx!"</post>
   <post id="f4e565e6-dbc8-456a-8eb7-98798e11204b" section="General Hardware" discussion="Laser printer suggestions?">"Hp LaserJet 5P Absolutely the best, most reliable and indestructible BW laserjet I ve ever serviced or worked around. And I HATE printers and faxes with a fucking passion. But the 5P gets glowing accolades in my books. I ve seen them survive for 12+ years at a highschool. Those bitches would survive a nuclear war and could probably be used as anti tank defences. Enough said."</post>
   <post id="9db3326b-22ac-487d-a590-7cddcddb23f1" section="General Hardware" discussion="Laser printer suggestions?">"Bought that monochrome Samsung. It does everything I want and costs just $30 more than the Canon inkjet that died on me after less than six months. Thanks for the input!"</post>
   <post id="6e618096-982e-46f4-997f-d9e053d7ebdb" section="General Hardware" discussion="Laser printer suggestions?">"Have had good luck with Brother and Samsung branded laser printers, those drums last forever. We were still using the "starter" drum that the Brother printer came with 3 years later."</post>
   <post id="6acf53b6-518d-427a-90a3-4e0a8f327904" section="General Hardware" discussion="Laser printer suggestions?">"I agree with the Samsung printer, I bought the 3405w laser printer 1.5 years ago, have printed hundreds of pages from starter drum and still works ... What concerns me is I bought a replacement drum same day as the printer and the expiration date has come and gone. I didn t realize the starter drum would last so long, otherwise I would ve waited on buying the spare drum."</post>
   <post id="453ae2fb-092f-4cd9-b7aa-729bbad3fb13" section="General Hardware" discussion="Laser printer suggestions?">"It s toner. Chances are it ll work fine, "expired" or not."</post>
   <post id="1a4c28b9-3b86-455b-b70b-a69095824599" section="General Hardware" discussion="Laser printer suggestions?">"I don t think toners expire, it s not like milk. Each toner also has a little clear part on the sides that the printer shines a laser through to determine remaining toner amount. I ve found that even when my printer says toner is low, if I tape that little hole, I can still print hundreds of pages before I can truly see a difference in the printed material. The low toner warning on most printers are way too aggressive, and they are that way so companies make money on toner sales."</post>
   <post id="f807d4fa-73af-43c9-bafd-da40abd3d6cd" section="General Hardware" discussion="Laser printer suggestions?">"ok, well , my toner date is may 2014.... so I called Samsung and talked to rep she said the date on their toner is the born on date and good for 1 year after that..."</post>
   <post id="0ff28f52-8ddc-4cca-a458-5ce74f7a6236" section="General Hardware" discussion="Laser printer suggestions?">"It will be fine. It s black powder. It doesn t go bad."</post>
   <post id="83983959-7fb7-4a11-8dfe-6044fcd8c391" section="General Hardware" discussion="Laser printer suggestions?">"The way Samsung and any other printer maker makes money is through toner/ink post-sale. It s in their best interest for you to buy toner as frequently as possible. Again, toner isn t like milk, it doesn t just go sour. Them saying it s good for "1 year" is just marketing talk."</post>
   <post id="4a2ea292-d1b6-4397-a403-7ede8af492e5" section="General Hardware" discussion="Laser printer suggestions?">"ok, thanks for info , didn t realize it was powder either"</post>
   <post id="2c384727-21ef-462c-8af4-b7b927c52601" section="General Hardware" discussion="Laser printer suggestions?">"I bought this two Black Fridays ago to use at work for something way too cheap like $79. I like it better than the $500 HP I have at home."</post>
   <post id="7467955e-eb52-4f17-bbff-36845afe894d" section="General Hardware" discussion="Laser printer suggestions?">"Been using my new Samsung M2885 for a few days and love it. Should have jumped to laser years ago. Thanks, again, to BlindedByScience for the suggestion!"</post>
   <post id="d681da60-7d90-4503-8798-be60b0c83b7d" section="General Hardware" discussion="Workstation upgrade from i7-920 feedback">"My i7-920 is limping along. It has worked well for many years, but lately the motherboard seems to be slowly dying. It can no longer see all attached drives and has lost the C: drive while the machine was running. Rather than spending the money on a used motherboard, I figured this is a good excuse to upgrade. 1) What will you be doing with this PC? Gaming? Photoshop? Web browsing? etc A little bit of everything. I plan to do some gaming, photo editing, light video editing, programming, some light VM testing, web browsing, etc. 2) What s your budget? Are tax and shipping included? The parts I ve been looking at are coming in around $700, but I m willing to spend more if it ll provide enough benefit. 3) Which country do you live in? If the U.S, please tell us the state and city if possible. U.S. Chanhassen, Minnesota I have access to a Micro Center. 4) What exact parts do you need for that budget? CPU, RAM, case, etc. The word "Everything" is not a valid answer. Please list out all the parts you ll need. I ll need CPU, RAM, Motherboard, Cooler and possibly power supply 5) If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. List make and model. Case - NZXT H440 Graphics Card - Radeon HD 6950 (Looking at picking up a GTX 1070 when they re released) SSD - Samsung 850 Evo 500 GB HD - HGST 4TB Power Supply - Corsair HX 850 (This was purchased with the CPU around 7 years ago, so it may be worth getting a new one.) Monitors Keyboard Mouse Speakers 6) Will you be overclocking? I m not planning to. 7) What is the max resolution of your monitor? What size is it? I run 3 monitors (Dell U2415) at 1920x1200, but only use one for gaming. 8) When do you plan on building/buying the PC? I d like to order soon and build it this coming weekend. 9) What features do you need in a motherboard? RAID? Firewire? Crossfire or SLI support? USB 3.0? SATA 6Gb/s? eSATA? Onboard video (as a backup or main GPU)? UEFI? etc. Nothing comes to mind 10) Do you already have a legit and reusable/transferable OS key/license? If yes, what OS? Is it 32bit or 64bit? Windows 10 64bit This is what I ve come up with so far: PC Hound Part List CPU: Intel Core i7-6700K 8M ($346.39 @ Amazon) Motherboard: MSI MSI Gaming Z170A-G45 Gaming ($122.98 @ Newegg) Memory: G.SKILL 32GB (2 x 16GB) Ripjaws V Series ($109.99 @ Newegg) Power Supply: EVGA 750W 220-G2-0750-XR ($79.99 @ NCIX) CPU Cooler: COOLER MASTER Hyper 212 EVO RR-212E-20PK-R2 ($29.49 @ Amazon) Total: $688.84 Price may include shipping, rebates, promotions, and tax Generated by PC Hound There s currently a package deal on the processor and motherboard from B&amp;H. It is 459.99 with $40 MIR. Seems like a good deal, and with some looking there doesn t seem to be much difference between this motherboard and the MSI Gaming Z170A GAMING M5. I m not sure how I feel about the Killer NIC, but I figure if it causes problems I can get an Intel PCIE NIC (and it seems difficult to get away from). From what I read, there isn t much of a performance difference with different memory speeds. Has that changed with the z170 chipset? Anything that should change? Any possible problems with the listed hardware?"</post>
   <post id="d9b70bd6-8c3a-4148-b769-1a33b7b4c195" section="General Hardware" discussion="I Need Help - System Issues">"Hi, I have a computer issue that I can t figure out. Please help! Here is what happened: Yesterday I turned on my computer and everything was normal for about 30 minutes. I was watching a YouTube video when it suddenly froze. The audio continued but the image was frozen, and the computer refused to respond to any keyboard or mouse input so I turned it off after a few minutes. After that it wouldn t boot up Windows again. It would get to first Windows splash screen and then my monitor turns off and nothing happens. After restarting it three times I tried Windows repairs, system restore to different points, nothing worked. Safe mode worked just fine. I figured since it just finished installing a Windows update maybe it corrupted something, so I backed up what I needed in safe mode and reinstalled Windows fresh from a USB drive. I reinstall, everything goes normally for a few minutes until I start downloading and installing video drivers, Chrome, etc, and it just suddenly reboots. Once again it fails to load in to Windows at the same splash screen point, and the monitor turns off. Except now, it will just reboot at this point about 50% of the time. I reset the BIOS to defaults, reseat all my cards and connections inside and clean out the small amount of dust. I ran Memtest for an hour, no issues. So I re-install Windows again. Download and install drivers, and reboot. Except now, it will boot in to Windows each time, but just restart after I try to do something. It seems like it is fine if I just leave it idle. I am unsure what to try next. The last hardware change I made was a year ago when I added an SSD, it has not shown any issues whatsoever before all this. The specs of my computer are in my signature, except for the added Samsung 850 Evo 250GB. Also, the BIOS reports all normal voltages with the power supply. And all temps seem normal, and all the fans are working. And one other thing that I can t figure out. I tried booting up Linux Mint from a USB drive. I ve done this plenty of times before, but each time after it completes the 10 second countdown, the monitor just goes in to standby, just like with Windows."</post>
   <post id="ee24bf11-a993-499c-8a8a-140e1beea831" section="General Hardware" discussion="I Need Help - System Issues">"Take the undervolt off your GPU. It s more than likely a video or power issue. Either the GPU is going, it just doesn t "like" the undervolt anymore, or your PSU is going. There s a chance it s the motherboard, but that s unlikely. So first step is take the GPU back up to stock voltage. If that doesn t work you have 2 options -- swap in a spare GPU or spare PSU. To help narrow it down, if you have onboard video use that and run something like OCCT to stress the CPU and bring up the wattage load on the PSU. If it reboots with the GPU removed, it s likely the PSU. If it s stable under load without the GPU, it s likely the GPU."</post>
   <post id="4fe81590-0674-43db-9b4b-d0a17249cff6" section="General Hardware" discussion="I Need Help - System Issues">"silent-circuit said: ↑ Take the undervolt off your GPU. It s more than likely a video or power issue. Either the GPU is going, it just doesn t "like" the undervolt anymore, or your PSU is going. There s a chance it s the motherboard, but that s unlikely. So first step is take the GPU back up to stock voltage. If that doesn t work you have 2 options -- swap in a spare GPU or spare PSU. To help narrow it down, if you have onboard video use that and run something like OCCT to stress the CPU and bring up the wattage load on the PSU. If it reboots with the GPU removed, it s likely the PSU. If it s stable under load without the GPU, it s likely the GPU. Click to expand... Sorry about that, the under volt went away a year ago when I installed Windows 10, I couldn t remember how I even did it all those years ago. Wouldn t the GPU show artifacts if it was failing? I hope it s not the the motherboard. Back when this was new, I had to RMA my first mobo and they were known to have a high failure rate out of the box, but considering it s been stable for years now, it seems unlikely. All the caps look like they re solid and there is no leakage. But I ll try to eliminate those points of failure later. I have a spare GPU but not a power supply."</post>
   <post id="7b52f50e-a212-40c9-8500-15bee71d4a23" section="General Hardware" discussion="I Need Help - System Issues">"So far as artifacting, no, not necessarily. Seems like the reboot is happening when you get "proper" drivers installed; until then the GPU is just in a low power 2D only mode. Failure when it switches over to fully accelerated mode (windows 10 desktop uses some hardware acceleration for stuff like transparency and composition) leads me to suspect the GPU or PSU. Either the GPU itself is bad and the fault causes the reboot when it "turns on" fully, or the PSU is bad and can t supply enough wattage when the GPU "turns on". Make sense? Does that board have video out? Can you pull the GPU and try with onboard?"</post>
   <post id="e8ea9a2f-8186-4558-a6a0-746a198ed87c" section="General Hardware" discussion="I Need Help - System Issues">"You might try stripping the machine down to the base essentials, mobo, ram and a hd, and try out the on-board video to see if you are getting the same behavior as mentioned above. You might try grabbing the ultimate boot cd / usb and booting through some stress tests. Also while you were cleaning / check again for any kind of damages capacitors on the devices you have in there."</post>
   <post id="5c63a34f-49f8-4b40-a4f7-269137b44e43" section="General Hardware" discussion="I Need Help - System Issues">"silent-circuit said: ↑ So far as artifacting, no, not necessarily. Seems like the reboot is happening when you get "proper" drivers installed; until then the GPU is just in a low power 2D only mode. Failure when it switches over to fully accelerated mode (windows 10 desktop uses some hardware acceleration for stuff like transparency and composition) leads me to suspect the GPU or PSU. Either the GPU itself is bad and the fault causes the reboot when it "turns on" fully, or the PSU is bad and can t supply enough wattage when the GPU "turns on". Make sense? Does that board have video out? Can you pull the GPU and try with onboard? Click to expand... I couldn t even get far enough to fully install the driver when it happened. It would get maybe 25% in to installation and restart. Or maybe it had installed enough components to trigger the restart. rhansen5_99 said: ↑ You might try stripping the machine down to the base essentials, mobo, ram and a hd, and try out the on-board video to see if you are getting the same behavior as mentioned above. You might try grabbing the ultimate boot cd / usb and booting through some stress tests. Also while you were cleaning / check again for any kind of damages capacitors on the devices you have in there. Click to expand... All caps looked fine, but they are all solid on this motherbard, so I don t know what else to check for."</post>
   <post id="83446f22-418b-4152-b304-bfa7f083bff7" section="General Hardware" discussion="I Need Help - System Issues">"You need to pull the GPU and try onboard video if that s an option. Run a test like OCCT Linpack that ll stress the CPU and RAM a lot and create a high wattage load. If the machine reboots under the test, it s probably the PSU that is bad. If you don t have onboard video, boot in to safemode (since you said that was working before) and run OCCT Linpack to check stability. If it reboots then, probably the PSU, but this is less certain than the first method since the GPU is still in the machine, just not fully enabled. If you can t / won t do either of the above you need to get / borrow a spare GPU and swap it out, or get / borrow a spare PSU and swap that out. Really the only way forward at this point."</post>
   <post id="a7f21fbe-d7fb-4046-9de1-3f9755992149" section="General Hardware" discussion="I Need Help - System Issues">"silent-circuit said: ↑ You need to pull the GPU and try onboard video if that s an option. Run a test like OCCT Linpack that ll stress the CPU and RAM a lot and create a high wattage load. If the machine reboots under the test, it s probably the PSU that is bad. If you don t have onboard video, boot in to safemode (since you said that was working before) and run OCCT Linpack to check stability. If it reboots then, probably the PSU, but this is less certain than the first method since the GPU is still in the machine, just not fully enabled. If you can t / won t do either of the above you need to get / borrow a spare GPU and swap it out, or get / borrow a spare PSU and swap that out. Really the only way forward at this point. Click to expand... Yeah, I have onboard video and a spare GPU. I ll give it a try when I get home later."</post>
   <post id="471a499f-e349-4c05-bad3-68214916abff" section="General Hardware" discussion="I Need Help - System Issues">"Well here are my findings: I confirmed it once more. When the graphics driver attempts to install, the monitor loses the signal and the PC reboots. I pulled the card and ran OCCT Linpack for one hour and had no issues. Also, the only spare GPU I have is a GT 430, so not nearly the same as far as testing goes. But...I popped it in, powered up and within seconds of booting it installed the drivers and everything was working. Is it pretty safe to say at this point that the video card is the culprit?"</post>
   <post id="c624e871-e4da-4c18-9f54-5fd0cac6787a" section="General Hardware" discussion="I Need Help - System Issues">"&gt;&gt;Is it pretty safe to say at this point that the video card is the culprit? Sure looks that way. silent-circuit gave you great advice on troubleshooting this."</post>
   <post id="603e727c-e19e-48fd-ab42-848166052974" section="General Hardware" discussion="I Need Help - System Issues">"Sounds like it, yes."</post>
   <post id="b44d6b16-594e-41f0-88fb-0eb1540cd60a" section="General Hardware" discussion="I Need Help - System Issues">"Yeah video card for sure."</post>
   <post id="8e0b27a7-9528-4639-bf2b-9e2e987d8770" section="General Hardware" discussion="I Need Help - System Issues">"Thank you everyone for all the help. It still makes me wonder what could have failed on the card, but I m glad I now know the cause of the system instability. I guess it isn t too bad considering it probably had about 17,000 hours on it (number taken from smart data of hard drive installed at the same time). I ll probably be going for a GTX 960 next."</post>
   <post id="138df907-7a7f-45d7-af3e-bf5e899ab37a" section="General Hardware" discussion="I Need Help - System Issues">"Use your on-board video for 60 days or so until the new Nvidia cards are out. Prices on current top end cards will plummet."</post>
   <post id="39f3d524-f804-4210-963e-005ebd8140d6" section="General Hardware" discussion="gaming/light room build.">"Hello, I need help with a budget build, and if possible I want it to be better than my previous PC. I plan to use it for gaming Wolfenstien, Diablo 3 Rocksmith 2014 (possibly streaming it on twitch). I also like to take RAW photos and want to edit them in light room/photoshop. I plan to purchase the same case I use with my previous build outside of the budget.I have a keyboard, mouse, and the same monitor as used with my old build. My budget is to try and stay under $780 and I will be purchasing parts over the next two to four weeks. So I have time if there are sales i should wait for. The previous build is Intel Core i5 3470 MSI B75MA-P45 Corsair XMS3 2x4GB DDR3 1333 kit Lite-On IHAS124-04 SATA DVD burner NZXT Source 210 Elite Themaltake TR2 600w PSU Asus VE247H (23.6 inch, 1920x1080, 2ms response time, LED backlighting, built-in speakers, TN panel) monitor. Radeon HD6850 graphics card. The current build works fine and i will keep using it but I ve noticed it loads a little slow and some games seem to perform poorly. Thanks for any help you can give."</post>
   <post id="4ec1b0b8-f843-49bc-ae2a-715f2a10c2a2" section="General Hardware" discussion="gaming/light room build.">"Just upgrade your GPU and up your ram to 32GB. Your CPU is still fine."</post>
   <post id="8b3d74d2-f0a1-4bbd-952a-c9ed263c6e8a" section="General Hardware" discussion="gaming/light room build.">"Notice you didn t say what your system drive was. If it is a hard drive, consider moving to a suitably sized SSD too."</post>
   <post id="97a5079f-7219-4600-8ebe-bd1e172a23e2" section="General Hardware" discussion="gaming/light room build.">"I m going to agree with the others there here and say your platform is solid. No need to upgrade the CPU/MB (or even the PSU for that matter although I m not a huge fan of the tr2) and with the budget you have in mind I don t think a CPU/MB upgrade would be very noticeable anyways. I d upgrade the ram to 32gb since you do some editing, add a solid state hard drive for fast loading times and spend the majority of the rest of the budget on a GPU and call it good (you should see huge performance gains). If you re wanting to keep the old system and build a second... I think you re going to have to step up your budget if you want to see a noticeable improvement over your current setup."</post>
   <post id="7cab9626-e910-41c3-822f-91767801636d" section="General Hardware" discussion="gaming/light room build.">"Thanks for the suggestion, I am using a 1 TB HDD, a 1 TB External drive, and a 500 GB external drive the larger external drive holds most of my steam games, the smaller is for photos. I was considering a second build, but I m open to upgrading my current build. I ve never had a SSD but, they seem mostly small so I assume I would only load the games/programs with the longest load times to it. I m thinking if i just upgrade my current PC I would also benefit from a larger internal HDD. So if we fall back to just upgrading my current system, which I am leaning towards more. Let s drop the budget down a bit, say #300 for the ram/gpu? What would be the cheapest GPU upgrade that would give me a performance boost? Also what SSD do you suggest? Thanks again guys."</post>
   <post id="fcb5da11-72cd-47ed-bb26-dc64b3f0efc8" section="General Hardware" discussion="gaming/light room build.">"Okay, you re playing off an external drive? USB2 I m betting? If so it s no wonder your system seems to be slowing down... USB is a nice interface and all, but it just isn t meant for that kind of use. A 500GB Samsung Evo SSD will run you about $150. Use something like that as a boot drive. It ll speed up system loads fairly dramatically. www.amazon.com/Samsung-2-5-Inch-Internal-MZ-75E500B-AM/dp/B00OBRE5UE/ Then repurpose your 1TB INTERNAL HDD for game loads. And/or buy another internal HDD, like a 4TB HGST. http://www.amazon.com/HGST-Deskstar-3-5-Inch-Internal-0S03664/dp/B00HHAJRU0/ Having the drives on SATA, rather than USB will speed up game loads dramatically. And for the ones you want loading as quickly as possible, you can put a few on your SSD."</post>
   <post id="c9e5b1e8-2831-41c3-a989-7308a5f73807" section="General Hardware" discussion="gaming/light room build.">"Sorry, let me clear this up a bit. My original 1TB HDD held everything, but photos. I load my photos to the HDD, edit them, then move them to the 500 GB external. Even with that my HDD was starting to run out of space. So I got the 1TB external to put my games on. I only moved games to it that I am not currently playing. So right now the games I play run from the HDD. Mostly rocksmith 2014, Diablo 3, Heroes of the storm, the forest, and wolfenstien. I have tried a game or two on the external, but the load times seem about the same. With the advice I ve gotten so far and taking a better look at things... Maybe I just need to upgrade ram and the GPU? My GPU doesn t perform as well as my brother s build. If it helps an example is if we both play diablo on the same internet connection and I go into a rift or new area then he clicks in after me, when I load in I notice he has already killed a few things and moved on. Had I to venture a guess I would say if I click just one second before he does, he still seems to be loaded up about 3 or 4 seconds faster than me. That doesn t seem too bad, but it s enough to feel the load screen. I will likely get the SSD, not sure I want to get a 4TB HDD just yet because the externals though not ideal work fine for me because I play games in phases. So If I am not playing the game it is simple enough to toss it on an external, also that s useful for moving the photos or games pc to pc. I looked at ram and dialed back my budget considering I won t likely need to update my whole build. 32Gigs seems too much at once, so maybe I should get another 16 gigs in addition to the 8 I have if that s possible. Someone did mention a Geforce graphics card as an upgrade for around $200 that would be much faster than mine. Any suggestions on Ram/GPU? I have amazon Prime so I can get free shipping on most things from them. Thanks for any help you can give."</post>
   <post id="943c5df5-8010-479b-ab66-6e9ce24f2118" section="General Hardware" discussion="gaming/light room build.">"I looked at ram and dialed back my budget considering I won t likely need to update my whole build. 32Gigs seems too much at once, so maybe I should get another 16 gigs in addition to the 8 I have if that s possible. Someone did mention a Geforce graphics card as an upgrade for around $200 that would be much faster than mine. Click to expand... There is no such thing as too much at once when it comes to ram. Especially with Adobe. Max out what you have. DDR3 1600 32GB Kit: $140 http://www.newegg.com/Product/Product.aspx?Item=N82E16820231569 Someone did mention a Geforce graphics card as an upgrade for around $200 that would be much faster than mine. Click to expand... That would be virtually any card on the market. You have an old-ass card there. Your motherboard supports PCIe 3.0, so you don t even need to upgrade that. Your HD6850 is about on par with a GeForce GT 645. A GTX 760 would pretty much kick the snot out of it. You could get those used. However, new and for the price point of $200, the R9 380 is probably the best way to go if you continue gaming at FHD resolution. However, since you said GeForce... It d be hard to say no to this: EVGA GTX GeForce 960 with 4GB Ram $205 http://www.newegg.com/Product/Product.aspx?Item=N82E16814487224 But if you re willing to go with a non-GeForce card... Sapphire R9 380 4GB $190 after rebate. http://www.newegg.com/Product/Product.aspx?Item=N82E16814202166 Tradeoffs between both cards are effectively a wash from what I can tell. Each are better in about as many games as the other and only by single digit framerates. No need to upgrade your CPU, motherboard or PSU with all this. Seriously. You have a good CPU. Stick with it for another 5 years. The rest will last at least that long."</post>
   <post id="e0fed2c9-5953-415b-8e8e-8847c5fb5dd0" section="General Hardware" discussion="gaming/light room build.">"Thanks for the reply, I m not stuck on Geforce at all. Just want the best value, and a performance boost that I can notice. I only mentioned Geforce because that was the brand that was suggested to me. Also do you have any amazon links? I m trying to make use of my prime membership and free shipping."</post>
   <post id="4256efb0-0ce6-4a27-b678-4a1091eea042" section="General Hardware" discussion="gaming/light room build.">"Zenprophet said: ↑ Sorry, let me clear this up a bit. My original 1TB HDD held everything, but photos. I load my photos to the HDD, edit them, then move them to the 500 GB external. Even with that my HDD was starting to run out of space. So I got the 1TB external to put my games on. I only moved games to it that I am not currently playing. So right now the games I play run from the HDD. Mostly rocksmith 2014, Diablo 3, Heroes of the storm, the forest, and wolfenstien. I have tried a game or two on the external, but the load times seem about the same. With the advice I ve gotten so far and taking a better look at things... Maybe I just need to upgrade ram and the GPU? My GPU doesn t perform as well as my brother s build. If it helps an example is if we both play diablo on the same internet connection and I go into a rift or new area then he clicks in after me, when I load in I notice he has already killed a few things and moved on. Had I to venture a guess I would say if I click just one second before he does, he still seems to be loaded up about 3 or 4 seconds faster than me. That doesn t seem too bad, but it s enough to feel the load screen. I will likely get the SSD, not sure I want to get a 4TB HDD just yet because the externals though not ideal work fine for me because I play games in phases. So If I am not playing the game it is simple enough to toss it on an external, also that s useful for moving the photos or games pc to pc. I looked at ram and dialed back my budget considering I won t likely need to update my whole build. 32Gigs seems too much at once, so maybe I should get another 16 gigs in addition to the 8 I have if that s possible. Someone did mention a Geforce graphics card as an upgrade for around $200 that would be much faster than mine. Any suggestions on Ram/GPU? I have amazon Prime so I can get free shipping on most things from them. Thanks for any help you can give. Click to expand... Sorry for the delay... It s hang with the lady day, lol. I never suggest mixing unmatched RAM, so I can t recommend you pick up a pair of 8gb sticks to add to your existing RAM. The chances of instability from mismatched RAM is low, but why even take the chance? Since you do some work with Photoshop, I really think you would get the most use out of a 32gb setup. How about one of these (if you don t like the blue you can get a set of your color choice with timings that are only slightly sloppier). Both sets are the same price, one set is 2133 and one is 2400 but because of the timings, they should perform roughly the same. I used to just suggest going with 1600mhz RAM, but in some cases you do get a small benefit from the faster speeds. And for an extra $5, why the hell not? http://www.newegg.com/Product/Product.aspx?Item=N82E16820231712 http://www.newegg.com/Product/Product.aspx?Item=N82E16820231714 Here s my strategy when it comes to storage. I use an SSD for the operating system, programs and any flavor of the week games that can be improved by super fast load times. A regular high capacity mechanical drive for any the rest of my games and mass storage I want to keep locally on the computer (pictures, backup, files, etc) and then I use an external drive for movies (so I can connect it to the TV easily) and extra backup. That works out pretty well for me. As far as an SSD goes... The Samsung Evo Chas linked is really solid. You could also get similar performance out of a Crucial BX200 and save a bit of cash. The 240gb is $65 and would probably get you by if you don t juggle more than a couple AAA game titles at a time. With SSD prices being as low as they are however, I REALLY suggest you bump it up to the 480gb for $130. http://www.newegg.com/Product/Produ...66&amp;cm_re=crucial_bx200-_-20-156-066-_-Product http://www.newegg.com/Product/Produ...67&amp;cm_re=crucial_bx200-_-20-156-067-_-Product On the GPU side of things... I haven t been very happy with AMD for the last few years so I ll only be talking about Nvidia GPUs (I don t really like AMD s offerings at this price point anyways). For $180 (after $10 rebate) you can get a GTX 960, which is a solid little card. If you are comfortable buying a used card (if you go with a company with a transferable warranty, you should have 0 issues here and it s a great way to save some money and get more horsepower) you can probably find a GTX 780ti on the forums here for $230 - $250. Personally... If I were you... I would try to bump my GPU budget up just a bit (maybe by selling your old RAM and GPU?) and try for a GTX 970. I really feel that would be the sweet spot for your setup. They start at anywhere from $250 (if you buy from Jet.com) or $290 if you buy from Amazon/Newegg. GTX 960 for $180 after ($10 rebate). http://www.newegg.com/Product/Product.aspx?Item=N82E16814487091 A used GTX 780 here on the forums for $200. http://hardforum.com/showthread.php?t=1888584 There was a 780ti for $230 and another for $240 that sold on the forums in the past couple days. I would hunt for one of those if you re ok going used and don t want to bump up your budget for a GTX 970."</post>
   <post id="5a4e0ea7-1f00-4b0a-8df5-7afe808dfc83" section="General Hardware" discussion="gaming/light room build.">"Thanks for the reply, no worries about the delay I m in no hurry and today is the day to spoil them, or try to behave as much as possible. Sorry, didn t mean to imply that you suggested I mix ram, it was my own thought. I m trying to order from amazon because of prime so I can get the parts faster, and free shipping. I m probably over thinking a few things, but I m not really sure what I m doing when looking at parts for example what is the difference between a EVGA GeForce GTX 970 4GB SC GAMING ACX 2.0, 26% Cooler and 36% Quieter Cooling Graphics Card 04G-P4-2974-KR And a EVGA GeForce GTX 970 4GB SSC Gaming ACX 2.0+ Cooling Graphics Card (04G-P4-3975-KR) Besides one claiming to be 26% cooler and 26% quieter and the ssc/sc differences? As for the Ram color doesn t matter to me I will hopefully only see it once."</post>
   <post id="af4b8c5d-954e-4255-b470-2bfe69bb4727" section="General Hardware" discussion="gaming/light room build.">"That RAM is rated at 1.6V. Not a good choice considering an Intel Rep here on the forums specifically stated before that anything over 1.5v could damage the CPU. I d stick with a 1.5v kit or less. You can currently get some low voltage 1.35v RAM 32GB for $135. Also you linked a GTX 960, not a 760. Though I am sure you just hit 760 by accident and meant to type 960. Which I too recommend. However, unless the OIP is doing something that take advantage of GPU acceleration in Lightroom/Photoshop a GPU upgrade wont make much of a difference anyway. I imagine since the OP mentioned RAW images he is just post-processing large images from his DSLR or other digital camera and editing white balance, exposure and possibly light/dark levels. I doubt he ll be using much filters which takes more advantage of GPU acceleration. Possibly even using the image processor to resize images for "Internet" use which doesn t use GPU acceleration either. If this is the case, then don t bother with a GPU upgrade yet. Non of the games he mentioned are GPU extensive anyway. However, the OP did mention wanting to stream twich. This is where I would suggest an upgrade to an i7 Skylake, DDR4 + SSD upgrade for his system. The i7 s really help with Twitch streaming. That is, only if he really intends to do this a lot and wants good quality on the streams. Otherwise, don t bother. The i5 he has now is more than adequate for what he is doing. So stick with what others suggested. Max out his RAM, add an SSD and go ahead and upgrade that GPU."</post>
   <post id="738ad9a1-48f5-48a9-9b8d-d98ec116f7da" section="General Hardware" discussion="gaming/light room build.">"Skillz, You are right about my photo editing, I have a couple of DSLR s and take landscape/moon/milkyway photos. I will eventually be getting into filters for HDR photos. Wolfenstien seems to be the biggest challenge for my current set up. After I first installed and started playing the game it would always crash at a specific point until I updated the driver for my GPU. I m not in a hurry to get anything done so I m thinking maybe I should stick with expanding ram now and maybe a SSD. Then in a few weeks get the GTX 960."</post>
   <post id="4d7b1360-6cb4-4119-b747-d9b3145baa68" section="General Hardware" discussion="gaming/light room build.">"Skillz said: ↑ That RAM is rated at 1.6V. Not a good choice considering an Intel Rep here on the forums specifically stated before that anything over 1.5v could damage the CPU. I d stick with a 1.5v kit or less. You can currently get some low voltage 1.35v RAM 32GB for $135. Also you linked a GTX 960, not a 760. Though I am sure you just hit 760 by accident and meant to type 960. Which I too recommend. However, unless the OIP is doing something that take advantage of GPU acceleration in Lightroom/Photoshop a GPU upgrade wont make much of a difference anyway. I imagine since the OP mentioned RAW images he is just post-processing large images from his DSLR or other digital camera and editing white balance, exposure and possibly light/dark levels. I doubt he ll be using much filters which takes more advantage of GPU acceleration. Possibly even using the image processor to resize images for "Internet" use which doesn t use GPU acceleration either. If this is the case, then don t bother with a GPU upgrade yet. Non of the games he mentioned are GPU extensive anyway. However, the OP did mention wanting to stream twich. This is where I would suggest an upgrade to an i7 Skylake, DDR4 + SSD upgrade for his system. The i7 s really help with Twitch streaming. That is, only if he really intends to do this a lot and wants good quality on the streams. Otherwise, don t bother. The i5 he has now is more than adequate for what he is doing. So stick with what others suggested. Max out his RAM, add an SSD and go ahead and upgrade that GPU. Click to expand... Good catch on the RAM being 1.6v instead of 1.5v. I was really just trying to show how affordable a 32gb set of ddr3 could be these days. That Muskin RAM is great stuff and was actually what I was going link originally until I found the 2133/2400 for $5 more. Haha, yea I just fat fingered and wrote 760 when I was talking about and linking the 960. The GPU won t have a huge effect on his editing... But I figured since he likes to game and wants to stream on Twitch, it would be a great idea. A 960 would be such a HUGE leap over a 6850. I concur about an i7 being an excellent choice if he wants to get heavy into streaming... But man, that that can become a pretty speedy upgrade if you re not careful (that damn upgrade bug)."</post>
   <post id="bc9846dd-26b5-4f26-ba61-a685f66023d5" section="General Hardware" discussion="gaming/light room build.">"I Think I will start with the ram, then the GPU, then SSD. But, on the thought of the SSD, I found this on amazon and can t see how it can be legit. http://www.amazon.com/gp/product/B0...id=1455552391&amp;ref_=sr_1_10&amp;s=software&amp;sr=1-10 This claims to be all versions of windows 7 pre activated, is this really a full install, is it legal?"</post>
   <post id="b4073450-a8b1-4e4f-b7b3-ec740178768e" section="General Hardware" discussion="gaming/light room build.">"Zenprophet said: ↑ I Think I will start with the ram, then the GPU, then SSD. But, on the thought of the SSD, I found this on amazon and can t see how it can be legit. http://www.amazon.com/gp/product/B0...id=1455552391&amp;ref_=sr_1_10&amp;s=software&amp;sr=1-10 This claims to be all versions of windows 7 pre activated, is this really a full install, is it legal? Click to expand... No reviews on the seller and only one available. I wouldn t trust it. Question for ya... Is your current system a pre-built machine or or was it built by you/a friend/etc? If it s a pre-built, it likely has a non-transferable copy of Windows. If it s a homebuilt system you can probably transfer the Windows key to your new system with a little help from Microsoft. I d probably purchase the components in the same order as you plan on doing so I could avoid reinstalling Windows as long as possible, lol. However... I will say, you ll get the most noticeable day to day performance out of upgrading to an SSD. The difference is night and day."</post>
   <post id="b2eab8c4-bc8f-4776-a18e-80d23b8aa3ec" section="General Hardware" discussion="gaming/light room build.">"Yeah I ve walked away from that I can t see how that would be legit, and I question why amazon would even allow it on there. But, my system is home built and I can transfer windows over. Just wondering if I should get a windows OS for the future because of windows 10. I can upgrade to 10, so can everyone from what I understand. But, I worry that there will be issues/crashes/ect. And windows 10 is supposed to have tons of information gathering software on it. Not sure if I really care about that at all. But, it does feel kind of big brotherish. I was also looking at the windows OS purchase for the SSD because it just seems like less of a mess than calling microsoft. And if something went wrong the the install, or the ssd (never had one) then I d still have my os on my HDD."</post>
   <post id="2f3d83dd-baa0-455a-a5ed-ebbdb6090826" section="General Hardware" discussion="gaming/light room build.">"If you re going to stick with your 3470/p45 you don t have to worry about transferring your copy of Windows (shouldn t have to call either), you can just reinstall it. If you end up changing your mind and decide to upgrade the CPU/MB like Skillz suggested, be sure to transfer Windows 7 over to the new motherboard BEFORE you upgrade to Windows 10. As far as I know Windows 10 is locked to the original motherboard. If you re worried about not liking Windows 10 or it having issues... As long as you have your original Windows 7 key (if you can t find it, you can use a program called Magical Jelly Bean to get it, just be sure to do this BEFORE you upgrade to Windows 10) you can always "downgrade" back to Windows 7."</post>
   <post id="c5d78cad-4b9e-441e-8f67-3769be7a9cc8" section="General Hardware" discussion="gaming/light room build.">"Keep the motherboard, clone your boot drive to an SSD, upgrade the ram, upgrade the GPU and leave everything else alone."</post>
   <post id="5d52e345-6aad-4a07-b842-3cac18fcff70" section="General Hardware" discussion="gaming/light room build.">"A friend of mine offered to sell me a EVGA GTX 960 4gb ssc acx 2.0+ card for $150 that he purchased for a build and doesn t need. Will that work for my set up? If so I ll get that and the RAM now."</post>
   <post id="27becda4-c7fe-4b12-8a46-8a5c1b71475e" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"It may sound silly, but I often doubt which brand, material, price etc to choose. Which do you think are the best value for money screwdrivers and tools? Which material do they use (Chorme-Vanadium, etc). Many thanks"</post>
   <post id="9c76032a-9782-4c75-8e42-156ff5ab1504" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"a dewalt or milwakee power screwdriver and decent side cutters fluke dvom . house brand kobalt will work but if you do it for a living get high quality tools. could just get a pc service kit from microcenter"</post>
   <post id="be64a9b1-5f58-4460-995a-e04f3c240a95" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"ESD strap is a nice touch"</post>
   <post id="ea2356d7-1348-44f7-be3f-04cfde846ab1" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Bahco does good stuff without being absolutely ridiculous pricing, properly hardened tips (where most  hardened  screwdrivers fall short), have a few around the place which have had many years of service in a past job. Best screwdriver I ever used was a Toshiba internal tool, only for certified Toshiba techs. They were coveted and highly guarded when they were no longer available ;D I have one laying around somewhere."</post>
   <post id="d5ee7505-13c1-4090-97f0-f45da7dda921" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"This cheap set has served me well. Highly recommend."</post>
   <post id="f654bc46-1811-4c39-8783-2ea5f704b6a7" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Do you need ESD-safe screwdrivers? That will make a difference in price."</post>
   <post id="30d9e6af-bff4-4015-938c-59d579b6bc5b" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Freakin  awesome deal man, I m in for two!"</post>
   <post id="fbf7dc45-7d51-42d6-965d-425cb04da379" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"The iFixit toolkit is actually really well made and sturdy, I have abused the hell of them and haven t chipped a bit yet. It s expensive but literally the best all-in-one kit you can find. The new model got rid of the hole in the back of the driver which is odd since it really helps provide that much needed torque for stubborn screws/nuts. (Note, there is some sort of chinese made version of the iFixit kit going around that is cheap and breaks apart easily) For just a good tech screwdrivers/torx kit I recommend they grip screws really well with no slip and it s pretty damn cheap for what it is."</post>
   <post id="85f8c495-64b0-4fbb-8130-190839e1bc31" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Anyone else not seeing pictures in this thread? I know I used to see pictures at least, there was a  show off your desktop  one a while back. Am I missing something in  Settings  or what?"</post>
   <post id="f720c457-67df-4ca2-80b3-e6e62c5b085d" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"For all systems - a strong neodymium magnet to stick to screwdriver shanks in order to be able to have the screwdriver be able to lift screws out easily. You can also magnetize the small screwdrivers and/or the large screwdrivers with the magnet so you don t always have to have the magnet attached to the screwdriver. For laptops: A set of 6 small plastic handled screwdrivers that includes various sized of both flat/phillips. Can be had at Walmart - The Stanly brand ones have held up the best for me. For desktops: 1. Regular length #1 and #2 Phillips as well as a couple different sizes of flat head screwdrivers 2. Same as above except longer 3. Wire snips - to cut zip ties 4. Needle nose pliers - not really necessary but come in handy every once in a while. 5. extending magnetic tool - to grab dropped screws in hard to reach places. The brand doesn t usually matter so much as long as you don t get super duper cheap ones. For example, the super cheap screwdriver set that Harbor Freight sells in which the Phillips screwdriver tips do not fit the screw heads properly. Their better quality ones are just fine though. I would NEVER recommend an electric screwdriver of any type for working on computers as it is too easy to strip the screw heads - pretty much every person I have ever seen use an electric screwdriver for computers and other electronics always messes up the screw heads at least a little bit. And way too easy to over tighten and/or strip the threads."</post>
   <post id="a0cb50b2-6719-4893-8547-f75b423a2851" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"fuzchunk said: ↑ ESD strap is a nice touch Click to expand... Never in my life of building computers has ESD ever been an issue or ever fried anything computer related. And I put my computers together while sitting on carpet, wearing socks, in the dead of winter."</post>
   <post id="266d4c2b-e460-4c09-8b0c-495ec650df30" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"I also have a complete set of iFixit ones but I did also add a few Wiha parts here and there. Good build quality there also."</post>
   <post id="c44df5d9-f285-4349-a3bb-1cc29c3ce7d8" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Solhokuten said: ↑ This cheap set has served me well. Highly recommend. Click to expand... just found one is really nice. 45-in-1 interchangeable precise manual tool set. Precision 45 In 1 Electron Torx Mini Magnetic Screwdriver Tool Set hand tools Screwdrivers Kit   Attached Files: small_201506031154224211.jpg File size: 10.5 KB Views: 0"</post>
   <post id="c4f10973-2200-49aa-ace5-59d3c1ccdd67" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"OrangeWolf said: ↑ Anyone else not seeing pictures in this thread? I know I used to see pictures at least, there was a  show off your desktop  one a while back. Am I missing something in  Settings  or what? Click to expand... The "pics" are showing up as "Buy from Amazon" ads and my content blocker is nuking the ads."</post>
   <post id="a2182b20-f81c-4a99-b841-825a9cfc4055" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"I like my Wiha system 4 set SYSTEM 4 Precision ESD - Screwdrivers | Wiha Tools USA"</post>
   <post id="1b31d68e-333a-467d-843c-a5250bd31847" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Honestly something cheap with a #2 philips is about all you need. I ve got a cheap rosewill set that works well, that plus a strong magnet (i ve got one I pulled from a dead HDD) to magnetize the head and you re good."</post>
   <post id="a6b43eb3-ecb5-4cf5-87d4-6be6a2bf376b" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"st4rk said: ↑ Never in my life of building computers has ESD ever been an issue or ever fried anything computer related. And I put my computers together while sitting on carpet, wearing socks, in the dead of winter. Click to expand... I m not going to go on a rant, but I d bet money you ve done ESD damage in that case. You do not always fry a component, they can still work and be degraded/damaged. I ve worked in some very high end ESD controlled environments, I m just pointing it out."</post>
   <post id="b28d34f0-4419-42d9-b3c8-ad3599b6ae3f" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"I dig the iFixit set as well. Nice set of drivers, also comes with case and accessories."</post>
   <post id="4b47934d-32d2-48a4-82e9-937900f231ea" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"Is this the iFixit kit people are talking about? I could use a set of computer-tools for &lt;$50, and it looks to have a nice mix of things."</post>
   <post id="c23b3e24-ff87-4873-8bf4-2a7c95e3d78b" section="General Hardware" discussion="What are the best screwdrivers for computer technicians?">"That s one of them I ve had an iFixIt kit for years and it s a great little set for computers, cell phones, you name it. Massdrop usually offers different iFixIt sets from time to time, too."</post>
   <post id="5c0aaf36-73fe-4095-825d-64ff36dcad36" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"Does anyone remember how to install this thing because I know there is a way? I just can t find anything on the internet that tells me how and I don t remember."</post>
   <post id="656b1b50-c8ab-49de-aa88-427d9215d34e" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"Find a computer running Windows 98 first."</post>
   <post id="0b759060-39e9-472d-984a-36f8b49ca320" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"find a computer with a parallel port 1st."</post>
   <post id="a8102f69-832f-44f2-9371-b974c4467d60" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"Find a computer with VMware, a copy of Windows 98, and a PCI parallel port PCI/PCI-E/PCI-X card."</post>
   <post id="b8af37cc-8e06-4dba-88bc-98c540fa0d86" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"Blue Fox said: ↑ Find a computer running Windows 98 first. Click to expand... There is a way to do it with Windows XP using add new hardware I just can t remember how."</post>
   <post id="7c9a0d28-1037-4745-9235-ca679e2772fb" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"bastage said: ↑ find a computer with a parallel port 1st. Click to expand... Thats not the problem I have a parallel port on my Asus TUSL2 motherboard for my Pentium 3 and on the Supermicro P4SCT+II motherboard for my pentium 4. Its attached to an HP Pavilion with the Asus TUSL-L motherboard which is using a Pentium III 1.4GHz Tualatin. I just don t know what to select under add new hardware wizard."</post>
   <post id="17eb45fe-d767-49f4-a725-ac88445d2c72" section="General Hardware" discussion="Imation Super Disk Drive Parallel Port version">"Cerulean said: ↑ Find a computer with VMware, a copy of Windows 98, and a PCI parallel port PCI/PCI-E/PCI-X card. Click to expand... I found a Parallel Port to USB cable for this drive, but now I can t find the drive and I also have the USB version of this drive now along with the ZIP 750 USB drive. However, the USB SuperDisk drive is very flaky in Modern WIndows or at least 7 and refuses to work on a Mac. I did how manage to get the files I wanted off the SuperDisk one way or another and deleted the files I didn t. However, I kinda had to resort to the internal version a few times and Ubuntu Linux."</post>
<post id="33a36871-6672-47e4-8d08-1e48ec32cc08" section="Home Theater PCs and Equipment" discussion="Question about HDMI and sound.">"I posted in another topic about how my software Blu-ray player no longer supports some new DRM and wouldn t play a new movie. Rather than spend $80 on new Blu-ray software, I m considering picking up a stand-alone Blu-ray player. I m looking at a few for under $80. My monitor has the typical 3 inputs, VGA, DVI and HDMI. I m using DVI from the PC, so I can plug the Blu-ray player into the HDMI for video. The problem now is how do I get sound? I have a 5.1 sound system on my PC, but it does not accept any other inputs. I m going to need to get the sound from the Blu-ray player to the line in on the PC. My sound card has an optical input, but none of the players in that price range have an optical out, they all have a coax output. On the back of the monitor is a 3.5mm headphone out jack which passes the sound from HDMI source. If I run a patch cable from this to the line in on the PC, will the surround sound signal pass through or will it only be stereo sound?"</post>
   <post id="37def192-3a34-43e4-b577-ef4e6e42e084" section="Home Theater PCs and Equipment" discussion="Question about HDMI and sound.">"Yeah you re not going to get surround through a headphone jack. You re going to need to get hardware capable of outputting the sound you need."</post>
   <post id="22aeaab9-9502-4c2f-8d38-933427ba3bb0" section="Home Theater PCs and Equipment" discussion="Question about HDMI and sound.">"You re better of spending $80 on Powerdvd. You may want to search for coupons, I get emails about it sometimes dropping to $50. Now I don t know if that is because I purchased a previous version of powerdvd. I used to use TMT and once the support for it dropped I got Powerdvd. I m using version 14 and so far the AACS stuff has been updated. So even though I m two version behind I ve been able to play the latest and greatest titles so far. The amount of money you would spend trying to get that surround sound through a stand alone player probably more then $80. Not only that it will be more of a headache."</post>
   <post id="a74757ee-9121-499a-8de4-df5a4e06c309" section="Home Theater PCs and Equipment" discussion="Question about HDMI and sound.">"I d hunt around for an older copy of PowerDVD. They re on version 16 and the changes are minimal from version 15. Version 14 should still work fine, too. Amazon has those on sale for $45-55 and I m sure that isn t the cheapest option."</post>
   <post id="ae74b0ef-52e2-4327-8259-e9b0e9516a38" section="Home Theater PCs and Equipment" discussion="Question about HDMI and sound.">"If you go the optical out route you won t be able to get anything higher than DTS core - No DTS-HD or TrueHD. And there s no way a single analog cord coming out of the monitor will be able to support multichannel that I know about. I d try and find a key like others suggested."</post>
   <post id="19e568f2-9d02-44dd-bac0-091d09e70822" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"So, last week I signed up for Amazon Prime when they had their $73 deal. I figured I d be able to save $73 in shipping charges over the next year to at least break even and make it worth it. Another nice benefit to Prime is their Prime Video. I ve slowly been working towards cutting the cord. I had this thread a while back about cleaning up the coax in our house and then getting a network port, coax, HDMI and USB ports set up by my living room TV for my HTPC. I wanted to make sure that everything was wired up correctly and that I had network access in the appropriate places to have access to my media. Things have for the most part been good. Currently all of the TV series &amp; movies that we watch are ripped / downloaded and put down on my WHS server and then we either watch them with Kodi / HTPC on the living room TV or with the WD TV Live on our bedroom TV. Again no major issues. Now I m attempting to add streaming videos into the mix. Over the weekend we were gonna watch the Hunger Games with our niece. So I figured it would be a perfect time to try out Amazon Video (don t really think it matters, but the first Hunger Games movie wasn t available for free via Amazon Prime Video, so we ordered it from Amazon for $3.99 and then streamed it). We got everything going and the movie played ok for a couple minutes, but then started stuttering pretty bad. I tried to pause it for a few minutes and then play it again thinking it would buffer for a bit, but that made no difference. I was able to switch to the standard definition version without much hassle and from that point on it played perfectly. I would think with my setup that I d be able to stream HD content without any issues. I m pretty confident that my modem, router and switch can handle HD streaming. They have all be recently upgraded with this thought in mind. But I wanted to get some [H] opinions about what s going on. SURFboard SB6141 DOCSIS 3.0 Cable Modem TP-LINK TL-WDR3600 Wireless N600 Dual Band Router TP-LINK TL-SG108 8-Port 10/100/1000Mbps Switch All of the network cabling in the house is Cat5e from Monoprice. I bought pre-made cables so there wouldn t be any issues with putting ends on correctly, etc. Also about 95% of the coax in the house has been replaced. I do have Time Warner Cable for internet and we have "standard internet". I ve been trying to figure out the speeds for their standard level, but I m having some trouble finding any info on it. Another thing that I thought of is that we tried to stream this movie around 8:00pm on a Saturday, so would it be possible that the slowness was on Amazon s end because it was a weekend night, which would possibly be busier for them?? Thanks in advance for any assistance."</post>
   <post id="a8c5ffee-7bc6-4151-9040-17bffaec29f0" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I doubt your equipment is causing any bottleneck but it could be your "standard internet" connection. You can do a speed test here http://www.speedtest.net There is a more advanced speed test you might also want to try here https://www.dslreports.com/speedtest HD Amazon streaming supposedly only needs 3.5 MBit/s, I would think your connection can handle that. http://www.amazon.com/gp/help/customer/display.html?nodeId=201422810 You could try using a different web browser."</post>
   <post id="d3aa46ce-fff7-4e32-a38c-8585db0fd73d" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Honestly, I ve been a little frustrated too with Amazon Prime Video myself. I have 25/5 connection with ATT U-Verse, 2 users, with my roommate just doing basic internet crap. At first I was viewing it through a browser, and it stuttered. I got a Roku and it now stops to buffer and occasionally goes to 480p instead of HD. I don t have anything running on the network that s using bandwidth. I even went as far as shutting down anything that may be using internet bandwidth, and it s done it still. It seems better on the Roku, but still isn t perfect. I think it has more to do with the ISP throttling, similar to Netflix, but I have to do more research to figure that out."</post>
   <post id="a48bdcd3-3466-42aa-b909-9dff04833946" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Probably your ISP, but check the QOS options in your router - sometimes those can cause funny problems"</post>
   <post id="ab879af6-de14-46f7-96df-9fa238055c68" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"sharknice said: ↑ I doubt your equipment is causing any bottleneck but it could be your "standard internet" connection. You can do a speed test here http://www.speedtest.net There is a more advanced speed test you might also want to try here https://www.dslreports.com/speedtest HD Amazon streaming supposedly only needs 3.5 MBit/s, I would think your connection can handle that. http://www.amazon.com/gp/help/customer/display.html?nodeId=201422810 You could try using a different web browser. Click to expand... I looked a bit more on TWC s site and wasn t able to find anything about the "standard internet" speeds. So I called them and it s 15 down / 1 up, which seems to fall into Amazon s requirements for streaming HD. The next step up would be their "Turbo" plan with 20 down / 2 up for another $10 per month. If we go farther with cutting the cord I would probably look at that time to upgrade a bit to get a bit better speed. And now that I think about it a bit more, I do notice a bit of slowness If I m downloading a few torrents and also trying to do something online. Or downloading and being online with our phones, so maybe the standard isn t quite enough. But we re trying to lower our cable bill, so it s gonna have to do for now!!! I ll check out those speed tests when I get home to see how close to the 15/1 I m getting."</post>
   <post id="1a39965f-8812-448c-96c9-8eea3510d950" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I have business class 90 mb down hardwired from Netgear Nighthawk x6 router and the video rarely stutters but it doesn t play in HD all the time. Often it downgrades into crap quality. Totally not impressed with Amazon Video and I ve had it for a long time now."</post>
   <post id="bfcd4ac3-2434-4240-9fa8-081bf4ca3f44" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I ran both speed tests this morning. The results are below. It looks like I m getting a bit above the 15/1 speeds. That seems good, for what I m paying for, even though I got a "F" for Buffering and for Speed. Is the "F" for speed just because my connection is the lowest / slowest option at 15/1 that TWC offers??"</post>
   <post id="793c56a6-a16c-48a0-a4a9-2a4a604a53b8" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Maybe the issues really were on Amazon s end?? Just a few minutes ago I received this email: Hello, We noticed that you recently experienced poor video playback on Amazon Video. We re sorry for the inconvenience, and have issued you a refund for the following rental(s) and amount(s): $3.99 - The Hunger Games While Amazon Video transactions are typically not refundable, we are happy to make an exception in this case. This refund should be processed within the next 2 to 3 business days and will appear on your next billing statement for the same credit card used to purchase this item. Please visit our troubleshooting page for tips on ways you can potentially improve your viewing experience: http://www.amazon.com/gp/help/customer/display.html?nodeId=201431300 We hope to see you again soon, Amazon Video Team"</post>
   <post id="03c271d4-3638-4d5c-aad8-51f1deeb4e01" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"dar124 said: ↑ Maybe the issues really were on Amazon s end?? Just a few minutes ago I received this email: Hello, We noticed that you recently experienced poor video playback on Amazon Video. We re sorry for the inconvenience, and have issued you a refund for the following rental(s) and amount(s): $3.99 - The Hunger Games While Amazon Video transactions are typically not refundable, we are happy to make an exception in this case. This refund should be processed within the next 2 to 3 business days and will appear on your next billing statement for the same credit card used to purchase this item. Please visit our troubleshooting page for tips on ways you can potentially improve your viewing experience: http://www.amazon.com/gp/help/customer/display.html?nodeId=201431300 We hope to see you again soon, Amazon Video Team Click to expand... Maybe not. Streaming video services typically do monitoring how "smooth" the data transfer is. If it gets really bad...they know something is going wrong. Amazon is just "playing nice" because it makes sense to not blame the customer for something they most likely don t have control over. Sorta like this. You make a reservation at a cabin that is "no refunds". Sometime before the rental the bridge to that location is out. The cabin owner could say FU...but it wouldn t be smart. Better to say...here is a refund."</post>
   <post id="22eaefe0-efef-43cf-ac65-46740b7306fc" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Something is definitely up. I only have a 7 Mbps download connection and Amazon streams fine. Even before I stepped up to 7, I only had a 4 Mbps connection, and it was fine."</post>
   <post id="b57ebc10-8ec2-4533-8fcf-40c6662137f4" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I ve used Prime Video for years and haven t many problems with it. In the beginning I had a few problems with buffering and losing quality. I m now using Prime UHD and and 4k video streaming from them without problem. The big question are you streaming wirelessly or are you hardwired? Are you using MOCA adapters or a powerline network? All of those tended to be the weak point when I first started using Prime Video and Netflix."</post>
   <post id="c2f57806-6548-4f54-ad9c-9de81e6a32be" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I only have a crappy cheap internet connection (DSL) and Amazon Prime works fine for me. I have a wireless connection to a laptop I have in the bedroom hooked up to a led tv with hdmi and it works just fine. The laptop is an ASUS RoG high end version, but that shouldn t make much difference."</post>
   <post id="f1efebcc-f13f-48f1-95da-d3eea9b44c75" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Climber said: ↑ I ve used Prime Video for years and haven t many problems with it. In the beginning I had a few problems with buffering and losing quality. I m now using Prime UHD and and 4k video streaming from them without problem. The big question are you streaming wirelessly or are you hardwired? Are you using MOCA adapters or a powerline network? All of those tended to be the weak point when I first started using Prime Video and Netflix. Click to expand... I m streaming the Prime Video from my hardwired HTPC which is connected to my TV via HDMI. Not using either MOCA adapters or a powerline network. Regular old coax - modem - router - switch - network cable to the PC s. I ve done the extra work over the last year or so so that I wont have to rely on WiFi (eventhough it could probably handle it) to stream my media. I replaced all of my coax, coax splitters, I m using all new Cat5e network cables and recently upgraded my modem, router &amp; switch. In the past I ve wirelessly streamed my local media to my TV, but I went thru these upgrades preparing to get to the point that I d be streaming online media. This was really the first time that I ve streamed any online video s so maybe it was just bad luck the first time?? I ll hopefully be able to try it again this weekend and will report back with the results."</post>
   <post id="93adae68-f7e3-4aae-b5bb-df1ce71c42e3" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Yeah, it could just be YOUR Time Warner local shared cable node gets overloaded at prime time (to be expected if there are lots of cord-cutters like you intend to be). Or it could be Amazon getting overloaded. Two easy ways to check this: 1. Try streaming from another service like Netflix RIGHT AFTER you have streaming issues on Amazon. If Netflix streams fast, it s Amazon s servers at fault. If it streams slow, it s your local node getting overloaded (nothing you can do except wait until later to stream, or change providers). 2. Run these speed tests during the time you are having video problems. If the speed is low, then your local node is overloaded. You have to test WHEN you re having the issue, not later. Cable is shared, and the bandwidth on Amazon s server is shared, so if one of those bottlenecks, it can cause your issue only for a short while."</post>
   <post id="ac503193-2313-41a3-8269-25d071d0b822" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Also can be a peering issue with which data center your trying to get to on Amazon s side. I used to see this kinda thing on Youtube back when I lived in LA with u-verse. Certain 1080P streams would hardly download while others were fine and these were back to back."</post>
   <post id="0ab99f3a-f406-45cb-ba3b-1cff4f078473" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"So over the weekend I used Amazon Prime Video twice. Once on Saturday around 3:00pm and then again on Sunday around 7:00pm. Both times I got the same stuttering when using the HD stream. When it happened on Saturday I immediately stopped and ran both speed tests, which are posted below. Each time I was able to switch to the SD version and it worked without any issues. Also, when I had the stuttering on Sunday I installed Google Chrome and tried playing the show with that browser, but still got the same stuttering. I m still working on trying to borrow someone s Netflix to test with another service to see if it s just with Amazon."</post>
   <post id="d0530ee9-a1c0-4d1f-b4b5-2129087a1af2" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Right, as Vengance_01 stated, it may be a peering issue (connection between Amazon server and your ISP). That Is why I suggested you try Netflix and see what kind of performance you get. Or you could just try streaming something in 4k resolution on Youtube. Just choose something that will stress your connection properly, and make sure it s from a different company (different peering). Read here if you want to understand the money behind poor peering between companies: http://arstechnica.com/information-...ecret-deals-that-make-and-break-online-video/ Long story short: you won t know how well a particular streaming service is connected to your ISP until you try it out for yourself!"</post>
   <post id="5524b0e7-14ef-447b-ac9a-0849b68585e6" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"I love Amazon Prime haha Especially if your a student you can grab it for around $60"</post>
   <post id="48366bfc-c124-4734-bf0c-b6118d3b494d" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"Not sure if same issue, but my Fire TV sometime stutters and horrible synch issues with vid/audio. Usually with Netflix. Only thing that fixes it for awhile is a hard power cycle of the Fire box. Has to be hardware related? Maybe. The fix usually lasts for a few days then starts again. I have 75 up/down FIOS."</post>
   <post id="4548bb95-1246-468e-a7aa-0b553cfc4d9b" section="Home Theater PCs and Equipment" discussion="Amazon Prime HD Videos Stuttering">"try using a VPN to rule out ISPs messing with your traffic... ProXPN is just one example of one that offer free trails that are fast enough to stream 1080p content.... With using once to rule it out"</post>
   <post id="b3e19500-b4f2-43b9-8016-bf4c2da51351" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"I currently have an Onkyo TX-SR605 with 7.1 speakers, I run analog from my X-Fi to the analog inputs on the Onkyo. This TX-SR605 is developing issues (aside from its HDMI problem) so I think it s about time to move on. I really wish I could get a new receiver with 8-channel analog inputs, but that doesn t look like it ll be happening due to the cost of something with analog inputs on it. I d like something with Dolby Atmos but I would prefer it be the 7.1.4 type, does that typically require a costly 9.2 speaker unit? Considering that I d only use Atmos if a game supported it, I m thinking I can skimp on that and go with a standard 7.x receiver. My budget is $450-$550, so that probably rules out a 9.x receiver, and I m even open to suggestions on used equipment. I m considering ditching the X-Fi, since I ve not played an EAX game in a while, and move on to using HDMI from the video card or motherboard."</post>
   <post id="a72ea852-3972-420b-978e-0f04362d7a02" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"In order to get Atmos working, you ll have to use HDMI out from PC -&gt; Receiver. If you want to use analog out via your sound card, that Atmos stream will need to be decoded to PCM via software (like Jriver Media Center, etc), but I don t know how that decoding process handles the Atmos ceiling channels (still haven t upgraded to an Atmos-enabled receiver). There are some pre-pros out there that accept 8 channel input but not in that price range; I ve been looking at the new Yamahas (Audioholics link), but I love my Pioneer VSX-1123 s sabre DACs - the VSX-1124/1130 is Atmos enabled but I think you have to move up to their Elite range for 7.1.2/4... I ve read a bunch about some higher end stuff like Anthem and Emotiva, but those are a bit out of the price range..."</post>
   <post id="f42bd9db-83f8-4506-af01-62b6cbdc925f" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"If you want something that will last decades, get a Yamaha... They are IMHO the best bang for the buck."</post>
   <post id="6c5f7e2a-9f2d-49e3-a686-cbd275a4a0db" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"You can t go wrong with this ONKYO TX-NR747 7.2-Ch x 110 Watts Networking A/V Receiver or this ONKYO TX-NR646 7.2-Ch x 100 Watts Networking A/V Receiver"</post>
   <post id="4ed5b6fc-3d47-48d8-bb2d-5228cba87d42" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"+1 to Yamaha YAMAHA RX-A1040 7.2-Ch x 110 Watts Networking A/V Receiver"</post>
   <post id="f6f5d2df-9568-42fc-b42a-96ac7b151c59" section="Home Theater PCs and Equipment" discussion="I need a new AV receiver for PC gaming.">"Hey, Accessories4Less is a legit place to buy, as well, in case you are wondering. I ve ordered 3 AVRs from them for myself and family members, a refurbished Denon had a problem and was covered under warranty and fixed for free at my local Denon electrician. Just wanted to share because they have GREAT deals sometimes and the stock photo people may throw you off..."</post>
   <post id="2afdbbbd-be75-41f4-84a0-d8c77086d60a" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"So I had $3700 in store credit at best buy. My Epson 5030UBe kicked the bucket and I needed to replace it along with getting a nice home theater audio system. I picked up the following: 2x R-28F floor standing 1x R-25C center 2x R-15M Bookshelfs (for surround) 1x R-12SW Sub Onkyo TX-NR656 AVR I know I could have went with the Reference Premiere line for the money I paid for the reference line. I was locked in at Best Buy so I didn t have a lot of choice. That being said, are the speakers above: Great, Just okay, awful? So far they sound great in my space now that I ve got them calibrated. Just trying to see if I should sell them and try to get cash to move up to the RP series (but I have a feeling I would lose a ton of cash that way)."</post>
   <post id="087f4c14-0bb7-4722-a3dd-71437b460ed3" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"The most important thing is that you like the way they sound. When you turn those bad boys up during your favorite movie/game/song and you can t keep from smiling you are good. That being said there is no harm in attempting to sell them if you can break even. If you don t get any offers you like no big deal. It is important to keep future purchases in mind as well when choosing current speakers, make sure whatever speakers you own now will still be affordable to you down the road incase you ever want to upgrade to a 7.1/Atmos/DTS-X setup down the road."</post>
   <post id="e44c7a4f-d82e-44c2-b87b-8ed2fb54aab5" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"I appreciate the feedback. I may get the Klipsch Atmos add-on speakers to sit on top of my floor standing ones to add some depth to the sound stage."</post>
   <post id="a61af549-60b6-4baa-b218-1040ec547ceb" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"Speakers being "good" is pretty subjective. If you like them, keep them."</post>
   <post id="4d894161-e178-4b33-af08-5776fcf78756" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"I m wondering now if my Onkyo 656 has enough power to drive these at 50% volume. I noticed a little crackling during an intense action sequence watching the Force Awakens."</post>
   <post id="b2ef73aa-93e0-4b14-a0f3-7b968f523967" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"As others have said, only you can say if you like them or not. I personally dont understand how people can buy speakers based on reviews. Everyone s ears are different and the technical specs are only a small piece of what makes speakers appealing to a listener. The reason why there are so many speaker companies is because they cater to different listeners. Personally, I love PSB. Someone else may like JBL, Klipsh, Polk, Velodyne, NHT, Infinity, Paradigm, B&amp;O, Martin Logan etc etc etc etc. There are hundres of speaker companies, all for different ears and wallets."</post>
   <post id="baf74bee-a603-43e2-863a-1543f2057ecd" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"clayton006 said: ↑ I m wondering now if my Onkyo 656 has enough power to drive these at 50% volume. I noticed a little crackling during an intense action sequence watching the Force Awakens. Click to expand... What was the source (disc, download etc...etc...)? With a 98db sensitivity level the 656 should provide enough power to get these to reference levels."</post>
   <post id="f88ef907-9e03-4ead-9e58-0f31c869c454" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"It was a Blu Ray. Star Wars the force awakens part when they are stealing the Falcon. I think the crackle may have just been part of the source material."</post>
   <post id="5e795a88-bad8-4fd4-94d2-585f651a83c3" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"I m not dogging on your purchase, speakers are only good if the person listening to them likes them. But I will say that the RP-280 s sound considerably better in both music and movie criteria, I tested both and decided to order the RP-280 s and wait for them instead of purchasing the 28 s from BB. I didn t test the bookshelves, center or sub so I won t comment on those. grifter_66 said: ↑ What was the source (disc, download etc...etc...)? With a 98db sensitivity level the 656 should provide enough power to get these to reference levels. Click to expand... I am suspecting the Amp in this case. It should have plenty of power looking at the listed spec s but they don t have an RMS rating. I m assuming its the 100w @ 8ohm in stereo but they don t list it for 5 channels being used. I m powering a set of RP-280 s with a receiver that hits 85watts @ 8ohm s in stereo but only does 65 in 5 channel mode. I haven t tested it out to see if I could get mine to clip but this would be a different case scenario with a different line of speakers. The reason why I don t think its the source is due to BD s being considerably harder to damage and usually damaged disc s don t cause crackling, I m assuming the crackling is clipping."</post>
   <post id="74b7c66c-5dce-42f0-885d-9bcb8ac52422" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"I figured the RP-280 s would sound much better. I may hold on to this system and use it in the corner where my other projector is when I go to replace my main set."</post>
   <post id="669f7d6a-d485-45ad-8d12-66d502c9df94" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"clayton006 said: ↑ I figured the RP-280 s would sound much better. I may hold on to this system and use it in the corner where my other projector is when I go to replace my main set. Click to expand... I plan on finishing my RP system when I pick up a 4k receiver."</post>
   <post id="036b2ebb-da80-407d-b0ab-60d24550b913" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"Trimlock said: ↑ I didn t test the bookshelves, center or sub so I won t comment on those. Click to expand... I have Polk for my fronts and center so I can’t comment on these, but I do have the R-12SW Sub. I thought it sounded much better than 12" Polk sub. I m not an audiophile by any means, but I felt like the Klipsch sub sounded much better with both movies and music. I wasn’t going to spend $ 1500+ for something that exceled at both And of course, as several people have mentioned, what matters is whether or not it sounds good to you."</post>
   <post id="861ab53c-9bc5-4e85-8695-ea0ce9800d44" section="Home Theater PCs and Equipment" discussion="Question about Speakers I purchased... Klipsch">"I ve heard the R-12SW since posting this and read a bunch of negativity towards it and I can t say I agree with the notion that it s not a solid sub. I quite like it."</post>
   <post id="d67e5dfe-44be-42c6-ae82-6d38a540559e" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"I picked up a 37" 1080p TV at an estate sale for $75 today. It s a Panasonic IPS and looks brand new. I d like to set it up in my home office with a pair of bookshelf speakers. So far, I m leaning towards a set of Infinity Primus P163. I have this little SMSL PQ amp to drive them. "SMSL Q5 PRO Stereo Amplifier USB Optical Coaxial DAC with Subwoofer Output 2x40W" from www.parts-express.com! Any suggestions besides the P163? I d like to get under $150/pair. Thanks!"</post>
   <post id="5907234e-a4ec-4a51-a217-99614fc256e4" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"Commander Shepard said: ↑ P163 Click to expand... Got these a few weeks ago, like them a whole lot"</post>
   <post id="86742a80-2c0b-40e1-b0b8-6a7c19a561a7" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"Those Primuses (Primii)? sound more open and full range than the super bass heavy Pioneer SB22s designed by Andrew Jones - his new ELAC B5s are outstanding though but thats a bit above your price range. The Infinitys are probably your best bet at that $. Also, let us know how the SMSL is, they have great reviews and I was going to get one to run my SB22s in my dining room (the smsl handles 6 ohms well, supposedly, which my T amp does not)"</post>
   <post id="d7388570-ff42-45a0-b07d-e507a60de8e3" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"Think I ll just go with the 163. Found an open box pair at Crutchfield for $149 shipped. Will report back when I have everything set up. I m looking at the new Elac uni-fi B5 for my computer audio. Just waiting for some reviews."</post>
   <post id="c644471a-d0d8-484f-940e-a320acefc36a" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"P163 is a pretty solid choice, it should satisfy for your usage."</post>
   <post id="f77e0ba5-13fb-4726-95f7-d3a175a7d846" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"And don t forget about Craigs List and eBay. I got an older pair of Infinity RS2000.2 s on eBay for a decent price. I picked up a reciever and some big floor speakers for the garage last year for $40 from a local guy."</post>
   <post id="568cff81-f3b2-4fa9-ae67-3072bee1f55b" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"Commander Shepard said: ↑ Think I ll just go with the 163. Found an open box pair at Crutchfield for $149 shipped. Will report back when I have everything set up. I m looking at the new Elac uni-fi B5 for my computer audio. Just waiting for some reviews. Click to expand... Those are the ones with the built-in amp, correct? I have the passive B5s in my movie room set up, they definitely match all the hype around them. If you re going for powered speakers in that price range, take a look at the JBL 305s as well."</post>
   <post id="135c70fa-c24c-4e2a-a06c-0a7f340d1b36" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"windianrecords said: ↑ Those are the ones with the built-in amp, correct? I have the passive B5s in my movie room set up, they definitely match all the hype around them. If you re going for powered speakers in that price range, take a look at the JBL 305s as well. Click to expand... The new Elacs are passive, too. Good to know that the older B5 lives up to its reputation. All the pre-release hype surrounding the Uni-Fi line is encouraging. Hope it proves to be true."</post>
   <post id="e2bae0fd-7ffa-43c4-8484-afebcbdad455" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"My stuff was delivered, today. Don t have time to hook up everything until the weekend. That amp on the left is for my PC."</post>
   <post id="8461d9b6-0c43-40a3-8a32-e0de1c5ab6b3" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"Commander Shepard said: ↑ My stuff was delivered, today. Don t have time to hook up everything until the weekend. That amp on the left is for my PC. Click to expand... Peachtree products are LEGIT! Their Sabre chip filters are very musical, plus really well built gear. Enjoy!"</post>
   <post id="dd3d4bcd-ddf9-4087-ad8f-aef9f40c2644" section="Home Theater PCs and Equipment" discussion="Inexpensive bookshelf speaker recommendation?">"windianrecords said: ↑ Peachtree products are LEGIT! Their Sabre chip filters are very musical, plus really well built gear. Enjoy! Click to expand... Great to know. Thanks! I bought it purely on the recommendation of the guys at Crutchfield. I was set on the Yamaha S801, but they preferred the Nova. And it was $100 cheaper."</post>
   <post id="dbb7e6c9-c3c9-4dbf-97c3-58d4d826ce02" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"I just got a 4K monitor and was wanting to know if there are any internal DVD drives that I can play 4K discs on?"</post>
   <post id="4e36662e-563e-4cfb-8509-1ea3bff166e1" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"No there isn t."</post>
   <post id="2ed84cac-69b1-4206-a877-7f9710f1733a" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"The 4K Blu Rays aren t physically different from regular Blu Rays from everything I ve read. With an update to whatever software you re using for Blu Ray playback you ll be able to watch 4K Blu Rays as long as you have a newer model player."</post>
   <post id="9168be0a-6d7e-46da-a5a8-f431c9c9e5ea" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"I was curious about this a few months ago and apparently there is a newer (2014-15 model) LG drive that has been confirmed to work with seemingly everything out of the box. At least with the few 4K disks people on AVS tried on it. I can t recall the model number, but it was one of the Modisk RW models. Supposedly it does relate to firmware and not hardware, but I can t imagine 6-7 year old drives like mine getting free updates."</post>
   <post id="57b33d21-417b-4f58-bdbb-82b1cdb2b9f9" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"shinjinian said: ↑ The 4K Blu Rays aren t physically different from regular Blu Rays from everything I ve read. With an update to whatever software you re using for Blu Ray playback you ll be able to watch 4K Blu Rays as long as you have a newer model player. Click to expand... According to this thread at AVS, it s NOT guaranteed compatible with older drives. And also, there s still no way to play the 4k movies, and thus we have no idea if they will be capable of decryption. 4K Optical Drives: Will Existing BDXL Options Work? - Page 4 - AVS Forum | Home Theater Discussions And Reviews As usual, PC Blu-Ray is getting left high-and-dry."</post>
   <post id="8dce7c7e-6e32-48db-af9d-a3b4a92c3dff" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"defaultluser said: ↑ According to this thread at AVS, it s NOT guaranteed compatible with older drives. And also, there s still no way to play the 4k movies, and thus we have no idea if they will be capable of decryption. 4K Optical Drives: Will Existing BDXL Options Work? - Page 4 - AVS Forum | Home Theater Discussions And Reviews As usual, PC Blu-Ray is getting left high-and-dry. Click to expand... That s why I said as long as you have a newer player/drive. You d need a Blu Ray player that supports the high/extended capacity Blu Rays because of the size of 4K video. I m pretty sure I heard cyberlinks powerdvd is getting an update or already has support for 4K Blu Rays."</post>
   <post id="d0741996-8327-4b4e-afee-5f634e6863bc" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"I have the new PowerDVD (#16) and they said that 4K support will be coming soon, but it doesn t play  em yet. Not like I have a drive or any disks that would work anyway. I m just going to keep watching the AVS forums and see where all of this goes. It is annoying that this spec has been completely ignored on the PC front thus far. You d think that if it did work in an official way, both drive makers and Cyberlink would be all over it."</post>
   <post id="c64f94c1-4081-40b4-a515-0905c1972fb9" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"PC s have always lagged behind when it comes to optical tech. Honestly there s no reason to complain about lack of support for something that s practically nonexistent since there next to no content at the moment. Btw how do you like PowerDVD 16? I was thinking about going for it once I pick up a Blu Ray drive for my PC."</post>
   <post id="44addbee-463a-4be5-b359-b0dc08c8a896" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"shinjinian said: ↑ Btw how do you like PowerDVD 16? I was thinking about going for it once I pick up a Blu Ray drive for my PC. Click to expand... In all honesty, it s like 90% the same as Power DVD 15 for me. The main difference is the addition of a new TV mode with a cleaner interface designed for remotes and simple viewing. It also supports disk ISOs and some additional casting functions I don t really use. While I tend to play most of my non-disk media with MPC, it s no longer a horrible choice to use PowerDVD. It opens the media quickly, doesn t eat up 1/2 your resources, and will play anything you throw at it. Out of the box with minimal tweaks no less. The new streamlined TV mode combined with that better functionality actually make it a pretty killer casual user app. As a power user, there is minimal reason to upgrade if you have 15. It s a lot better than older ones, though."</post>
   <post id="933259f4-aa0b-4d1a-bcdf-0f6c0698969a" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"shinjinian said: ↑ The 4K Blu Rays aren t physically different from regular Blu Rays from everything I ve read. With an update to whatever software you re using for Blu Ray playback you ll be able to watch 4K Blu Rays as long as you have a newer model player. Click to expand... Why did you post this?"</post>
   <post id="0b063aa3-9d98-4230-aafc-f9b3038a3758" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"Verge said: ↑ Why did you post this? Click to expand... Because the OP asked if any drives played 4K Blu Rays and I was explaining its not a matter of hardware, what s required is updated software for most newer Blu Ray drive to work. Did you read the thread?"</post>
   <post id="b1c667e2-e924-4a6c-98e3-d8a78e1cd4f6" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"shinjinian said: ↑ Did you read the thread? Click to expand... Did you piratepress said: ↑ I just got a 4K monitor and was wanting to know if there are any internal DVD drives that I can play 4K discs on? Click to expand..."</post>
   <post id="f8874929-7b9a-4932-8d4d-b683901476cc" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"Dion said: ↑ Did you Click to expand... There is no such thing as a 4K dvd. Unless you re storing short 4K videos on a writable disc in which case the answer is any DVD drive would work."</post>
   <post id="e91bdd31-6172-452a-a768-cb4cb93408a2" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"shinjinian said: ↑ Because the OP asked if any drives played 4K Blu Rays and I was explaining its not a matter of hardware, what s required is updated software for most newer Blu Ray drive to work. Did you read the thread? Click to expand... Blu Ray drives will not read UHD discs. You comments aren t even partly correct. Don t waste time posting incorrect info."</post>
   <post id="146022f9-c246-45e1-9212-9516d1a441c8" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"I m pretty sure no DVD player ever will play 4k UHD BluRay discs. Gonna take a wild stab in the dark, and say you might need a BR player to play BR discs"</post>
   <post id="b8b89118-060f-4a9d-b6d0-0ee382e94e62" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"Verge said: ↑ Blu Ray drives will not read UHD discs. You comments aren t even partly correct. Don t waste time posting incorrect info. Click to expand... Some of them will read the discs. Of course there s no software to play them back so it s not of a whole lot of use."</post>
   <post id="ce53c7ba-2058-4585-8ff6-65999daeb14f" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"Stereodude said: ↑ Some of them will read the discs. Of course there s no software to play them back so it s not of a whole lot of use. Click to expand... They won t read them either right now, even if the appropriate software was released, you will need a new drive as well."</post>
   <post id="885b2686-33c9-4704-ac3b-cff4452bb10f" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"There are people on AVS that swear some drives can at least see the file structure of UHD disks. I have no idea if that could translate into anything more, though."</post>
   <post id="31b0f909-b112-495c-b169-a0b58ef6fbf4" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"Verge said: ↑ They won t read them either right now, even if the appropriate software was released, you will need a new drive as well. Click to expand... You re wrong. There are drives that can read the discs now. People who have those drives won t need new ones."</post>
   <post id="616c0162-c4c9-4bf4-bf2b-5a1a55fbb51b" section="Home Theater PCs and Equipment" discussion="4K Ulta HD Internal DVD Player?">"I m interested in being able to decode/view 4k UHD discs on the PC also - I just searched AVS Forum to follow that thread but couldn t find the one where users talking about seeing disc structure - do you have a link in your history? EDIT - NM found it by simplifying my search... does look like people s PC BD drives are able to see the structure/tagging, hopefully MakeMKV or the like can do something about that AVS FORUM LINK"</post>
   <post id="c36ed2b2-eba4-4abd-ba74-ac6b147448aa" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Been looking for a cheap pair, non powered for a little project, may be moved to my PC later. Had my eye on the $40 pair of Daytons at parts express. Anyone have a recommendation for a better pair? Going to hook them up to a small amp either my 10 watt or 20 watt. Thanks!"</post>
   <post id="3b210627-67ed-4d0c-9678-b1480d59de1e" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Only issue with those Daytons, which are very nice for the money, is the speaker wire terminals. They re the old style clips. If that s not a problem for you, then it d be hard to find better speakers at that price."</post>
   <post id="95dbe3d8-42a4-4e8e-8782-a10010f1b362" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Commander Shepard said: ↑ Only issue with those Daytons, which are very nice for the money, is the speaker wire terminals. They re the old style clips. If that s not a problem for you, then it d be hard to find better speakers at that price. Click to expand... Yea terminals are a non issue"</post>
   <post id="63c8fc7e-6f78-472c-974b-5dab7ec1c5b3" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Barring finding something at a garage sale or thrift shop, yeah, that s probably your best bet. Plus, anything you find that ll sound significantly better will probably be old enough that they ll need to be re-foamed, and that s kind of a pain in the ass. That or do a little research and look around on eBay, though at that price point I wouldn t expect wonders."</post>
   <post id="804bce26-264a-402a-b9c0-54dd96ddb01c" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Well have you seen anything used go for $50 that would blow these away? I m looking now and only see extremely old stuff. Re foaming isn t that big of a pain, I still have a roll of foam that I can use."</post>
   <post id="6f45980e-d390-4985-aba2-54bd65106f75" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"I haven t seen anything on eBay, but depending on your area, Craigslist or the local thrift shops / Goodwill / Salvation Army / Habitat ReStore may have some gems. Also, old is not bad (as you probably know). Some of the best speakers ever were made back in the 60s and 70s."</post>
   <post id="5c9bcc54-91e8-49c8-815d-c47c8670edd7" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"I just noticed that between you two, there are 22 years and 27,672 posts on [H]"</post>
   <post id="1c4bf9cb-7eb8-4f16-bb35-a65aae3516b2" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"silent-circuit said: ↑ I haven t seen anything on eBay, but depending on your area, Craigslist or the local thrift shops / Goodwill / Salvation Army / Habitat ReStore may have some gems. Also, old is not bad (as you probably know). Some of the best speakers ever were made back in the 60s and 70s. Click to expand... Yea I never see those speakers less than $200 at least with a working cross over or a non blown driver. I would like something a bit more sensitive than the Daytons but I m not in need of it. I ll look a bit longer locally. Commander Shepard said: ↑ I just noticed that between you two, there are 22 years and 27,672 posts on [H] Click to expand... Lol we are lifers!"</post>
   <post id="ccf22aa8-9052-41b7-af2f-2cf4d605f6b9" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"The old guard. Granted, there are people that have been here /way/ longer than us. Luck in the search! If I see anything I ll let you know."</post>
   <post id="50d36952-f477-4ac3-9364-90fb37996d91" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"silent-circuit said: ↑ The old guard. Granted, there are people that have been here /way/ longer than us. Luck in the search! If I see anything I ll let you know. Click to expand... Awesome, thanks! I ve been here since 2001/2002, a bit longer actually but I didn t start using the forum till then. The Celeron 300A era is when I started using the site, I had no idea how to OC and heard through the grape vine you could steal more MHz from Intel with a little BIOS hackery."</post>
   <post id="b55f95e4-3c3f-4d27-b62c-399a65e3ac30" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"Yeah, I was lurking for years before I made an account. Built a system with an AMD T-Bird and started hanging around here, so that d be mid 2000."</post>
   <post id="d9b3c0a0-722d-42f4-a374-5eee8f31ff1d" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"I had built an account then too, accounts gone but I made it to complain about how I chipped my 1.4 T-Bird lol."</post>
   <post id="2c025d26-e5dc-4f2d-b241-21257f8624a8" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"I love noaudiophile s reviews of speakers in this price range, I don t know which exact Dayton model you re talking about but here s his AIR model review - Dayton B652 AIR Review - he also mentions the non-AIR models as well as these little MICCA speakers available on Amazon. What s even cooler about his site are the measurement/EQ files he provides, I found they were quite accurate with the Pioneer 22s and JBL 305s"</post>
   <post id="2f862152-0861-42b0-9294-5db248b7978d" section="Home Theater PCs and Equipment" discussion="Bookshelf pair recommendations $50 ish">"The airs contain the special tweeter by PE, I don t consider them worth the extra $20 or so dollars they charge. Thanks for the link, I enjoyed the reviewers writing style."</post>
   <post id="7e9e5f52-5432-490b-b9a9-cead765d7228" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I ve been using Total Media Theater for a few years now but, apparently, it s no longer being supported and it won t play most newer disks. Thus, I need something new for my HTPC. I don t mind paying for something but I d rather not put money into a player that is just crap bloatware or something that isn t going to be supported long term. Let me know what you like or, equally good, if you ve tried something that is junk and I ought to stay away from it."</post>
   <post id="09fb06a9-9525-4b39-a750-58727e10594b" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"Powerdvd is pretty much the only one left. Its what I ve been using for the past few years."</post>
   <post id="d2814c7f-b2ed-4f8e-a356-1caa6e981a86" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"MPC-HC as I have a tendency of ripping it first with MakeMKV of AnyDVD HD. If I need to do menus and such it gets chucked in the PS4."</post>
   <post id="65ba1ece-c2a4-4685-970e-984b9d20a419" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I m still using PowerDVD 12. Was wondering myself what else is out there that s reasonable in price and not bloat ware."</post>
   <post id="c2629a91-fa23-4366-aabd-e28dfe3ced85" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"The Pirate Bay"</post>
   <post id="74e66b88-e39d-4e30-8f4a-cbc39c4c3acc" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"It all depends. Do you mean playing the discs directly? What OS are you using on your HTPC? I m guessing Windows, as I searched that Total Media Theater and it seems to be Windows based. Have you tried... VLC Media Player - .videolan.org - This is a great player that has a lot of included filters/codecs, including the ability to play BluRay. Media Player Classic - Home Cinema - .mpc-hc.org - This is another fantastic media player. It works best with a handful of additional renderers such as MadVR, LAVFilters, XYSubFilter etc.. but it can be a bitch to configure them all together. Thankfully, there are a handful of codec packs that do just this, but there are only a few with no bloatware (ie CCCP Project, and Kawaii Codec Pack). Note, there is also a fork of MPC-HC called Media Player Classic - Black Edition, that is very similar but some prefer it. I typically just use the original. These are both open source, extensible, and pretty much play just about everything. It even has chapter support and whatnot. Now, if you re looking for something remote control/TV style UI focused... Kodi (formerly XBMC) - kodi.tv - This is a famously supported open source media center. Pretty much plays everything and has addons for even more. Easy to navigate with a remote (physical, or smartphone) . There is a windows build so you should be good for your HTPC. Check these out and see if they will work for you."</post>
   <post id="b01bcb2c-4aa7-4aa2-899f-aa83d5c69d97" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I ve never had a whole lot of luck playing Blu-Ray movies using free software. It kinda works, but it always seems like something doesn t work quite right. Either the menus don t work quite right or the audio keeps un-syncing via bitstream. It was enough to get me to fork over $ to Cyberlink. I ended up just biting the bullet and getting PowerDVD. It s only in the neighborhood of $50 now, which isn t terrible. Supposedly this free one works okay, but I ve never tried it: Best Free Blu-ray Player Software for Windows - Leawo Free Blu-ray Player"</post>
   <post id="9fdebab8-14db-4d9e-9562-32da98a77869" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"Probably worth mentioning - Cyberlink just released PowerDVD 16, so older versions like 14 and 15 are probably going to get cheaper while they re still available. 16 doesn t offer all that much more than 15 does (on the surface) and you can always get a discounted upgrade in the future if you ever do want to move up."</post>
   <post id="2d21d904-c0d2-4230-b21f-574796b7ea23" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I ve been a long time user of Total Media Theatre for years. I bought it when it was version 3 and upgraded through till the end. It did just what I wanted and nothing else. I also use AnyDVD HD. I had to buy it after I put in the blu Ray drive and bought Total Media Theatre only to be told I didn t have an HDCP compatible display, which I did. I wrestled with it for a while, then gave up and bought AnyDVD HD. Even after getting a new monitor that it did recognize as HCDP, I continued to use AnyDVD HD out of convenience to be able to skip the un-skippable BS they put in blu ray movies. Last night my night was ruined by BS blu ray DRM. I fired up AnyDVD HD, put in the disk, started Total Media Theatre, skipped the ads to get to the main menu. Went to the kitchen and popped my pop corn and grab a beer. I started up the movie, then 3 minutes in I get a message about the Cinavia DRM crap. I ve gotten these before, but usually 15-20 minutes into the movie not 3 minutes. If it had waited 15-20 minutes as usual I at least I would have had time to eat my popcorn while it was hot and fresh and drink my beer while it was cold. No problem I thought, I ll just close AnyDVD HD and it ll let me play it. Nope, it wouldn t play at all without AnyDVD running. I got the un-skippable ads but was able to fast forward, then it tried to play something which the old Total Media Theatre didn t support and just stopped. To make a long story short, after 2 hours of trying to get it to work, I finally ended up downloading the trial for PowerDVD 16, but by then I had cold, stale popcorn and a warm, flat beer. PowerDVD 16 seems way too bloated to me. I just want a damn blu ray player, and it wants to take over my system and be the default app for all video, music and pictures. Sadly it seems that s all that s left for PC play back, except the free one someone mentioned above. I might try that because to buy PowerDVD 16 for blu ray is $80 and you can buy a blu ray player now for the same or less. AnyDVD HD is not going to be working much longer once the new RedFox opens for business. I had a lifetime license for AnyDVD HD and for that I ll get a 20% discount, but they re going to ask 109 Euro (~ $125 USD) for the same product under a new name. I dug out my receipt from when I bought it and it was only 79 Euro back then and it and just happened to be 20% off at the time. I would consider buying a new lifetime license if they sold it for a more reasonable price and/or offered a better discount for old SlySoft lifetime license holders, but at that price no thanks. So now I gotta decide if I want to spend $80 on PowerDVD or about the same price on a dedicated player. I already have a spare HDMI cable somewhere and an audio cable to run the audio pass through to my sound card s line in."</post>
   <post id="1cf2dd47-a2f1-4023-969a-878695dacec3" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"jimnms said: ↑ So now I gotta decide if I want to spend $80 on PowerDVD or about the same price on a dedicated player. I already have a spare HDMI cable somewhere and an audio cable to run the audio pass through to my sound card s line in. Click to expand... If you want to watch the movie as it s presented on the disc (menus and zero compromise) and on a TV then I say get a dedicated player. It s quiet and works. If you are wanting to rip movies then sure, a computer is needed all the way (at least for the ripping)."</post>
   <post id="1d89451d-5133-44b3-844f-5ed0a2bdd29f" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I don t rip movies, I just rent and watch. I rarely ever find a movie I d want to re-watch. Right now I do almost everything on my PCs. I record TV, watch movies and play games. The thing about Total Media Theatre is that it integrated with Windows Media Center and I could control it with my media center remote. I briefly looked at some blu-ray players last night and saw in the reviews that even some newer ones get this Cinavia error, a couple even specifically mentioning the movie I watched last night. I did try that Leawo Free Blu-ray Player, and it didn t work. It played the movie, but it was all out of order. A quick search on blu-ray software lead me to two players I ve never heard of which are a lot cheaper than PowerDVD. One is called Macgo, the other is iDeer. I haven t had a lot of time to research either, but I ve seen good reviews about Macgo. They both have free trials, so I ll have to try them later and reply with a review."</post>
   <post id="5644b0b4-c6bc-4634-9a4b-ce66d7eef10f" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"Oh well, those two were a bust. They were identical and both worked just like that free player. It started the movie, but it doesn t play the chapters in the right order."</post>
   <post id="4da6cb97-fa61-4818-adee-5bbf5da5bc0c" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"What a cluster fuck... jesus. I am looking for a BR drive too (to rent and watch movies like any normal joe), but this has just made me want to rip them to watch it in the first fucking place. What a total, stupid clusterfucking DRM move. It s like they re forcing you to rip it or download it. I would be cautious about buying a player because just like DVDs, they are outdated every time they fuck with the DRM. Pisses me off so much. Digital Restriction Moronity.."</post>
   <post id="55dd60f3-bb36-4f8e-97fe-ecfd64e3d65e" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I never had much luck with anything free...hence I just took the Cyberlink plunge. It is a horribly bloated program by default, but you can luckily turn most of the nonsense off. I still have MPC-HC as my default movie player for everything except disk media. I also don t have any of the library functions turned on either. In fact, I just turned on the TV mode UI just to keep it extra simple. While I know they d never do it, I wish they actually had a streamlined version that was missing all of the extra nonsense for $50. That said, it IS one of the few areas where PDVD16 improved over 15. It opens media files much faster and it seems fairly bulletproof while doing so. I d happily recommend it to non power users because it can handle nearly everything you throw at it."</post>
   <post id="ead4e4b5-0bf4-4db3-bec3-409d5ef4fb99" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"I use an actual/standalone BR player. Aside from the lackluster experience using a PC - it s less maintenance with an actual/standalone player in regards to updates."</post>
   <post id="b8d94a5d-940e-4f1e-9a4f-bbc4e0399377" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"staknhalo said: ↑ I use an actual/standalone BR player. Aside from the lackluster experience using a PC - it s less maintenance with an actual/standalone player in regards to updates. Click to expand... Do they get updated much or is only the higher end/pricier stuff? This is my greatest fear about a player. I guess a PS3 or PS4 would be a safe bet (support wise..). "Forgive me, Lord GabeN, for I have had impure thoughts.." &gt; Self flagellates with ram sticks tied to a lan cable ."</post>
   <post id="decc6b22-4b0c-4970-ae24-b118571e06db" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"You ll be fine in regards to updates with a standalone player (even at the low end). Just avoid no-name brands. Low end Sony, Samsung etc units get updates for new AACS titles as needed."</post>
   <post id="13cb21ff-0105-435c-8f14-e65fdd160e26" section="Home Theater PCs and Equipment" discussion="What software are you using for Blu-Rays these days?">"Sony is definitely a best bet, even their little ones with Netflix/wifi built in - their video processing chips are very good for the money, I still use my PS3 as a player in the bedroom."</post>
   <post id="026ebe42-939e-423f-a0f8-7e30116ee6e2" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"I ve been wanting to buy a projector cuz i m broke to afford a real home theater stuff. i narrowed it down to two projectors. Sony s MP-CL1 and UO Smart Beam Laser. Planning on using with ipad2, Mac Air, LG G4, and Playstation 4 The specs are: Sony (349.99)- sleek &amp; flat design, 32-37 lumens, max screen size 120  1.0W speaker, focus-free, headphone jack UO (379.99)- interesting cube design, 60-100 lumens, max screen size 150 , 1.0W speaker, focus-free, no headphone jack I couldn t really find a lot of reviews online for UO Smart Beam Laser so I don t really get the whole 60- max100 lumen. Is it possible for the difference to be that big? Or does that mean like your perceived brightness would be 100? But I guess even if it doesn t reach 100, 60 is going to be lot brighter than 32. Does anybody own a 32 lumen projector? Is it bright enough to see images crisp and clear or does things look airbrushed and soft? Neither one is cheap, so I think if I m spending 350+ on it, I might as well go all in and buy the one that has higher resolution, but I m still deciding..... Any recommendation would be appreciated!!!"</post>
   <post id="b3fdd5bf-3548-436a-ba01-db433d65cb09" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"32 lumens you need like basement dark for $350 you can get a 1080p 1000+ lumens projector that would be much better, unless portability it important for you"</post>
   <post id="a81d2a3c-2aa1-4dbb-b198-91fc92ed2985" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"Adidas4275 said: ↑ 32 lumens you need like basement dark for $350 you can get a 1080p 1000+ lumens projector that would be much better, unless portability it important for you Click to expand... Thanks! Basement dark will not work for me.. lol But would 60 be sufficient? Yeah I want a compact projector even though I will be using it mostly at home."</post>
   <post id="f485965d-c765-425a-886d-ee511d91cdea" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"SkylerGrey said: ↑ Thanks! Basement dark will not work for me.. lol But would 60 be sufficient? Yeah I want a compact projector even though I will be using it mostly at home. Click to expand... Those pico projectors are designed for no-light rooms for optimal use since they have no lumens. Any amount of ambient light annihilates contrast. So...even a little bit of sunlight or small table lamp will crush your contrast into the 50:1 range. For a PowerPoint presentation...this might be okay. For a movie, I would rather just watch a TV. Second, those PicoProjectors are limited to ~60" screen if you want enough LUX (in a highly controlled light environment) to have a reasonably bright picture. Anything bigger than that and things start falling apart again. Don t get me wrong...for travel they are amazing. For home...dunno."</post>
   <post id="6e9fb644-c329-4c66-9220-a890e7588229" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"fwiw.. I picked up a $200 Elmo BOXi T-200 pico projector that does 1280 x 800 that I ve been real happy with. It s 150 lumens and haven t had any issues with brightness. I got it at B&amp;H but it appears to be discontinued there."</post>
   <post id="ea3dc487-091f-4c3d-83ae-498036b86b0e" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"Do you NEED a pico projector? Because $350 gets you close to buying a used real projector with 1200+ lumens and usability in anything by pitch black conditions. Even with absolutely darkness, they still look bad due to a lack of contrast when displayed on large screens. Lack of pixels absolutely won t be the biggest issue. 32 to 100 lumens is close to nothing if you want a large screen, much better off with almost anything else at that point. I m using a 2000 lumens projector on a 100 inch screen and I think it s barely enough to be satisfied."</post>
   <post id="d81e1983-5ac7-41be-9244-0b119100cadc" section="Home Theater PCs and Equipment" discussion="Pico Projector Recommendation Needed!">"SkylerGrey said: ↑ Thanks! Basement dark will not work for me.. lol But would 60 be sufficient? Yeah I want a compact projector even though I will be using it mostly at home. Click to expand... Sure, for a 25 inch screen. Those are novelty items, your throwing money away if you buy them."</post>
   <post id="06664a95-1e24-46e2-b161-a7561dab35cb" section="Home Theater PCs and Equipment" discussion="Gen 2 Chromecast + Older Hitachi HDTV">"Hi, I bought the Portta PETHR HDMI to Component YPbPr + R/L Audio Converter v1.3 to connect my Chromecast to my older Hitachi HDTV. I get audio but the picture is scrambled. I tried rebooting the Chromecast and it worked perfectly until it got to the home screen then the picture scrambled again. Any suggestions on how to make this work before I return it? Is it EDID issues I m dealing with?"</post>
   <post id="874ca74d-e0cd-4703-81ef-a8fe8b495b2e" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"As the topic states im going to build a new HTPC my question is should i go for older CPU an discrete graphics or newest CPU with integrated graphics? i m trying to get mobo/CPU/GPU?/ram for no more then $600USD has to be itx board. Ive just never used integrated graphics ever an i have no clue how much it has progressed with the newest stuff out. Thank you for all input/advice an even if you have a totally different way to approach this please feel free to speak on it as im all about learning more!"</post>
   <post id="4de171cc-f604-4929-8543-0426c6491ba0" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"You need to give us some requirements. What are you planning to do on this HTPC?"</post>
   <post id="aa13d2a4-3d3e-4c42-9406-530bf7e2b417" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"Youtube, Hulu, Amazon prime, Netflix, 1080p rips."</post>
   <post id="1a6b2994-7a69-47dd-a907-047558ccabaa" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"So for $600, all you need is board/gpu/gpu/ram? Or all components?"</post>
   <post id="d7c726e5-a7ee-4cc9-a215-296154f3b38d" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"What case, PSU, and SSD are you using?"</post>
   <post id="212891ed-f8e3-461c-ba2f-549d3854f3dd" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"^ same question"</post>
   <post id="c8fcf2da-50dd-4bee-9c3b-de22f606f04d" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"really an intel or AMD IGP or APU will be fine. You may not be able to play back full bitstreaming of the non-existant 4k blu-ray audio in full fidelity, but that is nitpicking. I believe intel and AMD s soultions all bitstream multi-channel via HDMI today ( that use to be an issue) so as long as you are going with a modern chipset then you are good. but be warned there is not an Amazon Video app for windows so you will be using the browser or a hack app that may or may not have support or work long term. Also using a HTPC with a remote is basically a none starter unless you want to use windows 8.1 and a hobbled WMC I have a HTPC and the reasons to have one are dwindling. our FireTV is just as capable and the WAF is much higher with the same apps since they were designed arunnd a remote and 10  UI"</post>
   <post id="63f65cbe-5214-4715-a282-9971782f7c81" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"I currently have these parts with $600-$700 to go: SilverStone Milo Series ML07B Black Reinforced plastic outer shell, steel body Mini-ITX DTX Computer Case with PCI-E Riser - Newegg.com SILVERSTONE SX500-LG 500W SFX-L 80 PLUS GOLD Certified Full Modular Active PFC Power Supply - Newegg.com SAMSUNG 850 PRO 2.5" 1TB SATA III 3-D Vertical Internal Solid State Drive (SSD) MZ-7KE1T0BW - Newegg.com Again Thank you so much for the input i am pretty lost with this."</post>
   <post id="831dc487-93ae-45c4-b827-145db872ecd6" section="Home Theater PCs and Equipment" discussion="Help with new HTPC build">"Your best bet is an i3 skylake. I d get an Asrock or Asus H170 motheboard. They have all the bells you need for HTPC and none of the whistles (meaning you don t pay for things you aren t using). And they are good brands. You don t need a 500w power supply. If you are fully loading it with hard drives 500w is ok. If you are not go with a 350w and safe some money. Go with 8GB of RAM, which is overkill yes, but its cheap overkill. And for ripping. Use MakeMKV or download the Assassin HTPC setup that they have now which takes a lot of guesswork out and things and has MakeMKV/ripping integrated right into the Kodi interface. Great for beginners of HTPC. And I agree with Adidas and the remote. Buy a $15 Rii RF mini keyboard with touchpad as long as your system is less than 20 feet away from you. They are cool devices. Last about a year or two though only but for $15 shipped just buy another one."</post>
   <post id="72b14f0d-d260-4cdb-8a23-30d914f03023" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"I have had a heck of a time trying to get this to work. Here is my scenario: - Vizio M70-C3 TV (one HDMI port supports 4K @ 60hz while the rest support 4K @ 30hz. - HDMI Cable is rated HDMI 2.0 for HDCP 2.2 and 4K @ 60hz compatibility. - HTPC System: Fatal1ty Z170 Gaming-ITX/ac (the ONLY motherboard with onboard HDMI in a MicroATX/ITX form factor that supports 4K @ 60 hz via the optional chipset to allow 4k @ 60 hz with onboard graphics) Core i3 6300 with Intel 530 graphics 16 GB DDR4 Corsair 2600 MHz Samsung 850 EVO SSD Ceton Labs InfiniTV PCIE 6 Cable Card Tuner Windows 7 x64 Behavior: - Using either the Intel utility or the built in Windows screen resolution panel, when switch to 4K resolutions, 30 Hz works perfectly fine. 60 Hz will black the screen out and will not display. Things I have tried already: - I have a Roku 4 and it can connect to the display just fine at 4K 60 hz so I m pretty sure it s not a display issue - Verified that I have plugged into the proper HDMI out on the motherboard (there are 2 and only 1 is for 4k60 hz) - Purchased brand new verified and 4k60hz capable HDMI cables - Googled it Anyone else have ideas?"</post>
   <post id="66f48219-f78c-4aa9-8337-54605170df81" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"Ok, I think I found out what the issue might be. On ASROCKs website, there is a PDF that talks about 60 hz at 2K or 4K needing an HDMI firmware update (my guess it s for the extra controller since that s what handles the high resolutions at 60hz). The problem is that I run the utility and it says "bobcat aux-isp tool firmware updating can t be started." I look at the logs and it doesn t say anything other than it detected the intel graphics adapter. Thoughts? Here s a link to their PDF document: http://asrock.pc.cdn.bitgravity.com/TSD/TheGuildofsupporting4kx2k@60Hz.pdf"</post>
   <post id="bce6b034-a2fd-4c56-8a6c-f51c0ec46703" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"So I was able to FINALLY get the stupid firmware installed but still no 4K at anything above 30Hz. This is so aggravating. Grr..."</post>
   <post id="73700fde-695c-4ec2-a5ea-664f55a36bd7" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"Well you could always go display port to hdmi 2.0 : Amazon.com: Club3D Displayport 1.2 to HDMI 2.0 UHD (CAC-1070): Computers &amp; Accessories"</post>
   <post id="d54e5ef6-848b-4d17-b545-ecb572001446" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"rhansen5_99 said: ↑ Well you could always go display port to hdmi 2.0 : Amazon.com: Club3D Displayport 1.2 to HDMI 2.0 UHD (CAC-1070): Computers &amp; Accessories Click to expand... x2 if you need a mini-DP to HDMI 2.0 adapter, and don t feel like waiting months for yours to arive, I have one for sale that I don t need. EDIT: can you get any other machine to produce a 60hz/4K signal on that TV?"</post>
   <post id="64193aa9-5608-4783-8353-6e6f0df6c626" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"i had a headache trying to get my vizio m49 to run 4k60hz. i ended up having to use a different cable cause that one was buggy, and played with nvidia control panel settings till it finally recognized chroma 4:2:0 that way i can do 4k60hz"</post>
   <post id="2715ec29-0beb-4738-80b9-896b4ba6c116" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"I haven t been able to get it work yet, no. As for another machine, I may just have to move my desktop down there to see if it s the TV or something with Intel or perhaps even just a stupid cable."</post>
   <post id="0c022726-c7ba-4727-8880-260cff492a5b" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"HDMI 1.4 can only do 4K@60 when you use 4:2:0 subsampling. I m not for sure how you would change that in the Intel drivers. You may be stuck with whatever Asrock provides since it s something unique to them and Intel graphics."</post>
   <post id="9cf57a8b-0db6-41bd-b6d3-d91df2de7ca7" section="Home Theater PCs and Equipment" discussion="Trouble getting 4k 60 Hz to work">"Ryokurin said: ↑ HDMI 1.4 can only do 4K@60 when you use 4:2:0 subsampling. I m not for sure how you would change that in the Intel drivers. You may be stuck with whatever Asrock provides since it s something unique to them and Intel graphics. Click to expand... The board has HDMI 2.0."</post>
   <post id="1c514968-d04c-45a6-882f-ae514921e56c" section="Home Theater PCs and Equipment" discussion="2ch audio only uses 2 speakers. Doesn t upmix to 5.1">"Currently choosing 5.1 output on the windows 10 sound forces every audio source, including stereo sources to output in a 5.1 wrapper, but with 3 dead channels. Because it s outputting 5.1 signal to my AV receiver I can t have it upmix it to dolby surround/atmos/pro logic 2 to make use of the dead channels. When I choose 2 Channels in Windows 10 sound menu it ll properly upmix 2ch videos to 5.1 using all speakers. But the problem then is that it down samples all audio including 5.1 audio to 2ch before sending it to my receiver. Which will then upmix it back but in a inferior way to the source. Anything I can do where for 2ch audio it ll send the audio in a 2ch wrapper rather than a 5.1 channel wrapper and automatically switch to 5.1 channel if the source file has it? I m using HDMI through my laptop. Using an onkyo nr838. Thanks"</post>
   <post id="1315fbde-5623-43a0-aa45-cf826830eb86" section="Home Theater PCs and Equipment" discussion="2ch audio only uses 2 speakers. Doesn t upmix to 5.1">"Are you talking about videos, or audio files, or what? Most programs with proper WASAPI support will do what you want. FWIW, MPC-HC isn t one of them. It has WASAPI support that strictly adheres to your Windows speaker settings. Like Foobar2k with the WASAPI plugin will send 2 channel audio as 2 channel audio over HDMI. 5.1 as 5.1, 7.1 as 7.1 etc regardless of how you ve set the Windows speaker config. It won t send empty channels unless there are empty channels in the audio file."</post>
   <post id="306726d7-bfac-43f2-9859-4d73ad169367" section="Home Theater PCs and Equipment" discussion="2ch audio only uses 2 speakers. Doesn t upmix to 5.1">"To get WASAPI support with MPC-HC, use ReClock."</post>
   <post id="d7b65db3-920d-4c14-bdff-e3702432a3e2" section="Home Theater PCs and Equipment" discussion="2ch audio only uses 2 speakers. Doesn t upmix to 5.1">"I use Shark007 s codecs with Windows Media Center with Windows  Sound Options set to either "Stereo" or "5.1" (running through Nvidia HDMI out) and WMC automatically handles switching, whether its Dolby Digital, DD-ES, DTS or even DTS-HD. Same can be said with your zone settings in Jriver Media Center, but that s a paid app which isn t very friendly to a couch viewer..."</post>
   <post id="67c6fb6a-7379-4731-a314-0f5640c0639c" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Neither amazon, nor newegg nor their site has these for sale or any information why they aren t available anywhere. My ceton Infinitv 4 PCIE has been screwing up a lot lately(disappearing, freezing etc) and I was considering getting the Ceton ETH 6 and surprise surprise can t buy it anymore. I am wondering whats going on."</post>
   <post id="f5a1efa6-d190-41ba-bdc4-25c1964e4bb9" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"They re still in business? My 4-tuner is in a box somewhere. Turned into a POS after a while too."</post>
   <post id="c2702645-5434-4bc5-b99f-1d5e9a767274" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"I didnt know they werent in business. Edit: Found their facebook page. Based on some of the posts it looks like they may be done. But nothing definitive. I posted a visitor message. Lets see. I was going to get a HDHR anyway, because its cheaper."</post>
   <post id="784fd7c3-9b0e-4f9b-9728-5c39e4a35576" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"I d say they ve been done for a while - they were being sued by Gibson over a year ago; not sure what came out of that."</post>
   <post id="4ddb7415-a25f-427b-aa14-f94c206ff640" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Woh, youre right. Back in 2014 Gibson sued Ceton for 12 million alleging Ceton is in breach of contract to develop some kind of wireless media device. From the brief reading I did, it seems to me like someone(ceton) figured out someone(gibson) was onto something good and tried to change the terms of the agreement."</post>
   <post id="6e796606-ceaa-49b3-98a7-89b485b7e3de" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Ceton discontinued the Echo, which is the basis of my home setup. At this point, I would stay away from them"</post>
   <post id="84f73ff9-1424-4b1f-a953-a947d5667d2e" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"The Lurker said: ↑ Neither amazon, nor newegg nor their site has these for sale or any information why they aren t available anywhere. My ceton Infinitv 4 PCIE has been screwing up a lot lately(disappearing, freezing etc) and I was considering getting the Ceton ETH 6 and surprise surprise can t buy it anymore. I am wondering whats going on. Click to expand... I know this thread is a few weeks old at this point... but don t buy a Ceton ETH under any circumstances. It is a piece of garbage (I still own one), it crashes every few days and will require all your HTPCs to reboot in order to remain paired with WMC. The HDHR Prime is MUCH more stable."</post>
   <post id="5238b37d-84d2-4d0a-bd25-3f728912a8d5" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"nite0 said: ↑ I know this thread is a few weeks old at this point... but don t buy a Ceton ETH under any circumstances. It is a piece of garbage (I still own one), it crashes every few days and will require all your HTPCs to reboot in order to remain paired with WMC. The HDHR Prime is MUCH more stable. Click to expand... Do you have the proper ports opened up in your routers firewall for it to do WMDRM validation? I had the same exactly problem you described with the internal card and it was remedied after the ports were opened.Except in my case it would need a reboot every 48 hours. Otherwise, wife and I decided to cut the cord entirely. Its been 2 weeks and we dont miss it at all. The few shows we do watch, we have other ways of obtaining."</post>
   <post id="dc982001-601d-4a59-b4d1-9883e2f60eeb" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Both my 4 channel and 6 channel cards ran like a champ when I had them. There weak point was the crappy mini connector to connect the coax to. But at this point the company is toast so its HDHomerun or nothing at this point."</post>
   <post id="31d78680-ea77-499c-89c4-0a32a723bf90" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Personally I would say don t bother ceton. I ve only had bad experiences with the Infinitv4, and it seems people have issues with the Infinitv6 as well. I ve been using two HDHomerun Primes and I ve been very satisfied. Sucks to have to use 2 cablecards but it was worth the extra $3 for less headaches."</post>
   <post id="f133e1d4-dcee-4e35-8f27-ee6b17911480" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"The Lurker said: ↑ Do you have the proper ports opened up in your routers firewall for it to do WMDRM validation? I had the same exactly problem you described with the internal card and it was remedied after the ports were opened.Except in my case it would need a reboot every 48 hours. Otherwise, wife and I decided to cut the cord entirely. Its been 2 weeks and we dont miss it at all. The few shows we do watch, we have other ways of obtaining. Click to expand... I m not a networking guru by any means but why would ports need to be opened to communicate over the local network?"</post>
   <post id="75228724-f8e4-44c0-b7a1-2931d86ab3fc" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Vengance_01 said: ↑ Both my 4 channel and 6 channel cards ran like a champ when I had them. There weak point was the crappy mini connector to connect the coax to. But at this point the company is toast so its HDHomerun or nothing at this point. Click to expand... My internal card was pretty solid so the issues do seem to be related to the ETH version. HDHR is the way to go though either way."</post>
   <post id="94fc693a-50ab-4d8d-8584-784cf3cb8d41" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"nite0 said: ↑ I m not a networking guru by any means but why would ports need to be opened to communicate over the local network? Click to expand... Not the local network. The tuner is trying to communicate outside of your network. If you dont have the following ports open, it will constantly screw up the pairing with media center. Name UDP/TCP Port Range In/Out RTP UDP 5001-5016 IN SSDP UDP 1900 IN/OUT RTSP TCP 554 OUT UPnP TCP 2869 IN/OUT WMDRM UDP 5757-5772 OUT You need these open in the windows firewall and your gateway firewall. Ceton drivers normally set this up if you have uPNP enabled."</post>
   <post id="b7cef47d-349b-4dd7-881c-16755d96e049" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"My understanding is that Ceton didn t go out of business, but they left the CableCard tuner industry (sold off the technology). No internet sources, sorry . So I wouldn t expect to see InfiniTV products in stock or have any type of viable support. Move over to Silicon Dust - less tuners per unit, but way better product for consumers in my experience."</post>
   <post id="89a01cc5-74d7-4a8b-ba66-4e711d3ac40c" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Doesn t matter anymore. We decided to cut the cord."</post>
   <post id="6a1c6e4f-e720-4521-9742-2c5692c97cbf" section="Home Theater PCs and Equipment" discussion="Anyone know why Ceton tuners are not available anywhere?">"Don t forget HD has an 2 tuner for OTA signals"</post>
   <post id="411e7f0a-6c76-4c11-a517-420b9cc6d00b" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"I have been using a home-made Windows 7 HPTC running Windows Media Center for a couple of years. I live in Comcastland (don t we all) and currently use a Hauppauage WinTV-HVR-2250 CableCard tuner to decrypt the digital signal from Comcast (I am not using OTA signals). My relationship with MCE is complicated. When it works, it s great, but I continue to have glitchy technical issues around (a) downloading updated media guides, (b) CableCard or tuner issues, and (c) random bugs inside MCE. It s obvious Microsoft has moved on, and we all know MCE isn t supported in Windows 10 and beyond. So, I m looking for the next step. For those who want to use their CableCards, it seems the only viable route is to go with SiliconDust. I know they re working on their own DVR app right now. Has anyone had any experience with it? Is it an adequate replacement for MCE? I don t mind springing for the tuner (plus I ll get a third tuner = less family conflict) but I m not so hot on paying $60 for the DVR beta access... Any idea on the upcoming release date?"</post>
   <post id="8ac1c451-5611-4251-b7a3-1c17a35ce718" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"Stick with WMC (for now at the very least). While their tuners are the best out there IMO - the DVR software is a letdown to say the least. You can see many complaints about just the general design/execution/features or lack thereof (like no grid epg, the fact if their server or your internet goes down you have no guide data and recordings will not record after a certain amount of time without a connection - whereas WMC all the guide data/recording schedule is cached - so everything continues to function if you net goes down) as well as persistent bugs (like the record engine randomly stopping thus not recording). Plus their communication/support is severely lacking and a major complaint too - the Channels app devs for Apple TV had to cease integration of the SD DVR with their product and have decided to develop their own because even they were getting the short end of the stick when it came to communication/support from SD (that was the main reason, lacking features was another reason given by them). I ended up having to do a chargeback to get my money back from the Kickstarter due to all the broken promises/details and features left omitted/lack of support/communication."</post>
   <post id="7abd08c9-e953-42b5-973c-4e00539540b8" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"staknhalo said: ↑ I ended up having to do a chargeback to get my money back from the Kickstarter due to all the broken promises/details and features left omitted/lack of support/communication. Click to expand... Wow, that s great to know! I won t be buying into the beta any time soon. I was noticing a distinct... lack of updates and communications from them. It s actually a bit underhanded in my opinion, to have a for-profit company asking for us to fund a Kickstarter when the capability is inherent to their own survival. They need a replacement to WMC or else their tuner revenue disappears - I won t be lining up to "invest" in their software development any time soon."</post>
   <post id="162d51cf-3f93-4551-ac49-3eea422aa27c" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"i have been using it daily without issues.... my wife and 3 year old use it also. we use it on Amazon FireTV and Window 10 So i have not felt the same as others who have posted here...... just wanted to add"</post>
   <post id="837f70b4-58a2-4b33-bb08-f8dc6e572be8" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"Get yourself onto Windows 8.1. All the issues you are experiencing will be a thing of the past. I had all the same problems as you, worked great for a long stretch then problems if you so much as looked in its direction. All of it due to a deprecated version of play ready that they stopped maintaining on Windows 7. ryanjg11 said: ↑ I have been using a home-made Windows 7 HPTC running Windows Media Center for a couple of years. I live in Comcastland (don t we all) and currently use a Hauppauage WinTV-HVR-2250 CableCard tuner to decrypt the digital signal from Comcast (I am not using OTA signals). Click to expand... Question for you. When you plug your coax directly into your TV. Do you get a video signal or does it notify you that the signal is encrypted? I ask because we cut the cord and the option is either OTA or FIOS with Local TV only, but plugging the coax into the TV doesn t yield any TV. They say I need to get a STB from them to watch TV. Wondering if the Happauge card gets around the STB requirement somehow. OTA is cheaper by far, but still, I am curious."</post>
   <post id="f68a2c8c-c198-4f89-9b68-6365042f6df3" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"The Lurker said: ↑ Question for you. When you plug your coax directly into your TV. Do you get a video signal or does it notify you that the signal is encrypted? I ask because we cut the cord and the option is either OTA or FIOS with Local TV only, but plugging the coax into the TV doesn t yield any TV. They say I need to get a STB from them to watch TV. Wondering if the Happauge card gets around the STB requirement somehow. OTA is cheaper by far, but still, I am curious. Click to expand... With FiOS (formerly Verizon and now Frontier in TX) my local channels are all in the clear from 465mhz to 531mhz. I can plug coax into anything with a QAM tuner (including TV s) and pick up these channels. I believe there is a local channel plan for ~$10/mo or so that gives you access to these so you don t have to use OTA."</post>
   <post id="0665a87b-0e58-47f4-8195-ba2b16ad9415" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"So to the original OP question - I spent a few hours upgrading my main HTPC to Windows 10 to test out the HDHR DVR application, and well.... I m going back to WMC on W7. I sincerely hope SD develops it into a more robust solution, but it s no where near WMC in functionality at the moment. No DD/AC3 bitstreaming, poor remote control implementation, clunky interface, channels sometimes take 15+ seconds to change, MPEG2 1080i channels play back poorly. Granted, it s not a finished product, but I couldn t imagine using it as a primary frontend at the moment."</post>
   <post id="97aae715-436c-436b-bacb-4f15645dd4ee" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"I ve ben using two HDHomeRun s on our home network for a few years now and I ve had no problems. I use them only on WMC though (Win 7 and Win 8.1) and it all works perfectly. I never really gave their DVR software a try. It didn t look couch-friendly enough for me to buy in comfortably knowing my non-techy wife would be using it as well."</post>
   <post id="04ef2e16-7156-45df-a71a-80555730293a" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"sKiDmArK said: ↑ So to the original OP question - I spent a few hours upgrading my main HTPC to Windows 10 to test out the HDHR DVR application, and well.... I m going back to WMC on W7. I sincerely hope SD develops it into a more robust solution, but it s no where near WMC in functionality at the moment. No DD/AC3 bitstreaming, poor remote control implementation, clunky interface, channels sometimes take 15+ seconds to change, MPEG2 1080i channels play back poorly. Granted, it s not a finished product, but I couldn t imagine using it as a primary frontend at the moment. Click to expand... Go to windows 8.1. I know you dont want to, but trust me on this. If you are using windows media center, you owe it to yourself to get on Windows 8.1 for the latest play ready alone."</post>
   <post id="c4a857d4-ac85-4f61-886d-e5940bbfac5b" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"My windows 8/8.1 keys don t have the media center option, and I ve heard the only way you can get one now is to beg on thegreenbutton since MS no longer sells them. This is also the first I ve heard about WMC being better on 8 - I ve always heard the experience is identical."</post>
   <post id="71b56a00-0d95-4448-9700-27e06e71618e" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"Right now to be honest its garbage. They are no where near where they said they would be at release for October 2015. Stick with WMC for now. If you tried to use it coming from WMC you would be very frustrated."</post>
   <post id="08e1bbdc-da9b-45ad-826d-d9f241849b32" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"sKiDmArK said: ↑ My windows 8/8.1 keys don t have the media center option, and I ve heard the only way you can get one now is to beg on thegreenbutton since MS no longer sells them. This is also the first I ve heard about WMC being better on 8 - I ve always heard the experience is identical. Click to expand... The interface on WMC on Win8 is identical. IIRC, almost everything about WMC was almost as if they copy-pasted the code from Win7 and put it in a separate installer package. The issue was other things installed on the backend like the PlayReady DRM and any other Win8 OS optimizations in play that affect the overall responsiveness of the software. Playready was a separate download for WMC and it forced you to get it before you used the TV app."</post>
   <post id="8a8616f8-d4f5-4671-8774-ffea2f5869ea" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"qbanb8582 said: ↑ Right now to be honest its garbage. They are no where near where they said they would be at release for October 2015. Stick with WMC for now. If you tried to use it coming from WMC you would be very frustrated. Click to expand... Must be just my usecase but I haven t had any real issues with it. We use it all the time with Plex very similar to how we used WMC and MediaBrowser in the past. Our house has it all working on a W10 AIO, HTPC, Windows 10 tablet, Amazon FireTV The DVR app works well enough at recording TV series, then comskip, and into Plex I love that I finally get a unified recording engine! My wife open the app on the tablet. Goes to discover, movies and sets recordings for the HTPC all the time! That was the holy grail for WMC that never happened."</post>
   <post id="79b6ea61-69a3-4617-b1e1-1aa3ce20f189" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"Adidas4275 said: ↑ Must be just my usecase but I haven t had any real issues with it. We use it all the time with Plex very similar to how we used WMC and MediaBrowser in the past. Our house has it all working on a W10 AIO, HTPC, Windows 10 tablet, Amazon FireTV The DVR app works well enough at recording TV series, then comskip, and into Plex I love that I finally get a unified recording engine! My wife open the app on the tablet. Goes to discover, movies and sets recordings for the HTPC all the time! That was the holy grail for WMC that never happened. Click to expand... That is amazing, but until they get copy-once drm working on some form of windows client I m not giving them a dime. After all, it was one of the original kickstarter goals. I m one of the unfortunate TWC customer s that has everything flagged as copy-once."</post>
   <post id="5baf822c-cdf4-4d52-963d-0840b8df1e78" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"That s a bummer. Yeah I have HBO and such but just use the apps Everything else on my comcast is not flagged. Guess I am lucky​"</post>
   <post id="3e5231bc-ca6d-41e7-8cb6-09357f6baa69" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"sKiDmArK said: ↑ My windows 8/8.1 keys don t have the media center option, and I ve heard the only way you can get one now is to beg on thegreenbutton since MS no longer sells them. This is also the first I ve heard about WMC being better on 8 - I ve always heard the experience is identical. Click to expand... The only legal way, maybe. As far as the experience goes, it is identical. But as Captnumbnutz said the back end components are new. Specifically, the play ready version. Windows 7 stopped at 2.1, Windows 8 gets 3+ which is a lot more reliable."</post>
   <post id="4d80701d-8bd7-41f7-9987-f1963293914e" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"The Lurker said: ↑ The only legal way, maybe. As far as the experience goes, it is identical. But as Captnumbnutz said the back end components are new. Specifically, the play ready version. Windows 7 stopped at 2.1, Windows 8 gets 3+ which is a lot more reliable. Click to expand... Can you elaborate on a lot more reliable? Is there any tangible evidence of this or more detailed discussions on the web? W7 WMC has been pretty stable for me over the past 4 years. Most of the quirks I ve had with it, are on DRM channels using Intel GPUs and the 29/59 bug. My Skylake NUC is not playing nice, and if there is a chance the newer playready may help, I might be willing to go through the hassle of getting it."</post>
   <post id="d0b4c6f1-79dd-42db-89aa-d856944cfab3" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"sKiDmArK said: ↑ Can you elaborate on a lot more reliable? Is there any tangible evidence of this or more detailed discussions on the web? W7 WMC has been pretty stable for me over the past 4 years. Most of the quirks I ve had with it, are on DRM channels using Intel GPUs and the 29/59 bug. My Skylake NUC is not playing nice, and if there is a chance the newer playready may help, I might be willing to go through the hassle of getting it. Click to expand... The first thing I noticed that improved was the initial setup. On Win7 I always had issues getting through the play ready setup. On Win8, no such issue. Worked the first time, flawlessly. The second issue I had was, sometimes I would get a message saying something like "this device does not support playback of protected content". I would then have to Alt+Enter to minimize and maximize the window several times for it to handshake. Win8, never had a single issue like this. I also think it tunes the protected channels faster than Win7, but that could just be because Win8 is faster overall then Win7. In summation, the entire thing just felt like it had less quirks."</post>
   <post id="f62854f5-2ed1-4ce1-9e98-75bf9d67c2ce" section="Home Theater PCs and Equipment" discussion="SiliconDust DVR app experiences?">"Thanks for the info. I ve luckily haven t had issues with any of those in a while, so I think I ll stick with 7 for now. Channel changing greatly sped up since I moved over to SD hardware - it used to lag on everything with my Ceton card."</post>
   <post id="d128aa0b-efb0-49db-9f76-392e181fb397" section="Home Theater PCs and Equipment" discussion="4K Playback Issues - Intel NUC5I5RYK">"-------EDIT/UPDATE-------- I conferred with a bit of an expert on this sort of thing and the issue with my file is this: Format profile : High 10@L5.2 There is no hardware decoding for 10b H.264 (Hi10P profile) currently, only software. A CPU of the NUC or any U series simply can t cut it. You need a desktop class i7 etc. to decode this in software without hardware decoding. So, there is nothing to be done about this issue for now, hope this is helpful to someone else in the future. ------EDIT/UPDATE----- Basically, when I attempt to playback 4K media Intel NUC5I5RYK it stutters like crazy, it s completely unwatchable with the CPU pegged at 100%. I have played with codec settings, used MPC-HC and VLC, updated LAV filters (modified LAV filter settings) all to no avail; it continues to drop frames all over the place, pixelate and stutter with audio/video out of sync. Here are the relevant details of my system: Intel NUC5I5RYK Core i5-5250U 1.60Ghz 8GB RAM Intel 6000 Series GPU Driver Version: 20.19.15.4352 (Driver Date 12/15/15) LAV filter version .67 Information about the 4K file I am trying to playback from mediainfo: Video ID : 1 Format : AVC Format/Info : Advanced Video Codec Format profile : High 10@L5.2 Format settings, CABAC : Yes Format settings, ReFrames : 5 frames Codec ID : V_MPEG4/ISO/AVC Duration : 29mn 45s Bit rate : 36.0 Mbps Width : 3 840 pixels Height : 2 160 pixels Display aspect ratio : 16:9 Frame rate mode : Constant Frame rate : 24.000 fps Color space : YUV Chroma subsampling : 4:2:0 Bit depth : 10 bits Scan type : Progressive Bits/(Pixel*Frame) : 0.181 Stream size : 7.49 GiB (98%) Writing library : x264 core 146 r2538 121396c Encoding settings : cabac=1 / ref=5 / deblock=1:-2:-2 / analyse=0x3:0x133 / me=umh / subme=10 / psy=1 / psy_rd=1.00:0.15 / mixed_ref=1 / me_range=48 / chroma_me=1 / trellis=2 / 8x8dct=1 / cqm=0 / deadzone=21,11 / fast_pskip=1 / chroma_qp_offset=-3 / threads=12 / lookahead_threads=2 / sliced_threads=0 / nr=0 / decimate=0 / interlaced=0 / bluray_compat=0 / constrained_intra=0 / bframes=8 / b_pyramid=2 / b_adapt=2 / b_bias=0 / direct=3 / weightb=1 / open_gop=0 / weightp=2 / keyint=240 / keyint_min=24 / scenecut=40 / intra_refresh=0 / rc_lookahead=60 / rc=crf / mbtree=1 / crf=18.0 / qcomp=0.70 / qpmin=0 / qpmax=81 / qpstep=4 / vbv_maxrate=300000 / vbv_bufsize=300000 / crf_max=0.0 / nal_hrd=none / filler=0 / ip_ratio=1.30 / aq=1:0.90 Default : Yes Forced : No"</post>
   <post id="559803ea-ad2f-4e72-a624-2729f3485304" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Sling TV Launches Multi-Streams, New $20 Channel Bundle. 3 connections at once! Sling TV Launches Multi-Streams, New $20 Channel Bundle Sling TV link. https://www.sling.com/service Originally saw it on... The Pirate Bay Twitter. Yes, their Twitter account is pretty informative. The Pirate Bay on Twitter So why do you still have a Cable TV account again? Hmm?"</post>
   <post id="09141b9c-4a10-4364-9f60-bd94ab3d8e48" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Because my ISP is my cable company and they make it so that it s not really cheaper to cut the cord. Am I supposed to just cut the cord on principle when it doesn t save me any money? Still, interesting service. If I ever get an ISP that won t pressure me to bundle, I ll look into it."</post>
   <post id="93fd6774-8ea6-45d2-abe3-29ecef92817d" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"That s awesome that your Cable TV is that cheap. Around here it s really expensive with all the fees for DVR rentals and crap. Basic stuff + 300mbps internet starts off at $129 before you get into adding in Premium channels."</post>
   <post id="ae89e074-ce13-4caf-9f21-77aab204907e" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"We use sling TV, free OTA TV, plex, and amazon prime content. All this runs on amazon fire TV stick. 20$ plus internet makes for a good mix of content. TWC is pretty cheap but its still at least 30 to 40 more. Plus part of me likes not having cable. Forces me to seek out other items like reading or listening to npr"</post>
   <post id="9df40e9b-7b51-47be-810f-30a385b69ac4" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"cageymaru said: ↑ So why do you still have a Cable TV account again? Hmm? Click to expand... 1. It s $15 more expensive to have triple play rather than internet alone. 2. The PC player sucked balls when I tried it upon Sling s original release."</post>
   <post id="d3d45344-7daf-4bcb-aeb1-2dccae00eb72" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"HeavensCloud said: ↑ 1. It s $15 more expensive to have triple play rather than internet alone. 2. The PC player sucked balls when I tried it upon Sling s original release. Click to expand... Wish they had that around here. I would have Cable if it was only $15 on top of my internet. The Sling PC player sucked for me also, but then they fixed it. I haven t used it lately though. They have a 7 day trial so if you re Cable wasn t so cheap it would be worthwhile to give it a try again. What I liked about it was the ability to record my shows using other programs. That was pretty awesome. Hopefully that still works."</post>
   <post id="b42974da-3ef1-4232-91ea-764e51e714d4" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Comcast (and probably other cable companies as well) sure like to make it difficult to buy a stand alone internet service. I had a 1 year internet-only plan with Comcast, when it expired prices went way up. As I inquired about options, it became abundantly clear that they wanted me to have internet + at least some cable channels. It cost substantially less than internet alone, which makes no sense but hey, I ll take it! This Sling thing looks interesting but I expect it needs to evolve a bit more before it gets good. They are all trying to feel out the market at this point."</post>
   <post id="42a154df-edae-459f-a3b1-eea6c127556d" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"My TWC 300/20 internet alone costs $130 a month normally. On their website they have a $65 a month promotion for new subscribers. I just make them price match that yearly by saying that I m leaving. I tried Sling s 3 stream package during a 7 day trial. It seems that only certain channels are able to be multistreamed and others aren t. So if you pop open ESPN, which isn t a multistream channel, and Fox, which is a multistream channel; you will kick the other device off for having too many devices. I canceled it so fast. Faster than lightning. Not going to play musical chairs with my mom s TV."</post>
   <post id="c0f9dc3c-d48f-4095-afab-156302d4d061" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"My 50/5 connection costs 55$ a month. Add sling TV is not a bad deal. I have an ota signal for live broadcast stuff. The combo is plenty for me"</post>
   <post id="dc4b2c53-f65f-4648-9478-cf0d814e5127" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Sling is a good idea but the implementation is horrible. The UI (bleh), the limited number of streams, I cancelled after I found out about Sony Playstation Vue. The cheapest package is 29.99 I think. The only downside is 1) You have to have a PS3 or 4 and 2) it s geo-limited to your house unless you have IOS / apple gear (licensing reasons? IDK) - but I m an android user so ... I don t need a DVR (none of us do) if every program we subscribed to had true on demand viewing. Why would I ever need to record anything, if I can just call it up and watch it when I was in the mood to see it? I think that would be my dream setup."</post>
   <post id="1dac7631-a062-4635-9362-6d56b7322e12" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"live sports Baseball specifically...... and cable companies know it"</post>
   <post id="a5bdffc4-1c3a-4fe4-ba75-4a92e079067b" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"cageymaru said: ↑ Sling TV Launches Multi-Streams, New $20 Channel Bundle. 3 connections at once! Sling TV Launches Multi-Streams, New $20 Channel Bundle Sling TV link. https://www.sling.com/service Originally saw it on... The Pirate Bay Twitter. Yes, their Twitter account is pretty informative. The Pirate Bay on Twitter So why do you still have a Cable TV account again? Hmm? Click to expand... For soccer. But with PlayStation Vue is surprising.y cheap."</post>
   <post id="10b85f85-5406-4b6c-9225-f94aef488f16" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"I wish Vue was cheaper in the LA area. 40$ for 60 channels. Its not bad, but I like sling as I use an Amazon Fire TV stick to access all my media content(plex, Amazon Prime, OTA HD Channels via side loaded app, and sling) Plus I am really trying to wean myself off of cable. Slings channel lineup is not bad at all. Just wish there app ran smoother on the Amazon Fire TV Stick. Its slow as ass!"</post>
   <post id="198d6a58-3fb3-4670-ba1b-ab8d35365876" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Vengance_01 said: ↑ I wish Vue was cheaper in the LA area. 40$ for 60 channels. Its not bad, but I like sling as I use an Amazon Fire TV stick to access all my media content(plex, Amazon Prime, OTA HD Channels via side loaded app, and sling) Plus I am really trying to wean myself off of cable. Slings channel lineup is not bad at all. Just wish there app ran smoother on the Amazon Fire TV Stick. Its slow as ass! Click to expand... The Vue app runs like ass on the stick as well."</post>
   <post id="9c2476ea-b081-4687-810f-0c3c99665df2" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"The apps run great on the regular Fire TV box. Worth the 99 bucks I paid for it, considering how many people are complaining about the Fire stick s performance."</post>
   <post id="a6867564-629e-4252-bf0f-e35098fe431d" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"cageymaru said: ↑ That s awesome that your Cable TV is that cheap. Around here it s really expensive with all the fees for DVR rentals and crap. Basic stuff + 300mbps internet starts off at $129 before you get into adding in Premium channels. Click to expand... Threaten to leave(if you have options) and see if you can get discounts. I was paying 103 w/taxes and cable card for Fios 50/50 and Extreme HD + showtime + HBO. Was going to increase to $110 when we move because of higher taxes. But we decided to cut the cord instead. 50/50 internet only is $57 all inclusive."</post>
   <post id="9295e204-4721-484f-bcc9-e77498ae11b4" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"I just hate having to do the whole "threaten to leave" dance every year. You call, or chat, and they refuse, and you try again, until you end up playing customer service rep roulette so many times.... you eventually make it happen but it s such a hassle."</post>
   <post id="8a4d5448-c98d-462c-a770-e72790c6a1dc" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"Good move on Sling to offer a package without ESPN"</post>
   <post id="0450bb71-f460-4f31-a70b-4e95e22e8f6c" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"project86 said: ↑ I just hate having to do the whole "threaten to leave" dance every year. You call, or chat, and they refuse, and you try again, until you end up playing customer service rep roulette so many times.... you eventually make it happen but it s such a hassle. Click to expand... When they refuse you have to cancel. Either then you do cancel and get transferred to the customer retention department where the magic happens or you cancel and re-sign using your dogs name to get the best current deal."</post>
   <post id="890f6523-cd88-49e4-9600-253023184af7" section="Home Theater PCs and Equipment" discussion="Sling TV Launches Multi-Streams, New $20 Channel Bundle 3 connections at once!">"The Lurker said: ↑ When they refuse you have to cancel. Either then you do cancel and get transferred to the customer retention department where the magic happens or you cancel and re-sign using your dogs name to get the best current deal. Click to expand... Sounds good in theory but I m always so busy, and also because I use my connection every day... I really want to avoid any interruption in service. So I hate to have them call my bluff and then have to deal with that. It sucks that ATT Uverse doesn t seem remotely competitive. Their promo rates are very similar to the standard rates for comcast!"</post>
   <post id="6f120a00-7674-42a3-b345-497ec9960440" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"well I was wondering when it would happen, AnyDVD no longer works... from the Slysoft website: Due to recent regulatory requirements we have had to cease all activities relating to SlySoft Inc. We wish to thank our loyal customers/clients for their patronage over the years."</post>
   <post id="53459a8e-4ed3-481f-9759-d69374971458" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"It still works on any title you previously decrypted or any title that s stored in the local database. The local database for Blu-ray is from October 2015 if I read the date correctly. So, titles newer titles that would phone home to get the key can t be decrypted, but everything else can."</post>
   <post id="f75d49eb-a369-4520-be2e-a25a5e0f279a" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Ugh horrible news"</post>
   <post id="c4dc6573-099d-4b3f-ba85-639ccc9c4b43" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Here s the front page thread."</post>
   <post id="456af68a-e84f-4000-8478-45e9ebb32c62" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Awesome. And DvdFab is fubared as well. Edit: so apparently you now need their Passkey software to unlock the disc first. Then use DvdFab."</post>
   <post id="fe0e531d-9273-49b4-b3dc-9e23b2973069" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"12 AnyDVD alternatives - now Slysoft is down and gone - Myce.com"</post>
   <post id="dd057818-4143-4198-b273-b122a6bfe3ed" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"sad to see them go.... loved their free utilities"</post>
   <post id="38490f34-4d88-4981-a91f-d3318ae40c88" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Just found out about this, definitely a sad day."</post>
   <post id="60055164-2671-4311-acc5-85aaa702ae13" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Slysoft is already back. They changed their name to RedFox, slapped a mask onto their old Fox logo, and moved the company registration to Belize. http://hardforum.com/threads/its-back-baby.1893024/"</post>
   <post id="b174d18e-99a1-4221-813d-5bd2adf6fa8c" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"lol, they are doing a Pirate Bay."</post>
   <post id="6805e9ba-7d9d-4b8c-923e-5a64637f2866" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"After slysoft down, dvdfab passkey is a good alternative."</post>
   <post id="64218b61-5034-48c0-9f74-922a77f27aae" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Redfox is their new name. Hilarious."</post>
   <post id="69a93e3a-358a-4653-9373-5cb944e78c06" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"RedFox it s a garbage company, I paid for a product of Slysoft for life time use, now I am asked to pay extra money just because Slysoft changes its name to Redfox, funny! it s fucking robbery, I will block it if I see any products from your company."</post>
   <post id="7f83539f-3a27-48f7-a44c-64265ff49408" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Supposedly the same keys that worked for the Slysoft version AnyDVD work for the new Redfox version. Is that not the case?"</post>
   <post id="31cdd3b9-2407-41dd-9841-61d9a4736b2d" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"zscheng365 said: ↑ RedFox it s a garbage company, I paid for a product of Slysoft for life time use, now I am asked to pay extra money just because Slysoft changes its name to Redfox, funny! it s fucking robbery, I will block it if I see any products from your company. Click to expand... Never trust "lifelime" licenses for anything. No company can make money if they don t have income. So either they die off or stop supporting the license. The concept is pretty much always a scam."</post>
   <post id="acd76bc1-9576-46a3-b799-d9a1d82be8a0" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Domingo said: ↑ Supposedly the same keys that worked for the Slysoft version AnyDVD work for the new Redfox version. Is that not the case? Click to expand... It depends what you mean by "work". As of the last I looked your Slysoft key (if still valid) will work with any future Redfox version, but will not decrypt and discs / protections that are cracked post Slysoft."</post>
   <post id="d1d4d466-f563-4579-9d38-1310770cdffb" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Stereodude said: ↑ It depends what you mean by "work". As of the last I looked your Slysoft key (if still valid) will work with any future Redfox version, but will not decrypt and discs / protections that are cracked post Slysoft. Click to expand... Hmmmm. Gotcha. So those keys simple allow the new version to work, but it won t download any new updates unless you have a new Redfox key. Right? I dunno, I haven t used this program in years, so was just curious."</post>
   <post id="6739ae72-4a22-4a87-a3f6-97585f9699a5" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Domingo said: ↑ Hmmmm. Gotcha. So those keys simple allow the new version to work, but it won t download any new updates unless you have a new Redfox key. Right? Click to expand... Something like that."</post>
   <post id="9bb0b613-2533-41c0-b959-0fa55e462fef" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Muy Old AnyDVDHD key is working just fine with the new RedFox updates. What exactly are you people talking about?"</post>
   <post id="ced232e6-411d-4a61-8077-cd37a1566b8b" section="Home Theater PCs and Equipment" discussion="Slysoft Shut down">"Ah, ok, Just read up on their forums. Slysoft went out of business and people are bitching they ll have to pay. lulz. Welcome to the real world bitches."</post>
   <post id="58315b38-cc47-43de-8186-1c24ef10f673" section="Home Theater PCs and Equipment" discussion="creative X-Fi Sonic Carrier vs Bose Cinemate (soundtouch) 130 for Speakers for PC">"I want better sounding audio than my current setup which is failing at 5.1 sound. I currently have a Bose Cinemate 130 with a Creative X7 LE Soundcard/DAC/Amp that sits under my Samsung 4k SUHD monitor. I recently found out that I was misled in buying the Creative X7 LE to process 5.1 sound to my soundbar(does not pass through 5.1 sound as it does not enode dolby digital). This leaves me with the unique position to sell my brand new setup at a slight loss(I already spent $2k) or spend $2,150 for the Xi-fi Carrier to replace it. Yes, I am aware how I spent stupid money and I was better off saving $500 and using my Asus X99 Rampage V motherboard audio to pass through sound. Right now its just a $500 kick ass amp for my AKG Annie headphones (it does sound badass). To be more clear, I can get 5.1 sound on Windows 7 with the bose Soundtouch 130 by running optical from the motherboard to the Bose dock(Acoustimass module). However, in windows 10 Ent LTSB there is no update on my Asus X99 Rampage V realtek windows driver to allow DTS sound. It just does not work with this nor the Creative X7. The X7 LE only works if the audio was already encoded in 5.1 (think of a movie or game as it cannot encode audio and pass it through). So what should I do? cross my fingers and hope the new Sonic Carrier can be my AIO solution I originally wanted? Or do I bite the bullet and just use this current setup with motherboard sound? I have always been a fan of creatives software suite and it kills me I have this $500 paperweight I cannot use. The Bose I do love for its ability to play spotify and other music apps without turning on my computer. But I would have been able to do that with bluetooth anyways. There truly is no reason for me to have an extra dock sitting on my computer. Question: I preordered the sonic carrier for $1750 already but..... Should upgrade? If it is an upgrade from my $2200 current setup (Bose Soundtouch 130 to to the new Creative X-Fi Sonic Carrier 55" 11.1 sound bar. I want 5.1 sound or greater in games and video and could use some guidance to help me out. links: Tech Hive Preview MaximumPC / Pc Gamer preview Sonic Carrier Spoiler: Sonic Carrier Hardware Specs * System Configuration Main Unit + Wireless Subwoofer Total Output Power 800W RMS Peak Power Output 2000W Weight Main Unit: 16 kg / 35 lbs Subwoofer: 25 kg / 55 lbs Dimensions (H × W × D) Main Unit: 90 × 1440 × 145 mm / 3.5 × 56.7 × 5.7 in Subwoofer: 583 x 530 x 300 mm / 23.0 x 20.9 x 11.8 in Connectivity Bluetooth 4.0 2x Line level 2x Mic analog input 1x USB host and 2x USB power 3x microSD card slots 1x SD card slot 4x HDMI 2.0a/HDCP 2.2 Inputs 1x HDMI 2.0a/HDCP 2.2 Output 2x Optical Digital In 802.11a/b/g/n/ac Wi-Fi Up to Gigabit Ethernet Drivers Main Unit 10x 2.75″ Aluminum Midbass 5x 0.75″ Titanium Super Tweeter Subwoofer 2x 10″ Drivers Bose Sound Touch Hardware Specs Spoiler: Hardware specs Specs Dimensions/weight Soundbar speaker:4.9" H x 36.8" W x 2.4" D (7.8 lbs) Acoustimass® module:11.3" H x 7.6" W x 14.8" D (13.8 lbs) Control console:2.5" H x 12.3" W x 8.2" D (3.28 lbs) Remote:8.8" H x 2.1" W x 1.2" D Additional details Power supply: Dual voltage 100-240 Wireless range of Acoustimass module: Up to 30 ft Supported audio formats: MP3, WMA, AAC, FLAC, Apple lossless Shipping weight: 44 lbs (20 kg) Inputs/outputs Console rear panel 4 HDMI inputs Coaxial audio input (digital) Optical audio input (digital) R-L audio input (analog) 1 HDMI output (to TV) Console side panel 3.5 mm connection (for headphones/analog audio) In the box SoundTouch® 130 soundbar speaker Wireless Acoustimass module Control console SoundTouch® wireless adapter II Universal remote control HDMI cable Speaker cable Power cords USB cable (for updates) ADAPTiQ headset Please feel free to ask any questions since I am hoping my question is clear enough without this running on. Thanks!"</post>
   <post id="bd80470e-7504-4f38-96a5-c667bd865905" section="Home Theater PCs and Equipment" discussion="creative X-Fi Sonic Carrier vs Bose Cinemate (soundtouch) 130 for Speakers for PC">"Why don t you just get a real home theater receiver and surround speaker setup? You can get a crazy good of system for $2000 and have real discrete speakers instead of a sound bad trying to be fancy. And of those two options, I d get the Sonic Carrier, that thing looks amazing for a sound bar"</post>
   <post id="637a9d41-5c4d-4f86-b58f-cfe1857f678e" section="Home Theater PCs and Equipment" discussion="creative X-Fi Sonic Carrier vs Bose Cinemate (soundtouch) 130 for Speakers for PC">"Thanks! I would die discrete speakers but the problem is the room. I have the 55" Sammy on a rotating mount (omnimount play70) So it s moving any direction I choose which changes where the sound is. This is why the soundbar works so well."</post>
   <post id="af25cb48-b822-495b-b831-8f571459dae7" section="Home Theater PCs and Equipment" discussion="creative X-Fi Sonic Carrier vs Bose Cinemate (soundtouch) 130 for Speakers for PC">"Are you really going to have a lot of flexibility rotating a heavy 55 inch sound bar? Or is the sound bar on the mount?"</post>
   <post id="c986014f-af99-4be1-93cc-4a49d39fb8cb" section="Home Theater PCs and Equipment" discussion="creative X-Fi Sonic Carrier vs Bose Cinemate (soundtouch) 130 for Speakers for PC">"For sure! Right now I have a 55" TV and below it is connected my Bose Soundtouch 130 which are both connected to my omnimount Play70. It s great since it moves 360 degrees 10"up - 10"down. Cost a pretty penny but was worth it since I use this setup to work from a computer chair with the sculpt keyboard in my lap and I have a mouse pad attached to the chair for the razer Naga epix(wireless). Is really great, since then I can sit back on the other side of the room, move the TV to watch movies and chillax. In summary Yes, I will be moving it. I already do everyday"</post>
   <post id="542caf8c-9a87-454a-a615-ed5681dc0d5f" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"So I want to build a steaming box (Netflix, Hulu, Sling, etc etc) and connect it to my Vizio M65. This machine won t be used for gaming at all but before I continue to buy other parts I would use some processors I had laying around. Would either of those be able to handle 4K content not including the GPU I would buy? I know those processors have their age but curious. Thank you"</post>
   <post id="379ab10c-c8ce-4171-887d-d8792700621b" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"either CPU will be fine, but the i7 is a power HOG! I would use the i3 550"</post>
   <post id="ab2d8f7a-143e-4296-8899-fae32845d2cb" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"both will be fine but I recommend getting a GTX 950 or another video card that supports HDMI 2.0."</post>
   <post id="b4ff52aa-f405-44fd-87ff-18a302baf3aa" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Trimlock said: ↑ both will be fine but I recommend getting a GTX 950 or another video card that supports HDMI 2.0. Click to expand... The full h.265/hevc decode support in the 950 will also be a nice extra."</post>
   <post id="268884af-365a-41d9-bbb2-f142dfd0b72a" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Sweet you guys answered my question as to which gpu should i am for I will stick to the i3 and go with a 950. Now to see what to do with the old i7-860."</post>
   <post id="fb701860-5077-4fb5-955a-1abb3ad1cdb7" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Adidas4275 said: ↑ either CPU will be fine, but the i7 is a power HOG! I would use the i3 550 Click to expand... I disagree. Nehalem is the first architecture Intel made with per-core shutdown. This means they can shut-down idle cores, just like all newer processors. So I d be willing to bet the idle power for both systems is the same. You ll only use more power than the i3 if you stress the i7 hard enough The LGA1366 chips got a reputation for being power hogs because those extra 24 lanes of PCIe added tons of vampire power to the platform. Also, you might be able to save yourself some money on the GTX 950 if you have a H55 motherboard in that pile of detritus. Because if you do, The HD Graphics on the Core i3 can decode h.264 video."</post>
   <post id="09ee83ba-f82a-4565-92c6-60f1a15cbea2" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"IMO its all overkill. Get an nvidia shield or other 4k streaming device"</post>
   <post id="1d2b79f2-fcc5-4927-9863-75d9bbfc4fa8" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Vengance_01 said: ↑ IMO its all overkill. Get an nvidia shield or other 4k streaming device Click to expand... The OP does have a 4K TV so the recommendations on HDMI 2.0 on a GPU is valid."</post>
   <post id="25eedf93-acbc-44e9-9a64-6fb658eb7da2" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Vengance_01 said: ↑ IMO its all overkill. Get an nvidia shield or other 4k streaming device Click to expand... you may like moving to a streaming box, but there are still good reasons to use an actual computer..... gaming comes to mind...."</post>
   <post id="9cdf2039-a7b3-4424-af4e-06f102105a7e" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"KingRaptor said: ↑ The OP does have a 4K TV so the recommendations on HDMI 2.0 on a GPU is valid. Click to expand... Why? Netflix Hulu Amazon won t stream 4K to a computer. Overkill, yup!"</post>
   <post id="f4f93632-cc04-46f4-b2a1-caf1dca5199f" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Adidas4275 said: ↑ you may like moving to a streaming box, but there are still good reasons to use an actual computer..... gaming comes to mind.... Click to expand... Your right for sure. For purely a streaming of video content It would overkill IMO."</post>
   <post id="5d996728-d762-4acb-b78c-909af4c1ea6b" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Vengance_01 said: ↑ Your right for sure. For purely a streaming of video content It would overkill IMO. Click to expand... That is true, its even quite a bit more convenient to forgo a PC in favor of a streaming device if that is all you are into."</post>
   <post id="c360c757-3090-4585-9798-f5589a6b9c1c" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"I am pretty sure the Vizio s smart apps would work out too, say for Netflix and Hulu , Plex and Amazon Prime. The only down side is the stupid Yahoo app store, so no mlb tv, and prob not for sling. As far as a gpu, the 950 is great for 4k60, but again are you doing anything that needs 60fps? Maybe good for some light gaming, or if you are doing desktop work on there, but most video stuff is 24 or maybe 30 fps."</post>
   <post id="90e67435-e1be-4470-92fb-6ea5dceaec39" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"rhansen5_99 said: ↑ I am pretty sure the Vizio s smart apps would work out too, say for Netflix and Hulu , Plex and Amazon Prime. The only down side is the stupid Yahoo app store, so no mlb tv, and prob not for sling. As far as a gpu, the 950 is great for 4k60, but again are you doing anything that needs 60fps? Maybe good for some light gaming, or if you are doing desktop work on there, but most video stuff is 24 or maybe 30 fps. Click to expand... On Vizio s new 2016 TVs they are ending the yahoo deal and moving to using chromecast thats integrated. So anything that can be casted should work on the TV"</post>
   <post id="ddc3b043-38b7-4594-b1a6-3c213692546a" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"I thought the M65 was a 2015 model : http://www.amazon.com/VIZIO-M65-C1-65-Inch-Ultra-Smart/dp/B00T63YUDK"</post>
   <post id="a7e00aec-e68e-4a2c-bbba-bc93a3a4dc56" section="Home Theater PCs and Equipment" discussion="Can I use an Intel i7-860 or I3-550 for 4K HTPC">"Updated: Vizio M series TV includes free tablet remote and Dolby Vision HDR, starts at $850 They now have D0."</post>
<post id="90beba37-004d-40f4-9a22-69d17dafc9cb" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Core i7-5960X 5930K 5820K Overclocking &amp; Performance - We headed out to Microcenter and purchased two new Haswell-E processors, the Intel Core i7-5930K and Core i7-5820K CPUs. We have spent some time overclocking those and figuring out where the headroom is. Today we discuss overclocking these and what to expect with rock solid stability in mind."</post>
   <post id="35b9b2c2-cbcc-403c-94e0-3c481cf60120" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Looks like the 5820k is the sweet spot. The PCI-E lanes shouldn t be an issue for a 2 card SLI setup and you still have 4 lanes left over for a M.2 SSD (4xPCIe) unless I am mistaken..."</post>
   <post id="0dbe0fa5-55f6-4cab-a95a-214d1f65b90a" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"You are right, I made a fully incorrect statement. Will fix that. Thanks for the extra eyes. - Kyle Edit 2: OK, got into the numbers on this and I fat fingered the keys. I have made an update and left my analysis out on that benchmark, so you can draw your own conclusion. - Kyle Cheers!"</post>
   <post id="69308ccd-8935-4b32-947e-1014073015b0" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Just wanted to say, I grabbed my i7-5930K for $499.99 at Micro Center a couple weeks ago. Good deal, if you happen to live near a Micro Center. http://www.microcenter.com/product/437204/Core_i7-5930K_35_GHz_LGA_2011-V3_Processor"</post>
   <post id="6537f77c-c9f7-4adc-800f-56c0ee8d1d3f" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Talking about the 5820K being the sweet spot, gets even sweeter at $299.99. http://www.microcenter.com/product/437203/Core_i7-5820k_33_GHz_LGA_2011_V3_Tray_Processor"</post>
   <post id="489f30d3-c73a-44c6-bece-371077fa7576" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"DrezKill said: ↑ Talking about the 5820K being the sweet spot, gets even sweeter at $299.99. http://www.microcenter.com/product/437203/Core_i7-5820k_33_GHz_LGA_2011_V3_Tray_Processor Click to expand... First time I saw that I checked to see if Microcenter was in Canada anywhere, no luck of course. That easily makes up the price of DDR4....for the most part anway."</post>
   <post id="9eac1df9-c106-4eb8-afe5-cbed5744d834" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"I bought mine at Microcenter."</post>
   <post id="689cbdf4-14b9-44af-aa21-aacdcb3c7c29" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Typo fixed. Thanks for the extra eyes. - Kyle"</post>
   <post id="6ac49a27-3b9a-4250-bb89-c886e99cc24e" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Thanks for the review and highlighting the early days of this completely new platform, hopefully memory speeds will come up and its not due to a weak IMC in Haswell-E. I do have a question about the bandwidth though, my setup below pulls 50.5 GB/s in Sandra. Is it lower on HW-E because of the increased latency and not very speedy 2666 DDR4?"</post>
   <post id="18ae5cd3-8fb3-4a2d-baee-147981832fc0" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"psyclist said: ↑ Thanks for the review and highlighting the early days of this completely new platform, hopefully memory speeds will come up and its not due to a weak IMC in Haswell-E. I do have a question about the bandwidth though, my setup below pulls 50.5 GB/s in Sandra. Is it lower on HW-E because of the increased latency and not very speedy 2666 DDR4? Click to expand... Latency on DDR4 is going to be the biggest hiccup for the technology at lower clock speeds. Of course then scaling the clock speeds on DD4 is going to bring with it a huge upside. That said, I did NOT tune these DIMMs at all, using stock timings. I would suggest that all the memory companies are going to be heavily culling modules for the fastest ones and I would not expect to find a lot of highly overclockable sticks in reference to the speeds noted on the package you purchase. As mentioned in the review, the ODMs are expecting speeds above 3000MHz are so to be very sensitive to the IMC quality on a per CPU basis. I had no issues with 2666MHz or 2800MHz speeds on all three of these CPUs, and two of those were retail purchased."</post>
   <post id="30fed991-d291-45c5-a874-d2b12aca1b00" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Fair enough then, im just trying to figure out the benefits of the jump to X99. Great to see decent speeds out of all three of your chips though! as that was one of Haswell s issues, inconsistency of OC s."</post>
   <post id="41eb1816-4823-4a99-954b-800e6c62ae2d" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"One of the things I noticed when P95-ing my 5960X is that it would hover around 60C for the first round of the Blend test and then the second round would come and it would spike to 100C. I ve just raised the TJmax up to 105C to deal with this condition."</post>
   <post id="c9324a7b-4b50-4c0a-bbb7-6226aa62e128" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"I m currently running a 3930k, so even just sticking with the same number of cores means buying a 5930K, motherboard and ddr-4. If I stick with the current 64GB of RAM, the new setup would cost me about $2k. Considering I could just drop a new E5-2687W v2 (8 cores, 3.4Ghz, 25MB cache) for just about the same price, makes the new platform slightly less enticing. Obviously it will be worth looking at again when DDR4 comes down in price, but not just yet."</post>
   <post id="67f44c02-0857-41ee-8615-362c715b607f" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"DrezKill said: ↑ Talking about the 5820K being the sweet spot, gets even sweeter at $299.99. http://www.microcenter.com/product/437203/Core_i7-5820k_33_GHz_LGA_2011_V3_Tray_Processor Click to expand... $90 off Newegg s price is sweet. Too bad there isn t one even remotely close to my location."</post>
   <post id="d4116ca9-7e82-42f3-ba44-5d2b0b7d0c2a" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"S.T.A.L.K.E.R. said: ↑ Looks like the 5820k is the sweet spot. The PCI-E lanes shouldn t be an issue for a 2 card SLI setup and you still have 4 lanes left over for a M.2 SSD (4xPCIe) unless I am mistaken... Click to expand... With 28 lanes in the 5820k wouldn t that leave you with 4 lanes left for an M.2 even with tri SLI/fire? 8x/8x/8x and 4x for the M.2? If that s the case then it is really tough to justify the 5930k unless you re going for a 4 way GPU setup. With 3 cards it would be identical at 8x/8x/8x yeah? I suppose with 2 way on the 5930k you would have he benefit of 16x/16x however slight that may be. Oh, and Kyle you mention in the conclusion that the 5930k has more cache than the 5820k. I believe that is a typo."</post>
   <post id="335337f9-9dcb-40d6-8043-8e7278037320" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Kyle - Were you able to keep the 1.0 BCLK multiplier on the Gigabyte X99-UD4 when running the 2666MHz memory speed? I m currently using a Gigabyte X99-Gaming G1 on BIOS F8c and using XMP settings or manually raising the memory frequency past 2133MHz will automatically set the BCLK multiplier to 1.25."</post>
   <post id="fd9722b6-3c7f-4494-9323-53fe1e22a681" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"How thermally limited or sensitive to voltage are the new Haswell-E cpus? Many of your Sandy-E reviews were in the 1.35 - ~1.4v and even your initial Ivy-E started at 1.35 and mentioned going to 1.4v to squeeze out an extra 100Mhz. Here though you seem to have stopped well short of even 1.35v, instead keeping it to a mere 1.32v."</post>
   <post id="f06ef80c-06b9-496f-8e86-83b431e5fe62" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Kyle_Bennett said: ↑ Latency on DDR4 is going to be the biggest hiccup for the technology at lower clock speeds. Of course then scaling the clock speeds on DD4 is going to bring with it a huge upside. Click to expand... Do you know where hiccup ends and the upside begins as of yet?"</post>
   <post id="f6c509e3-3999-4619-abde-5aad7c503b87" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Regarding the use of cores in games, I was wondering how others out there see the possibility in better subthreading in the next couple of years in titles as developers begin to stress out the lower clock speeds of the new consoles and being forced into smarter subthreading since the PS4 and XBO both have 8 cores."</post>
   <post id="f922ca4c-5896-4f95-b8fd-11d937cc343b" section="Intel Processors" discussion="Core i7-5960X 5930K 5820K Overclocking &amp; Performance @ [H]">"Soooo... all I want to know is where should my $ go? I am running a 2700k which seems fast (4.4g totally stable for years) and a 670 video card. (Dell 27" 2560x1440) Should I worry more for video or CPU, or, frankly, as everything I run now is running very well, should I bother with anything and keep waiting? In a way, this PC has been [H]ard so long in the $ savings area and stability, should I even think about upgrading yet? Are these CPUs and newer advancements enough finally to consider making the jump?"</post>
   <post id="d9fcea36-d204-4a89-be48-3e808945d463" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Intel Skylake Core i7-6700K IPC &amp; Overclocking Review - Today we finally get to share with you our Intel Skylake experiences. As we like to, we are going to focus on Instructions Per Clock / IPC and overclocking this new CPU architecture. We hope to give our readers a definitive answer to whether or not it is time to make the jump to a new desktop PC platform."</post>
   <post id="0de79f11-1502-4a4a-8a78-f5105e94422f" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"well, time to finally retire my old lynnfield system. thanks for the excellent review, as always!"</post>
   <post id="a4fd5abe-8da4-49e3-8f09-1c9dc3e5bae0" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Was hoping to see some x99 based comparisons but excellent review. Looks like a bigger jump than normal."</post>
   <post id="8ce61efa-d5c3-4097-b1b2-8dd33ce73beb" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"I still think I m good enough with my 4.5GHz 2600K, this doesn t really seem tempting for the money needed to upgrade."</post>
   <post id="ec3c22d6-8ade-43c3-92a2-5dc0aa7404a7" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"cant do 5ghz, epic fail again"</post>
   <post id="a3446acd-943c-42b3-83f2-89bd03307cc7" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"About what I expected. Was hoping to see a bit more in terms of IPC, but it delivers in the range that has been typical. Load temps are impressive."</post>
   <post id="0567ca3d-6307-4ffb-82b1-2e151241eca7" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Flopper said: ↑ cant do 5ghz, epic fail again Click to expand... Realistically neither could Sandy Bridge. Most chips were clocking around 4.6-4.8GHz on air or water. While we certainly saw chips that were indeed that capable I ll wager most didn t get pushed that far and are 24/7 stable. 28-40% IPC improvement at nearly the same clocks as Sandy Bridge is nothing to scoff at. Whether or not that s worth the cost of upgrading is entirely up to you but that hardly constitutes an epic fail on Intel s part."</post>
   <post id="a0fe8e8f-91e2-404e-8c8e-bd0a25df33b0" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"so looking forward to reading this review"</post>
   <post id="5e7f2786-ab5e-4145-adc5-765ccfa7c76d" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"desktop process innovation has really slowed down over the past few years. ive been running a 4770k since a few days after launch (june 2013). 2 years later and this cpu at best 5-10% faster? that said there are some improvements on the chipset that would defiantly make this a good upgrade for x58/z68 users."</post>
   <post id="7f0e20a6-92d5-4ca7-a9d4-b9806cd7875a" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Good review, looks like a great platform for that new PCIe scaling article"</post>
   <post id="69c90aa4-8c8f-45b2-89b9-54aa379d3484" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Well, I am in the process of upgrading my AMD to a i7 2600...While I never really felt I would be missing anything vs Haswell, I do feel like I am missing out a little when compared to Skylake."</post>
   <post id="5028a564-61b2-41ec-a631-afcc5f26906b" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"I am wondering how skylake compares to older cpus, especially sandybridge, in real world gaming situations where users will run games at 1080P at least? Anandtech s benches suggest negligible improvements.... http://www.anandtech.com/show/9483/intel-skylake-review-6700k-6600k-ddr4-ddr3-ipc-6th-generation/16 which is hard to reconcile with their final conclusion that there is enough of an incentive for sandybridge owners to upgrade. Really? There is a 37% improvement in synthetic CPU benchmarks, but who cares in the real world if it makes no difference to current gaming performance. Thoughts?"</post>
   <post id="53d6a916-bfc8-4d5b-b71b-05d622c09634" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Dan_D said: ↑ Realistically neither could Sandy Bridge. Most chips were clocking around 4.6-4.8GHz on air or water. While we certainly saw chips that were indeed that capable I ll wager most didn t get pushed that far and are 24/7 stable. 28-40% IPC improvement at nearly the same clocks as Sandy Bridge is nothing to scoff at. Whether or not that s worth the cost of upgrading is entirely up to you but that hardly constitutes an epic fail on Intel s part. Click to expand... Not clocking any higher for 4 generations is a pretty big failure. So, Haswell-E then? Nah, I m just keeping my i5-2500K, let s see what AMD comes up with with their new core design. I expect it will either be excellent or atrocious, with no middle ground. Can t wait to see. But if I had to upgrade this second it would probably be Haswell-E."</post>
   <post id="be6d874d-dce7-491a-a0f7-4838eb5cf8bb" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"I took a gamble last week when my board died with my 2600k. I went to a local Microcenter and got the 4790k + board for a steal. Decent upgrade and offered a couple new platform features. I like the improvements here, but I don t see myself returning the cpu+mobo to get the latest and greatest. As always, nice review [H] crew."</post>
   <post id="d9a02b14-d919-44ef-b5c2-342e2a7a98d3" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Well, it may seem like a good review, but it s lacking 3rd party experience. Tell you what: you send me a skylake chip and mobo, and I ll let you know if I like it. As always, [H] does it best. Thanks! Ken"</post>
   <post id="f3e7dbd3-7999-45fb-adc0-e30fb2a13c44" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Blade-Runner said: ↑ I am wondering how skylake compares to older cpus, especially sandybridge, in real world gaming situations where users will run games at 1080P at least? Anandtech s benches suggest negligible improvements.... http://www.anandtech.com/show/9483/intel-skylake-review-6700k-6600k-ddr4-ddr3-ipc-6th-generation/16 which is hard to reconcile with their final conclusion that there is enough of an incentive for sandybridge owners to upgrade. Really? There is a 37% improvement in synthetic CPU benchmarks, but who cares in the real world if it makes no difference to current gaming performance. Thoughts? Click to expand... Most modern games are GPU bound (especially as resolution, refresh, and eye candy increases). With adequate PCIe bandwidth and GPU horsepower, the CPU isn t going to be as critical in the outcome. However, DX12 and Vulkan may very well be a bit more sensitive to higher IPC processors in regards to a real-world difference with gaming results. Going to depend a lot on how devs code their games for DX12 and how efficient their code can exploit the advantages of these new LLAPIs."</post>
   <post id="ef24dd26-8632-4444-b057-dc6131936ead" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Great review! [H] rocks! This worries me, however: I have been able to confirm from multiple sources (or I would not be telling you this) that Intel will not have its projected amount of Skylake processor inventory in the retail sales channel on launch day. I could not get any information when more Skylake inventory would be coming."</post>
   <post id="fcbf6bdc-6196-469c-8f43-549460f5fd97" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Not sure it s enough to justify upgrading from my i7-2600K either. I think I ll spend the money on new pipes for one of the bikes instead. Will see what things look like next year with DX12 and such."</post>
   <post id="4c762f3f-d654-4970-8081-280ee20ce65a" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"DejaWiz said: ↑ Most modern games are GPU bound (especially as resolution, refresh, and eye candy increases). With adequate PCIe bandwidth and GPU horsepower, the CPU isn t going to be as critical in the outcome. However, DX12 and Vulkan may very well be a bit more sensitive to higher IPC processors in regards to a real-world difference with gaming results. Going to depend a lot on how devs code their games for DX12 and how efficient their code can exploit the advantages of these new LLAPIs. Click to expand... That s what I suspect, but it would be nice to see some empirical evidence to back that up. So far my i7-2600K clocked at 4.7ghz is the best value buy I have ever experienced in terms of upgrades. Over 3 years and still going strong, at this rate I may be able to squeeze out another 2 years of usage"</post>
   <post id="0f14748d-797e-46e1-8ee6-152e3ca1488b" section="Intel Processors" discussion="Intel Skylake Core i7-6700K IPC &amp; Overclocking Review @ [H]">"Man, at this rate I ll still be rocking my 2600K for another 2 generations at least I think once I can get a good 50% boost I ll jump"</post>
   <post id="08f585b8-5747-407d-872c-3273343b1548" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Intel Devil s Canyon: The Good, the Bad, the Ugly - When Intel pulled back the covers from its new Devil s Canyon enthusiast processor last week, there was one thing missing: the Devil s Canyon processors in reviewers  and enthusiasts  hands. We have now had a single Core i7-4790K engineering sample in our hands for 72 hours and this is what we have found."</post>
   <post id="bb381e16-6b14-40e8-8b05-64cd9cf9c65d" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Darn, I was actually looking forward to upgrading from my I5 2500k. Guess I ll wait some more. Thanks Kyle."</post>
   <post id="0bb401b8-e8de-449c-8827-c71ac698e88d" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"I can t believe Intel is going around touting 5Ghz on air all over the place, when it isnt even really legit! Come on! This is BASIC Journalism crap! They will catch more flak for claiming and missing the 5Ghz mark than anything else related to this CPU/release!"</post>
   <post id="8b386dd0-7b72-4879-9512-58a60887634a" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"The Intel representative has just confused GHZ with MHZ. 5MHZ overlclock FTW!!"</post>
   <post id="79c1bcc8-952f-4591-9726-7c64ea7624f3" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"much disappoint"</post>
   <post id="959ddb1e-7ca8-4071-b68f-912ec0fedb9d" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Looks like Intel took a page from the AMD Bulldozer playbook; lots of pre-launch hype and lots of dashed hopes post-launch. There are improvements but not as expected and advertised. Hoping X99 brings something worthy of a nice upgrade."</post>
   <post id="f4ff7780-5715-4194-a4ca-089cf4e1a0cc" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"It sure is disappointing. I want to point something out; the new K chip has TSX-NI instructions, which the previous Haswell "K" parts did NOT have. Not a huge deal, but something to consider for some geeks. Outside of that, this is a somewhat unusual situation for Intel to be in; bragging left and right and it seems none of it holds up. That s more of an AMD thing to do. And really, what I really mostly hate about all this is, it was used to rope in exactly THIS audience. WE the nerds who clock shit high on a $50 aftermarket cooler, were supposed to get a cool thing. Well I am reserving judgement yet, but it doesn t look all that magical save for the Pentium buyers who will get a really cool 2-core chip for cheap and it will clock like nothing else out at the moment. Nice article, Kyle, thank you."</post>
   <post id="33271955-a4e2-49d1-8043-a11afe9621be" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Makes me all the more certain I did the right thing upgrading to 16gb on my 2500k. Going to get another three years out of it at this rate, which makes me happy and sad. Meh!"</post>
   <post id="800f15ba-2328-4528-a130-bbb20e5e2558" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Waiting for the new AMD core in 2016ish..."</post>
   <post id="db181dbb-5d58-4025-920a-e1c8405dda9e" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"I think they meant 4ghz. Sounds like a major disconnect from the enthusiast community."</post>
   <post id="937c81d8-03be-4000-8096-27ae4ff6bc91" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Looks like I am going to just go with an i5 4670K on a MSI Gaming 5 motherboard. BTW Kyle, a big shout out from an old Senior Gaming League member and when ya gonna do another Texas GamExperience"</post>
   <post id="da0adf69-9f7f-4de3-b7e9-8ce2ded29a57" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Wake me up when Skylake hits..."</post>
   <post id="4da1e5e8-64e0-496e-8e20-01efe906957f" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"The low price was too good to be true. Thanks for your hard work Kyle and crew, I very much appreciate it. I don t mean to be a d*ck but in a way I m relieved. I wasn t reel keen on ditching my cherry picked proc over this shit and you guys have saved me the trouble. If they start kicking out better procs like it seems to me they did with Haswell, I ll have another look."</post>
   <post id="45d49fea-2b1c-490c-bfc4-15505a11df4e" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Really disappointing - I was planning on finally ditching my aging i7 930... we ll see how this pans out in the next few days before retail availability."</post>
   <post id="b71d654a-b8ac-441e-81dd-2d1ea81712a6" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"I m looking to upgrade from my i7-950@4.2GHz to a newer i7 either way. I guess I could just buy this setup and then lock it in at 4.5GHz. Surely I ll see some performance improvements... right?"</post>
   <post id="ce524a8d-02d8-4991-b86b-a9b753d42627" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"My 2700K will be going a while longer it seems. Maybe by Christmas we ll see an another opportunity for upgrading."</post>
   <post id="60078f83-422f-443f-80db-f5f730cfa7a9" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"My 4.6ghz 2600K won t be replaced until 2015 at the earliest. Now that s what I call getting my money s worth"</post>
   <post id="2f65b3b1-d654-457e-8d4e-4f7edaf35b3b" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"For people with x58 boards core i7 9xx platforms. Hex core westmere Xeon s (5600 series) are getting cheap on the second hand market and they also overclock well (5650,5660,5670)."</post>
   <post id="613d18e9-730d-457b-89a2-e3e2c2481e7f" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Well, as I m the kind of guy that will get the Pentium to play with,,, go go Devil s Canyon!"</post>
   <post id="d995e889-bc6c-4c31-8c6e-89120bb5d97f" section="Intel Processors" discussion="Intel Devil s Canyon: The Good, the Bad, the Ugly @ [H]">"Very disappointing what with all the hype. Just as well I suppose because my two year old Asus Z77 Pro took a dump and I RMA d it. May as well run my 2500K a bit longer. :|"</post>
   <post id="92707b78-9f45-43f6-9fb8-7736065de856" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Intel Z170 Chipset Summary - The Intel Z170 Chipset will be seen on most motherboard reviews that we publish here at HardOCP for the coming months. Before you dig through those however, what does the Z170 Chipset actually bring to desktop PC users? We give you a quick write up in hopes of covering what will be most important to you."</post>
   <post id="8af31c8b-56bd-43ff-aa14-99af752d5b01" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Searched, and no mention of NVMe. Since is the latest and greatest, this should be fully supported right?"</post>
   <post id="e34fd2e9-4686-42b3-a402-f63393d53d69" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"For someone requiring at least 10 sata ports, wld going x99 be better or the new z170 board from gigabyte?"</post>
   <post id="ddc38ecb-6b63-46cf-b830-c20c79bffd72" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Nonpareil said: ↑ For someone requiring at least 10 sata ports, wld going x99 be better or the new z170 board from gigabyte? Click to expand... If you want that many SATA ports without getting an additional controller then X99 is the better choice. There are/will be Z170 based boards with 10x SATA ports but these will have to incorporate a third party controller. Those are never as flexible as the Intel controllers are. They also do not cross RAID with the Intel controller."</post>
   <post id="7dd9cba6-3932-4223-80f6-5c07d4e2accd" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"I wonder if Intel will release 750 ssd in m2 form factor for m-atx crowd."</post>
   <post id="af14803a-b906-48c4-8976-eac9841ec99a" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"the dmi needs to go. intel offers 20 pcie 3.0 lanes off the chipset, but you are limited by the dmi link. there could be 100 pcie 3.0 lanes, but it is still only going to be as fast at the dmi link. i also find it interesting that there are no hard numbers on the speed of the dmi 3.0 link. is intel hiding something?"</post>
   <post id="85bc49f1-00e0-4af3-82f0-6f97bc231c99" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"trick0502 said: ↑ the dmi needs to go. intel offers 20 pcie 3.0 lanes off the chipset, but you are limited by the dmi link. there could be 100 pcie 3.0 lanes, but it is still only going to be as fast at the dmi link. i also find it interesting that there are no hard numbers on the speed of the dmi 3.0 link. is intel hiding something? Click to expand... There are hard numbers on the DMI 3.0 link speed. It is an 8GT/s link or when translated amounts to just under 40Gb/s. 3930MB/s to be exact or 3.93GB/s. As I pointed out in the article, it s fine until you start talking about RAID striping M.2 drives."</post>
   <post id="2ffbda24-997b-4e35-87c6-5eb7d679ee36" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Dan_D said: ↑ There are hard numbers on the DMI 3.0 link speed. It is an 8GT/s link or when translated amounts to just under 40Gb/s. 3930MB/s to be exact or 3.93GB/s. As I pointed out in the article, it s fine until you start talking about RAID striping M.2 drives. Click to expand... so you have 20 lanes with 4 lanes of bandwidth?"</post>
   <post id="2d9bf346-e57d-44e6-8422-44c2165341eb" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Here is my big question. Between X99 and Z170, which chipset is better for 2 or 3 way SLI? With the right CPU, X99 has 40 lanes which is 16X, 16X and 8X for 3 way SLI and 16X, 16X for 2 way SLI. What is the best that Z170 can do now, and will it get better somehow in the future? If Z170 can only do 16X, 8X for 2 way SLI, what is the in game performance difference when compared to a system that has two 16X PCI-E 3.0 lanes?"</post>
   <post id="0bb63e05-6dd2-4787-94a6-df0ac01d843f" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Third paragraph. http://hardocp.com/article/2015/08/05/intel_skylake_core_i76700k_ipc_overclocking_review/2 Three video cards can be utilized but PCIe configuration would be as follows; 1x8, 1x4, 1x4. Click to expand..."</post>
   <post id="fb9e8c9a-95fb-4679-bc4e-14913e73bd21" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"trick0502 said: ↑ so you have 20 lanes with 4 lanes of bandwidth? Click to expand... Basically. Again that isn t s bad as it sounds. Most of the integrated devices that use those links don t need or use nearly that much bandwidth. It s with M.2 drives in RAID that we start seeing issues. Even then you probably won t saturate the bus unless your benchmarking or doing large file transfers regularly. With a single drive it s fine. We got by with a lot less on Z97 and earlier chipsets. If it bothers you, X99 offers 40 lanes direct to the CPU. mentok1982 said: ↑ Here is my big question. Between X99 and Z170, which chipset is better for 2 or 3 way SLI? With the right CPU, X99 has 40 lanes which is 16X, 16X and 8X for 3 way SLI and 16X, 16X for 2 way SLI. What is the best that Z170 can do now, and will it get better somehow in the future? If Z170 can only do 16X, 8X for 2 way SLI, what is the in game performance difference when compared to a system that has two 16X PCI-E 3.0 lanes? Click to expand... it should be 8x8 for 2-Way SLi. Only 16 lanes come off the CPU. A third card will be limited to 4x unless a PLX is implemented. This is due to the sheer number of devices which all use the PCIe bus. 3x8 is theoretically possible but it would be a very lean board featurwise. This isn t going to get better. Intel won t increase the DMI bandwidth. I don t think they can at this point. A revised X99 PCH or a 100 series PCH for Broadwell-E would be your only hope anytime soon. We have no idea if either scenario is going to happen. My money says no. The reality is, it s enough. There is no difference most of the time comparing 2x8 to 2x16 configurations with 2-Way SLI."</post>
   <post id="4c31aaa5-aa7b-4d4e-8e5f-52d6d0fb10e8" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Dan_D said: ↑ There is no difference most of the time comparing 2x8 to 2x16 configurations with 2-Way SLI. Click to expand... Hmm... Maybe I should go with Z170 instead of X99 then. X99 only has 3 processors and I have a feeling that if I go with Z170 there will be more CPUs launched which will give me more upgrade options in the future."</post>
   <post id="8ebb3585-99b4-4c75-ac96-d8f2c6115d8d" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"mentok1982 said: ↑ Hmm... Maybe I should go with Z170 instead of X99 then. X99 only has 3 processors and I have a feeling that if I go with Z170 there will be more CPUs launched which will give me more upgrade options in the future. Click to expand... X99 will have Broadwell-E sometime next year. Possibly Q1."</post>
   <post id="d04ff2b5-60c7-43f2-a377-39a70d03dc70" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"I m not sure how you got these numbers. Also, I fixed your Bytes to bits. First of all that 64Gbps is only bidirectional. This is still an x4 link running at 8GT/s. You should clarify that in your article. Second, where do you get this claim from Unfortunately for users, you will find limited value in using multiple M.2 devices in RAID. DMI 3.0 has a maximum transfer rate of 8GT/s as stated earlier. Roughly translated, this should allow for up to 64Gbits/s of bandwidth for DMI 3.0 but you would be wrong. While the performance penalty of DMI 3.0 is extremely low, around 1.5% overhead, you are still limited by PCI-Express on the backend. In other words after overhead is accounted for you are going to see an actual limit of 40Gbits/s of bandwidth across the DMI bus. Click to expand... How does this overhead happen? That chipset diagram shows a direct path between the processor and the chipset, using 128b/130b encoding. The PCIe 3.0 lanes in the chipset use this same encoding. You mention a 1.5% overhead, which is in-line with 128b/130b encoding. Where is this transition documented, and how does it have 40% overhead on a bus that was designed to be much more efficient? Just a little confused here"</post>
   <post id="67ba2e2d-1441-414c-bf78-beee52b3b9fe" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"defaultluser said: ↑ I m not sure how you got these numbers. Also, I fixed your Bytes to bits. First of all that 64Gbps is only bidirectional. This is still an x4 link running at 8GT/s. You should clarify that in your article. Second, where do you get this claim from How does this overhead happen? That chipset diagram shows a direct path between the processor and the chipset, using 128b/130b encoding. The PCIe 3.0 lanes in the chipset use this same encoding. You mention a 1.5% overhead, which is in-line with 128b/130b encoding. Where is this transition documented, and how does it have 40% overhead on a bus that was designed to be much more efficient? Just a little confused here Click to expand... I don t recall saying anything about 40% overhead. The clarification comes from both ASUS and Intel, who told me that DMI 3.0 could only handle 3930MB/s. I could have worded that part of the article better I suppose. Perhaps one of the ASUS guys can explain better."</post>
   <post id="3a7b22ab-f559-4e29-b7d9-3b9240d9c45e" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"mentok1982 said: ↑ Hmm... Maybe I should go with Z170 instead of X99 then. X99 only has 3 processors and I have a feeling that if I go with Z170 there will be more CPUs launched which will give me more upgrade options in the future. Click to expand... In over 20 years of building my own systems, I ve never ever upgraded CPUs while keeping the same motherboard... Maybe your habits are different, but with Intel changing sockets every two generations these days I don t see why most people would do this either. Just choose based on what s out now. If you have a Microcenter nearby the price difference is like $100-150 for the most economical setup on either platform... Do you want the 2+ extra cores and potentially more PCI-E lanes with the more expensive CPU options (tho less 3.0 lanes than Skylake with the 5820K), or do you want the slightly higher OC headroom and IPC plus a slightly more modern chipset? Core count s the thing really IMO, either you want/need more or you don t. Intel knows this too, that s why they only have one hexa core SKU and they keep most 6+ core parts on the HEDT/X##, they know they can milk those that really need/want it."</post>
   <post id="79ffdd78-2a64-494d-a1b2-2c23b491b1eb" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"drescherjm said: ↑ X99 will have Broadwell-E sometime next year. Possibly Q1. Click to expand... Sounds good to me. I will do some searching for Broadwell-E rumors and whispers. Impulse said: ↑ In over 20 years of building my own systems, I ve never ever upgraded CPUs while keeping the same motherboard... Click to expand... Yeah, that s true. I ve never just slapped in a new CPU. Impulse said: ↑ If you have a Microcenter nearby the price difference is like $100-150 for the most economical setup on either platform... Click to expand... I do have a MC nearby. I went there to check it out once, and I look forward to actually buying something from them. Impulse said: ↑ Do you want the 2+ extra cores and potentially more PCI-E lanes with the more expensive CPU options (tho less 3.0 lanes than Skylake with the 5820K), or do you want the slightly higher OC headroom and IPC plus a slightly more modern chipset? Core count s the thing really IMO, either you want/need more or you don t. Click to expand... I am just a PC gamer so I don t need 6 cores, but I do like me some PCI-E lanes. Right now I am thinking I might go with X99 and a 5820K or 5930K."</post>
   <post id="307a23c6-76b1-4579-a5f7-758dcfcf531a" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Dan, I know your answer to this will probably be something like "none, M.2 to a U.2 adapter" but still, thought I d ask... What do you think think is the best location for the sole or primary M.2 slot? (specially for SLI/CF users, which probably takes me back to "none") I ve noticed some boards have it next to the top-most x1 PCI-E slot, seems like that would be one of the hottest locations possible (sandwiched between/below CPU and GPU)... Others have it along the bottom PCI-E slots, those with multiple might have them at either location obviously... Don t think I ve seen any Z170 boards with vertical slots jutting out like some of ASUS  X99 boards, think I ve read of M.2 behind the motherboard but I don t think I ve seen that at all. I m surprised no one built that M.2/U.2 adapter into their board, tho I guess having the option to use either is more flexible."</post>
   <post id="83fe54d7-59cf-4d3a-bc0c-7cbef00ba50b" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"mentok1982 said: ↑ Sounds good to me. I will do some searching for Broadwell-E rumors and whispers. Click to expand... Broadwell E will probably be crap - whole magic of that CPU comes from L4 cache in igpu."</post>
   <post id="01d72831-ae25-433e-9a40-0a18ad728deb" section="Intel Processors" discussion="Intel Z170 Chipset Summary @ [H]">"Grammatical error in the first paragraph of page 2: "Z170 is only moderately more exiting by itself." "exiting" needs to be changed to "exciting"."</post>
   <post id="e31e542a-a3e9-48ec-b21c-d93ece551965" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"I wasn t actually thinking about changing my CPU s OC until I saw some of the numbers people here have of their 2500k, stuff like 4.6 Ghz, up to even 5 Ghz. I ve been running an OC of my i5 2500k for years, and now I feel like it s time to ascend to the next level with my OC, like Goku and Vegeta did before fighting Cell. Similarly, there are some great GPUs coming out this year, and I plan to put one of them into my PC, and want to avoid FPS bottle-necking from my CPU in games. CPU: i5 2500k mobo: Asus P8P67 Pro Rev 3.1 (newest BIOS) cooling: CoolerMaster Hyper 212+ EVO Current OC: 4.4Ghz / 25% LLC / -0.010v voltage offset My current OC runs fully-stable at 4.4 GHz. If I bump the multiplier up to 45 for 4.5 Ghz, although that OC tests well in Intel Burn Test and Prime 95, it causes me some unpredictable PC hard-freezes, in certain games (AC4, GTA V). I like keeping speed-stepping active for power-saving, which is why I m using a voltage offset, rather than a manual voltage. One of the things I ve noticed, or suspect that I ve noticed, is that the voltage offset feature is not an accurate offset, in that, if I change it to an offset of -0.020v, it seems to actually lower the voltage by significantly more than an additional -0.010v, and my PC can no longer maintain itself when the CPU goes under load. Maybe I m misunderstanding things, though. People with the i5 2500k OCs higher (or lower) than mine, mind sharing your configuration settings, and what do you think of the particular OC configuration that I m running?"</post>
   <post id="d2a3648d-b353-42cc-bc88-29be8bd27a3e" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"A better cpu cooler will help keep those temps down, it would guaranty a better overclock. Personally, i dont believe a good bit of people have stable over clocks when seeing what some people claim I think high end cpu cooling is a decent investment regardless"</post>
   <post id="6b929a4e-8603-4a74-b385-3e5d9416d621" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"As primetime said, the 212+ Evo is a "budget" HSF. It s impressive enough you re managing a solid 4.4Ghz on it. If you want more than that stable, you re going to need better cooling. I m running a Prolimatech Megahalems, which is /worlds/ better (no offense) than the 212+ EVO... and I got another 100Mhz on your stable OC. 200Mhz when I really want to push it. That s with Panaflo 120x38mm (double thick) high CFM/static pressure fans on both sides. Most 2500Ks can t go over 4.5/4.6Ghz, even under water. The fact that you re managing 4.4Ghz with a budget cooler is impressive in an of itself. Not trying to run you off of a high end air cooler, of course -- pick up the highest end Noctua or similar that ll fit your current chip and current CPUs. You won t be disappointed in the long term."</post>
   <post id="5b653b26-7ea9-4aec-aad5-0a97958610e3" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Oh, well, that s cool, then. If it takes more investment to OC further, I m going to save that money for a new CPU / mobo / case / RAM, which I ll inevitably need. I think I can get a lot more from this CPU with voltage adjustment, though I don t know how that will affect my temps. And, unfortunately, the voltage offset feature in the BIOS seems to only offset in increments of a minimum of 0.01v. My current fluctuating idle voltages are 1.296v - 1.32v Idle CPU temps are 39 C (102 F), with fan speeds of: 1691 - 1698 RPM Running Intel Burn Test at the maximum setting just now for only a few minutes, I had a CPU temp of 55 C and core temps reaching up to 91 C."</post>
   <post id="61b4e670-1c58-4865-ba79-767aed0b17c8" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Either your cooler needs a clean, the heatsink paste isnt well applied or enough cold air is not making it into the PC case. (or possibly the voltage readings are so badly incorrect that they are nearer 1.4V+, doubtful but its possible. Stated for completeness) You should be idling at 30C or less unless your ambient is very high. 91C is not healthy for that chip if you want to maintain its clockability. As pointed out a better cooler is desirable anyway."</post>
   <post id="c5976744-b203-4880-a48b-3a652e307b93" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"I think those temps are what I got since installing the 212+ fan and OCing. I reapplied the paste once, and got the same temps. My case fans don t work, don t know why, but I have the sides of my case off, so there s no hot air buildup inside. I got a max core temp of 80 C just now while playing Battlefield 4."</post>
   <post id="0e954a6e-c9b0-40ca-b788-453926687dd6" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"You need case fans. Period. You wont achieve anything except burnt components unless you do, and thats without any overclocking. You take a risk."</post>
   <post id="c6ea1281-0f12-4cb0-a9be-4005e46bcf87" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Yeah, figure that out. If none of them are working I d say more than likely they just aren t hooked up right."</post>
   <post id="ab68bdeb-970d-4174-8a96-a6b8a1ec249e" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"They used to work, but stopped, and I figured that one of the wires in the cables that connects to all the fans broke. Like I said, I have the sides of the case off, so it s mostly open-air. I guess that doesn t do enough, though. I ll see if I can figure the exact problem out."</post>
   <post id="6fbd9a94-c50d-49d7-8587-b2c804adf7ee" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"silent-circuit said: ↑ As primetime said, the 212+ Evo is a "budget" HSF. It s impressive enough you re managing a solid 4.4Ghz on it. If you want more than that stable, you re going to need better cooling. Click to expand... The hyper 212+ has potential beyond stock, as it can run all the way up to dual high performance fans in push-pull. My hyper 212+ runs my 2500k @ 5Ghz at 1.48v."</post>
   <post id="de9f28ab-70dc-4ded-bb3a-7e0f1f736776" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"GotNoRice said: ↑ The hyper 212+ has potential beyond stock, as it can run all the way up to dual high performance fans in push-pull. My hyper 212+ runs my 2500k @ 5Ghz at 1.48v. Click to expand... What kind of load temps are you getting there? That s a lot of vcore."</post>
   <post id="4e72fc74-0f1e-4310-a08d-e488b6fa33fd" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"silent-circuit said: ↑ What kind of load temps are you getting there? That s a lot of vcore. Click to expand... It will throttle if I run something like Intel Burntest, but in actual games each core generally stays below 70C."</post>
   <post id="a12b1018-b936-45a6-a5c1-fbd6890b01fe" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"So my case fans seem to not power on when I connect the case fan control to the PSu, but I plugged the case fans directly into the mobo (I just don t get fan speed control that way), and ran Intel Burn Test at maximum again, and now the CPU core temps max out at 71 C, so that s at least 20 C cooler than before, haha. But the case fans increase the overall noise level But summer s coming and the reduced heat will make my room more bearable :/ GotNoRice, is your vcore a static manual setting?"</post>
   <post id="b86198b0-7db3-4753-a927-a179728f4ff8" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Delicieuxz said: ↑ GotNoRice, is your vcore a static manual setting? Click to expand... For the most part yes. I have it set manually to 1.45v in the bios, but I have LLC set to one of the higher settings, and that seems to push it to 1.48v under load."</post>
   <post id="b813867d-8280-4ee1-8564-6405a4360f11" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Delicieuxz said: ↑ So my case fans seem to not power on when I connect the case fan control to the PSu, but I plugged the case fans directly into the mobo (I just don t get fan speed control that way), and ran Intel Burn Test at maximum again, and now the CPU core temps max out at 71 C, so that s at least 20 C cooler than before, haha. But the case fans increase the overall noise level But summer s coming and the reduced heat will make my room more bearable :/ Click to expand... You havent got reduced heat production, that remains the same. If anything getting rid of the heat from the card faster will heat your room up faster. But it will also cool a bit faster when finished because the card wont be holding as much heat energy. You can get quieter case fans, even for the same size. Although the larger the fan, the more air it can shift at the same noise level. See if your case will take larger fans. If your case only takes 120mm fans, it might be an idea to look at a better case."</post>
   <post id="b0e449fa-927c-4080-9b40-50b9b7b5e249" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"If you have the space for them, "double thick" fans like Panaflos are a good choice. They have higher static pressure as a result and tend to move more air."</post>
   <post id="3f8561e7-22ae-4032-a491-a9bb7cf408f7" section="Intel Processors" discussion="Better OC possible for my 2500k on air cooling?">"Nenu said: ↑ You havent got reduced heat production, that remains the same. If anything getting rid of the heat from the card faster will heat your room up faster. But it will also cool a bit faster when finished because the card wont be holding as much heat energy. You can get quieter case fans, even for the same size. Although the larger the fan, the more air it can shift at the same noise level. See if your case will take larger fans. If your case only takes 120mm fans, it might be an idea to look at a better case. Click to expand... Well, the case fans apply directly to the case interior, but the cooling factor applies within the whole environment of the room. It s definitely making a difference already, and I can feel a cool breeze around my legs, and above my case. It looks like the case is a Corsair 600T. It has a 200mm fan on the front, a 200mm fan on the top, and a 120mm fan at the back."</post>
   <post id="2fc9464c-caf1-4908-b7c2-d693870a0c03" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"I was using a GTX960 for my media box and decided to sell it and go back to my 4600 Intel graphics built into the i5 cpu. It does not load a driver in device manager for the Audio pass through over HDMI. I am aware how to set the playback device and during the install of the video driver I saw the device show up in playback devices and then it went away. Nothing in device manager for it. This used to work but now I am on Windows 10 and curious if that is the issue. I have tried 3 different drivers.. I m lost!"</post>
   <post id="ebccb0c9-c14c-4458-9f00-a7b2e45e5d10" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"Did you check the bios to verify that HD audio is enabled? You could also try the Intel Driver Update Utility and just use whatever driver that tells you to use. I ve always used the default W10 audio driver and that seemed to work fine for playback unless I want support for recording software, in which case I add the Realtek audio driver. But the built in W10 Intel audio driver should get you sound playback on HDMI."</post>
   <post id="42c0f42d-db69-41d2-9309-5fc2e7e3c3c5" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"dwd999 said: ↑ Did you check the bios to verify that HD audio is enabled? You could also try the Intel Driver Update Utility and just use whatever driver that tells you to use. I ve always used the default W10 audio driver and that seemed to work fine for playback unless I want support for recording software, in which case I add the Realtek audio driver. But the built in W10 Intel audio driver should get you sound playback on HDMI. Click to expand... I don t believe the onboard audio has to be enabled for the HDMI audio to work? I thought that was primarliy for the realtek chipset. I did go in and enable that just in case but no luck. I did not see an option in the bios that allowed me to enable or disable the HDMI Audio."</post>
   <post id="bcc52d0d-ad72-40f4-8fac-479bc5b9fe67" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"I ll be damned there was a section under CPU Video that had the Audio disabled... flipped it to enabled and boom all is working! I was able to disable the on board audio since I don t use the Realtek and only HDMI. All good!!"</post>
   <post id="6f465a0d-7c71-4d35-a554-ac45ba54bd4a" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"Under Windows audio settings make sure your Intel HD video is selected as the sound source."</post>
   <post id="d4a0d560-a745-448e-b0cf-e245cba3d4d8" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"Already know that and I posted above its fixed. I assume I disabled it in bios a while back."</post>
   <post id="89cf501e-0ce8-4a06-b5b2-92737c49b07c" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"Copyright said: ↑ Already know that and I posted above its fixed. I assume I disabled it in bios a while back. Click to expand... Whoops sorry about that."</post>
   <post id="ffb12b87-9800-4760-aa5d-522536ea5148" section="Intel Processors" discussion="HELP! Intel 4600 no sound over HDMI..">"No problem appreciate the advice!"</post>
   <post id="364cc43c-cc01-4145-87b3-f7ddb10d57e6" section="Intel Processors" discussion="Upgrade i5 2500K @4.6 for 1080?">"I m trying to decide whether my next system upgrade should be put towards a new video card like the NV 1080 (or possibly the generation after that) or a new CPU. I ve read a lot of conflicting articles lately about this subject, and I m unsure of what my next move should be. My current system specs are in my sig. I ve actually had the CPU overclocked as high as 4.8 in the past and it s 100% stable under load. But, I was never able to get it to wake from sleep reliably so I decided to keep it at 4.6 until/unless I needed the extra speed. I game on a 1920x1200 monitor that I m not looking to replace anytime soon and I plan to get a VR HMD within the next few months. I m thinking that I could try upgrading my RAM from 1600 Mhz to 2100 Mhz DIMMs, as RAM speed and latency seems to have the larger effect on games currently vs. the CPU speed and architecture. However my motherboard doesn t support this natively so I will have to overclock the system bus and cross my fingers that I can reach these timings. Correct?"</post>
   <post id="07c63599-717e-48c7-95df-741ce73f8791" section="Intel Processors" discussion="Upgrade i5 2500K @4.6 for 1080?">"I m not an expert, but my vote definitely goes to getting a newer GPU. That CPU still has a ton of kick and I really can t see any game out there currently challenging it. On the other hand, if you like to do encoding or rendering, wait until intel starts to add more cores to their consumer cpu s or go for their x99 platform. BTW, wait for non-refrence 1080 s. The reference power design is kinda meh."</post>
   <post id="376b7ab6-a11d-46a2-badf-716192a67ed0" section="Intel Processors" discussion="Upgrade i5 2500K @4.6 for 1080?">"I would get the 1080 first, because it will help more than anything. And if you upgrade your CPU later on, just get a 2600k or something and keep the motherboard. There s really not much benefit to a new platform. I know one guy sold off his 2500k and then we had to tell him that there wasn t anything better in his price range and he was going to get stuck with an i3 that wasn t as good. Easy mistake to make if you haven t been following the CPU market, totally counter-intuitive to any instincts you would have developed in the late 1990s up to 2010."</post>
   <post id="c26f1433-0089-4283-b64e-8b556162a68b" section="Intel Processors" discussion="Upgrade i5 2500K @4.6 for 1080?">"Pick up a cheap Z77 like this and the faster RAM, and you should be fine for gaming on your 1920x1200 monitor for a long, long time with a GTX 1080. I d also bump up to 16GB of RAM while you re at it. With Z77 you get native USB 3 support and you can drop in a 37XX chip if it s determined PCIe 3.0 is really that beneficial for the 1080. The issue for you is VR. Never CPUs seem to benefit most in terms of minimum frames... and that s super important in VR as I understand. I m currently happy maintaining 60+ FPS with all options (save motion blur, as I hate it) on at 3440x1440 in most titles, but you may need more than 60FPS... and hence, it may turn out a newer architecture is actually beneficial for you. We ll need some of the guys who already have VR setups to chime in here to be sure."</post>
   <post id="b5353cd0-b4a7-4e5b-bc89-895ccab221fd" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"what processor are you getting next? i ll probably get the 6800k. you?"</post>
   <post id="f86ec374-dc9f-45a5-9696-42d585d3679a" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Might flag the desktop range and go xeon this time around.."</post>
   <post id="609be1c6-6ec9-4b3c-9001-36d48317212d" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"I already have a 5960X, so I ll probably go with a 6950X on the next go round... if I upgrade at all."</post>
   <post id="047ef872-348c-48ca-bf90-0f75a1ed93c3" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Skylake E"</post>
   <post id="1cb148aa-3336-4557-967a-f6a2f86944cd" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"fairly certain i ll go with the 6800K. If price is outrageous and/or performance is lacking i ll go with the 6700K. no matter what i m upgrading to something in June."</post>
   <post id="5b91f55b-5d66-400a-b35b-301ae576cdbf" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"6700k is a dead end imo. better bet is the 2011-v3 platform!!"</post>
   <post id="b8485671-4e8f-4e5d-a963-e583531bd32d" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"N4CR said: ↑ Might flag the desktop range and go xeon this time around.. Click to expand... Unless you need an 18, 20, or 22-core CPU, the i7-6950X should be the better option..."</post>
   <post id="291a5d5c-4b15-4fad-aa98-eb8ef6fc7bfb" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Recently built a mini itx Lanbox with a 6700k. It has a GTX 970 in it for now. Waiting to see what new GPUs hit the street later this year. I would like to try a 6+ core build some day. Right now though I don t really need that kind of cpu power."</post>
   <post id="ad4d8188-a78b-4f76-a02d-3274a8429b15" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"2x E5 2670 v1s for $65 each. Building a 32-Thread Xeon Monster PC for Less Than the Price of a Haswell-E Core i7 Joseph"</post>
   <post id="3bc3073b-3e9b-4ab9-a8be-5a2c91c92657" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"josephnunn said: ↑ 2x E5 2670 v1s for $65 each. Building a 32-Thread Xeon Monster PC for Less Than the Price of a Haswell-E Core i7 Joseph Click to expand... It s a damn shame that you still have to drop $200-300 for a C602 board to go along with those chips. Regardless, if i was going to be upgrading...it would be a 6800k/X99 setup."</post>
   <post id="5b567d5f-766d-4f66-8985-6a0bb293a1c8" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"I just got a 5820k so there s probably really no gain."</post>
   <post id="03d1fe52-8a75-41f7-931d-c8a9eb7d8ad8" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"I expect the 10 core / 20 threaded Skylake-E on Black Friday of 2017. However by then we should know what Zen has to offer."</post>
   <post id="87a7a515-9df9-4144-acf0-9f0b62c72899" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"N4CR said: ↑ Might flag the desktop range and go xeon this time around.. Click to expand... Agree 100%"</post>
   <post id="0b76e45c-ac8f-490b-b6a1-0f56326ddfda" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"atp1916 said: ↑ It s a damn shame that you still have to drop $200-300 for a C602 board to go along with those chips. Regardless, if i was going to be upgrading...it would be a 6800k/X99 setup. Click to expand... You can get a dual socket Intel s2600p from Natex.us for $175 if money is tight. However I think its a damn shame that people might buy a single socket X99 board for the same price as they could have a dual socket C612 for. Joseph"</post>
   <post id="b89c4530-20d4-4e15-9963-e773ed8182a1" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"I recently updated from the X79 and a 1650V2 (4930K equivalent) to the X99 Classified with a 5820K to tide me over. I m waiting for some 1650 to 1680V4 processors to drop. The Xeons are much higher quality, run much cooler even with higher voltage, and overclock just as good as their i7 counterparts."</post>
   <post id="02c83e68-56ee-4964-8438-b95973095042" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"I built a 5820k x99 setup last summer. I can t really say which chip I will upgrade to, or if I will upgrade at all, before I see some solid benchmarks. Broadwell-E into my existing motherboard seems tempting though, assuming there are no roadblocks to making that work."</post>
   <post id="949ee83c-6e21-4115-8bd3-fe3dfb8626da" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"It would be nice to get an 8 core if it came down to around $300. I did score my x99/5820k system for free. Son bought a new system with the 8 core for his first system that he built himself. I think that with the new systems having more cores, its better for people who need a gaming and fast workstation. They can have the best of both."</post>
   <post id="b0ec7e37-1ad5-4cc7-9dfe-354ed6222439" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Still on Ivy Bridge, wil get an i7 soon though. Still incrimental upgrades each year, haven t seen a reason to upgrade."</post>
   <post id="2cb08eda-a77f-43be-a28d-1311dcc73965" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Buying? Bought a 6600k ~2 months ago or so. Have it running at 4.3Ghz at 1.160v"</post>
   <post id="41472c95-ebff-4a2c-ac19-3546cb0eaceb" section="Intel Processors" discussion="what your buying, Intel i7 6950X , i7 6900K , i7 6850K or i7 6800K?">"Just upgrading from an i5-3470 to an 6700K."</post>
   <post id="2aa9cb0d-838c-43a6-8acd-b685fdbf4a62" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Intel Broadwell-E Core i7-6850K vs Core i7-5820K Haswell-E Benchmark Results Leaked - Clock-To-Clock Performance Revealed Looks promising with those good clock to clock numbers. Gotta decide between 6 and 8 cores. Might do 6 for now and then upgrade when new board comes out. I think this will be a worthy upgrade from my 3930K"</post>
   <post id="b97b62a8-c721-4839-b381-50dcc3d43969" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"can t wait"</post>
   <post id="f886af62-bd7b-4aba-9d01-26b6aba04424" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"I have been considering 8 cores for a while... maybe now is the time!"</post>
   <post id="bd29087a-d534-49b8-9ee8-31f5f4a42541" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"8 is great right?"</post>
   <post id="d364cf8c-5477-496a-9acc-eba6680a8705" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"I m really wondering the IPC and Overclock. I was trying to hold out for Skylake-E but I might bite the bullet if Broadwell-E makes a big enough splash"</post>
   <post id="0fd4891b-4f2d-41d5-a1da-f8aaab8982ab" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Bottom line for those with x99a boards have a hell of nice upgrade path as the years go by"</post>
   <post id="4290b78e-fc78-43d2-ba4a-60a7fe114139" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"I m looking to upgrade from Z77 to X99. Should I go with 5820K and possibly get a deal on one since the Broadwell-E is coming next month? Or should I just wait for Boradwell-E 6850K? Anyone know for sure the price difference? One other concern going 6850K - What if I purchase a new mobo that needs a bios update to support Broadwell-E? Would I be screwed then without a Haswell-E around to flash it? thanks"</post>
   <post id="48b26873-f17d-4e18-8cf1-154cfb60ebb6" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"jester55 said: ↑ I m looking to upgrade from Z77 to X99. Should I go with 5820K and possibly get a deal on one since the Broadwell-E is coming next month? Or should I just wait for Boradwell-E 6850K? Anyone know for sure the price difference? One other concern going 6850K - What if I purchase a new mobo that needs a bios update to support Broadwell-E? Would I be screwed then without a Haswell-E around to flash it? thanks Click to expand... I d just wait until Broadwell-E releases and see how everything shakes out. I m going with the 6800K if the rumors/leaks im reading come to be true."</post>
   <post id="c733cea7-a041-4d99-84fc-700cff8a93e1" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Porter_ said: ↑ I d just wait until Broadwell-E releases and see how everything shakes out. I m going with the 6800K if the rumors/leaks im reading come to be true. Click to expand... Yeah, I meant 6800k not 6850K Really wish I knew price difference between 5820K and 6800K. So, if the release date is in June, does that mean retailers have it at release date or have to wait until a month later once retailers receive shipments?"</post>
   <post id="dae90562-28ca-49ec-8c09-aecb3c8f8529" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Meh. Another 10% IPC gain. Looks like I ll be using my X79 setup for a while."</post>
   <post id="36f2b099-7c43-4470-8b74-c027f6e7b57d" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"DeathFromBelow said: ↑ Meh. Another 10% IPC gain. Looks like I ll be using my X79 setup for a while. Click to expand... The interesting CPU here is the 10 core / 20 threaded processor. Well that depends on if you can use that many threads."</post>
   <post id="a657a6c4-7234-495e-9fd2-49f3896a1ccb" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"I think I am going to wait and see how close the prices are between the 5820K and 6800K. Hopefully whatever board I purchase will support bios flash from USB without CPU if I go 6800k route. Either way, I am hoping for a decent bump all around coming from a 3770K. Quick question - Besides EVGA and Gigabyte, are there any other mobo manufacturers releasing a X99 refresh with Broadwell-E release?"</post>
   <post id="15a49af3-153e-475c-921f-4220a7f9806b" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"drescherjm said: ↑ The interesting CPU here is the 10 core / 20 threaded processor. Well that depends on if you can use that many threads. Click to expand... Uh, a CPU only upgrade for $1500? Those who want that probably already have the 8 core CPU. Probably not good for most games as they overclock less and most games can t use so many cores. It just seems like an expensive toy. I like. But I d rather buy a professional drone with Fatshark googles for that money and have a lot more fun."</post>
   <post id="e3ea3c1e-07c2-43c5-84c6-3184b5a1331e" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Nebell said: ↑ Uh, a CPU only upgrade for $1500? Those who want that probably already have the 8 core CPU. Probably not good for most games as they overclock less and most games can t use so many cores. It just seems like an expensive toy. I like. But I d rather buy a professional drone with Fatshark googles for that money and have a lot more fun. Click to expand... No doubt, but with DX12 there s some preliminary evidence that high core CPU s will really benefit. Now whether that extends all the way up to 10 cores is unknown... Still for something like a 10 core at that price you re probably investing because of the benefits to video encoding and other utility stuff rather than gaming."</post>
   <post id="bb203c2c-f319-4aa5-b8ac-b670f4b903df" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Kloudzero said: ↑ Still for something like a 10 core at that price you re probably investing because of the benefits to video encoding and other utility stuff rather than gaming. Click to expand... My interest in the 10 core mainly programming for medical Imaging research. It will be a significant upgrade over the 6 core / 12 threaded processor I currently have. Uh, a CPU only upgrade for $1500? Click to expand... At $1500 this will be the most expensive CPU I have purchased at home ( a little more than the dual cpu setups in the 1990s). However I would expect that this one I would use for a much longer time period. I expect a decade of usage minimum."</post>
   <post id="637d91e1-3d3f-43bd-998f-38500498c3e0" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"drescherjm said: ↑ The interesting CPU here is the 10 core / 20 threaded processor. Well that depends on if you can use that many threads. Click to expand... Ivy Bridge-EP also has a 10 core / 20 threaded processor and that is much more affordable than the 6950X will be. Just look at the MSRP of the 6950X and compare it to that of a E5-2670/E5-2680 V2 and there is a huge difference. The only advantage the 6950X would have is that it is unlocked but the parameters are pretty much very similar aside from architecture and TDP between the Xeon and the 6950X. It s just another small IPC gain with Broadwell-E following in the incremental IPC gains since Ivy Bridge LGA1155 set as a precedent. DeathFromBelow said: ↑ Meh. Another 10% IPC gain. Looks like I ll be using my X79 setup for a while. Click to expand... I ll admit I like the IHS design compared to the Haswell-E design but another 10% average gain is too small to warrant an upgrade. Even LGA2011/X79 has plenty of life left in it and it offers 10c/20t Xeon processors."</post>
   <post id="578cf28a-4d84-426d-a18b-dbd492ee95bf" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"My 2600K is in getting long in the tooth, I m going BALLS OUT on this Broadwell Build."</post>
   <post id="b20c4683-ce24-4c4f-af5e-7adc3f4ca54e" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"DeathFromBelow said: ↑ Meh. Another 10% IPC gain. Looks like I ll be using my X79 setup for a while. Click to expand... 10% really isn t bad considering it is pretty much just a die shrink. Then figuring a clock-for-clock match up between Broadwell and Haswell, you should see less real world power consumption. It should ease the burden on cooling a tad, and possibly allow higher clocks."</post>
   <post id="23277944-70ec-4967-95bc-f0541d575ce5" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"But wouldn t you guys be better off buying one of the specialized CPU s for work instead of a $1500 i7? Isn t this one worse than Xeon for work? And worse than 4/6 core for gaming? It s like a middle spot but quite expensive."</post>
   <post id="2ecfc792-1784-47ad-932e-9a64026d551f" section="Intel Processors" discussion="Some of the first Broadwell-E Benchmarks">"Nebell said: ↑ But wouldn t you guys be better off buying one of the specialized CPU s for work instead of a $1500 i7? Isn t this one worse than Xeon for work? And worse than 4/6 core for gaming? It s like a middle spot but quite expensive. Click to expand... I agree with you unless you want to OC for fun/hobby. Most Xeon are locked and at stock are lower clocks than enthusiast processors from what I understand? correct me if I am wrong. Either way, it all boils down to what your intentions are for your build."</post>
   <post id="d67dfba2-835a-4d4a-b85f-a4d6cdf099f8" section="Intel Processors" discussion="Will Kaby still use Alpine Lake?">"Or will TB be controlled on CPU? I ve read conflicting info and I m hoping for clarity."</post>
   <post id="8d77f18c-714c-4f78-b9aa-51640ee8a512" section="Intel Processors" discussion="Will Kaby still use Alpine Lake?">"The only thing confirmed on the Wikipedia page is USB 3.1 integrated on the hub. Kaby Lake - Wikipedia, the free encyclopedia Thunderbolt could also be included, or could still require a third-party chipset...the wording is unclear. There s a lot more demand for USB 3.1 than there is Thunderbolt 3, so I d expect it to remain "supported" but a separate chipset."</post>
   <post id="8f3866e7-e2e6-428c-868b-62867a0c27df" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"First they laid off 12,000 of their workforce. Now they are cancelling "Braxton," their (previously) upcoming Atom chip and have conceded defeat to ARM in the mobile market. They re apparently bowing out of the PC market as well. What the hell is happening? Is there something going on within Intel that isn t apparent? I m confused as to how such a huge multi-billion dollar CPU leader is tucking their tails between their legs and just "giving up" so easily. Is Intel afraid of AMD s Zen CPU? Seems like with each news story related to Intel, they re falling further behind technologically."</post>
   <post id="478bdeae-f0c6-4e1f-9db4-55c588def619" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Already a thread with this topic and its already closed, so nothing to speak/talk here. Wait a sec. Intel just said "Screw it, we re out"?"</post>
   <post id="35976657-b41b-4ada-b4cb-78aae29115bf" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Stop reading clickbait headlines, and start digging deeper and reading between the lines."</post>
   <post id="803674a5-b86a-470e-b168-44c10dcc4d95" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Intel are in a REALLY difficult place for a multi-billion dollar corporation. When you have that amount of money, and the control over the market Intel has, you can t move and react to the industry very quickly. Take for instance. ARM RISC CPUs are inherently more efficient than Intel s X86 CISC CPUs per cycle, at the same process node. RISC CPUs are just MUCH better for tight, efficient cycles, given that software works for them. But here s the thing: ARM can be licensed and used pretty easily. Samsung, Apple, AMD, Qualcom, everyone licenses and makes different ARM-based silicon. Why doesn t Intel just license ARM? Whelp, that s the thing: They cant because they are the big multi-billion-dollar corporation. Licensing ARM would reduce the value of their own X86 technology IP, which they hold all the rights to and sunk trillions of dollars over the years in producing and promoting. They are one of three companies who have a license to x86, and the other companies are a fraction of the size and Intel own the IP. They have secured the market, and nearly ALL PCs and servers run X86 operating systems and hardware because of this. Licensing ARM would mean they enter into a market they don t control, and also give MORE viability to the ARM market. This would mean lower profits for Intel. So what s the issue? Well, the X86 market is shrinking. ARM devices are starting to be seen in servers, ARM is almost totally conquered the tablet and phone market, and because its efficient and cheap to license, many MANY companies are producing highly competitive chips with ARM-based OS software taking advantage of them. With Intel being the only real company making X86 chips, the consumer computer market is moving to more competitive (read: cheaper) landscapes, including ARM. This means lower profits for Intel. Well, why doesn t Intel sell licenses to X86? Whelp, that s the thing: They cant because they are the big multi-billion-dollar corporation. Selling licenses to other companies would then affect their share of X86 PC market, which is how they generate literally all their profits and investments. The X86 PC market is shrinking rapidly, but Intel CAN T loose market share in a shrinking market while there is still profit to be made. If they sold licenses for X86, its highly likely other (non AMD) companies would release hardware that competes aggressively with Intel s products, forcing Intel to cut prices to compete. This would mean lower profits for Intel."</post>
   <post id="cdeddfaf-871e-479c-8858-2f4020ed0774" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"People thinking Intel are in trouble or irrelevant are not so well informed. We are a small part of the market. Servers/commercial/industrial/mobile/blah dwarfs us. And that s just the computing stuff.. But first up; 50bn profit. Per year. edit: this is hookers and blow powering a mars mission or ten type budget. Per year. That s a lot of cash they re sitting on each year to distribute, invest, R&amp;D, etc.... a craptonne of options. The desktop PC market has plateaued. It is not rapidly shrinking. PC gaming is bigger than either of the consoles, so nothing to worry about there, this seems to be accelerating, as people grow discontent with the way consoles are becoming an even more obvious money sucker than before.. pay less now pay more later etc. Pay for shitty online experience with kids abusing you etc.. crappy hardware. Overall mostly mediocre games. Few exclusives. What Intel is doing, is what any smart company with no room to expand in current market would do. Buying companies and technology relevant to future applications, expanding out of its  typical market. Moving out of your typical market worked for my company, went from nearly closing the doors to a nation leading company (in its  field). If managed correctly, it can be the key to success in times of necessity. Intel have made some very big moves lately, in fields you would never expect, or if you knew, it would be hard to put two and two together to work out the long term strategy - but rest assured it s all under control. I d love to elaborate further but an enn deee ayye makes that rather impossible.."</post>
   <post id="6e52ff3e-6cb3-4a28-bfd7-61aed0dd8450" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"What do you think most of all the world s supercomputers are made of? This title is ridiculous."</post>
   <post id="c8360d82-5d8c-4c68-aa45-2ada0b6b1628" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Is Intel afraid of AMD s Zen CPU? Click to expand... I expect not at all. AMD has not done anything to push Intel in a decade. They re apparently bowing out of the PC market as well. Click to expand... They are certainly not bowing out of the PC market."</post>
   <post id="97ed6e07-b68f-4333-b326-124c23defd71" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"I don t think I ve ever seen an Intel Atom based device that wasn t slow as shit. Android, iOS, etc can get away with "slow" ARM chips because the OS was built from the ground-up to work around that fact. What did Intel have going for it with Atom? Trying to run Windows on an Atom is noticeably slow most of the time. I think it s good that they cancelled Atom, because it could never realistically compete with ARM in it s core market, and the market that it does have just gives Intel a bad reputation since Atom is so damn slow... Did I mention that Atom is slow? The Desktop PC market shouldn t be an issue for them, even with much less company resources pushing it. Going forward, they can just continue to repackage and relabel server chips as desktop PC chips and do so at very little expense to them."</post>
   <post id="190e9344-b788-4ff5-a0be-8bcb7dd6c5d5" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"aphexcoil said: ↑ Is Intel becoming irrelevant? Click to expand... Nope."</post>
   <post id="8705bad8-eb68-4eae-816f-f405110f8ae9" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"GotNoRice said: ↑ I don t think I ve ever seen an Intel Atom based device that wasn t slow as shit. Android, iOS, etc can get away with "slow" ARM chips because the OS was built from the ground-up to work around that fact. What did Intel have going for it with Atom? Trying to run Windows on an Atom is noticeably slow most of the time. I think it s good that they cancelled Atom, because it could never realistically compete with ARM in it s core market, and the market that it does have just gives Intel a bad reputation since Atom is so damn slow... Did I mention that Atom is slow? The Desktop PC market shouldn t be an issue for them, even with much less company resources pushing it. Going forward, they can just continue to repackage and relabel server chips as desktop PC chips and do so at very little expense to them. Click to expand... In addition to that, they now have Core M CPUs (based on their main architecture) sipping power almost like the Atoms while providing good performance on demand."</post>
   <post id="9c0f69f2-44c4-4289-a927-339e48028144" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Tsumi said: ↑ In addition to that, they now have Core M CPUs (based on their main architecture) sipping power almost like the Atoms while providing good performance on demand. Click to expand... Yeah but how much do they cost? That s one area Intel refuses to budge."</post>
   <post id="93cc8dc6-2fae-4d77-a32e-6e36fd4ce110" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"jwcalla said: ↑ Yeah but how much do they cost? That s one area Intel refuses to budge. Click to expand... If you have a product that no one else can provide, why wouldn t you milk it?"</post>
   <post id="0c4e83ab-43e0-47c4-a1e0-f334a11a0dfd" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Someone mentioned Intel canceled atom, they didn t cancel atom. They canned the cell/tablet atom chip and mobile modem platform it would operate. Which btw can be brought back at any time or released under a different program. The chip was working great just gained zero ground even though Intel tried to buy their way into the market. Intel underestimated driver compatibility and OEMs giving a shit enough to write proper software for their platform."</post>
   <post id="f8d7d002-7ce1-44cd-a4c3-0ccc96420df3" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Trimlock said: ↑ Someone mentioned Intel canceled atom, they didn t cancel atom. They canned the cell/tablet atom chip and mobile modem platform it would operate. Which btw can be brought back at any time or released under a different program. The chip was working great just gained zero ground even though Intel tried to buy their way into the market. Intel underestimated driver compatibility and OEMs giving a shit enough to write proper software for their platform. Click to expand... So, does that mean that if a manufacturer like Microsoft approached them and said they were interested in something to power an x86-compatible phone, they d be able to come up with something rather than just shrugging and telling them to use ARM like everyone else? I ask because I ve always really wanted a phone that could run PC applications and be plugged into a bigger monitor like a laptop. It would be great for me because I would be able to use a full-sized keyboard and monitor for texting, which is something so many people want to do these days and I have to tell them to e-mail me instead because I don t like having conversations via text message. Not to mention all the other applications I could run."</post>
   <post id="bfdd2030-9cc8-4f12-8bab-d33b191341d4" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"aphexcoil said: ↑ Seems like with each news story related to Intel, they re falling further behind technologically. Click to expand... It is a matter of marketing Intel proceeded by dominating the x86 market and there for making a killing. Now that markets have shifted to other devices Intel can not leverage their chest pounding "x86 domination" any more since people in stock markets know that the technology is useful but it is not the only party in town any more. Since Intel is hell bent on doing things their way they lost track a long time ago of what would happen in the market. Windows for Intel (mobile) devices is not selling how hard they have been trying it is as dead as a doornail. Even when there trying to run Android on those devices it still does not want to make any waves in a matter where Intel could have some wiggle room to improve upon so market share can be captured and gained."</post>
   <post id="f3bd1459-d84b-46b1-8959-d2607f6917d1" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Intel is still relevant, but has not been innovative for years."</post>
   <post id="1c5cd762-3603-4e69-8ade-a017b216ac0c" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Good god not another uninformed thread like the last one......"</post>
   <post id="bf7cdd0f-fc83-4222-acfd-07dfed92b8a3" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Yakk said: ↑ Intel is still relevant, but has not been innovative for years. Click to expand... Bullshit"</post>
   <post id="318a3298-7985-4875-aac4-055543401052" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"Intel powers a HUGE chunk of hardware from car engine control modules to a crap load of embedded devices. they are not going anywhere anytime soon Core series has a huge jump over Pentium 4 and Sandy Bridge was a huge improvement over Core. Atom has made leaps and bounds since it s introduction and the current one is great for powering tablets. The problem the entire industry faces is related to process improvement/shrinks and that is going to get that much harder as they near the absolute limits...."</post>
   <post id="31274ff8-f3db-4631-aaca-93d1e7b94157" section="Intel Processors" discussion="Is Intel becoming irrelevant?">"SomeGuy133 said: ↑ Bullshit Click to expand... Yeah 3 to 5 percent improvement over previous generation cpu and requiring brand spanking new hardware each time is innovative"</post>
   <post id="ffed4d4e-94e5-41a9-904c-439202998a3e" section="Intel Processors" discussion="Xeon benchmarks.">"Xeon benchmarks. Need translator. Inside Your Xeon E5 V4 : 22코어 브로드웰-EP 전격 대해부"</post>
   <post id="a747f71a-904a-489c-9a79-2026c49a25f7" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Edit: I wanted to include this in the first post since the information is super important as so people when trying to find there max overclocks they don t damage there brand new cpus. Please do not exceed these values as a safety precaution if you don t wan t to fry your brand new 32nm cpu Zoson [H]ardness Supreme, 13.1 Years vCore: 1.45v CPU PLL: 1.9v QPI/UCLK/Vtt: 1.35v vDDR: 1.65v (Possibly QPI+0.5v) IOH/ICH: 1.25v PCI-E: 1.51v Here s the datasheet for reference http://www.intel.com/content/dam/www...heet-vol-1.pdf Click to expand... Edit#2 Everyone be aware of how easy it is to bend pins on the motherboard if its done in a rush or not placed down on the side when doing the swap. Bent pins will rune your board and cause you to have a really bad day. Take your time and be careful and or you could be shopping for a new board before you even get started. Wanted to start a new thread dedicated to using x58 1366 platform and using the popular used xeon 6 core cpu s going around everywhere ...back in the day we paid over 300 dollars for 920 cpus but now a days were flying with 44000mhz 6 core cpus sometimes at prices under 100 bucks a pop. Thats an unbelievable price per performance in my opinion The last thread i started has over 65000 views and takes quite a wile to read threw. Anybody still running a socket 1366 motherboard might be better off just throwing in a hexa core cpu and overclocking it versus spending several hundred dollars upgrading the hole thing system....some of us love making the most of what we have...cause thats all we have. This thread is not to brag about how bad ass our system is, but rather share info helping each other getting the most for there money...and get there systems running best as possible with least amount of money spent. Thees still lots of people unaware there x58 system STILL has plenty of performance and yeas ahead of it....I be willing to bet our systems still overpower amd and or intel setups 5-6 years newer...i could be wrong but i think the benchmarks could prove it.... I m hoping to get lots of people posting there success stories or problems with as many screen shots as possible proving stability/ performance for our sometimes 6 year old systems .....This is my day day out clocks....it just works [/URL][/IMG] [/URL][/IMG] Edited to include first of many Deimos contributions Some nice modded Bioses http://www.bios-mods.com/ P6X58D Premium P6X58D-E P6T Deluxe (perfect for me) speed test after using the newest (Updated Modded) for my board Ill post more links in time as they come it [/URL][/IMG] [/URL][/IMG] Edit for new content: For eVGA X58 Classified (3way) rev 1.0 boards that don t support Westmere-EP Hexa Cores ChineseStunna posted some info on modding it so it can work with these http://forums.evga.com/x58-classifie...-m2211553.aspx http://forums.evga.com/132BLE758A1-R...-m2153248.aspx or this from tbob22 http://www.overclock.net/t/1461359/...eon-l5639-benchmarks-inside/290#post_21897471"</post>
   <post id="558065af-5b81-4af6-8981-2bee5146da41" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"hyper_pi_0.99 results [/URL][/IMG]"</post>
   <post id="4d076b92-7615-4b5b-b44c-ba85e9454069" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Moved at request of OP to Intel Processor Sub Section"</post>
   <post id="c95c4f6b-2715-4506-b358-5b411b0d2ad0" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Delid experiment on an X5670 Read fully before attempting this, my first recommendation is don t try it unless you like throwing money away. This is the naked X5670. Steps and tips: If anyone wants to give this a go it s actually pretty straight forward, here are my recommendations: Use a short box cutter blade (the type that is shaped like a triangle with a corner cut off) and use a pair of locking pliers to hold it, this gives you way more control over the blade and how much force to use when cutting the silicone, it will also save your fingers from pain. When cutting the silicone, press and wiggle the blade back and forth its much cleaner and easier this way, don t try to cut it by dragging the blade around the edge. Use only one blade Put your blade in to one corner, then use a pre-heated stove element to heat the spreader to melt the solder, the CPU will "pop" off (you will actually hear a "pop") leave the spreader on the element and lift off the CPU, slide the spreader off the element only after the CPU is removed otherwise it will just set again and you will have to heat it once more to remove it. Heat the remaining solder and wipe it off with something rather than try to cut it off with a blade, finish off with a polishing cloth to give it a good flat finish. Further notes: You must remove the retention clip otherwise your heatsink or waterblock will fail to make contact with the CPU core. There are two possible ways to do this: The easiest way is to remove the entire bracket by unscrewing it. Another, possibly better way is to remove the top part of the mechanism and lever, leaving the back plate and surround still on the board, this has the benefit of reducing the amount the motherboard flexes when pressure is applied to the socket. If you decide to go this route you need to make sure the HSF/WB sits completely inside the retention bracket (mine does with room to spare). When screwing on the HSF/WB it becomes very difficult to screw it on flat, don t be too concerned, just don t screw it on too tight or you will kill the CPU like I did As you screw the HSF/WB on get a torch and check the clearance of the HSF/WB, it should be around half a mm clearance between each edge of the socket and your HSF/WB, not enough pressure and the pins won t make adequate contact with the CPU, you may not get post or have only some of your RAM show up if you don t have enough pressure on the CPU. Final note: delid isn t worth the risk IMO, I killed a Xeon and an i7 930 from suspected over tightening of my WB, the CPU worked fine for quite a while but when I swapped out the motherboard I was careless and killed a couple of CPUs all too easily. The temp difference is marginal, my first impression was that there was a significant drop, and have seen others report that they can run lower volts on delided CPUs, however in my own testing on this platform where the lid is soldered on, I can t say for sure that there was any significant drop in temps and it made no difference to my overclocking. Asus P6X58D Premium + LSI 9211 RAID card The LSI 9211 can give a nice improvement for SSDs, even without raid the card will outperform the Marvel controller by 20% in maximum transfer speeds and 30% better access letency (this isn t really noticeable though as the access latency is in nanoseconds) The only caveats with this config is the boot times are glacial and the card will only work in one of the top two PCIe x16 slots (the bottom slot caused issues for me). The LSI also has lower access latency and CPU usage. Single disk performance Update 05/08/2014 - I can only seem to get my LSI 9211 to work in the top slot on both the Asus P6X58D Premium and the Asus Rampage III Extreme RAID 0 performance Some interesting results running RAID 0 on the built in controllers. I ran the same benchmark on the LSI with RAID 0 but for some reason I lost the screen shot. For some reason the LSI controller suffers in small file transfers when set up with a RAID 0 array, The ICH10R and even the Marvell bests the LSI controller in small file transfers. once file sizes go over 32MB though the LSI controller takes the lead by a wide margin, achieving a max transfer speed of around 1GB/s And this is the original configuration that I abandoned a while ago, its a 6 disk RAID 0 array with OCZ Vertex 3 120GB drives. As you can see, small file transfer performance is awful. The array is also pretty slow, the hardware is capable of around 3GB/s but going from 2 disks to 6 only increases max speed by 300MB/s X58 24GB RAM limit As far as I can tell this limit is only for the consumer CPUs (i7s). Intel ARK lists the i7s as having a 24GB limit but the Xeons are listed as having a 288GB limit. I can confirm that 48GB (6 x 8GB G.Skill RipjawsX) works on a Rampage III Extreme and the Asus P6X58D Premium. Total ram is useable during my testing, I used IBT on Windows 8.1 x64 and told it to use 40GB of ram and it happily filled it. Sisoft Sandra was also quite capable of filling it up. I have not personally noticed any difference with stability with the larger amount of ram with the same overclock. Memory overclocking In my own testing, the Xeons cannot overclock the ram without increasing BCLK, this is different from the i7 which allow ram overclocking without bumping BCLK. You must run with your ram at 1333 at stock clocks otherwise no POST. Also, overclocking memory results in higher temps on the CPU which may limit your CPU overclock. I wouldn t recommend going far beyond 1600mhz, even just a small increase of 150mhz over this bumped my temps by up to 9C. YMMV. There is another thread on this topic for the i7 4770k, same thing applies here. X5660 vs newer X79 based hardware There is a nice post over at overclock.net with in-depth comparisons between the X5660 vs newer systems, including a few gaming benchmarks with surprising results. [Official] - Xeon X5660-X58 Full Review, Discussion &amp; Comparison to X79 High-End CPUs [and Xeon L5639 benchmarks inside] - Longest Post Ever!!!"</post>
   <post id="a188d2cd-0051-48e5-bd09-9be4bd339cbb" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Deimos said: ↑ I ve just been posting about some issues I m having with my setup, I m taking a break from tweaking for a little while, give this new CPU some time to settle I guess. Currently running the same (X5670) @ 4.03 Ghz (24x168 BCLK) with Ram at 1:1 and 1.256V Temps are amazing. I ve had this system pass 24h Prime at 4.4Ghz (22x200 1.35V) but for some reason my X-Fi Titanium doesn t like it. Haven t had time to continue trying to resolve it, at this point I m considering upgrading to a newer sound card. I haven t actually tested the stability of my current overclock (4.03Ghz) because I m desperate to just play some games (with sound LOL) especially Watch_dogs, I have very limited alone time at the moment and frankly I would rather play games than spend time tweaking. Click to expand... So is your sound working fine at the lower clocks? Yea that could make me crazy as well...luckily the sound blaster Z has has shown no problems here. It seemed like i was passing 9 out of 10 tests at 4400mhz but maybe it just wasn t meant to be idk.......im going to focus on getting it stable a 4200mhz in the mean time. 21x instead of 22x.........as much as i hate to do so"</post>
   <post id="f7f81b4a-6d7e-43d9-bc93-6b6af71738b7" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"I thought my sound was working at the lower clock but I loaded watch dogs last night and the sound cut out after a couple of minutes. It turns out it was the PSU, 3.3V was only at 3V, I swapped out the PSU and all is fine now at 4.4Ghz..."</post>
   <post id="ab7d11c7-8827-41ec-af14-8db04bf2417e" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Deimos said: ↑ I thought my sound was working at the lower clock but I loaded watch dogs last night and the sound cut out after a couple of minutes. It turns out it was the PSU, 3.3V was only at 3V, I swapped out the PSU and all is fine now at 4.4Ghz... Click to expand... awesome news...great troubleshooting there!"</post>
   <post id="b203cf45-ce4e-48d1-bf73-f7e03fcdf9ee" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"back to 4400mhz...gonna keep at it as long as it takes [/URL][/IMG]"</post>
   <post id="5744a7d1-b75a-4ee6-a0ee-32a444f04800" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"I heard that IBT is really no good for stability testing, even prime95 apparently. there is some other testing suite that will test every part of the CPU instead of just the narrow band of functions that IBT and P95 test, I forget what software it is though. Someone recommended the stress test built in to SiSoft Sandra..."</post>
   <post id="88a9a539-8892-4a79-a02b-c91f0751c6dc" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Deimos said: ↑ I heard that IBT is really no good for stability testing, even prime95 apparently. there is some other testing suite that will test every part of the CPU instead of just the narrow band of functions that IBT and P95 test, I forget what software it is though. Someone recommended the stress test built in to SiSoft Sandra... Click to expand... going to give occt an hour to see if it finds any errors..and update results"</post>
   <post id="15bdb61d-6624-43db-a256-211691b0dde3" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"primetime said: ↑ So is your sound working fine at the lower clocks? Yea that could make me crazy as well...luckily the sound blaster Z has has shown no problems here. It seemed like i was passing 9 out of 10 tests at 4400mhz but maybe it just wasn t meant to be idk.......im going to focus on getting it stable a 4200mhz in the mean time. 21x instead of 22x.........as much as i hate to do so Click to expand... What tests are you failing exactly? You have an awfully low Vcore in that screenshot @ 4.4Ghz..Don t be afraid to feed these chips voltage, anything up to 1.45V is fine, although I doubt you would need more then 1.4V to reach 4.5Ghz..Many people will feed them 1.5V+, although I wouldn t recommend that on air, as your one core is already pushing close to 80C..The "Westmere" cores in these CPU s are built on the same process as Sandy Bridge, and we all know how much SB loves Voltage..There are guys that have been running extreme 5Ghz+ O/C s on the 2500/2600K s since launch day, what 3~3.5 years ago? Are you running 3 X4GB of ram? Or 6x2GB? If it is the latter, your IMC likely needs more voltage, even running the ram @ 1600Mhz. Deimos said: ↑ I heard that IBT is really no good for stability testing, even prime95 apparently. there is some other testing suite that will test every part of the CPU instead of just the narrow band of functions that IBT and P95 test, I forget what software it is though. Someone recommended the stress test built in to SiSoft Sandra... Click to expand... What? IBT is fine, as long as you test it properly. You need to run it on "Xtreme Mode" with all available ram. The best way to test with it is to launch the program, and then open task manager and lock the core affinity to the physical cores, in the OP s case Cores 0,1,2,8,9, and 10. There is nothing wrong with using Prime95 either. It uses all available threads and uses the maximum amount of power of all the stres tests, thus producing the most amount of heat which is key to determining if your O/C is stable."</post>
   <post id="bc77250b-a61b-4ab7-85ff-f05f5e3f4f93" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"What? IBT is fine, as long as you test it properly. You need to run it on "Xtreme Mode" with all available ram. The best way to test with it is to launch the program, and then open task manager and lock the core affinity to the physical cores, in the OP s case Cores 0,1,2,8,9, and 10. Click to expand... then open task manager and lock the core affinity to the physical cores, in the OP s case Cores 0,1,2,8,9, and 10. i never heard of doing this before....what does this achieve? was a little warmer than usual today and without custom water cooling i do the next best thing: [/URL][/IMG] i have passed multiple burn test of hyper pi, sanda, pime95, occt (linpack and the other) but i fail this one about 1 out of 5 times.....pc just turned off like the power supply gave up or something during the very last time i tried this test ( i remember malwabytes asking to do a scan..... i figured wth not?...it was like flipping a switch...im open to ideas as its 100% stable in everything else.....i probably logged over 300 hours on bf4 and never a crash some im not to worried about it. this time it looks like it will pass no problem [/URL][/IMG] [/URL][/IMG] well"</post>
   <post id="8a572ff4-49d2-4e43-845f-2d9d14032f0f" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"primetime said: ↑ then open task manager and lock the core affinity to the physical cores, in the OP s case Cores 0,1,2,8,9, and 10. i never heard of doing this before....what does this achieve? was a little warmer than usual today and without custom water cooling i do the next best thing: Click to expand... it make IBT run without hyperthreading, processing only the true cores, making it more stressful and even making the processor to have better performance. it was discovered long time ago with i5 scoring better speed in IBT due to the way IBT process each core."</post>
   <post id="a60c0fbb-aadd-4bf6-aea8-961f32a4d545" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Araxie said: ↑ it make IBT run without hyperthreading, processing only the true cores, making it more stressful and even making the processor to have better performance. it was discovered long time ago with i5 scoring better speed in IBT due to the way IBT process each core. Click to expand... well ill be damed...i never ever would have knownShit so know i have to do the hole dam test over again because i didn t do it correct? that will have to wait for sleep time...I be honest with yea....what maybe 1% of people that even use IBT even know about this? Or i been living under a rock? Shit...and also you saying my system might not be stable......thanks for the info anyway"</post>
   <post id="e6292e88-183b-495a-b09d-9caeadc20471" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"ccityinstaller said: ↑ What tests are you failing exactly? You have an awfully low Vcore in that screenshot @ 4.4Ghz..Don t be afraid to feed these chips voltage, anything up to 1.45V is fine, although I doubt you would need more then 1.4V to reach 4.5Ghz..Many people will feed them 1.5V+, although I wouldn t recommend that on air, as your one core is already pushing close to 80C..The "Westmere" cores in these CPU s are built on the same process as Sandy Bridge, and we all know how much SB loves Voltage..There are guys that have been running extreme 5Ghz+ O/C s on the 2500/2600K s since launch day, what 3~3.5 years ago? Are you running 3 X4GB of ram? Or 6x2GB? If it is the latter, your IMC likely needs more voltage, even running the ram @ 1600Mhz. What? IBT is fine, as long as you test it properly. You need to run it on "Xtreme Mode" with all available ram. The best way to test with it is to launch the program, and then open task manager and lock the core affinity to the physical cores, in the OP s case Cores 0,1,2,8,9, and 10. There is nothing wrong with using Prime95 either. It uses all available threads and uses the maximum amount of power of all the stres tests, thus producing the most amount of heat which is key to determining if your O/C is stable. Click to expand... i discuss the voltage are another time....but regarding ibt...trying to use your settings it only seems to be using 36% now versus 100% before...what am i doing wrong? This cant be right, what im i misunderstanding? should i disable hyper threading in bios or something?"</post>
   <post id="3c60c53b-3e48-44b6-a093-f8b17f9aa5e7" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"primetime said: ↑ i discuss the voltage are another time....but regarding ibt...trying to use your settings it only seems to be using 36% now versus 100% before...what am i doing wrong? This cant be right, what im i misunderstanding? should i disable hyper threading in bios or something? Click to expand... just disable half of available processors. you probably have in the set affinity setup: CPU 0 - CPU 1 - CPU 2 - CPU 3 - CPU 4 - CPU 5 - CPU 6 - CPU 7 - CPU 8 - CPU 9 - CPU 10 - CPU 11 - CPU 12. you have to uncheck 1-3-5-7-9-11. that just to make it easy to disable hyperthreading anytime fast without reboot. in any case disable hyperthreading in Bios its the same."</post>
   <post id="3e3fde24-fb64-410f-8a9a-d8828d45141b" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Araxie said: ↑ just disable half of available processors. you probably have in the set affinity setup: CPU 0 - CPU 1 - CPU 2 - CPU 3 - CPU 4 - CPU 5 - CPU 6 - CPU 7 - CPU 8 - CPU 9 - CPU 10 - CPU 11 - CPU 12. you have to uncheck 1-3-5-7-9-11. that just to make it easy to disable hyperthreading anytime fast without reboot. in any case disable hyperthreading in Bios its the same. Click to expand... seriously this cant be right lol im pushing 22% how is that stressing my cpu? [/URL][/IMG] edit...im i doing the wrong process? should it be line pack possibly? this is what i did according to both of your instructions....i apologize if i seem a little "drunk as fuck" [/URL][/IMG]"</post>
   <post id="ee0fe346-6db9-4454-b6a3-cbf8815bfd0e" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"primetime said: ↑ seriously this cant be right lol im pushing 22% how is that stressing my cpu? [/URL][/IMG] Click to expand... Don t worry about seeing the CPU usage. If you properly disable the hyperthreaded cores, you should sit right @ 50% usage..The important thing is that you watch the GFlops output in IBT..They should be higher then they were in your screenshot above.. It appears that you only have 3 cores active..Notice that 2 of them are running @ 100%, and the third is loaded heavily as well..You may need to play around with which cores to turn off since a Xeon is different then the native 4 core dies with HT..with those, you just do like Axarie said and turn off the odd number cores.. In your case, based on your screenshot from before, it appears that cores 0,1,2 and 8,9,10 are the physical cores in your CPU..Try locking IBT to those cores, and monitor the GFlop output..it should be higher then those results in your first screenshot. It seems like you are stable, if you can pass everything you have and been able to game without issues as well. The issue where the system was doing a hard power off when loaded is most likely due to the Vcore being too low.. I had that issue when fine tuning my 3770K on my MSI Z77 MPower..Everything would be stable for hours and hours, and then I would get a random hard reboot. I had to boost my Vcore and then give my IMC a tiny bit of juice as well."</post>
   <post id="9dfd072c-ef5b-4333-af12-e25a54909c86" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Primetime how in the hell are your temps so low? according to my temp monitor my X5670 idles at 31C load as high as 85C and I have a pretty hardcore watercooling setup, what gives? I m starting to think that maybe the method I use to apply thermal paste is not ideal, I m going to have another crack at it, any tips from your obviously superior method?"</post>
   <post id="9e4c053b-f3e7-4d27-bd86-25e95cd2885c" section="Intel Processors" discussion="1366 x58 Xeon Enthusiast overclocks club">"Sorted. Looks like I put too much AS5 on there, I was using the "mound" method. Switch to some generic looking prolimatech compound I had lying around and switched back to the "thin spread" method and my temps dropped by 15C Further tweaking might be warranted, I m not sure the water block is applying good pressure on the socket and my application of the compound was hasty, I ll have another fiddle later on tonight and see what happens. I can definitely see room for improvement, just noticed that half my cores have now gone 5C higher than before I changed the compound."</post>
   <post id="58af28da-a196-4619-aaed-89832e41886c" section="Intel Processors" discussion="771 to 775 mod">"I gave this a shot. Ordered one of the little stickers. It worked for me with a GA-G31M-S2L and E5335 I had laying around"</post>
   <post id="ed0cd755-5cb7-43ca-8973-d66ca53e0c37" section="Intel Processors" discussion="771 to 775 mod">"Ive got one machine running for about 4 months now with the tape mod...no problems so far eBay is loaded with the stickers if anyone needs them..just search 771/775"</post>
   <post id="ec9c78f0-522a-49ca-869e-e5563eef6d50" section="Intel Processors" discussion="771 to 775 mod">"I guess the question for me now is... "What do I do with it?" The board only supports 4GB across two DIMM slots, and it s nothing fancy in and of itself. I suppose I could replace my file server s guts (runs on a sempron 145) but then the Xeon could be a little more power hungry. What to do... what to do...?"</post>
   <post id="ee3e7b3d-838d-4cb1-80f0-2bc35e913e2f" section="Intel Processors" discussion="771 to 775 mod">"Hmmm....interesting. Gotta figure out if it s worth it in cost for one of my older systems."</post>
   <post id="41641ef0-c31f-4421-b32c-e77f3f44c168" section="Intel Processors" discussion="771 to 775 mod">"Dangman said: ↑ Hmmm....interesting. Gotta figure out if it s worth it in cost for one of my older systems. Click to expand... depends on how much you wind up paying for the Xeon I suppose. I had a pair of E5335 s layin  around from a retired server. Most people seem to shooting for Q9650 equivalent-type stuff like E5640 s. For me it was worth the inflated $8 I paid for one little sticker just for the giggles since I already had all the other stuff."</post>
   <post id="5bd0fd7f-77f4-4c15-9d50-6e3508e7e06e" section="Intel Processors" discussion="771 to 775 mod">"too bad this wasn t figured out YEARS ago! This is a very interesting mod! Will for sure increase the value of some xeons on ebay."</post>
   <post id="891f9ffa-8cf4-4d2f-b005-0762eb02f23c" section="Intel Processors" discussion="771 to 775 mod">"Tried it on my Gigabyte 965p-DS3 v1. No workie. Need a version 3.x. Oh well, got a Q6600 from eBay for $30 after shipping as well, and that one worked... Rocking at 3GHz..."</post>
   <post id="8913209f-13d9-472c-8fdd-6f71ad753cb0" section="Intel Processors" discussion="771 to 775 mod">"I did it. I can take my E5450 all the way to the FSB limit of my MSI P35 Platinum. It seems most boards that support 45nm quads will work whit the 54xx Xeons except for X38 and X48 for some reason. I was about to build a Haswelll rig but with this I ll hold off another year or more. These are some pretty good CPUs when clocked over 4ghz. Now I need to get a GPU.."</post>
   <post id="1b295402-bacc-489e-8056-7d730b369563" section="Intel Processors" discussion="771 to 775 mod">"At the expense of sounding stupid what exactly does that pin "sticker" do that makes them work in an LGA 775 motherboard?"</post>
   <post id="8c1ad030-3761-48fe-b0a5-dc59efc79e05" section="Intel Processors" discussion="771 to 775 mod">"Format _C: said: ↑ At the expense of sounding stupid what exactly does that pin "sticker" do that makes them work in an LGA 775 motherboard? Click to expand... Blocks the contacts that are not needed."</post>
   <post id="649f8aed-d6b9-4be0-97dc-668b5ac2d928" section="Intel Processors" discussion="771 to 775 mod">"Format _C: said: ↑ At the expense of sounding stupid what exactly does that pin "sticker" do that makes them work in an LGA 775 motherboard? Click to expand... There s two parts to the equation. You have to shave off the socket guides in the 775 socket because the 771 CPU will be inserted into the 775 socket positioned 90 degrees from its typical orientation in a 771 socket. The sticker literally just swaps the two affected pins jmilcher said: ↑ Blocks the contacts that are not needed. Click to expand... Nope, those lands on the CPU are definitely necessary, if they weren t you could pull this off with a simple tape mask instead of needing the little custom sticker."</post>
   <post id="63e6188e-5083-4724-80b4-32e36e6e5908" section="Intel Processors" discussion="771 to 775 mod">"Format _C: said: ↑ At the expense of sounding stupid what exactly does that pin "sticker" do that makes them work in an LGA 775 motherboard? Click to expand... It flips two pins with each other.There are holes so the other pins still make contact. 771 is keyed on the other sides so the keys on the socket have to be cut off with a razor. You have to be sure to put CPUs it in the right way without them."</post>
   <post id="6979ed10-834f-419e-a477-f9a1af1fd096" section="Intel Processors" discussion="771 to 775 mod">"Nice job! I love seeing hardware being modified to get around manufacturer limitations. I guess you could always use it as an HTPC or make it a file server to run a Plex stream. I have never done it since all my HTPCs are fast enough to decode HD on their own."</post>
   <post id="4c597a6b-d644-4bd0-8633-204757de97c2" section="Intel Processors" discussion="771 to 775 mod">"At 4.2ghz a Herpertown is faster than a i5 4430. At 4.0 it still faster than i3 especially in multithreaded stuff. These Xeons overclock quite well and their performance scales very well with clockspeed. The real drawback is the outdated platform. I ll just upgrade what I can carry over to my next rig. I already got a new PSU, now I need a GPU and a bigger SSD. It ll hold me off until 14nm and DDR4 or longer. Maybe this rig will last me 10 years."</post>
   <post id="4a6bdb73-df92-4207-9628-4be02bb59db8" section="Intel Processors" discussion="771 to 775 mod">"I m in on this! Picked up a sticker and L5410 for $29 shipped. Should be able to sell my E8400 for around $20 after the swap Been wanting to upgrade to a quad core for a while, but didn t want to invest a lot of money in my old platform. Running a P5K Deluxe with 6gb and E8400, 7850, 750 watt PSU, SSD, couple of drives, etc. Basically a good system with an aging board and processor."</post>
   <post id="8aded865-31ed-40f1-8eb8-56cb6b9fe94e" section="Intel Processors" discussion="771 to 775 mod">"I ordered another E5450 SLBBM for my Wife s Biostar G41 DVI. It will overclock it a little bit. My first one was $40, this one was $50. Still worth it. Here it is at 4.2 in Pass Mark compared to non-K Haswells At 4.2 is about equal to a 4440 Haswell i5 in all the benchmarks I ve ran."</post>
   <post id="276895d3-ee0f-427e-be99-4f45855a53bd" section="Intel Processors" discussion="771 to 775 mod">"$29 for the CPU and sticker and I m up and running. I killed a fucking P5K Deluxe by accidentally putting it in the wrong way, but I had another board and I m up and running on that: Motherboard is a Gigabyte P35-DS3L running bios F9 (no modifications)."</post>
   <post id="e528021e-071f-45c7-90f5-fad8eddf165a" section="Intel Processors" discussion="771 to 775 mod">"Couldn t overclock much; locked mult @ 7x and the mobo doesn t seem to like 400fsb, so I stopped at 366. Still, for $29 with everything included, it s a nice upgrade from 2 core to 4 core and a lot more cache (while using significantly less power)."</post>
   <post id="8740ad23-f980-43f8-a672-abb358e418ec" section="Intel Processors" discussion="771 to 775 mod">"The fact that this even works is pretty insulting, shame on Intel"</post>
   <post id="648a3952-7693-4599-924a-dfa3f80e9993" section="Intel Processors" discussion="771 to 775 mod">"The ability of these Xeons to overclock so well just makes me depressed. The E5-2687W and it s big brother, the E5-2697V2 run so cool at default, it s maddening to imagine what these chips would be capable of running at if they were unlocked. They clearly have an incredible amount of headroom and they d be absolute monsters if they were able to be pushed. So much performance wasted...it s enought to make an enthusiast cry...."</post>
   <post id="ec0358b9-13af-4725-8d9c-f9b73f214d88" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"About 6 months ago I upgraded from a GTX970 to a 980Ti... when I did that, I had to upgrade my old 750w PSU to a new EVGA B2 850w... I m running a 2500k on the Asus P8Z68-M Pro, and it "was" Auto-OC to 4.3GHz... I ve been contemplating an upgrade to the new 6600k... (board, proc and RAM @ $450) But Just today I decided to finally get the latest version of ASUS AI Suite and run the Auto-OC with my 850W PSU... The i5-2500k is now running at 4.9GHz!!! Temps are cool while gaming (@34c), and runs perfectly stable.... (CORRECTION - 34c is idle... hitting @64c while gaming...) I don t care for tinkering anymore, I like Auto-OC... so with that in mind, should I even bother with a 6600k? Or just keep my 2500k at 4.9??? If I could only get the 6600k to 4.4 or 4.5.... would it even be worth the money? Based on what I m seeing online... the 6600k does perform better, clock-4-clock... and I would get a huge benefit from other processing tasks... but for gaming (the only thing I care about), the benefit would be minimal, especially if I could only get a low OC out of it. Seems my money would be better invested in a PCIe - M.2 adapter and M.2 SSD, along with selling the 980Ti to get a 1080..."</post>
   <post id="5553ceb0-56ec-46d9-884a-5d273c7743ce" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"You won t be able to upgrade that processor without a new motherboard to go with it. Yours is LGA 1155, Skylake is LGA 1151. For gaming, I wouldn t bother upgrading it. But if you want to do something like use an NVMe drive or use USB 3, then you need a new platform to do that anyway. Essentially, the only reason to upgrade a processor these days is because you need new chipset features, and most of the time, a PCI-E expansion card is "good enough" to add functionality to your system. The downside is that you only have so many PCI-E lanes, and the more of them you have to use, the more lanes get taken away from your graphics card and the more likely you are to feel a performance hit. So there are real benefits to an upgrade, but I wouldn t say that any of those benefits are important for gaming."</post>
   <post id="323d3a2b-f726-4657-b9d4-090de5a40aed" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"Yeah, I mentioned that my priced out upgrade would be around $450 (and that s for a moderate board in the $160 price range)... And that s why I m questioning whether it would even be worth it for gaming..."</post>
   <post id="222cd246-092e-422f-83dd-c5570cf29d57" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"Wow, you got a great OC. Even if we are to assume a 25% IPC increase with Skylake over Sandybridge, your overclocked 2500k is the equivalent of a stock 6600k (and I would venture to say that in gaming scenarios, the difference isn t anywhere near 25%) Once again, athenian200 highlighted that the benefits of upgrading are for the additional features that the Z170 chipset offers. Only you can answer whether that is worth $450 to you, but personally, I wouldn t bother. At the very least, see what Kirby Lake and Zen brings to the table before considering upgrading your platform. Personally, going from 4 core to a moderatelly faster 4 core isn t a tangible increase."</post>
   <post id="cf014311-4776-4365-a49f-d9ecd8db4e83" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"Thanks guys... just wanted to make sure I was looking at this logically."</post>
   <post id="0589889c-29d0-4c6e-9c3c-b12c92485aa5" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"Do you live in a freezer, or are you using a refrigerated cooling setup? Because ~34c is what most people would get at IDLE with a room temperature of around 23-24c."</post>
   <post id="169539a3-06ab-44b6-862b-f4841c495dbd" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"doubletake said: ↑ Do you live in a freezer, or are you using a refrigerated cooling setup? Because ~34c is what most people would get at IDLE with a room temperature of around 23-24c. Click to expand... SORRY.... Typo.... 34c is idle... @64c gaming (I will confirm this soon) ... utilization bounces between 50% and 80%. I saw an increase in FireStrike min-FPS from 24 up to 30 (1080p), didn t expect that... Air Cooling with a Hyper EVO 212"</post>
   <post id="acffe8e0-cf53-46d2-b599-5fe4c1c5ada5" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"wow nice draw in the silicon lottery! Personally I wouldn t upgrade unless it was for NVMe booting or USB 3.0 integration (if your ASMedia chip isn t acting up). In your case since your OC is so good, I d probably wait out this whole M.2/U.2/SATA express fiasco."</post>
   <post id="4b26db63-2d6a-4dac-aaf1-53094cdf112e" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"rastaban said: ↑ wow nice draw in the silicon lottery! Personally I wouldn t upgrade unless it was for NVMe booting or USB 3.0 integration (if your ASMedia chip isn t acting up). In your case since your OC is so good, I d probably wait out this whole M.2/U.2/SATA express fiasco. Click to expand... Yeah... I had always only gotten low, or moderate overclocks and had always attributed it to just bad luck of the draw.... So I was surprised at just how much influence a quality power supply really matters. Probably because everybody just spouts out crap like ... "your PSU sucks, you need to upgrade"... without offering any practical information regarding a direct experience. Anyway, I did some more testing last night and the numbers are actually better than I had recalled above.... Idle - 30c Gaming - 50c peak temp, 40c avg... 60% peak use, 35% avg - Shadow of Mordor and the new Tomb Raider... 1440 res (1.5x scaling on 1080p TV), everything on Ultra (with FXAA)... Barely ever drops below 60fps Full load - 76c Given these results.... I think I will just stick with this setup for a while.... I plan to get a 4K 35" Ultra wide Curved Gsync display and the GTX 1080 (or 1080Ti, depending on time frame).... Seems as though going to 4K gaming should keep my 2500k in the game for a while longer. Keeping that in mind... I think I will go ahead and look at a PCI-e expansion m.2 upgrade.... Then when I actually do a full system upgrade, I ll see what s been solidified as a standard after the dust settles.... but 2GB/s is still going to be a huge upgrade from my 450MB/s SSD at the moment."</post>
   <post id="870a1551-1a1b-4733-a1d9-17f4d1711c9a" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"if you were aiming for 1080p 144fps and were still happy to oc then a new cpu may be worth it otherwise i wouldnt bother m.2 ssd dont seem to make a huge difference to load times these seem to be affected more by cpu\ram performance lol shadow of mordor that game is so badly gpu bottlnecked a pentium can beat a 6700k CPU Benchmarks - Compare Products on AnandTech CPU Benchmarks - Compare Products on AnandTech"</post>
   <post id="589c55ee-b4d0-4898-b2e9-12b8d020b26e" section="Intel Processors" discussion="Keep my i5-2500k @4.9? Or go 6600k?">"That chart looks similar to the results from Digital Foundry... I had seen that before as well. However, I plan to game at 4K once I get the GTX 1080 and the 35" wide screen, that should shift any bottle neck over to the GPU with the extra work it will have to do to run games at 4K. In any case... I m going to start there and see what the results are before I spend the extra money on the new parts to go with a new CPU. It will be a while, but I ll post my results here."</post>
   <post id="04e78ddb-08fe-4507-a10d-87d70894f2b7" section="Intel Processors" discussion="is a intel 2500k getting too old???">"Im stll running a 2500k at 2.8 ghz. Im going to upgrade from my gtx 970 to a 1070. When is the point that the processor is going to bottleneck me? It seems to run everything great. I just want to know when is it time to drop the $$$ and upgrade? Im still a noob in this forum but thanks for any insight."</post>
   <post id="993a0c33-acb1-462f-9722-43ba98439a13" section="Intel Processors" discussion="is a intel 2500k getting too old???">"A processor is too old when it stops doing what you want it to do."</post>
   <post id="00ce4c36-e593-433e-b6c9-724cc444d84b" section="Intel Processors" discussion="is a intel 2500k getting too old???">"You should easily be able to get 4.5-4.6GHz out of that chip with sufficient cooling, so unless you aren t willing to OC (in which case don t bother with a K variant next time around, just save the cash) you can get a ~40% clock boost vs stock and get some more time out of it considering you say it s working well for you now. Why are you running it at 2.8 when stock is 3.3?"</post>
   <post id="389a1cf8-000d-4cfe-8f98-8bb85d16c596" section="Intel Processors" discussion="is a intel 2500k getting too old???">"rpbbmw said: ↑ 2500k at 2.8 ghz. Click to expand... WTF why? My 2500k @ 5Ghz is a beast in my secondary rig."</post>
   <post id="a97504d5-7e3d-4076-a172-8722ea717ced" section="Intel Processors" discussion="is a intel 2500k getting too old???">"Trimlock said: ↑ A processor is too old when it stops doing what you want it to do. Click to expand... This. A 920 and 980x are still viable for many games with modern video cards. Simply depends on the game, screen resolution, and your expectations."</post>
   <post id="7a56dbb8-c3db-406c-9794-b392cebd520e" section="Intel Processors" discussion="is a intel 2500k getting too old???">"I bet that if you OC your processor that you ll be right there neck in neck with a 4770K or really close to it. Here is a CPU comparison with the new Doom game that came out yesterday. Lots of life left in your processor."</post>
   <post id="9415186e-8a7f-4977-83fd-dc2b3d896471" section="Intel Processors" discussion="is a intel 2500k getting too old???">"Tsumi said: ↑ This. A 920 and 980x are still viable for many games with modern video cards. Simply depends on the game, screen resolution, and your expectations. Click to expand... Yeah, this. My i5 750 still performs shocking well considering its age."</post>
   <post id="003f8176-11b8-4a1c-8175-01a224cb0484" section="Intel Processors" discussion="is a intel 2500k getting too old???">"I was just pondering this same question... The answer depends on what you do with your computer. Just Gaming? (Or, primarily gaming?) Given the upgrade to the GTX 1080, if you are playing games at 1080p, then you will likley see a nice boost in performance if you go to the i5-6600k... (I5-6500 if you dont want to overclock). If you play at 4k res, the 2500k is probably going to be just fine. Might be a little gain from an upgrade, but probably not worth the cost. At 4k res gaming, it would be better to see if you can OC that 2500k a bit more to get the extra performance with out spending more money. Video or audio encoding? You will definity see a benefit to an upgrade to the 6600k or 6500. This would include playing instruments through an amp simulator, making backups of DVDs or BluRays, Compiling your own videos to upload to the internet... Some video encoding programs will use NVidia CUDA cores, and in that case the newer 6500 / 6600k probably won t matter much. Overclocking. You have to consider 3 things to OC the chip. CPU Cooler, motherboard, and power supply. For this discussion, know that each component can hold you back... So a high grade motherboard and cpu cooler will still not produce a high overclock when using a mediocre power supply.... All other combinations apply as well. Motherboard - First, your MB has to support overclocking. 3.8GHz is quite low for the 2500k, goven that 3.7GHz is the built-in boost clock speed. Cooler - The stock cooler can get you from 4.3 to 4.5. Somthing like the Cooler Master 212 EVO can get you up to 5GHz, but it s big anf you need a big case. I think the H5 variant is smaller, and just as affordable. Power Supply - Cheap psu means low, or NO overclock. I used to think this was bullshit until i upgraded my power supply recently. I had a Cooler Master GX 750W psu, which was more than enough wattage for my system, but my 2500k never made it past 4.3GHz. I bought a GTX 980Ti and was forced to upgrade... Got an EVGA B2 850w and now my 2500k hits 4.9GHz. Note that it wasn t the difference from 750 to 850... But the old psu was low quality and the new one is much higher qaulity. A good 650w is usually better than a cheap 1000w (especially for overclocking) The simple answer is... Ok, no simple answer. Its based on what you do with your pc... Are you gaming at 1080p or 4k? Do you encode video or audio? What parts you have now, do you even care about overclocking? So.... More information will get more advice"</post>
   <post id="994f94a3-b56c-499c-906e-c0faea1ace50" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"So I ve been using an i7-920 for many years now and lately the machine just hasn t been stable. I want to upgrade but I feel like Skylake isn t well suited as I could use more than 4 cores (I ll use AWS sometimes for certain tasks). Right now there is a fire sale on these E5-2670 chips. They can be obtained for around $90 a pop, memory is dirt cheap as well. Basically I m debating if it makes sense to invest in Sandybridge until we see some new processors eg Skylake-E or the E5 V4s. Any thoughts on this? Am I better off just going with X99 or does this make sense?"</post>
   <post id="6d049f43-0a94-4b73-a4b8-cb1b86f147fb" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"If you are on a budget then you can t go wrong with Sandybridge. Some games that are heavily limited by a single thread will not perform as well due to the lower boost clock, and hopefully with DX12 that issue will go extinct. If money is no object then go with a X99 with a 5930K or 5960X and overclock - the overclock alone, disregarding the architectural improvements, will make it much better than the 2670 V1 (which benches like a 3930K in the 3DMark11 benchmark test)"</post>
   <post id="4d4bf3bd-2227-4f1b-9a0e-d00534c802f6" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Don t really play games but hey you never know. SB just seems so damn cheap. I mean my up front cost is 450 (2xCPU, 1 Dual Board and 32GB Ram). Overclocking isn t really an option. I d likely go with the E5 58xx equivalent which uses the C612 chipset along with ECC memory. Really looking for stability."</post>
   <post id="a9de1194-e0b6-43c5-837d-3a73984c7940" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"So you are more of a workstation user that will be using multithreaded applications? Yeah, it is a no brainer. 2X E5-2670s will beat the snot out of a single 5960X, even if that 5960X is over clocked like a raped ape. As for the equivalent on the server side, obviously the 2670 V1 won t be nearly as fast. But the COSTS! My god man, it s excessive going for the same thing compared to what you can get with the 2670 V1 at $90 to $110 per CPU (compared with $2500 or more per CPU)."</post>
   <post id="b0162932-aefe-4ec9-a3ae-fc08bec69142" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Also, the 2670 V1 supports ECC memory. Just get a board that does as well."</post>
   <post id="6b0bbcfb-0a7c-432e-8a94-45f7c1e5cb67" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Correct this is purely workstation"</post>
   <post id="a83f0d83-b4a3-4512-9f33-90c40376d718" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"For a workstation user coming from an i7 920, you will be extremely happy with a 2P E5 2670V1 system. There is no doubt about that - the difference will be rather, well, large. If you want the best, and have very (VERY) deep pockets, the equivalent on a C612 (or if you wait an unknown amount of time for the Skylake-E) will be better performance. Coming from an i7 920? Just go with that 2P Sandy and pocket all that extra money for a vacation. You ll be just as glad you did. Oh, and you can splurge on a really nice SSD (or one of those PCIE card SSDs) if you don t already have one with those savings, and experience even better workstation performance."</post>
   <post id="e6154818-8562-43db-86e7-4aae6f53e10d" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"No kidding for the C612 equivalent. To get reasonable performance in an 8 core chip you are looking at minimum $1000 per CPU. Just need to figure out what PSU now."</post>
   <post id="6e94bf5e-5a46-41b1-9cf5-c6fc37bcc5a1" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"If you go 2P, you ll want one with two 12V CPU cables - but I m sure you knew that. You can get consumer grade PSUs, even platinum rated, that have two. Usually they are higher wattage. I ve used a http://www.newegg.com/Product/Product.aspx?Item=N82E16817121089 back when I had a 2P AMD system, and it worked wonderfully - still use that same PSU in my desktop now. EDIT: FSP also makes good power supplies and they have good warranties on them (7 years!) - http://www.newegg.com/Product/Product.aspx?Item=N82E16817104192 should work nicely, but may be more than what you want/need. The 850W model looks to also have two 12V cables."</post>
   <post id="ba9820ac-bf6b-4c04-9280-3ead72bb15e7" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"arestavo said: ↑ If you go 2P, you ll want one with two 12V CPU cables - but I m sure you knew that. You can get consumer grade PSUs, even platinum rated, that have two. Usually they are higher wattage. I ve used a http://www.newegg.com/Product/Product.aspx?Item=N82E16817121089 back when I had a 2P AMD system, and it worked wonderfully - still use that same PSU in my desktop now. EDIT: FSP also makes good power supplies and they have good warranties on them (7 years!) - http://www.newegg.com/Product/Product.aspx?Item=N82E16817104192 should work nicely, but may be more than what you want/need. The 850W model looks to also have two 12V cables. Click to expand... Was actually considering the Corsair AXi series. Not sure if it makes more sense to get 860 or 1200."</post>
   <post id="757171ea-a7f7-446a-90c8-a1b960f9ecbe" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"I am running a E5-2670 on an Asus Sabertooth x79 board. Works great for crunching BOINC primegrid Waiting for the IVYbridge xeons to fall farther in price, I want a 12 core CPU."</post>
   <post id="47c041c9-786d-4708-86ff-51a52efe28d2" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"You can get the other cable for modular seasonic and others that don t come with it..."</post>
   <post id="da5c7145-6ad7-4c4e-925c-5962cc7af1f6" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"davewolfs said: ↑ Was actually considering the Corsair AXi series. Not sure if it makes more sense to get 860 or 1200. Click to expand... I am running a 2p e5-2670 machine with 2x gtx 980ti with the evga g2 850 psu. With both processors and both gpu maxed out I am drawing 700w max at the wall, so an 850 psu should be fine."</post>
   <post id="50ed4f22-1a62-43e7-ae58-3008586f95df" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Shumph said: ↑ I am running a 2p e5-2670 machine with 2x gtx 980ti with the evga g2 850 psu. With both processors and both gpu maxed out I am drawing 700w max at the wall, so an 850 psu should be fine. Click to expand... put some pics of that...sounds like a bad ass workstation"</post>
   <post id="02012ccd-6bb4-4a40-8a7e-0110963198a6" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"E5-2670, while 8c/16Ht, are not OCable. so you should consider going 2p with them if that tickles you. In your position i would keep the mobo and upgrade to a Xeon 1366, which are overcloable on most x58 mobos and can be found cheaper. From the X5650 to the x5690 , they all reach around 4.2GHz at a lower voltage than your 920. i found a direct comparison between 2p systems running E5-2670s and x5680s without overclock, For some task they are equal, for others they are up to 25% faster than X5690s. I run dual X5675 on EVGA SR2, and price wise, 2p G34 opterons mobo are (much)cheaper that 2p LGA2011 mobos, but cooling hardware LGA2011 is easier to find. personally, if i needed a build for many slow cores, i would go 4p G34, which are cheap and can be overclocked."</post>
   <post id="ac8494fb-21c4-4cca-8353-1e42c1b15bf7" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"You can get a 2P AMD board and two 12 core Operon 6172 with 2 heatsinks 75$ shipped lower 48 USA. Uses a standard PSU http://hardforum.com/showthread.php?t=1886166 I just ordered 2 xeon e5-2670 and a 2p board for them. For BOINC primegrid the xeons (Sandy-bridge or better) rock, for WCG the AMD hold their own. AMD 4P boards are still expensive, The ones for 100+ do not use a standard PSU I have two 4P AMD one socket G34 and one socket F, Two dual xeon e5620, one dual x5660, four single overclocked x5660 systems and the one 1P e5-2670. Keep in mind win7 can only see two processors, so you have to use a win server OS or Linux"</post>
   <post id="35fe3093-8894-4ff0-b2c6-84e78728b2e1" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Bill1024 said: ↑ You can get a 2P AMD board and two 12 core Operon 6172 with 2 heatsinks 75$ shipped lower 48 USA. Uses a standard PSU http://hardforum.com/showthread.php?t=1886166 I just ordered 2 xeon e5-2670 and a 2p board for them. For BOINC primegrid the xeons (Sandy-bridge or better) rock, for WCG the AMD hold their own. AMD 4P boards are still expensive, The ones for 100+ do not use a standard PSU I have two 4P AMD one socket G34 and one socket F, Two dual xeon e5620, one dual x5660, four single overclocked x5660 systems and the one 1P e5-2670. Keep in mind win7 can only see two processors, so you have to use a win server OS or Linux Click to expand... How much did you get your 2P board cost and what did you get?"</post>
   <post id="5cb25254-6c67-40df-b9a8-3d6c0b32e28f" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"davewolfs said: ↑ How much did you get your 2P board cost and what did you get? Click to expand... This is the 2P socket 2011 board. Bord came in today, waiting on the two e5-2670 to come. Paid 200$ for the two CPUs. I had a 50$ gift cert. for newegg so I used that to cut the cost. 279$ Not many cheap 2P 2011 out there. ASRock EP2C602 http://www.newegg.com/Product/Product.aspx?Item=N82E16813157352"</post>
   <post id="2afd8c2f-cfd8-479a-9567-5b1a610d2696" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"I ve been thinking about these ES chips on ebay and wanted to know if they are ok. http://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2047675.m570.l1313.TR0.TRC0.H0.XE5-2670V3+es.TRS0&amp;_nkw=E5-2670V3+es&amp;_sacat=0 Is there a post covering this? I ve found some old archived ones on reddit. 6core i7 vs 12core xeon processor hmm"</post>
   <post id="cd1efa7c-d97a-44ae-861e-a7fc48ba4e20" section="Intel Processors" discussion="Thoughts on first gen E5-2670">"Coming from a quasi-server usage standpoint, i find a LOT of use for the extra cores. Even a Q19D Xeon, with its low speed but 8 cores, is still quite a match for my X5650 at stock speeds. IMO, i would test first with a X56xx 1366 CPU. My X5650 did awesomely on anything it ran, way better than any 115x CPU, and even my old W3530. Plus, you save the RAM/Mobo updates as it is a ready upgrade for well under $100. Plus, it can be OCed, unlike the E5-2600 Xeons which are fully locked. If it does not work, i find X79 to still have a lot of life, as expected of any "big socket" platforms. Hell, if you ever need more muscle than 8 cores, you can get a E5 2695 v2 or higher, and get 12 cores for relatively cheap (compared to newer Haswell-E equivalents). Plus, server boards for Ivy-E for dual socket are cheap nowadays, to get up to 24 cores. Only get Haswell-E if you need way more power than that, core-wise. I really see no benefit of C60X chipsets over C61X chipsets (or X79 to X99). Maybe Intel s next chipset refresh may bring more improvements (like the Z170 for Skylake) but it is a long way until then."</post>
   <post id="9df233bc-ef84-4dc0-9473-8e52cbe11445" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I recently replaced aging hardware with Z170-based platforms in two machines as both were having issues with stability, issues which I was pretty sure were attributable to the original hardware. After a very drawn out installation period attempting to get either system to boot at all, I eventually traced the issue down to a faulty displayport cable stopping the machines from entering POST, which amusingly enough could power the graphics card and light the motherboard LEDs off the monitor without the PC s PSU even having a power cable plugged into it. With the displayport cable gone, both machines were upgraded and by and large they work. However, neither machine is much more stable than the pair they replaced, but for totally different reasons (better in one case, worse in the other). I find myself wondering, is there any likelihood that the stability issues affecting Skylake CPUs can affect regular usage (i.e. not running Prime95), or is it a technical impossibility? I wasn t sure whether the Prime calculation was one of the only rare cases to trigger the issue, or simply a test that would prompt it (for the same reason you might run it as a stress test to examine an overclock). Neither of the two PCs in question do anything particularly out of the ordinary and are used for entirely different purposes (both software and hardware configuration). The stability problem, however, manifests itself in exactly the same way for both PCs - the PC will  freeze  - image on the screen remains static, sound stops and loops (at about 50Hz, effectively sounding like a 50Hz square wave, a very loud one at that, in can sometimes be loud enough to make me reflexively throw my headphones off my head due to the sudden increase in volume), the PC will no longer to respond to a ping on its IP address (this is allowed normally), and even the reset button, which normally works on both PCs, will do nothing. The only fix is to either hold the power button for 5s, or turn off the PSU at the back and then re-power the machine. (Note I have not tested sound on the file server, but all other symptoms are identical) The gaming PC is shut down every night so typically has a maximum uptime of around 15 hours. The issue very rarely comes up at the desktop, I think I may have seen it once. The only game which seems to trigger it is Warframe, which is the game I play most often, so not a very fair test, but it must have happened maybe a dozen or so times, over the span of 2-3 months. The file server was only rebuilt at the beginning of March and is not of course used for games, but runs 24/7, and so far has had this happen three times. The PC is occasionally used as a terminal server (hence running Windows 10 rather than a server operating system), but at present the only real applications running are FileZilla Server, Backblaze, NZXT CAM and Synology DiskStation. I closed NZXT CAM immediately after boot on one occasion in case it was CAM responsible, to no avail. Perhaps unsurprisingly, there are no application event logs of note at the time when the issue occurs, other than the usual  previous system shutdown was unexpected  after reboot. Is this what people would expect to see from Skylake CPUs, or is the known bug something different? The Windows 10 installation on the file server was clean onto a reformatted disk with a new license at the time the hardware upgraded. Previous stability issues on both machines were BSOD related,  Memory Management  on the gaming PC which had always been triggered by its overclock but started to carry on at stock speeds, hence replacement.  Unexpected Kernel Mode Trap  came up on the server on average every 1-2 weeks, but could sometimes happen three times in a day, usually citing ntoskrnl.exe. I was less convinced this one was hardware, but as it happened more often in warmer weather, I figured given the age of the hardware I d replace it anyway. Clearly the previous behaviour was preferable as a PC that automatically reboots periodically is better than one that freezes and requires manual intervention to bring back. Current Specifications Voyager (Gaming PC) i5 6600 16GB Corsair Vengeance LPX 2400 (2x8GB) MSI Z170 Gaming Pro Corsair RM1000i Gainward GTX970 Crucial M500 480GB WD40EZRX, WD2002FAEX Windows 8.1 Pro x64 Intrepid (File Server) i5 6500 16GB Corsair Vengeance LPX 2400 (2x8GB) Gigabyte Z170-HD3P Corsair RM650 Adaptec 71605E Samsung 830 128GB WD20EARS x2, WD20EARX x2, WD30EZRX x6, WD30EFRX x2 WD40EFX x4, WD60EFRX x2 NZXT GRID+ v2 Windows 10 Pro x64 Previous Specifications Voyager (Gaming PC) i5 750 12GB Corsair XMS3 (2x4GB + 2x2GB) Gigabyte P55A-UD4 Zalman ZM850-HP Gainward GTX970 Crucial M500 480GB WD40EZRX, WD2002FAEX Windows 8.1 Pro x64 Intrepid (File Server) Core 2 Q9550 4GB Corsair XMS2 Dominator 8500 (2x2GB) Gigabyte X48-DS4 Corsair RM650 Adaptec 71605E Intel 320 series 40GB SSD WD20EARS x2, WD20EARX x2, WD30EZRX x6, WD30EFRX x2 WD40EFX x4, WD60EFRX x2 NZXT GRID+ v1 Windows 8.1 Pro x64 Does anyone think there is any likelihood that the known issues with Skylake CPUs could be causing this? If I m looking at something else, I m not entirely sure where to start. Environmental issues can probably be ruled out as the PCs do not freeze at the same time, and there are two other older systems in the same room which are entirely unaffected by these issues (i5 3470 based, and i5 4690S based). I will stress that the BIOS has not been updated on the MSI board as of yet - I understand that can potentially improve this issue, IF it s the cause. The Z170-HD3P BIOS was updated during the initial install issue with the displayport cable, as at the time I was unaware what the issue was. I m reluctant to blame hardware damage from the displayport cable incident as both systems are capable of often (but not always) running for over a week without this issue occurring. Running stress tests do not seem to provoke it. Grateful for any advice on this one! Thanks in advance Sam"</post>
   <post id="482c7d32-582d-40fb-b852-a8847648f2d1" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Cliff notes: Two Skylake builds with different hardware both experience a hard lockup where the screen freezes and sound loops. The only fix is to hold the power button for five seconds. What s up with that?!?"</post>
   <post id="022f8b6f-bd77-4f1d-96c0-923bb23f4a8b" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Yes, I really should have put a tl;dr in there, thanks for the synopsis!"</post>
   <post id="6dc70513-894f-4b5a-b494-2a805e4b30e5" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Are the computers plugged into the same outlet and/or sharing the mains with other high power draw things in your residence? Edit: are you also reusing the psu from the original builds? I find it hard to believe that two independent systems will display the same symptoms."</post>
   <post id="06054600-420d-4fc5-a40a-8ca277d22672" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"1. No - the PCs are actually on separate trailing sockets, each fed from sockets on opposite sides of the same room. 2. In one case (Voyager) no, the PSU was replaced at the same time as changing the CPU/board (it was 7 years old and had suspected stability problems on two of its rails, then unused due to downsizing my graphics), in the other case yes, the RM650 is common to the previous build but was only purchased a year or so ago as the original PSU in that system (a Nexus NX-5000) had a very noisy fan bearing so was replaced before the fan failed (and to provide more molex connections to avoid the use of splitters). I too find two machines with the same symptoms an odd situation, so given that they didn t before, I can only really point the finger at the things that have changed."</post>
   <post id="ab02fd8b-6ff2-438a-9fae-021af8497009" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I believe a lot of motherboards bios settings require almost perfect bios setting. (Mine included) Voltage settings being to low or to high here or there...yea its not going to be stable simple as that..It could be a memory settings with timings to tight or to fast...it wont be stable"</post>
   <post id="ce287b93-bce4-4f5b-a512-5de2dfd35e68" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Are you saying that with respect to Skylake or just PCs in general? That s a given with an overclocked CPU, but on a CPU model with a locked multiplier that s effectively not overclockable to begin with, that seems crazy. Previous generations were able to do this without issue. Essentially what i m trying to establish in this thread is if this is a potential liability with Skylake, I think I will try and get Haswell components to replace the Z170s in both machines and have done with it. However, that s a lot of effort and up-front expense to do without cause (The performance difference is not likely to be significant)."</post>
   <post id="b63dc81e-eaa6-4113-9be9-a1371a97e54c" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"samuelmorris said: ↑ Are you saying that with respect to Skylake or just PCs in general? That s a given with an overclocked CPU, but on a CPU model with a locked multiplier that s effectively not overclockable to begin with, that seems crazy. Previous generations were able to do this without issue. Essentially what i m trying to establish in this thread is if this is a potential liability with Skylake, I think I will try and get Haswell components to replace the Z170s in both machines and have done with it. However, that s a lot of effort and up-front expense to do without cause (The performance difference is not likely to be significant). Click to expand... Believe what you want lol.....You mentioned having 2 out of 2 unstable pcs..whatever you do dont go changing any bios settings that might fix the issues. But yea im talking in general - Its almost always the bios settings! (Unless you have faulty hardware) and no i dont believe all skylakes are faulty lol"</post>
   <post id="c8177916-8403-4006-a32d-949cf9ea8951" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I believe your having bios issues. On the hd3 make sure you have latest bios,I was looking at getting that board and was warned about that. "First off, I wish I could rate this at 4.5 stars as the board needs a beta UEFI to be stable, but other than that it is perfect for what you pay for. **Be sure to update to F5i for memory compatibility**" From a post at micro center. Might need to do bios update for both boards. Also possibly memory choice, only constant on both builds. Could be some incomparability issue. Good luck."</post>
   <post id="c9d04897-4eb0-46d5-aecc-a69f2815b1e3" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I m on my second Skylake system. Both are rock stable. However I had memory issues for a while with Corsair LPX ram like yours. Keep your ram at 2133MHz and see if things improve. Work from there. If the OS has corrupted due to memory problems or previous issues, you will have compound problems. It might be wise to try a fresh install of Windows if problems continue."</post>
   <post id="926c44a3-f2c4-4f93-af4b-a94fc27c1f6e" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"My Skylake build has proven to be the most stable of any of my builds so far. Skyrim with 100+ mods not playing with each other nicely is the only thing that has crashed it."</post>
   <post id="c2ad8711-6037-451d-9bcf-df2e6e9ebf3f" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I would find it very surprising if there s a wide-spread stability issue with Skylake CPUs. Intel does a very good doing engineering samples and working with PC manufacturers to ensure nearly everything related to CPU and platform is 1000% stable before releasing."</post>
   <post id="06ccf14e-10c8-4e2e-b189-221dca232beb" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I too would find that very surprising, but it s hard to get the measure of exactly whether the  Skylake bug  is in fact confined to specialist applications or otherwise. I ll definitely try the BIOS update on the HD3P machine and see what happens. One thing I have noticed on the file server is that after the last time it happened, Sleep Mode is now enabled in Windows even with the power settings disabling it across the board, so I ve had to start running Caffeine to stop it going to sleep overnight. Not sure if the machine attempting to enter sleep state before would have been causing the freezes unknowingly. Doesn t explain the issue happening mid-game on the other PC though..."</post>
   <post id="832b04a8-25b7-4876-877c-278bd727eb91" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I got one of the first batches, and mine has been running super well. No problems whatsoever."</post>
   <post id="57144917-d200-4411-8779-698e2fcee1eb" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Skylake bug was fixed via microcode update..."</post>
   <post id="3a82984a-25d8-401b-992e-2e40317a8413" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Freezing is now becoming more regular on the file server so I have updated the BIOS to version F5, removed a now redundant 2-port PCIe 1x SATA card and removed the NZXT GRID+ V2 from the system entirely (I tried just removing the USB cable but alas doing this isolates the power from the molex connector so fans don t spin at all!). I will see if this clears the issue - if not I probably still won t put the GRID+ back as I m not happy that it needs to actually seek every hard disk once a second in order to see its temperature. Apart from the annoying light show that s just extra wear on the drives (and noise) that isn t needed, so I have ordered a Corsair Link Commander to potentially replace it. Reviews of the software seem equally scathing but I can only experiment, there aren t really any other software options out there and in a 4U case manual controllers aren t viable (not that I want them). Contemplating hiding some sort of micro-PC inside the case just to run fan controller software on that so if it crashes it doesn t take down the whole system but I wouldn t know where to start with wiring up its reset button externally, going inside the case to reset it every time would be a real drag."</post>
   <post id="2f4b3543-e61a-416e-9391-3b81481be861" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"On my second skylake 6700k build here, apart from a faulty soundchip on the first board everything has been smooth sailing and thats with a total of 9 hdds in one of them connected with an extra pcie controller to make up for the lack of inbuilt sata ports. Rock solid stable, even at default bios settings I never had any real problems and if I recall Ive only reset the cmos once on each board. In my experience skylake is not inherently unstable, far from it to be honest."</post>
   <post id="de0c4664-b252-4322-987d-221b4f64170f" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"op exactly what speed is your memory running in the bios? There has been several skylake threads regarding memory speed settings in the bios causing instabality"</post>
   <post id="c1e3393d-6b20-497d-b601-00b86105d642" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"I tried to help him sort out if its a memory problem but he doesnt seem to have a care."</post>
   <post id="13d75443-2f85-4f65-a91b-085f0f51fd67" section="Intel Processors" discussion="How prevalent are the Skylake stability issues in real world use?">"Nenu said: ↑ I tried to help him sort out if its a memory problem but he doesnt seem to have a care. Click to expand... I think its Safe to consider this issue solved and Maybe even just a troll thread"</post>
   <post id="467898ac-415e-4cc8-8310-8d2f7bd3cb3b" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"Going from an intel i7 920 to 2x xeon x5670 cpus. How much of a speed increase should I see? I use a couple virtual machines and have 48GB of ECC ram. This is on an HP Z600 workstation."</post>
   <post id="eb4d16d3-8fd6-4860-955c-6e6aaba7eb35" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"Well you should have 3x the processing power, 4c/8t to 12c/24t. Also the x5670 is clocked higher then the 920, 2.92Ghz/2.66Ghz so there is that too."</post>
   <post id="63d1f59f-768c-4bec-b55e-d2a5f2cbee68" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"a bazillion amount of performance upgrade.. only going from single i7 920 to single Xeon X5670 its a considerable amount of performance jump, but you are not only that but you are going from 8 threads to 24.. so almost fully 3x jump in per thread performance, without take in consideration its an updated die shrink nehalem chip optimized with newer features and little bump of IPC... so a lot, a lot of performance.."</post>
   <post id="565d89cf-0cf7-457f-baba-0e0560682b58" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"Sweet, no idea what OS to throw on it yet. Can I overclock a Z600 workstation or is that a bad idea which 2x cpus in sync?"</post>
   <post id="0a1d4813-079d-48d8-9a2b-506c6fdf838a" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"Can I overclock a Z600 workstation Click to expand... I expect that the BIOS will be locked to prevent that."</post>
   <post id="237aff6e-1965-4539-b72e-ff57a53731a2" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"That s what I thought, damn."</post>
   <post id="3c26a3f9-c5b0-44be-ac15-f46e74342a2c" section="Intel Processors" discussion="Going from an intel i7 920 to 2x xeon x5670 cpus">"This thing seems faster than my home i7 5820k machines. Very surprised."</post>
   <post id="0b5b1795-5986-4115-9a05-1e841de7e884" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"Hello all, May be looking for a laptop upgrade soon, as I need 16GB of RAM (which my motherboard does not support), and since I can easily assign this laptop elsewhere. I m currently using a machine with an i5 3210M. Looking at the laptops available now in my country, most i5s are sporting the "U" suffix, with this or this processor as a common one. Compared to the 3210M, the 5200U has a lower TDP, lower base and lower turbo frequency, although we are talking about 2-3 generations of IPC improvements. Will an upgrade from the i5 3210M to an i5 xxxx U actually be a sidegrade? Seems we have a lack of mobile CPU related benchmarks on the internet. All I m seeing are CPUboss links which are next to useless. Thanks"</post>
   <post id="e8a51a0e-9431-43b2-af38-6c5b331bffa9" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"I havn t looked around for benchmarks, but given the clocks and TDP s I am inclined to believe it is pretty much a sidegrade in terms of raw performance. But if you re looking to put 16GB of memory into it....aren t notebooks that support SODIMMs usually bigger and run non-U chips? most of the U-chip devices I ve seen have soldered memory. Which devices are you looking at in particular?"</post>
   <post id="8674c11c-61e2-4ffc-a2f7-32891653ac38" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"With the lack of mobile CPU reviews, the best bet is to bank off the Passmark ratings: PassMark - Intel Core i3-3120M @ 2.50GHz - Price performance comparison PassMark - Intel Core i5-5200U @ 2.20GHz - Price performance comparison the i5-3210M scores ~3200 and the i5-5200U scores ~3500 , so about a 9% increase, with a 20w TDP decrease."</post>
   <post id="461d38f3-70a0-43c0-910c-2d596ae479f7" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"rastaban said: ↑ I havn t looked around for benchmarks, but given the clocks and TDP s I am inclined to believe it is pretty much a sidegrade in terms of raw performance. But if you re looking to put 16GB of memory into it....aren t notebooks that support SODIMMs usually bigger and run non-U chips? most of the U-chip devices I ve seen have soldered memory. Which devices are you looking at in particular? Click to expand... Don t really know which devices are available at the moment, mostly looking at Asus and Lenovo laptops but the info on their websites are sketchy. Buying laptops here are more of picking from what is available at the physical store. Suprfire said: ↑ With the lack of mobile CPU reviews, the best bet is to bank off the Passmark ratings: PassMark - Intel Core i3-3120M @ 2.50GHz - Price performance comparison PassMark - Intel Core i5-5200U @ 2.20GHz - Price performance comparison the i5-3210M scores ~3200 and the i5-5200U scores ~3500 , so about a 9% increase, with a 20w TDP decrease. Click to expand... Thanks. Even with the Skylake 6200U CPUs, seems like a sidegrade either way... Looks like going the mobile quads will be the way to go, if I can find one. Edit: Seems that even worldwide, a laptop, a 14" screen, and a quad core seems very rare at this point"</post>
   <post id="1ebc6813-148a-4c8c-a268-beb0402a9ce0" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"Which country are you in? I just checked the Lenovo site and there are plenty of Skylake non-U quadcores with 16GB memory preconfigured in the 1000-1300$ range."</post>
   <post id="d402ce31-b71d-452c-815f-23be86e5e2ac" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"With mobile you can t even really look at the CPU to see what performance is like considering it s not uncommon for these CPUs in small form factors to get thermally bound long before they hit their design performance limit. Two given laptops with the same exact CPUs may have similar performance for web browsing and office tasks but if one has a much better cooling solution than the other than tasks that take more than a second or two to complete such as gaming or any sort of heavy processing load will be much faster on one than the other. Instead of looking for benchmarks of the guts of the device you re interested in, just look for full benchmarks of the whole device, ideally including some sort of torture test to see how the system handles load. Even in the same device a CPU upgrade may not really gain you much under load if the cooling can t handle the bigger processors, for instance see the Surface line, in particular the Surface Pro 3 and how little of a difference the i7 made over the i5 for gaming despite much better paper specs due to thermal throttling."</post>
   <post id="1a51be70-e401-4683-853b-663eeba54a39" section="Intel Processors" discussion="How do newer &quot;U&quot; mobile processors compare to older &quot;M&quot; ones?">"rastaban said: ↑ Which country are you in? I just checked the Lenovo site and there are plenty of Skylake non-U quadcores with 16GB memory preconfigured in the 1000-1300$ range. Click to expand... From the Philippines. We have small quantities of i5 6200Us trickling in the stores, but most of the stuff available at competitive prices are all Broadwell 5200Us. Can t order online and what is on the actual website is often not updated versus what you can actually buy. -Dragon- said: ↑ With mobile you can t even really look at the CPU to see what performance is like considering it s not uncommon for these CPUs in small form factors to get thermally bound long before they hit their design performance limit. Two given laptops with the same exact CPUs may have similar performance for web browsing and office tasks but if one has a much better cooling solution than the other than tasks that take more than a second or two to complete such as gaming or any sort of heavy processing load will be much faster on one than the other. Instead of looking for benchmarks of the guts of the device you re interested in, just look for full benchmarks of the whole device, ideally including some sort of torture test to see how the system handles load. Even in the same device a CPU upgrade may not really gain you much under load if the cooling can t handle the bigger processors, for instance see the Surface line, in particular the Surface Pro 3 and how little of a difference the i7 made over the i5 for gaming despite much better paper specs due to thermal throttling. Click to expand... Thanks for this. This was at the back of my head and I ve read a few articles on the Surface Pro showing what you just described. Just wasn t able to connect it. This suggests really much more of a sidegrade unless the cooling has stayed the same and the process shrink would allow much higher clocks to be run by the laptop CPU, all things held equal."</post>
<post id="2b7e3555-3e09-405d-9732-7c764f2e6e08" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Edit: I have added Chris  writeup live from the Intel / Micron showfloor. http://hardocp.com/article/2015/07/28/intel_micron_live_reporting_3d_xpoint_memory"</post>
   <post id="9a6e0884-98bb-4b50-8d1e-c1173375620a" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Non-volatile 3D stacked material that doesn t store charge that s many times denser than flash and changes resistance? Soo...Memristors? Slower than but higher density than DRAM, faster and higher density than Flash. Still going to be a tough sell aside from servers. But hey any improvements in non-volatile memory are a good thing! Much love to HP for digging-up this old technology"</post>
   <post id="8f5ca89e-9fe2-4eff-ac33-e82bfb7be51e" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Well, so much for nvme, sounds like were back to the data bus being the bottleneck again, LOL."</post>
   <post id="5337ddf8-d68a-4a08-9c07-e4643a506f0b" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"I like how all the specs are put in perspective through a car analogy..."</post>
   <post id="7f6cc9a4-d8b4-4cd9-a60f-d8a7b6cc9023" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Fantastic news. Shame they could not actually demonstrate it working, but I get the impression that products will come to market next year. I hope for some consumer products to come late next year."</post>
   <post id="fab63e6c-d42d-469d-bf31-eff2fe127c31" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"I ll take two please."</post>
   <post id="18638022-e03a-4b7e-9993-cfc66966cef7" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"So from the sounds of things this will eliminate the need for memory as we know it in a PC. Sounds like all you need is a decent HD with this stuff in it and it will be fast enough to use in place of RAM and also offer permanent storage. Sounds like a win-win to me. Looks like DDR4 may be the last generation of Random Access Memory."</post>
   <post id="41d04b24-a0c6-4df0-bfef-59256529cb6e" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Yup, definitely a Memristor. See here, the cell structure is exactly the same (page 6): http://www.ece.ucsb.edu/~strukov/DmitriWebPage_files/MemristorSymposium2010Strukov.pdf Also, there s going to be the problem of price. Each of those cells uses Titanium, and the signal wires are Platinum. Yay expensive! https://en.wikipedia.org/wiki/Memristor#Titanium_dioxide_memristor"</post>
   <post id="404153ec-3206-494c-828f-0df02ee5d952" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"defaultluser said: ↑ Yup, definitely a Memristor. See here, the cell structure is exactly the same (page 6): http://www.ece.ucsb.edu/~strukov/DmitriWebPage_files/MemristorSymposium2010Strukov.pdf Also, there s going to be the problem of price. Each of those cells uses Titanium, and the signal wires are Platinum. Yay expensive! https://en.wikipedia.org/wiki/Memristor#Titanium_dioxide_memristor Click to expand... This is because Intel thinks everyone can afford thousands of $ for new components, granted even though is using these materials, if it is only using 1/100th of a gram of less then it wont drastically be expensive, but then again this is Intel charging $200+ for a chip that costs them $2 actual cost including margins. "quote" Intel and Micron unveil 3D Xpoint™ technology and create the first new memory category in more than 25 years. (huh what happened to HBM I thought that was also new memory, or HMC which is also micron?? if they are also new, then in the first line they lied lol. The biggest concerns for me are of course cost/capacity, power use, form-factor and compatibility as the current high end Intel drives while fast also pretty much REQUIRE specific Intel motherboards just to function which is no bueno for the intended customer base, I would love to see a USB sized ~500gb drive with in the 500+mb/s read AND write sustained speeds for ~$100 I don t see that happening however)"</post>
   <post id="0f3317db-da38-4a1d-8982-595e258cc7cf" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"It s only expensive to make compared to a flash chip, which uses much cheaper materials. If they can get it dense enough, they could justify the higher build cost."</post>
   <post id="060bffeb-ce24-4f04-bc59-024313cb7ed0" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"So, in the end, bottom line, I am going to need a new motherboard...."</post>
   <post id="a4aefc96-d0bb-41a7-97dd-3f42f7a1818d" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"If you re writing and calling individual memory cells instead of blocks, wouldn t this also require a massive change in programming? Meaning not only do you need to get the hardware out, but everything would have to be programmed for it as well? Or would it be backwards compatible, with entire blocks being written/read just fine, but to truly take advantage it would have to be programmed specifically?"</post>
   <post id="bc43d676-7f39-4cef-9b85-8e98ea5a90df" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"TwistedAegis said: ↑ If you re writing and calling individual memory cells instead of blocks, wouldn t this also require a massive change in programming? Meaning not only do you need to get the hardware out, but everything would have to be programmed for it as well? Or would it be backwards compatible, with entire blocks being written/read just fine, but to truly take advantage it would have to be programmed specifically? Click to expand... I m pretty sure this is managed by the controller on the drive."</post>
   <post id="85e303de-35be-455e-9d42-19402f668292" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"CrazyRob said: ↑ I m pretty sure this is managed by the controller on the drive. Click to expand... Yes and no. There s no need for, say, the concept of block size anymore. For stuff that s optimized at a low level (like databases or operating systems), that s major. Also, we don t even have the tools to do much of anything interesting with NVMe s focus on asynchronous data access just yet. I asked the Intel engineer that was in the Q&amp;A afterwards what was in store on this front, citing the example of what they did with Threading Building Blocks and MKL on the multicore front, and got the "we re just talking about the product today" response"</post>
   <post id="0a48bf54-5ded-4096-bc14-15bd9f15dcbb" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"dragonstongue said: ↑ ...but then again this is Intel charging $200+ for a chip that costs them $2 actual cost including margins. Click to expand... Wow, quit talking out of your ass. You know R&amp;D cost money right??"</post>
   <post id="8a8e67f5-85bd-4267-80b6-78d4f6b09322" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"AllStarMe said: ↑ Wow, quit talking out of your ass. You know R&amp;D cost money right?? Click to expand... Plus the multi-billion dollars fabs have to paid for somehow"</post>
   <post id="aba12814-03c4-4ebf-87d7-acae5974c65a" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">" from 4.4 zettabytes of digital data created in 2013 to an expected 44 zettabytes by 20204"</post>
   <post id="b6e5a9c4-b2cb-467e-8e7e-b7321dfa46d0" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"A bit confusing, it both sounds like it is, and is not fast enough to replace RAM, the guy in the video uses the example of gaming, specifically in game worlds without loading, so VRAM. But elsewhere it s hinted that it ll be in between NAND and RAM. If it s not as fast as RAM, won t it just be a better version of NAND? Also, poor HP, beaten to the punch, there must be some serious cursing going on there."</post>
   <post id="90999e79-0936-4bc8-a495-f77db9e7633e" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"The arrangement looks a lot like RRAM/memristors. Memristors don t necessarily need platinum. HP s memristors have cells built with hafnium oxide, for example. Intel and Micro are being very secretive about the devices, so they may have found another material and don t want to disclose it yet. dragonstongue said: ↑ (huh what happened to HBM I thought that was also new memory, or HMC which is also micron?? Click to expand... HBM is just DRAM connected with TSV and organized as a wide memory device. TSV have been used for a while for stacking memory on SoC and other chips, used in that way for over 15 years, and actually dates back to the 1960s. edit: TheRegister mentioned this: An Intel spokesperson categorically denied that it was a phase-change memory process or a memristor technology. Spin-transfer torque was also dismissed. Whatever it is, Intel and Micron have been developing it for about ten years. Click to expand... XPoint might be what was previously referred to as "New Memory B" coming in 2017, but is still a RRAM design. "New Memory A" is probably the crossbar based RRAM Micron is currently sampling."</post>
   <post id="698f05f4-a893-45ef-9ece-476618209ef3" section="Memory" discussion="Intel &amp; Micron 3D XPoint Memory">"Well, I guess the next build is going to wait until something is settled so I know I ll be able to use devices which run using this tech. This is what s going to lead to multi TB SSD s, yes?"</post>
   <post id="9e665c56-9620-4090-a680-5a8efbc83099" section="Memory" discussion="THE Memory FAQ">"Many, many thanks to Drisler for providing this FAQ feel free to post any additional information you may have on the subject. Memory FAQ: Basics, Tweaking and more Warning ..slightly AMD biased Not really Updated: 06/02/2004 Contents - Memory Basics - Installation - Mysterious Bios Settings - Overclocking &amp; Memory - Buying Memory Any flames or off topic posts WILL be deleted."</post>
   <post id="7583be85-52ef-4606-b079-f0f1cf99981e" section="Memory" discussion="THE Memory FAQ">"Memory Basics DRAM Memory Technologies DRAM is available in several different technology types. At their core, each technology is quite similar to the one that it replaces or the one used on a parallel platform. The differences between the various acronyms of DRAM technologies are primarily a result of how the DRAM inside the module is connected, configured and/or addressed, in addition to any special enhancements added to the technology. There are three well-known technologies: Synchronous DRAM (SDRAM) An older type of memory that quickly replaced earlier types and was able to synchronize with the speed of the system clock. SDRAM started out running at 66 MHz, faster than previous technologies and was able to scale to 133 MHz (PC133) officially and unofficially up to 180 MHz. As processors grew in speed and bandwidth capability, new generations of memory such as DDR and RDRAM were required to get proper performance. Double Data Rate Synchronous DRAM (DDR SDRAM) DDR SDRAM is a lot like regular SDRAM (Single Data Rate) but its main difference is its ability to effectively double the clock frequency without increasing the actual frequency, making it substantially faster than regular SDRAM. This is achieved by transferring data not only at the rising edge of the clock cycle but also at the falling edge. A clock cycle can be represented as a square wave, with the rising edge defined as the transition from ‘0’ to ‘1’, and the falling edge as ‘1’ to ‘0’. In SDRAM, only the rising edge of the wave is used, but DDR SDRAM references both, effectively doubling the rate of data transmission. For example, with DDR SDRAM, a 100 or 133 MHz memory bus clock rate yields an effective data rate of 200 MHz or 266 MHz, respectively. DDR modules utilize a 184-pin DIMM (Dual Inline Memory Module) packaging which, like SDRAM, allows for a 64 bit data path, allowing faster memory access with single modules over previous technologies. Although SDRAM and DDR share the same basic design, DDR is not backward compatible with older SDRAM motherboards and vice-versa. It is important to understand that while DDR doubles the available bandwidth, it generally does not improve the latency of the memory as compared to an otherwise equivalent SDRAM design. In fact the latency is slightly degraded, as there is no free lunch in the world of electronics or mechanics. So while the performance advantage offered by DDR is substantial, it does not double memory performance, and for some latency-dependant tasks does not improve application performance at all. Most applications will benefit significantly, though. Rambus DRAM (RDRAM) Developed by Rambus, Inc., RDRAM, or Rambus DRAM was a totally new DRAM technology that was aimed at processors that needed high bandwidth. RAMBUS, Inc. agreed to a development and license contract with Intel and that lead to Intel’s PC chipsets supporting RDRAM. RDRAM comes in PC600, PC700, PC800 and PC1066 speeds. Specific information on this memory technology can be found at the RAMBUS Website Unfortunately for Rambus, dual channel DDR memory solutions have proved to be quite efficient at delivering about the same levels of performance as RDRAM at a much lower cost. Intel eventually dropped RDRAM support in their new products and chose to follow the DDR dance, at which point RDRAM almost completely fell off the map. Rambus, SiS, Asus and Samsung have now teamed up and are planning a new RDRAM solution (the SiS 659 chipset) providing 9.6 GB/s of bandwidth for the Pentium 4. It will be an uphill battle to get RDRAM back in the mainstream market without Intel s support. What’s new, pussycat? Enter DDR-2 Second generation double date rate memory (DDR-2), expected to start at 400 MHz then go to 533 MHz and 667 MHz, should soon begin replacing DDR-1 (or DDR as we know it). DDR-2 seeks to increase the total memory bandwidth available to the system. This will be accomplished via increased clock frequencies in addition to streamlining the protocols used by the system to make memory reads and writes. According to the JEDEC standard, DDR-2 will have 240 pins and will offer reductions in power consumption and heat output, which are two problems that grow larger as systems carry more and faster memory. In a similar fashion to the migration from SDRAM to DDR, DDR-2 sacrifices latency. An interesting tidbit on the side is that Intel s P4 architecture, using all kinds of optimizations, will be hurt less than AMD by the high latencies of DDR II. We didn’t complain much last time, so maybe we won’t this time either? DDR-2 will likely be the dominant type of memory in desktop space for several years as DDR-1 is/was. DDR-II won t arrive in quantity until the second half of 2004, however. QDR and XDR Quad Data Rate Memory (QDR DRAM) - Instead of two data samples per clock cycle, QDR sends four data samples per cycle. QDR is not a JEDEC standard, but instead has been developed as a memory timing technology by Kentron. Kentron has said that QDR technology can leverage existing DDR-1 technology. Note that QDR isn t simply 2x the speed of standard DDR. Instead, Kentron and VIA propose using a single QDR channel to achieve the performance of dual-channel DDR. (DDR-2 is still on VIA s road map) XDR DRAM - getting catchy? XDR DRAM stands for eXtreme Data Rate DRAM, and is the final name for Rambus s "Yellowstone" technologies which have been announced in pieces over time. XDR brings all of these formerly announced technologies under one big umbrella, which will be marketed as a high-bandwidth memory solution. XDR is effectively a hybrid of DDR and Rambus DRAM, designed to combine the best elements of both. Rambus claims that their mid-range XDR memory module is 8x faster compared to today s DDR-400. By "faster", they are referring to the module clock speed, along with how many bits can be transmitted per clock cycle. XDR modules are not in production yet, and are not scheduled to go into full-scale production until 2006. The speed of DDR is usually expressed in terms of its "effective data rate", which is twice its actual clock speed. PC3200 memory, or DDR400, or 400 MHz DDR, is not running at 400 MHz, it is running at 200 MHz. The fact that it accomplishes two data transfers per clock cycle gives it nearly the same bandwidth as SDRAM running at 400 MHz, but DDR400 is indeed still running at 200 MHz. Actual clock speed/effective transfer rate 100/200 MHz =&gt; DDR200 or PC1600 133/266 MHz =&gt; DDR266 or PC2100 166/333 MHz =&gt; DDR333 or PC2700 185/370 MHz =&gt; DDR370 or PC3000 200/400 MHz =&gt; DDR400 or PC3200 217/433 MHz =&gt; DDR433 or PC3500 233/466 MHz =&gt; DDR466 or PC3700 250/500 MHz =&gt; DDR500 or PC4000 267/533 MHz =&gt; DDR533 or PC4200 283/566 MHz =&gt; DDR566 or PC4500 So how do they come about those names? Well, the industry specifications for memory operation, features and packaging are finalized by a standardization body called JEDEC. JEDEC, the acronym, once stood for Joint Electron Device Engineering Council, but now is just called the JEDEC Solid State Technology Association. The naming convention specified by JEDEC is as follows: Memory chips are referred to by their native speed. Example, 333 MHz DDR SDRAM memory chips are called DDR333 chips, and 400 MHz DDR SDRAM memory chips are called DDR400. DDR modules are also referred to by their peak bandwidth, which is the maximum amount of data that can be delivered per second. Example, a 400 MHz DDR DIMM is called a PC3200 DIMM. To illustrate this on a 400 MHz DDR module: Each module is 64 bits wide, or 8 Bytes wide (each byte = 8 bits). To get the transfer rate, multiply the width of the module (8 Bytes) by the rated speed of the memory module (in MHz): (8 Bytes) x (400 MHz/second) = 3,200 Mbytes/second or 3.2 Gbytes/second, hence the name PC3200 To date, the JEDEC consortium is yet to finalize specifications for PC3500 &amp; higher modules. PC2400 was a very short lived label applied to overclocked PC2100 memory. PC3000 was not and will not ever be an official JEDEC standard. Processors and Bandwidth The front side bus (FSB) is basically the main highway or channel between all the important functions in the motherboard that surround the processor through which information flows. The faster and wider the FSB, the more information can flow over the channel, much as a higher speed limit or wider lanes can improve the movement of cars on a highway. As with the FSB, a low speed limit or narrower lanes will retard the movement of cars on the highway causing a bottleneck of traffic. Intel has been able to reduce the FSB bottleneck by accomplishing four data transfers per clock cycle. This is known as quad-pumping, and has resulted in an effective FSB frequency of 800 MHz, with an underlying 200 MHz clock. AMD Athlon XPs, on the other hand, must be content with a bus that utilizes different technology, one that utilizes both the rising and falling sides of a signal. This is in essence the same double data rate technology used by memory of the same name (DDR), and results in a doubling of the FSB clock frequency. That is, a 200 MHz clock results in an effective 400 MHz FSB. Processors have a FSB data width. This data width is much like the "lanes on a highway" that go in and out of the processor. The processor uses this highway to transfer data mainly between itself and system. When the first 8088 processor was released, it had a data bus width of 8 bits and was able to access one character at a time (8 bits = 1 character/byte) every time memory was read or written. The size in bits thus determines how many characters it can transfer at any one time. An 8-bit data bus transfers one character at a time, a 16-bit data bus transfers 2 characters at a time and a 32-bit data bus transfers 4 characters at a time. Modern processors, like the Athlon XP and Pentium 4, have a 64-bit wide data bus enabling them to transfer 8 characters at a time. Although, these processors have 64-bit data bus widths, their internal registers are only 32 bits wide and they re only capable of processing 32 bit commands and instructions while new AMD64 series of processors are capable of processing both 32 bit and 64 bit commands and instructions. When talking memory, bandwidth refers to how fast data is transferred once it starts and is often expressed in quantities of data per unit time. The peak bandwidth that may be transmitted by an Athlon XP or a Pentium 4 is the product of the width of the FSB and the frequency it runs at. To illustrate: Athlon XP “Barton” 3200+ -- 400FSB 64(bits) * 400,000,000(Hz) = 25,600,000,000 bits/sec (25,600,000,000/8) / (1000*1000) = 3200 Mb/sec Intel Pentium 4 “C” 3.2 GHz -- 800FSB 64(bits) * 800,000,000(Hz) = 51,200,000,000 bits/sec (51,200,000,000/8) / (1000*1000) = 6400 Mb/sec These are the bus’ theoretical peak bandwidths. There s a difference between peak bus bandwidth and effective memory bandwidth. Where peak bandwidth is just the product of the bus width and bus frequency, effective bandwidth takes into consideration others factors such as addressing and delays that are necessary to perform a memory read or write. The memory could very well be capable of putting out 8 bytes on every single clock pulse for an indefinitely long time, and the CPU could likewise be capable of consuming data at this rate indefinitely. The problem is that there are turnaround times (or delays) in between when the processor places a request for data on the FSB; when the requested data is reproduced by RAM and when this requested data finally arrives for use by the CPU. Luckily, the bandwidth-killing effects of these delays are reduced through various methods; most important being reducing the number of requests the CPU must issue. DDR Dual Channel Most of today’s mainstream chipsets are using some form of dual channel to supply processors with bandwidth. The nForce and nForce2 are, at this time, the only two chipsets to supply dual-channel goodness for the Athlon XP. The original nForce was not on the same performance and stability level as the competitor VIA s chipset was, but the new and improved dual-channel DDR400 nForce2 has been a smash success -- in fact, is today s de facto choice for performance-minded / overclocker AMD desktop buyers. VIA is now about to release a Dual Channel chipset for the Athlon XP/Duron family called the KT880. Take note that the memory isn t dual channel, the platform is. In fact there is no such thing as dual channel memory. Rather, it is most often a memory interface composed of two (or more) normal memory modules coordinated by the chipset on the motherboard, or in the case of the AMD64 processors, coordinated by the integrated memory controller. But for the sake of simplicity, we refer to DDR dual channel architecture as dual channel memory. The nforce2 platform has two 64 bit memory controllers (which are independent of each other) instead of just a single controller like other chipsets. These two controllers are able to access "two channels" of memory simultaneously. The two channels, together, handle memory operations more efficiently than one module by utilizing the bandwidth of two modules (or more) combined. By combining DDR400 (PC3200) with dual memory controllers, the nForce2 could offer up to 6.4 GB/sec of bandwidth in theory. However, this extra bandwidth produced by dual channel cannot be fully utilitized by the Athlon XP and Duron family (K7) of processors. Data(bandwidth) will reach these processors no sooner than the system bus (FSB) allows them, and the processor therefore cannot derive an advantage from memory operating faster than DDR266 when operating on a 133/266Mhz FSB, DDR333 with a 166/333Mhz FSB or DDR400 at 200/400Mhz FSB even in single channel mode. Visualize a four lane highway, symbolizing your Dual Channel configuration. As you go along the highway you come up to a bridge that is only 2 lanes wide. That bridge is the restriction posed by the dual-pumped AMD FSB. Only two lanes of traffic may pass through the bridge at any one time. That s the way it is, with the K7 processors and Dual Channel chipsets. In case you re wondering, the K in K7 stands for Kryptonite later changed to Krypton to avoid copyright infringement. Yes, that very same fictional element from comic books that could bring the otherwise all-powerful Superman (Intel ) to his knees. Intel s P4 architecture, in contrast, is designed to exploit the increased bandwidth afforded by dual channel memory architectures. The 64-bit Quad Pumped Bus of the modern Pentium 4 CPU working at 800MHz, in theory, requires 6.4GB/s of bandwidth. This is the exact match of the bandwidth produced by the Intel i875 (Canterwood) and i865 (Springdale) chipset families. The quad pumped P4 FSB seemed like drastic overkill in the days of single channel SDR memory, but is paying handsome dividends in today s climate of dual channel DDR memory subsystems. This is one lasting and productive legacy of Intel s RDRAM efforts. As implemented on the P4 RDRAM was also dual channel architecture, and mandated the quad-pumped FSB for its extra bandwidth to be exploited. This factor continues to serve the P4 well in the dual channel DDR era we are currently in, and allows P4 s greater memory performance than all other PC platforms, save the new AMD Athlon64 FX with all its new bells and whistles. The Athlon 64 FX processor has a fully integrated DDR Dual Channel memory controller providing a 128-bit wide path to memory and therefore eliminating the need for a Dual Channel interface on the motherboard which traditionally was always located in the Northbridge. The old term front-side bus has always represented the speed at which the processor moves memory traffic and other data traffic to and from the chipset. Since the AMD64 processors has the memory controller located on the processor die, that memory subsystem traffic no longer has to go through the chipset for CPU-to-memory transfer. Therefore, the old term "front-side bus" does no good as it is not applicable anymore. With AMD64 processors, the CPU and memory controller interface with each other at full CPU core frequency. The speed at which the processor and chipset communicate is now dependent on the chipset s HyperTransport spec, running at speeds of up to 1600 MHz. Although the P4 (800fsb variety) and the A64 FX 940 pins, both share the same theoretical peak memory bandwidth of 6.4GB/sec, the Athlon FX realizes significantly more throughput due mainly to it’s integrated memory controller which drastically reduces latency. Even so, it still suffers from the required use of registered modules which are slower than regular modules. The upcoming Athlon 64 / A64 FX processors designed for Socket 939 will be free from this major drawback and will also feature Dual Channel memory controllers. One negative, though, of having the memory controller integrated into the processor is that to support emerging memory technologies, like DDR-2 for example, the controller has to be redesigned and the processor needs to be replaced."</post>
   <post id="79088a80-2067-493b-a92b-317f1e84f1bf" section="Memory" discussion="THE Memory FAQ">"Which slots to use? If you re using a single module, it s best practice to use the first slot. If using two or more modules in a non-dual channel motherboard, populate the first slot and use any other slots you wish. Q: I ve had my single module installed in slot 2 for the last few months now, should I change it? No, it s also best practice to keep on using the slot(s) you re been using before. If you replace RAM, then insert the new modules, in the same slots the older ones were in before. You may find the system overclocks better with the ram in a different slot. It is very hard to predict when this effect occurs, as well as which one might work best. In the overclocking game he who tries the most things wins, and if you are running an overclocked configuration that is asking a lot of the ram it is a good idea to try all available slots to make sure the one you are using yields the best results. If you re using two or more modules of unequal size, you will get the best performance if you put the largest module(s) (in megabytes) in the lowest-numbered slot(s). For example, if your system currently has 256MB of memory and you want to add 512MB, it would be best to put the 512MB module into slot 0 and the 256MB module into slot 1. Using Dual Channel Dual Channel requires at least two modules for operation. It is recommended that the modules you use be of the same size, speed, arrangement etc. Dual Channel is optional on the original nforce2 motherboards and nforce2 ultra400. You can choose to run in single channel mode on these motherboards. Nforce2 400 boards are singe-channel only. Most dual channel capable nforce2 motherboards come with three slots. On these motherboards the first memory controller controls only the first slot (or the slot by itself), while the second memory controller controls the last two slots (which are usually closer together). Name them slots 1, 2 &amp; 3 respectively. To implement Dual Channel, it is necessary to occupy the slot 1 (channel 0) and either one of the two slots that are closer together, slots 2 or 3 (channel 1). The entire config would be running in 128 bit mode. You can use three modules in Dual Channel Mode, by filling the third unoccupied slot. With three sticks, slots 1 remains as channel 0 while slot 2&amp;3 become channel 1. To maintain 128-bit mode, with all three slots filled, each channel must have an equal amount of memory. For example, slots 1 should be filled with a 512 Mb module, while slots 2 &amp; 3 are populated 256 Mb modules. If you were to use three modules of the same size, then only the first two modules would be running in 128 bit Dual Channel Mode. Example, using 3x 256 Mb modules will have the first 512 Mb running in 128 bit Dual Channel mode, while the remaining 256 Mb will be in 64-bit Single Channel mode. Intel dual-channel systems are different. The have either two or four slots, and to run dual channel mode must have either one or two pairs of (hopefully) matching modules. Running three modules on a P4 system will force it to run in single channel mode, and is therefore to be avoided. Consult your motherboard manual for instruction on exactly which slots exactly to use."</post>
   <post id="69d95a90-3b3c-49a2-a5aa-6e84c7daf31d" section="Memory" discussion="THE Memory FAQ">"Mysterious Bios Settings Memory timings Memory performance is not entirely determined by bandwidth, but also the speeds at which it responds to a command or the times it must wait before it can start or finish the processes of reading or writing data. These are memory latencies or reaction times (timings). Memory timings control the way your memory is accessed and can be either a contributing factor to better or worse  real-world  performance of your system. Internally DRAM has a huge array of cells that contain data. (If you ve ever used Microsoft s Excel, try and picture it that way) A pair of row and column addresses can uniquely address each cell in the DRAM. DRAM communicates with a memory controller through two main groups of signals: Control-Address signals and Data signals. These signals are sent to the RAM in order for it to read/write data, address and control. The address is of course where the data is located on the memory banks, and the control signals are various commands needed to read or write. There are delays before a control signal can be executed or finish and this is where we get memory timings. The standard format for memory timings are most often expressed as a string of four numbers, separated by dashes, from left to right or vice-versa like this 2-2-2-5 [CAS-tRP-tRCD-tRAS] . These values represent how many clock cycles long each delay is but are not expressed in the order in which they occur. Different bioses will display them differently and there maybe additional options (timings) available. Which timings mean what? In most motherboards, numerous settings can be found to optimize your memory. These settings are often found the Advanced Chipset section of the popular award bioses. In certain instances, the settings maybe placed in odd locations, so please consult your motherboard manual for specific information. Below are common latency options: Command rate - is the delay (in clock cycles) between when chip select is asserted (i.e. the RAM is selected) and commands (i.e. Activate Row) can be issued to the RAM. Typical values are 1T (one clock cycle) and 2T (two clock cycles). CAS (Column Address Strobe or Column Address Select) - is the number of clock cycles (or Ticks, denoted with T) between the issuance of the READ command and when the data arrives at the data bus. Memory can be visualized as a table of cell locations and the CAS delay is invoked every time the column changes, which is more often than row changing. tRP (RAS Precharge Delay) - is the speed or length of time that it takes DRAM to terminate one row access and start another. In simpler terms, it means switching memory banks. tRCD (RAS (Row Access Strobe) to CAS delay) - As it says it s the time between RAS and CAS access, ie. the delay between when a memory bank is activated to when a read/write command is sent to that bank. Picture an Excel spreadsheet with a number across the top and along the left side. They numbers down the left side represent the Rows and the numbers across the top represent the Columns. The time it would take you, for example, to move down to Row 20 and across to Column 20 is RAS to CAS. tRAS (Active to Precharge or Active Precharge Delay) - controls the length of the delay between the activation and precharge commands ---- basically how long after activation can the access cycle be started again. This influences row activation time which is taken into account when memory has hit the last column in a specific row, or when an entirely different memory location is requested. These timings or delays occur in a particular order. When a Row of memory is activated to be read by the memory controller, there is a delay before the data on that Row is ready to be accessed, this is known as tRCD (RAS to CAS, or Row Address Strobe to Column Access Strobe delay). Once the contents of the row have been activated, a read command is sent, again by the memory controller, and the delay before it starts actually reading is the CAS (Column Access Strobe) latency. When reading is complete, the Row of data must be de-activated, which requires another delay, known as tRP (RAS Precharge), before another Row can be activated. The final value is tRAS, which occurs whenever the controller has to address different rows in a RAM chip. Once a row is activated, it cannot be de-activated until the delay of tRAS is over. To tweak or not to tweak? In order to really maximize performance from your memory, you ll need to gain access to your system s bios. There is usually a Master Memory setting, often rightly called Memory Timing or Interface, which gives usually gives you the choice to set your memory timings by SPD or Auto, preset Optimal and Aggressive timings (e.g. turbo and ultra), and lastly an Expert or Manual setting that will enable you to manipulate individual memory timing settings to your liking. Are the gains of the perfect, hand-tweaked memory timing settings worth it over the automatic settings? If you re just looking to run at stock speeds and want absolute stability, then the answer to that question would probably be no. The relevance would be nominal at best and you would be better off going by SPD or Auto. However, if your setup is up on the cutting edge of technology or you’re pushing performance to the limit as do some overclockers, or gamers or tweakers, it may have great relevance. SPD (Serial Presence Detect) SPD is a feature available on all DDR modules. This feature solves compatibility problems by making it easier for the BIOS to properly configure the system to optimize your memory. The SPD device is an EEPROM (Electrically Erasable Programmable Read Only Memory) chip, located on the memory module itself that stores information about the DIMM modules  size, timings, speed, data width, voltage, and other parameters. If you configure your memory by SPD, the bios will read those parameters during the POST routine (bootup) and will automatically adjust values in the BIOS according preset module manufacturer specifications. There is one caveat though. At times the SPD contents are not read correctly by the bios. With certain combinations of motherboard, bios, and memory setting SPD or Auto may result in the bios selecting full-fast timings (lowest possible numbers), or at times full-slow timings (highest possible numbers). This is often the culprit in situations where it appears that a particular memory module is not compatible with a given board. Often in these cases the SPD contents are not being read correctly and the bios is using faster memory timings than the module or system as a whole can boot with. In cases like these try replacing the module with another, setting the bios to allow manual timings, and setting those timings to safer (higher) values will allow the combination to work. Ok so I want to tweak, what do I do? Now for the kewl stuff!!! The first order of business, when tweaking your memory, is to deactivate the automatic RAM configuration -- SPD or Auto. With SPD enabled, the SPD chip on the memory module is read to obtain information about the timings, voltage and clock speed and those settings are adjusted accordingly. These settings are, however, very conservative to ensure stable operation on as many systems as possible. With a manual configuration, you can customize these settings for your own system and in most cases, the memory modules will remain stable even when they exceed the manufacturer s specifications. As a general rule, a lower number (or timing) will result in improved performance. After all, if it takes fewer cycles to complete an operation, then it can fit more operations within X amount of time. However, this comes at a cost, and that is stability. It is similar to wireless networking with short and long preambles. A long pre-amble might be slower, but in a heavy network environment it is much more reliable than short preamble because there is more certainty a packet is for your NIC. The same is for memory - the more cycles used, in general, the more stable the performance. This is inherently true for all of them because to access precisely the right part of the memory, you have to be accurate, and the more time to do a calculation will make it more accurate in this instance. Most typical values are 2 and 3. You might ask: Why can t we use 1 or even 0 values for memory timings? JEDEC specifies that it s not possible for current DRAM technology to operate as it should under such conditions. Depending on motherboard, you might be able to squeeze  1  on certain timings, but will very likely result memory errors and instability. And even if it doesn t, it is unlikely to result in a performance gain. If you are not planning on overclocking the clock speed of your RAM or if you have fast RAM rated at speeds above that of your current FSB, it may be possible to just lower the timings for a performance gain in certain applications that require most frequent accesses to system memory like, for instance, games. Memory timings can vary depending on the performance of RAM chips used. Not all memory modules will exhibit the ability to use certain timings without producing errors. So testing, trial and error, is required. Here are general guidelines to follow while "tweaking": As with CPU/video card overclocking, adjusting the memory timings should be done methodically and with ample time to test each adjustment. lower figures = better performance, but lower overclockability and possibly diminished stability. higher figures = lesser performance, but increased overclockability and more stability -- to an extent tRCD &amp; tRP are usually equal numbers between 2 and 4. In tweaking for more overclockability, lower tRP first between these two CAS should be either 2.0 or 2.5. Many systems, most nforce2, fail to boot with a 3.0 setting or have stability problems. CAS is not most critical of the various timings, unlike what is taught by many. In general, the importance of CAS when placed against tRP and tRCD is nominal. Reducing CAS has a relatively minor effect on memory performance, while lower tRP &amp; tRCD values result in a much more substantial gain. In other words if you had to choose, 3-3-2.5 would be better than 4-4-2.0 (tRCD-tRP-CAS) tRAS should always be larger the before mentioned timings. – see below tRAS is unique, in that lowering it can lead to problems and lesser performance. tRAS is the only timing that has no effect on real performance, if it is configured as it should. By definition, real-life performance is the same with different tRAS settings with a certain exception. This document from Mushkin outlines how tRAS should be a sum of tRCD, CAS, and 2. For example, if you are using a tRCD of 2 and a CAS of 2 on your RAM, then you should set tRAS to 6. At values lower than that theory would dictate lesser performance as well as catastrophic consequences for data integrity including hard drive addressing schemes --- truncation, data corruption, etc --- as a cycle or process would be ended before it s done. How is it possible for memory timings to affect my hard drive? When the system is shut down or a program is closed, physical ram data that becomes corrupted may be written back to the hard drive and that’s where the consequences for the hard drive come in. Also let’s not forget when physical ram data is translated by the operating system to virtual memory space located on the hard drive. While it s important to consider the advice of experts like Mushkin, your own testing is still valuable. Systems – both AMD &amp; Intel alike, can indeed operate with stability with 2-2-2-5 timings, and even exhibit a performance gain as compared to the theoretically mandated 2-2-2-6 configuration. The most important thing in any endeavor is to keep an open mind, and don t spare the effort. Once you ve tried both approaches extensively it will be clear to you which is superior for your particular combination of components. The Anomaly: nVIDIA’s nForce2 and tRAS An anomaly can be described as something that’s difficult to classify; a deviation from the norm or common form. This is exactly the situation with tRAS (Active to Precharge) and nVIDIA’s nforce2 chipset. As said before, not sparing the effort is what has lead to the initial discovery of this anomaly many months ago. It’s pretty well known by now, in a nutshell, a higher tRAS (i.e. higher than, say, the Mushkin mandated sum of CAS+tRCD+2) on nforce2 motherboards consistently shows slightly better results in several benchmarks and programs. In most cases, 11 seems to be the magic number. Other chipsets do not display this “deviation from the norm”, so what makes the nforce2 different? This thread has been on the topic for a while now, and TheOtherDude has given a possible explanation for this anomaly. “Unlike most modern chipsets, the Nforce2 doesn t seem to make internal adjustments when you change the tRAS setting in the BIOS. These "internal" (not really sure if that’s the right word) settings seem to include Bank Interleave, Burst Rate and maybe even Auto-precharge. For optimal performance, tRAS (as measured in clock cycles) should equal the sum of burst length, plus the finite time it takes the RAM to conduct a number of clock independent operations involved with closing a bank (~40 ns) minus one clock if Auto-precharge is enabled (this factor can be slightly effected by CAS, but should not play a role in optimal tRAS). To complicate things even more, one bank cannot precharge a row while the other specifies a column. This brings tRCD into the mix. Higher isn t always better, but the reason everything is so weird with tRAS and the Nforce2 is simply because the chipset doesn t make the internal optimizations to accommodate your inputted tRAS value like most other chipsets.” Dealing with Memory Speeds / Frequencies When the memory frequency runs at the same speed as the FSB, it is said to be running in synchronous operation. When memory and FSB are clocked differently (lower or higher than), it is known to be in asynchronous mode. On both AMD and Intel platforms, the most performance benefits are seen when the FSB of the processor is run synchronously with the memory – Although Intel based systems have a slight exception, this is completely true of all AMD-supporting chipsets. When looking at the AMD-supporting chipsets async modes are to be avoided like a plague. AMD-supporting chipsets offer less flexibility in this regard due to poorly implemented async modes. Even if it means running our memory clock speed well below the maximum feasible for a given memory, an Athlon XP system will ALWAYS exhibit best performance running the memory in sync with the FSB. Therefore, a 166FSB Athlon XP would run synchronously with DDR333/PC2700 (2*166) and give better performance than running with DDR400/PC3200, despite its numbers being bigger. Only Intel chipsets have implemented async modes that have any merit. If you are talking about the older i845 series of chipsets, running an async mode that runs the memory faster than the FSB is crucial to top system performance. And with the newer dual channel Intel chipset (i865/875 series) in an overclocked configuration, often you must run an async mode that runs the memory slower than the FSB for optimal results. The async modes in SiS P4 chipsets also work correctly. To achieve synchronous operation, there is usually a Memory Frequency or DRAM ratio setting in the bios of your system that will allow you to manipulate the memory speed to a either a percentage of the FSB (i.e. 100%) or a fraction (or ratio) i.e. N/N where N is any integer available to you. If you want to run memory at non 1:1 ratio speeds, motherboards use dividers that create a ratio of CPU FSB: memory frequency. However, intrinsically, it is possible to see the problem with this and why synchronous operation is preferable on all PC platforms. If there is divider, then there is going to be a gap between the time that data is available for the memory, and when the memory is available to accept the data (or vica versa). There will also be a mismatch between the amount of data the CPU can send to the memory and how much the memory can accept from the CPU. This will cause slowdowns as you will be limited by the slowest component. Here are three examples illustrating the three possible states of memory operation: 200MHz FSB speed with 100% or 1:1 (FSB:Memory ratio) results in 200MHz memory speed (DDR400)​ Such a configuration is wholly acceptable for any AMD system, memory should be set this way at all times for best performance. Asynchronous FSB/Memory Speeds are horridly inefficient on AMD systems, but may well be the optimal configuration for P4 systems. 200MHz FSB speed with 120% or 5:6 (FSB:Memory ratio) results in 240MHz memory speed (DDR480)​ This example shows running the memory at higher asynchronous speeds. Assume we have a Barton 2500+ which by default is running at a FSB of 333 MHz (166 MHz X 2) and we also have PC3200 memory which by default is running at 400 MHz. This is a typical scenario because many people think that faster memory running at 400 MHz, will speed up their system. Or they fail to disable the SPD or Auto setting in their bios. There is NO benefit at all derived from running your memory at a higher frequency (MHz) than your FSB on Athlon XP/Duron sytems. In actuality, doing so has a negative effect. Why does this happen? It happens because the memory and FSB can t "talk" at the same speeds, even though the memory is running at higher speeds than the FSB. The memory would have to "wait for the FSB to catch up", because higher async speeds forces de-synchronization of the memory and FSB frequencies and therefore increases the initial access latency on the memory path -- causing as much as a 5% degradation in performance. This is another ramification of the limiting effect of the AMD dual-pumped FSB. A P4 s quad pumped FSB (along with the superior optimization of the async modes) allows P4 s to benefit in some cases from async modes that run the memory faster than the FSB. This is especially true of single channel P4 systems. There still are synchronization losses inherent in an async mode on any system, but the adequate FSB bandwidth of the P4 allows the additional memory bandwidth produced by async operation to overcome these losses and produce a net gain."</post>
   <post id="d1714a29-df4d-4fa0-be5c-74e1ff2a6668" section="Memory" discussion="THE Memory FAQ">"(cont d) 250MHz FSB speed with 80% or 5:4 (FSB:Memory ratio) results in 200MHz memory speed (DDR400)​ This example is most often used in overclocking situations where the memory is not able to keep up with the speed of the FSB. On AMD platforms, there is really no point having a high FSB, if the memory can’t keep up. When the memory or any other component is holding back system performance, this is called a “bottleneck”. As in the example above, a memory bottleneck would be if you were running your memory at DDR400 MHz with a 500 MHz (250x2) system bus. The memory would only be providing 3.2GB/s of bandwidth while the bus would be theoretically capable of transmitting 4.0GB/s of bandwidth. A situation like this would not help overall system performance. Think of it like this; let s say you had a highway going straight into a mall, with an identical highway going straight out of the mall. Both highways have the same number of lanes and initially they have the same 45mph speed limit. Now let s say that there s a great deal of traffic flowing in and out of the mall and in order to get more people in and out of the mall quicker, the department of transportation agrees to increase the speed limit of the highway going into the mall from 45mph to 70mph; the speed limit of the highway leaving the mall is still stuck at 45mph. While more people will be able to reach the mall quicker, there will still be a bottleneck in the parking area leaving the mall - since the increased numbers of people that are able to get to the mall still have to leave at the same rate. This is equivalent to increasing the FSB frequency but leaving the memory frequency/bandwidth unchanged or set to a slower speed. You re speeding up one part of the equation while leaving the other part untouched. Sometimes the fastest memory is not always afforded or available. In this case, more focus should be placed on balancing the FSB and memory frequencies while still keeping latencies as low as possible AND while still maintaining CPU clock speed (GHz) by increasing the multiplier. The benefit of a faster FSB (and higher bandwidth) will only become more and clearer as clock speeds (GHz) increase; the faster the CPU gets, the more it will depend on getting more data quicker. The only real benefit of async modes on AMD platforms is the fact that it comes in handy to overclockers for testing purposes; to determine their max FSB and to eliminate the memory as a possible cause for not being able to achieve a desired stable FSB speed. Even so, async modes on early nforce2 based motherboards caused many problems; problems as serious as bios corruption. Looking to the Intel side of the fence, async modes that run the memory slower than the FSB have merit because of how async modes are implemented in the Intel chipsets. This is extremely important, as we cannot change the CPU multiplier on modern Intel systems and therefore have to use and async mode to allow substantial overl!!!!! on the majority of systems utilizing the current 200/800MHz fsb family of P4 processors. To illustrate, if you increase the FSB on a new C stepped P4 to 250 MHz (250 x 4) with a 1:1 ratio, memory will work at 250 MHz (DDR500). This can be done in two ways. The first is with exotic PC4000 or DDR500 memory modules, but these are expensive just to run synchronously at such speeds and their timings are exactly delightful either. The other way is to overclock DDR400/DDR433 to much higher speeds through overvolting, but this is seemingly dangerous and often motherboards don’t provide nearly enough voltage to achieve such speeds without physical voltage mods. Therefore to avoid expensive PC4000 or volt mods, you change the memory ratio so that a 250FSB overclock will become something that the memory can handle to allow for a substantial overclock of the Pentium 4. In the example, to let PC3200(DDR400) remain as DDR400 with a 250MHz Overclocking &amp; Memory How do I overclock my memory? On modern systems, memory is very rarely, if ever, overclocked for the sake of overclocking memory. Lemme rephrase that, people don’t overclock memory to make it run higher than what is actually needed. There are many instances where memory is even underclocked. You first determine the default frequency of your memory, 1MHz higher than that frequency is the point where overclocking begins. Now how do you increase that frequency? As previously discussed, best performance on all platforms is gained by running the memory frequency synchronously with speed of the FSB. This means that for every 1MHz the FSB is increased, so too will the frequency of memory clock. So in effect, memory overclocking is just a part of overclocking your processor. They are done simultaneously. Since FSB frequency and Memory frequency are most times made to be the same, this poses a problem - as overclockers look for the highest possible FSB while the memory may struggle behind because it’s not able to keep. Other aspects to memory overclocking are memory timings and of course the amount of voltage supplied. Unlike CPU overclocking or video card tweaking, adjusting memory timings and frequencies offers very little physical risk to your system, other than the possibility of a windows failure to load or a program failure while testing. The memory will either be able to handle the overclocking/tweaking, handle it with instability or not handle it all. There are no grey areas in between, it either does, does with lots of problems, or doesn t at all. This makes it a bit simpler to quickly find the precise limits of any memory. The memory timings can also play a role in how far the memory will go, in keeping with the FSB. Lower timings (numbers) will hinder how fast the memory can run, while higher timings allow for more memory speed. So which is better, lower timings or higher memory speeds? Why not both? Overall data throughput depends on bandwidth and latencies. Peak bandwidth is important for certain applications that employ mostly streaming memory transfers. In these applications, the memory will burst the data, many words after each other. Only the very first word will have a latency of maybe several cycles, but all other words will be delivered one after another. Other applications with more random accesses, like games, will get more mileage out of lower latency timings. So weigh the importance of higher memory clocks against lower latency timings, and decide which is most important for your application. Memory Voltage Sometimes a little extra voltage is all that s required to encourage your defiant DDR to straighten up and fly right. You can adjust the ddr voltage quite easily through your motherboard’s BIOS as you would for your CPU’s voltage. Like CPU overclocking, raising memory voltage above default (default is usually 2.5v or 2.6v for DDR) at higher memory clock speeds may aid stability and/or enable you to use lower latency timings. Although the ddr voltage has nothing to do with the CPU itself, it plays an integral part in the big picture. If we are running a synchronous mode (1:1), then for every 1MHz increase in FSB speed, the RAM speed will increase by 1MHz. So in these cases an elevated memory voltage will often prove helpful in maximizing the overclocking potential of the CPU. A few points to consider when raising memory voltage: Like CPU overclocking, increasing memory voltage should be done in the smallest increments available. Put your system through a few paces of a program like memtest86 after each step. If it fails testing, bump the voltage a little more and test again. 0.3 Volts over Default - That s a bit conservative for some people (including me), but should be enough for most. This is also the maximum provided by most motherboards. On such motherboards, hardware mods or modified bioses maybe required to gain access to more voltage. Some of the higher voltages (2.9v to 3.3v) available on certain motherboards may damage the RAM with long exposure, so check with other people who have your RAM to get a feel for its voltage tolerances. The memory you save may be your own. Do I Need Ram Cooling? Memory cooling has become very popular, most notably on video cards. The effectiveness of memory cooling on both system ram, however, is often fuel for lengthy discussions on many internet hardware forums, including our own message board. Does system memory get hot enough to require cooling? Depends on what you consider is hot. My opinion is that memory modules never build up enough heat, to require any sort of cooling. Even when overclocking, they still stay pretty cool. If extra cooling, puts your mind at ease, then go for it, but you can t necessarily expect better overclocking results or even any extensions in the life of your overclocked / overvolted memory. Premier manufacturers such as Corsair, Mushkin, and OCZ ship their modules with heatspreaders across the chips. They look very nice and are often solid copper or aluminum. A handful of other companies sell ram cooling kits, and other solutions for modules that come without cooling. Ram sinks are pretty much the same as standard heatsinks for graphics chips and CPUs, except they re a lot smaller and tailored for RAM chip sizes. Tests show these heatspreaders &amp; kits to do VERY little as far as cooling the memory goes. With no real benefit, placing these cooling kits on memory modules is more for looks than for cooling, and that can be appreciated. Burning-In Memory Burn-in can be defined as the process of exercising an integrated circuit (IC) for a period of time at elevated voltage, speed and temperature with the aim of improving performance. With CPUs it’s another one of those debated topics, but in my experience “burning-in” memory does make it perform better. The time required varies and it doesn t always work, but it s worth a try. A tutorial on how to go about doing this. If your DDR400, for example, doesn’t run stably at 220MHz, try something lower. Leave the computer on for a few days straight. Give it a workout, then try it again at 220MHz Memory Chips and their Importance to Overclocking Very few companies in the world actually make memory chips, but literally hundreds of companies sell memory modules. Some of these few companies are Winbond, Hynix (Hyundai), Micron, Samsung, Infineon (Siemens), Nanya, Mosel-Vitalic, TwinMos and V-data/A-data. Like most other PC components, all RAM are not created equal. For DDR400, you can find memory varying from - very fast modules sporting 2-2-2-6 timings from Mushkin, Corsair, OCZ, Kingston (for example), to relatively low-cost modules that aren t as favorable with the timings. Even memories of the same brand and model may exhibit varying performance levels because of the chips being used. Manufactures use whatever memory chips are available at the time, and certain memory chips don’t stay in stock indefinitely. Take a look at the markings on the chips of your memory module. If your module has heatspreaders, it will have to be carefully removed to see the memory chips. (Doing so will void your warranty). Each chip is covered with numbers and those numbers have tell what chips they are and may even have the logo and name of the chip maker. Why does this matter? Like motherboards, for example, not all brands offer the same performance and overclocking potential. The same goes for memory chips. So people (usually overclockers) seek out certain preferred brands of memory chips for their systems. Example, Winbond’s famed BH-5 which was discontinued, then reintroduced and then was discontinued again to be replaced with newer cheaper CH-5, although there still is relatively high demand for BH-5. Check your module manufacturer’s website, they may or may not list what chips they use their modules."</post>
   <post id="11bb0433-46cb-43b5-b41f-be7b491113b6" section="Memory" discussion="THE Memory FAQ">"Buying Memory Memory Buying Very touchy subject for some. For others, RAM is RAM, right? Right!! If you plan on just running at stock speeds, then your hunt for memory just became easier. Not by a lot, but nevertheless, easier. With AMD platforms, the requirements for memory are more varied, due to the fact, that there are several different models of processors, many of which are utilizing different bus speeds. Higher end Athlon XPs, like the 3000+ and 3200+, require the use of at least DDR400 while lower end ones may be satisfied with the use of DDR333 or DDR266 modules. Newer C Stepped P4s, all require DDR400 for optimal performance. My only suggestion is to never buy generic RAM and for good reason. There are three factors that go into the quality of a memory module: the quality of the chips, the quality of the printed circuit board (PCB), and manufacturing. None of these factors are present on poorly manufactured modules. How do you tell what’s poorly manufactured? Simple, those are cheap and you don’t see a name of a company attached to it. So really, when buying memory for typical operation, buy something that’s fairly well known. As an IT professional, I work on a large network. I ll conservatively estimate that farm of PCs has 500 memory modules collectively. We buy name-brand memory (Crucial &amp; Kingston Value) exclusively. If your intention is to overclock, I can t stress this enough - YOU NEED HIGH QUALITY COMPONENTS!! I can t tell you how many times I ve tried to help people out with overclocking their systems and come find out that the one problem was they have no-name PC2100 dimms stuffed in their slots. Ick. One thing I can say with certainty is that you should buy PC3200/PC3500 at the bare minimum for any new system - AMD or Intel – if your sole purpose is to overclock. Not only for overclocked systems but for the sake of performance in general. Experience dictates that the advantages of fast memory are worth the slightly higher price that you have to pay to get it. Depending on the brand there isn t really much of a price differential between quality PC2700 and PC3200, to not get PC3200. Quality RAM is not always expensive, but expensive RAM is often quality. However, buying much faster RAM isn t always the best idea, especially for AMD chipsets. Overall, PC4000 and higher modules are not quite compatible with these motherboards. High speed DDR (PC3700 and all the way up to PC4500) generally, sacrifice all the useful functions (i.e. lower timings, compatibility with motherboards, ability to run in async mode) for the sake for attaining stable operation at high speeds. An individual buying these speeds of memory must be in a sound state of mind, and with a money-back guarantee or enough budget to avoid disappointment in the event of unsatisfactory results. Otherwise, it is advisable to stick with lower latency PC3200 or PC3500 modules. Consider that Fighter Jet A is your PC4000 memory and is built for super-fast speeds, but cannot maneuver as well as Fighter Jet B which is lower latency PC3200. In a dog fight on AMD terrain, Fighter Jet B will win because the terrain is mountainous and requires more maneuverability. Likewise, Fighter Jet A would have more of a chance on Intel terrain because on such a terrain speed matters more and maneuverability (or latency) isn t as important. But since, as discussed earlier, we can realistically use an async mode on Intel systems, it may well prove that doing so and using top quality PC3200 or PC3500 memory and their attendant lower latency will allow Fighter Jet B to triumph in most all cases. Bottom line is, don t skimp on your RAM selection. You ll be kicking yourself later if you do. But just the same, don t assume that because a particular memory type is expensive it is also superior for your application. Make all effort to avoid generic brands as they are famous for cutting corners during production and burning the wrong values into the SPD chips. Unhappy buyers are forced to struggle with poor performance or system crashes without knowing exactly why. Why are you recommending PC3500, when my motherboard only supports PC3200? Memory modules really have no fixed speed. Like the tire to a car, there is a "rating" on it. When a tire is rated to be 150mph, it means it can run as fast as 150mph maximum. It also means that it can run at any speed lower than that. It is also quite safe to say that the tire should also withstand at 160 mph, just not as "safe" according to the Government s test environment. Memory is very much similar in this way. Many people ask if a PC3500 or PC3700 module would run/blow up/be compatible in a motherboard originally designed to use PC3200 or PC2700. The answer is, hell ya! JEDEC (the “government”) has only approved PC3200. This reason, coupled with the fact that no processor needs memory rated higher than PC3200, are causes for motherboard manufacturers not stating support for newer, faster modules. But higher rated speeds of DDR are always ‘backward compatible’ so to speak, or capable of running at lower speeds. Older systems stand to gain from newer and faster modules. Even if they can t run the module at its top supported frequency, you can still tweak the timing parameters to maximize performance at lower clock speeds, that otherwise would not be possible with lower-rated modules. How much is enough? That, of course, depends on how you use your PC. When you determine memory needs, you ll also want to consider what your needs will be six months to a year down the road. If you think you may be upgrading your operating system or adding more software or doing futher system upgrades, it s a good idea to factor that into the equation now. Before you actually upgrade or buy new system memory, you need to obtain a few facts about your motherboard. The first bit of information you need is the amount of RAM that is currently installed, if you re upgrading. If you bought/built your PC a while ago and don t remember how much memory it has, there s a simple way to check without getting inside the box. Right-click the My Computer icon on your Windows desktop, and select Properties from the pop-up menu. On the General tab, you ll see the amount of installed memory listed in the lower right side of the box, just below the information about your PC s processor. Next, you need to determine how much memory your PC can handle. Every PC has an upper limit that is determined by the motherboard s chipset, which, in very simple terms, works as a bridge between the processor and the memory. Most new PCs have a maximum memory capacity of between 1GB and 4GB--more than you ll probably need, unless your job is calculating rocket-reentry effects for NASA. 4GB is the adressing limit for 32bit operating systems and processors, so until 64 bit devices and their supporting operating systems become common it is unwise to aspire to more than 4GB of memory. Chances are you already know exactly how much memory your motherboard can take, if you don t check your board s manual or inquire elsewhere. Will more memory speed up my computer? That depends almost entirely on how much memory the tasks you do on your computer take. If you are running simple or older programs that simply are not memory intensive, additional memory largely cannot help you. But over time operating systems and applications tend to require (and therefore benefit from) increasing amounts of memory, and in most cases it s hard to have too much. More memory will not increase the speed of the CPU, but it will reduce the time a CPU spends waiting for information from a hard drive. The operating system and applications will be able to load more of their data into ram at once, and the dependence on virtual memory will be reduced. Since RAM provides data to a CPU faster than a hard drive, you will not have to wait as long for programs to execute in most cases. If you want your computer to run considerably faster in nearly all cases, consider upgrading the CPU or overclocking. Matched or Certified Dual Channel Memory Companies like Corsair, Mushkin, OCZ, etc sell what they call "dual channel" memory, or Dual Channel Kits. These are sold in pairs, meaning, you might buy a 2x256MB Dual Channel Kit, which consists of 2 sticks of 256MB DDR memory paired together by the manufacturer for a total of 512Mb. Companies don t just throw two sticks of RAM together to produce these kits, but they don t necessarily produce a totally different batch of RAM either. Testing or qualifying Dual Channel memory might involve something as simple as technicians booting up pairs of RAM in a Dual Channel motherboard and ensuring they work together under a set of conditions, or it could be more complicated, including so called "SPD" optimizations and even chip selection. For your purposes, you should assume that Dual Channel memory is qualified through testing as all companies will claim that every pair of Dual Channel memory is tested for dual channel operation prior to being packaged. Will Non-Dual Channel Matched RAM work in my dual channel motherboard then? It most certainly, will. As long as it fits the requirements of Dual Channel operation (two of the same types of memory, same size modules, speed, etc). Two modules of the same model/brand purchased from the same vendor at the same time is essentially as likely to work properly in a dual channel configuration as is a dual channel kit. The ONLY thing you can lose by buying "single channel" memory for use in Dual Channel mode is that manufacturers may or may not provide support and replace your memory if it won t work in dual channel mode, whereas if Dual Channel memory fails to work in Dual Channel mode, the manufacturers will help you resolve the problem and possibly replace the memory to ensure proper Dual Channel operation. There are instances of people using two different types of RAM together and have had no problems. You can t damage your motherboard or RAM just by trying to use two un-identical module in Dual Channel mode. But be advised that if the machine is unstable for any reason, it is entirely possible to corrupt your data upon operation of the machine. Mis-matched memory sticks in a dual channel configuration often produce unstable operation, so as with any new overclocking or upgrading venture make sure you have adequate backups so you can recover from a data loss."</post>
   <post id="e1d18ce3-cd2b-439d-8658-6944f9dae5a1" section="Memory" discussion="THE Memory FAQ">"wow class guide mate, you ve saved me from asking a lot of questions that would ve made me look rather dumb"</post>
   <post id="957dee25-7751-4c1a-a60c-239f4472a67f" section="Memory" discussion="THE Memory FAQ">"Opteron Memory Guide NUMA FAQ (Non-Uniform Memory Access) Error Correcting Memory - Part I Error Correcting Memory - Part II: Myths and Realities Virtual Memory In XP Memory Timings @ Lost Circuits Corsair Memory Basics Interactive Macromedia Breeze presentation Understanding RAM Chip Numbers"</post>
   <post id="5fef5ee6-e0fa-43c8-a85e-abb6a815622e" section="Memory" discussion="THE Memory FAQ">"How about a nice guide on how to test RAM after installed step by step. Checking RAM for errors is a must in todays systems even if you dont have any problems with the system running properly. You could still have a DIMM thats causing an error or two now and then and needs to be RMA d. http://www.memtest.org/ Guide should tell how long to test, which tests to run, what settings to use, and so on."</post>
   <post id="589031a3-b801-4371-ba4a-a3651af9af31" section="Memory" discussion="THE Memory FAQ">"Fantastic Thread! I enjoyed reading every single bit of it."</post>
   <post id="9b194421-0581-4b5f-a93e-f03b3e2e0147" section="Memory" discussion="THE Memory FAQ">"Thanks Mostly noob here, but this answered WHY some of the forum guys were sliding me toward one or another type of memory. I m going to point some of my more techie oriented pals to this guide. Much appreciated. PinataUT"</post>
   <post id="61f7ff90-490a-479f-9cc1-32e47d247632" section="Memory" discussion="THE Memory FAQ">"Hi. Great work you ve done here. I wonder if you could help me. I just came back to AMD from Intel, and I did it with an Abit AV8 &amp; Athlon 64 3500. I m having a hard time getting my memory to run at pc3200 speed. The memory is 4x256mb Corsair pc3200 llc. I see no memory ratio adjustments in the bios. I am currently running the cpu at 225x11, for 2.475ghz. cpuZ says my memory is running at 177mhz. I don t know how to get the memory up to speed."</post>
   <post id="ccd5d1d8-f3fc-4ac6-84c8-edc38b2785f3" section="Memory" discussion="THE Memory FAQ">"Great thread. Thanks everyone. So I read the 939 mobo does away with the need for registered RAM. I read it s slower than non-reg RAM. But why does it exist? What AMD platforms use it? All 754 and 940 sockets? I take it another drawback would be if you went that socket route and bought the registered RAM you couldn t use it in a future 939 mobo? Thanks again. Great read. Great forums."</post>
   <post id="eafca5a3-e287-4851-98da-fec649e27d99" section="Memory" discussion="THE Memory FAQ">"EricDawg said: Great thread. Thanks everyone. So I read the 939 mobo does away with the need for registered RAM. I read it s slower than non-reg RAM. But why does it exist? What AMD platforms use it? All 754 and 940 sockets? I take it another drawback would be if you went that socket route and bought the registered RAM you couldn t use it in a future 939 mobo? Thanks again. Great read. Great forums. Click to expand... Server class and multi-processor machines use it."</post>
   <post id="3de1f799-418c-4732-9baf-2efaf7bef387" section="Memory" discussion="THE Memory FAQ">"My dream machine would have a dual socket Athlon 64 board. Would I need registered memory in order to have that? The same apply for dual socket, dual-core/quad-core in the future? Or would having a dual socket 939 eliminate the need for registered memory? Thanks"</post>
   <post id="7212f0ae-c296-488b-a578-9e472ba2bb07" section="Memory" discussion="THE Memory FAQ">"Posted Else where"</post>
   <post id="9f2c452c-887d-47e8-b2fe-e71146273bcf" section="Memory" discussion="THE Memory FAQ">"Binary Ape said: Posted Else where Click to expand... This was the first place, it was posted. The previous thread was nuked."</post>
   <post id="8752ee7a-3bbd-4097-b484-ee2447f61704" section="Memory" discussion="THE Memory FAQ">"This seriously saved my life."</post>
   <post id="404b922a-4b23-45b7-bd1b-586a89cd8628" section="Memory" discussion="THE Memory FAQ">"Brilliant read. It answered a lot of little questions I had about timings and so forth."</post>
   <post id="ef8eedb1-7761-4f61-9fe0-215f3c9f5bad" section="Memory" discussion="THE Memory FAQ">"What s TCCD? Maybe the FAQ could benefit from a glossary compiled of RAM terms. Most are already in there and a quick CTRL-F helps find them. Here s the best definition I could find on Google: http://www.dslreports.com/faq/11329"</post>
   <post id="956527eb-8aa5-4f31-b81d-617f6fc025c9" section="Memory" discussion="Mixed memory">"In my main machine I have: 2 sticks Corsair PC3-8500F 1 stick G.Skill PC3-12800 1 stick Hyundai PC3-12800 All are 4 gig. The Corsair are XMP memory and my board automatically overclocks them to XMP-1600 by increasing the voltage. They show 800mhz with a CAS of 9.0. The G.Skill is XMP memory but runs at stock voltage of 1.5. I shows XMP-1600 at 800mhz with a CAS of 9.0. The Hyundai is not XMP memory and runs at stock voltage. It shows JEDEK #6 with 800mhz and a CAS of 11.0. What should I do?"</post>
   <post id="162a0062-bcf7-4ab4-bfbd-4ddf2e4e2802" section="Memory" discussion="Mixed memory">"What CPU/board are you using? So you have 2 sticks of 1066, and 2 sticks of 1600 RAM. Assuming you are running an older Sandy/Ivy and on an Intel, you will probably see close to 0 improvements running overclocked RAM. I d say you can do 3 things: 1. Keeping everything at DDR3-1066 (8500), CAS 9-10 2. Trying for 1600Mhz (12800) at CAS11 and giving the RAM some added voltage - 1.55V? 3. Going for somewhere in between at DDR3-1333, CAS 11 and hope the Corsairs will OC just a little Option 1 is probably more stable given how your Corsairs are not guaranteed to OC all the way up to 1600."</post>
   <post id="4bf03241-ce2c-43eb-af0e-7a9da6cd6483" section="Memory" discussion="Mixed memory">"Buy 2 x 8GB sticks of budget DDR3 ram, and have better performance would be my vote. RAM is very affordable still."</post>
   <post id="de365b4d-2634-4f7c-a06e-789d0d145683" section="Memory" discussion="Mixed memory">"Not something I ve ever done myself, just over stability concerns. I still just use three of these at CAS 7 on my old P6T7 X58 with a X5680 in it, they OC well with that CPU. G.SKILL Ripjaws Series 12GB (3 x 4GB) 240-Pin DDR3 SDRAM DDR3 1333 (PC3 10666) Desktop Memory Model F3-10666CL7T-12GBRH - Newegg.com I ve always been tempted to buy a second set, but have never felt the need to really."</post>
   <post id="24a03b45-1fea-4751-ad59-386a46e4f548" section="Memory" discussion="Mixed memory">"Well by default most mobos will just downlock to the slowest rated ram, and voltage. The voltage variance will case the instability problem."</post>
   <post id="5ffe9c24-e07e-428a-b6a0-a246c067ca40" section="Memory" discussion="Mixed memory">"the Hynix is 1600 cas 11 so should be fine at 1333 cas 9. since the corsair requires over-volting to get to 1600 I would assume it is like my corsair 1600 and will run fine at 1333 with 1.5v. so you should be able to run all of them together at 1333 1.5v cas 9. so start with one stick at 1333 cas 9 1.5v and run memtest or something as you add in the other sticks to make sure they all play nice."</post>
   <post id="74577e39-c48c-4a73-b41e-c48c751a228c" section="Memory" discussion="Mixed memory">"jmilcher said: ↑ Buy 2 x 8GB sticks of budget DDR3 ram, and have better performance would be my vote. RAM is very affordable still. Click to expand... This."</post>
   <post id="94cc5396-86e2-4497-bf5a-af37e804c2b0" section="Memory" discussion="HTPC crashing waking from sleep.">"My HTPC was originally a 2500k on a P67 motherboard. It has 4 sticks of 2GB of DDR3 from G. Skill. Whenever its put into sleep it crashes. It will wake, but it boots from scratch everytime. I have another another Z77 motherboard that I moved all the components, thinking maybe the motherboard is faulty. The Z77 motherboard is in my file server and it hasn t had any issues waking from sleep. When I move the HTPC components to the Z77 motherboard the problem continued. So long story short I eventually narrowed it down to the memory. Once I put in the memory that was in my file server into my HTPC there hasn t been any issues. So far I ve been running memtest and it hasn t found any errors on the memory. My question is anyone had any issues like this know if there could be a BIOS setting or something that could cause this. In the past when I ve issues with memory there is usually other issues that are present as well."</post>
   <post id="78c1767b-2c6f-4813-b90c-f3ddff878700" section="Memory" discussion="HTPC crashing waking from sleep.">"I don t have any great ideas, but you can try bumping the VRAM voltage on the HTPC by .05"</post>
   <post id="c1d619aa-e032-49ec-bf15-bbebb8bc56e0" section="Memory" discussion="HTPC crashing waking from sleep.">"rastaban said: ↑ I don t have any great ideas, but you can try bumping the VRAM voltage on the HTPC by .05 Click to expand... Didn t think of that, that actually doesn t sound like a bad idea. Thanks"</post>
   <post id="ad773cce-5701-467e-9110-4db14fd7b814" section="Memory" discussion="does mushkin make the most reliable RAM?">"somebody was telling me mushkin RAM were moe stable (as in less doa) then cosair or g.skill... any thoughts?"</post>
   <post id="031d6a95-6867-414d-ac38-fed4e05348a1" section="Memory" discussion="does mushkin make the most reliable RAM?">"Personal experience as I use to do warranty and replacements for these sort of things, around the 1366 and early 1155 platforms G.Skill RipJaws and OCZ Gold Series in particular had the highest return and fault rate (as well as DOA) that needed to be RMA d or replaced. Corsair XMS modules also had a high fault rate but no-where near the figures of RipJaws. Kingston HyperX, Patroit, Mushkin, Geil and Crucial had the lowest returns, RMA, DOA, faults etc. The RipJaws was cheap for a reason compared to its competitors. I m not sure how RipJaws fare these days and whether or not G.Skill have improved there game but I don t touch them and put my money on Mushkin Blackline/Redline, Corsair Dominator and Kingston ram."</post>
   <post id="041f45f4-e182-4fc1-ac84-2b108362ae90" section="Memory" discussion="does mushkin make the most reliable RAM?">"Matthew Kane thanks for your info! I have also only been using mushkin ram for a while and have had absolutely no problems with it so far."</post>
   <post id="b56034b6-1efb-451c-875c-d8f8fad06659" section="Memory" discussion="does mushkin make the most reliable RAM?">"I have several GSkill DDR3 sets - all w/o any issues!"</post>
   <post id="286c76e7-2b01-4769-9fb4-76732a48503c" section="Memory" discussion="does mushkin make the most reliable RAM?">"Same here, Ripjaw, never a problem, but then I am just one sample. But then I have the 1000w Mushkin PSU that didn t get a stellar review here at H and it has been stellar for me and have been using it for a few years now."</post>
   <post id="f007fb6a-4a0b-4a15-8733-5faacba6a7d4" section="Memory" discussion="does mushkin make the most reliable RAM?">"In the past I d pick Mushkin above all others. ...haven t tried them in recent years though. Back in the Socket A SDR/DDR1 era days they made some of the best, if not THE best, RAM."</post>
   <post id="dd241a6b-bfbe-4462-98cd-f73e61462239" section="Memory" discussion="does mushkin make the most reliable RAM?">"Matthew Kane said: ↑ RipJaws Click to expand... dammit I hate it when I fall for marketing wank and sexy heatspreaders"</post>
   <post id="81445d07-a5f5-4915-9a22-0a0d8cc758aa" section="Memory" discussion="does mushkin make the most reliable RAM?">"rezerekted said: ↑ Same here, Ripjaw, never a problem, but then I am just one sample. Click to expand... I also have RipJaws running in 2 gaming boxes.... no issues with either one"</post>
   <post id="c0406168-2d52-42f9-87c8-0e099d94d57e" section="Memory" discussion="does mushkin make the most reliable RAM?">"I have had G.Skill in my last (3) builds. Have 2x8gb 1866 DDR3 G.Skill Ares in current machine. Never have had an issue with G.Skill. I wonder if the higher RMA rate for G.Skill is due to the quantity they sell? Most buy based on price and its seem G.Skill is always competitive priced. JMO"</post>
   <post id="f81a9768-a24e-4781-8338-65469845f3b0" section="Memory" discussion="does mushkin make the most reliable RAM?">"I ve never used Mushkin myself, have been using RipJaws for awhile now in builds. Once upon a time Mushkins were supposed to be fantastic, but I ve become a bit of a G.Skill fanboi myself. The RipJaws OC better than similar Dominators I have around in another rig, and I have a few old really odd OCZ sets around."</post>
   <post id="123b2289-5a0d-40ac-96ef-c036e60ddb3c" section="Memory" discussion="does mushkin make the most reliable RAM?">"MongGrel said: ↑ I ve never used Mushkin myself, have been using RipJaws mostly for awhile now. Once upon a time Mushkins were supposed to be fantastic, but I ve become a bit of a G.Skill fanboi myself. Click to expand... Agreed - when I first started building my own machines years ago, Mushkin was like the Cadillac/Mercedes of memory. And, it had the higher price to go with it. I wanted it - but just couldn t afford it. Now I can afford it, but it s hard when G.Skill has been so good to me over the years..."</post>
   <post id="eae35abc-9cbb-45d4-b6d5-764bcda5440f" section="Memory" discussion="does mushkin make the most reliable RAM?">"I have had extremely good results with G.Skill memory... Never had an issue at all, seems to be very reliable and stable.."</post>
   <post id="4b21b296-05b6-4342-8627-353edb3120c4" section="Memory" discussion="does mushkin make the most reliable RAM?">"RAM is RAM these days, honestly. Though apparently some Corsair kits aren t playing nice with Z170 / Skylake lately."</post>
   <post id="3037ed48-81a0-48dd-8ebd-b35e4a3e1147" section="Memory" discussion="does mushkin make the most reliable RAM?">"I run nothing but G.Skill now days for my builds and custom builds for clients. Out of 50 sets of ram that I used in the past 3 years I only had 1 bad stick."</post>
   <post id="08c18e92-0599-4651-9cc1-6a6feeb9ff8e" section="Memory" discussion="does mushkin make the most reliable RAM?">"Matthew Kane said: ↑ Personal experience as I use to do warranty and replacements for these sort of things, around the 1366 and early 1155 platforms G.Skill RipJaws and OCZ Gold Series in particular had the highest return and fault rate (as well as DOA) that needed to be RMA d or replaced. Corsair XMS modules also had a high fault rate but no-where near the figures of RipJaws. Kingston HyperX, Patroit, Mushkin, Geil and Crucial had the lowest returns, RMA, DOA, faults etc. The RipJaws was cheap for a reason compared to its competitors. I m not sure how RipJaws fare these days and whether or not G.Skill have improved there game but I don t touch them and put my money on Mushkin Blackline/Redline, Corsair Dominator and Kingston ram. Click to expand... No wonder they call them the RipJaws and not the LifeJaws. All joking aside, I ve used a few RipJaws kits over the past few years and none have failed. I usually stick to Crucial s Ballistix line (Tracer/Tactical/Tactical Tracer/Elite) only because I remember Voodoo would exclusively use them in their Omens which convinced me they were the best stuff haha The one memory manufacturer I avoid is Corsair because I feel all their products are hyped up by fanboys, and their oddly lowered CL and raised tRCD/tRP is a marking gimmick for lower latency. The only ones I would consider are the Dominators as they go through more rigorous testing (still true?) but they are never cost effective."</post>
   <post id="d52226db-e79d-482c-8456-f311a3204b11" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"I m trying to upgrade my garage PC to 8GB of memory, so I decided to give this a shot. The PC is an ASUS M3A79-T Deluxe motherboard with a Phenom II X6 1035T CPU and a Gigabyte 7970. ASUS says the board s four DIMM slots can take up to 16GB of RAM so it has to support 4GB individual sticks, and 4GB individual sticks are 512Mx64. I cleared the CMOS and took my 2GBx2 Dominators out, tossed in the new RAM, and the PC wouldn t boot to BIOS. I knew going into this that it was still a gamble whether it would work or not but I figured that for $21 shipped (versus $240 shipped for a 4GBx2 kit from Crucial) it was a gamble worth taking. Did I waste my money or am I missing something?"</post>
   <post id="22aaa28d-2233-41d9-acba-2a75c8d24188" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"try clearing the bios/cmos. you old ram settings might be throwing it off. if not that maybe your board does not like single sided ram(all chips on one side). there used to be issue with this. also are these supposed to be new? the pics look like theyre old. one of them even looks to have spill damage..."</post>
   <post id="fbebf691-bcf4-4147-9e59-0d88a49580c5" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"I cleared the CMOS several times. They are double-sided sticks. The sticks I received are new (were, anyway, until I installed/removed them several times), the gold contacts looked completely untouched when I unwrapped them. It has crossed my mind that they could actually be defective as well, and that it s not a compatibility issue."</post>
   <post id="ca7b3b90-28c7-4120-ba2b-25ba4a900e6c" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"Have you tried running on 1 stick? Are you using the right DIMM slots? Is it possible the memory is bad? Although it says new and unopened in the link, it is sometimes hard to say on ebay."</post>
   <post id="70063dff-03a1-4110-883f-e97a387997ff" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"I have tried single sticks and I m using the same DIMM slots that are functioning at this very moment (typing from the garage PC now). The other two slots are blocked by the Noctua CPU cooler. By every indication they were new sticks, the gold contacts were not scratched at all. It is quite possible that the RAM is defective, I m going to try them in another AMD board that I have floating around just to see what happens with that one."</post>
   <post id="4f16ecb5-0d94-407d-be0f-b1300a792693" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"Do you have the latest BIOS for your motherboard? Also, here is another eBay seller from the US that is selling a set of the Chinese RAM and says it works: 8GB(2x4GB) Sochox DDR2-800 PC2-6400U 240-Pin D22G1403 I would also not even try to buy new DDR2 anymore. The new stuff.. such as the stupidly overpriced stuff from Crucial is just laughable. I would find a good used set."</post>
   <post id="9513628b-0d51-411e-9bbd-6312ffce0215" section="Memory" discussion="Legacy RAM question - 512Mx64 &quot;AMD-only&quot; RAM">"cyclone3d said: ↑ Do you have the latest BIOS for your motherboard? Click to expand... I do have the latest BIOS, "latest" being April 2011. cyclone3d said: ↑ Also, here is another eBay seller from the US that is selling a set of the Chinese RAM and says it works: 8GB(2x4GB) Sochox DDR2-800 PC2-6400U 240-Pin D22G1403 Click to expand... I may have to get another set and decide if I want to eat the return shipping on these sticks or just find a use for them. cyclone3d said: ↑ I would also not even try to buy new DDR2 anymore. The new stuff.. such as the stupidly overpriced stuff from Crucial is just laughable. I would find a good used set. Click to expand... I know why the prices are so high - they have lifetime warranties to worry about and probably dwindling stock, so up go the prices. I would love to get another set of 2GBx2 Dominators so I have 8GB matching but the heatsinks on them are huge and will interfere with my CPU cooler."</post>
   <post id="7d1ef326-6e81-4750-88ee-944a5cd828d7" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"I m looking at potentially upgradeing from my 6GB ram to 3 sticks of either 4GB or 8GB. The price of this ram, , is impressively low and would be about $66 for 12gb or $108 for 24GB ram. It seems so cheap to be able to get 24GB; however, I don t know why I d need this (although I moved to W10 from W7 and it appears to hog more resources). I use my comp for gaming, Excel, some graphics editing, and that s about. I m planning on getting a Pascal-TI card in about a year and putting on this rig, if it s still alive I assume I should be able to reach my same timings at a lower vdimm and that this would be the last DDR3 I own on my ol  X58 board."</post>
   <post id="a6b3f470-8a9a-4ef2-950d-157a9bd36605" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"If you are experiencing slow computer performance due to a measurable lack of RAM, then add more of it. If you dont know you need this, you dont need it."</post>
   <post id="15210be7-2760-47fa-95d6-a675978f161c" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"Put as much in as you can afford.. I maxed my x58 motherboard out..I have 6-8gb sticks in a Asrock X58 extreme motherboard and it s running the full 48gb and in triple channel perfectly.. Probably don t need that much memory but what the heck it was dirt cheap when I bought it, got (3) 2x8 s of Gskill DDR 3 1866 for 49.99 each a couple years ago.."</post>
   <post id="1cfba458-d8e8-46a2-973e-1e1f8e79482d" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"JEKYLL said: ↑ Put as much in as you can afford.. I maxed my x58 motherboard out..I have 6-8gb sticks in a Asrock X58 extreme motherboard and it s running the full 48gb and in triple channel perfectly.. Probably don t need that much memory but what the heck it was dirt cheap when I bought it, got (3) 2x8 s of Gskill DDR 3 1866 for 49.99 each a couple years ago.. Click to expand... I like your style, I m going to get 3x8gb sticks of DDR3L Crucial Ballistix Tactical RAM and be done with it. Thanks for the advice, this will have a GTX 1080 or 1080TI on it, why pinch pennies when the GPU will cost a ton"</post>
   <post id="ea05ec17-2d1e-493e-9349-b26be1988fd5" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"What speed of the Crucial Ballistix are you looking for? Newegg has some good deals.. Crucial Ballistix Tactical 16GB (2 x 8GB) 240-Pin DDR3 SDRAM DDR3 1600 (PC3 12800) Desktop Memory Model BLT2KIT8G3D1608DT1TX0 - Newegg.com"</post>
   <post id="83a69f40-be33-4b21-968e-636443f3b3e4" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"Also I think memory on this board has to be paired in each bank to go from single channel, dual channel, and triple channel.."</post>
   <post id="d7a745eb-d969-4ef4-adb3-110ac8a1f920" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"That s the same ram I was Going to buy in Amazon, it s $36 a stick shipped on Amazon. I m using 3 sticks I bought individually and had no issues so was going to buy individually. The newegg 2x8 is a good deal but I figured I d buy all from Amazon, no need to do 2 vendors in case I need to return for under $10 savings Is that what you mean? I don t think they need to be paired Here s a good resource Everything You Need to Know About the Dual-, Triple-, and Quad-Channel Memory Architectures - Page 7 of 10 - Hardware Secrets"</post>
   <post id="50f5952f-1fea-4db6-88fe-896647e5bd6b" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"Check this thread out: Tri-Channel Memory Question. I think if you have six slots and put 2 sticks in bank 1 thats single channel, then 2 in bank 2 = dual, and 3 in bank 3 = triple.. So you proably would at least want 4 - 8 s to ensure dual..KazeoHin put an illustration in that thread to explain..."</post>
   <post id="3a9726e1-10bd-429a-a610-7c788d171309" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"Ohh, no I use bank 1,3,5 and will be good tri channel. Cool feature on older X58 boards"</post>
   <post id="e8b0b9ed-43c5-423f-bb26-c437263eea4f" section="Memory" discussion="DDR3 Upgrade from 6gb - 12gb or 24gb?">"Ahh, I got ya... Good luck on your upgrade... And may the X58 live long and prosper..."</post>
   <post id="55f5b1c1-0cd5-49e8-a579-f87efb6872ec" section="Memory" discussion="Tri-Channel Memory Question.">"Hello, all! I asked this a couple weeks ago and I m thinking that I might have been to blame, for not explaining things correctly. I have an X58 MoBo, with a Xeon X5560. All RAM slots have 2 GB RAM, so, 8 GB. Could somebody help me to understand this? Thank you, in advance."</post>
   <post id="45621f1a-ee87-4217-8ce8-32327581718d" section="Memory" discussion="Tri-Channel Memory Question.">"Okay, some early generation X58 boards supported Tripple Channel memory, but did it instead with 4 slots. I ll use text to illustrate. Normal X58 board: ---------------- 1A ---------------- ---------------- 1B ---------------- ---------------- 2A ---------------- ---------------- 2B ---------------- ---------------- 3A ---------------- ---------------- 3B ---------------- Old X58 boards: ---------------- 1A ---------------- ---------------- 2A ---------------- ---------------- 3A ---------------- ---------------- 3B ----------------"</post>
   <post id="f3bab73d-1b29-40e8-be94-e2dac3af54ae" section="Memory" discussion="Tri-Channel Memory Question.">"KazeoHin, so with 2 GB in all 4 slots I m still running triple channel?"</post>
   <post id="43d4e3e4-0580-44f2-b73a-e178910baac4" section="Memory" discussion="Tri-Channel Memory Question.">"Sounds wiered."</post>
   <post id="f4cfe709-2eff-4705-a674-74adf034bf3d" section="Memory" discussion="Tri-Channel Memory Question.">"Actually, I just got done with some research about my situation. First, I forgot that I have 6 slots. That doesn t matter. The info from Dell shows that my configuration is in fact running tri-channel. Weird, I know. When I can, I guess I ll add two more modules. No hurry, as I can t afford it, lol."</post>
   <post id="0a820120-290c-4950-b7bf-07a7a67ee7d3" section="Memory" discussion="Tri-Channel Memory Question.">"Memory controllers suppoort mispatched pairs. The memory controller will mix thuings together seamlessly, and overall you ll see a performance increase. We ve supported such mismatched pairs on dual-channel motherboards, like an installation with 10GB ram in 4x2 pair plus an extra 2GB in a single channel. Or even a dual channel system with mismatched dimm sizes. Intel calls that asymmetric mode: Intel Flex Memory Technology - Intel Stakes Its Vision of the PC Future with 775 Launch So yeah kids, those strange notebooks that ship with 6GB ram in two slots? Are probably running in dual-channel mode!"</post>
   <post id="c4918029-56b5-42a0-933c-d7408590b7cd" section="Memory" discussion="Tri-Channel Memory Question.">"I have 6-8gb sticks in a Asrock X58 extreme motherboard and it s running the full 48gb and in triple channel perfectly.. Probably don t need that much memory but what the heck it was dirt cheap when I bought it.."</post>
   <post id="bdfab26f-76ec-4ed5-838e-60e75ff1ab87" section="Memory" discussion="Tri-Channel Memory Question.">"Yeah, just thought it was odd having an even number of DIMMs on a triple channel board. I thought it was "un-possible." But from what you guys have told me, and from Speccy showing triple-channel, works for me."</post>
   <post id="d301e20e-bcf6-4a6e-b2c7-663f1fdb48db" section="Memory" discussion="My first X99 build ... DDR4 question">"OK I m hoping you guys can enlighten me / help me out on this. Originally, I got my hands on some DDR4 (GSkill 3200) that was on sale on Jet.com figuring DDR4 = DDR4. Not being able to get it to boot at all, I look closer and see that it s x100 chipset DDR4 ... which I am now guessing is not compatible with X99 chipset DDR4. Am I right in this? I need to get X99 specific DDR4? i.e. newer ram is not necessarily better in this case? I see that there is a voltage difference also, which might explain the issue but that s just a guess. Any thoughts would be appreciated."</post>
   <post id="dfae4cc7-1c85-4ed5-a786-3bbe7de8d0db" section="Memory" discussion="My first X99 build ... DDR4 question">"What is the voltage difference you noticed? Try booting with just 1 stick first in the right slot. Also, what density RAM / stick are you using?"</post>
   <post id="08e8a692-b38d-4040-83e7-2da2ef32b3ee" section="Memory" discussion="My first X99 build ... DDR4 question">"Well, RAM should be  just RAM  but I m sure some 6-and-8-core i7 5000 series chips have trouble running over 2400 Mhz RAM."</post>
   <post id="c792a488-8bc9-43ad-ad6b-5f709d9a74b6" section="Memory" discussion="My first X99 build ... DDR4 question">"The ram I happen to have in hand is GSkill Ripjaw V as well as Corsair Vengeance LPX - both are DDR4 1.35v. But after some reading it seems that X99 needs 1.2v DDR4??? I ve swapped mobos, cpus, psus - with the 2 types of ram being the only constant (1 DIMM at a time to test of course)."</post>
   <post id="ef010d61-7cec-4edf-94e7-e087737c014e" section="Memory" discussion="My first X99 build ... DDR4 question">"dvsman said: ↑ The ram I happen to have in hand is GSkill Ripjaw V as well as Corsair Vengeance LPX - both are DDR4 1.35v. But after some reading it seems that X99 needs 1.2v DDR4??? I ve swapped mobos, cpus, psus - with the 2 types of ram being the only constant (1 DIMM at a time to test of course). Click to expand... What is the capacity of each module? Some X99 boards require a BIOS update to handle 16GB modules, as these didn t exist when X99 first appeared."</post>
   <post id="fd2e36a8-8e61-4321-b3d4-704cfec9d0f3" section="Memory" discussion="My first X99 build ... DDR4 question">"They were all 16gb sticks. I had 4x 16gb Ripjaw Vs and 2x Vengeance LPXs. I have one stick of Crucial Ballistic Sport LT coming in (1.2v) for testing which I m hoping will be my way out. Either way I m going to keep the 4x 16gb Ripjaws for a future 170 or newer build down the road, so it s not entirely a loss but my  toys fund  is empty for a while (No new fog lights for my subie!)"</post>
   <post id="66c135dc-b1b9-46b6-9999-8a507689d17f" section="Memory" discussion="My first X99 build ... DDR4 question">"When you get the new stick, check for a BIOS update, and then try your 16GB ones again. I have a Gigabyte X99 board that had a BIOS update available that listed support for 16GB memory modules as one of its changes. I haven t tested whether it adds support for that, as I can t imagine what I d use 64GB of memory for, but this was apparently an issue for Gigabyte."</post>
   <post id="b7f66d69-7656-432f-98f6-a269522da016" section="Memory" discussion="My first X99 build ... DDR4 question">"Thanks man, I ll give it a shot when it gets here sometime next week."</post>
   <post id="a31673d0-f5d7-4221-ac32-90aa65d9c080" section="Memory" discussion="Samsung begins mass production of 10-nanometer class DRAM">"Samsung begins mass production of 10-nanometer class DRAM (DDR4) Samsung begins mass production of 10-nanometer class DRAM | ZDNet Samsung has begun mass production for 18-nanometer DRAM that boasts a transfer rate of 3,200 Mbps, which will boost PCs and servers for its enterprise clients. Samsung has started mass production of 10-nanometer class 8 Gigabit (Gb) Double Data Rate 4 (DDR4) DRAM, the company has announced, having started producing the memory chip in February. Wonder how long until it comes out on the desktop? Starting out at 3200 speeds sounds very nice to me."</post>
   <post id="6c41a7d0-1c01-4cd9-afa8-966f5623b0c1" section="Memory" discussion="Samsung begins mass production of 10-nanometer class DRAM">"cageymaru said: ↑ Samsung begins mass production of 10-nanometer class DRAM (DDR4) Samsung begins mass production of 10-nanometer class DRAM | ZDNet Samsung has begun mass production for 18-nanometer DRAM that boasts a transfer rate of 3,200 Mbps, which will boost PCs and servers for its enterprise clients. Samsung has started mass production of 10-nanometer class 8 Gigabit (Gb) Double Data Rate 4 (DDR4) DRAM, the company has announced, having started producing the memory chip in February. Wonder how long until it comes out on the desktop? Starting out at 3200 speeds sounds very nice to me. Click to expand... At the rate that new Samsung enterprise products hit the channel, I m guessing the end of the year at the earliest..."</post>
   <post id="9ae2a557-ad7b-4117-8a60-638337267813" section="Memory" discussion="Samsung begins mass production of 10-nanometer class DRAM">"I don t think current desktops will benefit form this. We re already hitting a performance improvement wall beyond 3000. But servers moving a lot of data around would"</post>
   <post id="fd079316-0842-4f42-bec7-67f2b0518805" section="Memory" discussion="Samsung begins mass production of 10-nanometer class DRAM">"I wonder when will fiber optic ram (optical ram) become a thing for the masses."</post>
   <post id="83f3d07d-7751-4456-9d64-b903fcb9998c" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"So I just upgraded my motherboard (Gigabyte Z170 Gaming 7), CPU (Core i7 6700K) and Memory (CORSAIR Vengeance LPX 16GB 2x8GB DDR4 3000). I ve been experiencing freezes at stock speeds. When I build a new PC I always just install the components and leave everything at default just to make sure everything s stable before I overclock. But this time I started experiencing freezes (during Windows install and when fully booted). Suspecting the ram, I went in and bumped up the voltage to 1.3, while keeping at stock speed, and everything stabilized. No problems at all, no crashes. But when I activate Corsair s XMP profile (which bumps the voltage to 1.35), I either crash while loading windows or soon after booting in. Since the platform is so new I guess it could be a motherboard bios issue (already updated to the most recent from Gigabyte), but what is your gut reaction to ram not being stable even at stock speed/voltage? I m guessing I ll need to order some new ram and try that out. Would "overclocking" ram ever be unstable at stock voltage and speed? Seems like a bad sign. Would love to try another brand but thanks to my Noctua D15 s clearance issues I have to go with low profile ram."</post>
   <post id="8bef3ef6-6fd7-4ec4-bd41-f2d5b0154c81" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I d probably get new ram. I quit buying corsair ram a few builds ago due to constant problems. I ve had zero issues with gskill. Sucks you ll have to pull the cooler but I d do it if you can easily return the ram."</post>
   <post id="9dcf035b-af1b-4c9a-b7ec-6206b4253eac" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I have seen a couple of reports that clocked memory may require a tweak on some CPUs . I think it was an Asus report that said System Agent can be used up to 1.3V, 1.25V is recommended. IO voltage up to 1.25V, recommended 1.2V"</post>
   <post id="e1a72461-4e98-4229-ada6-be1438fc3d6a" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Thanks for the replies. I actually just RMA d the Corsair ram and ordered a set of G.Skill Ripjaws V 16GB 3200. Figured that if I m having freezes at stock voltage and speed, there s more than likely something wrong with the ram. The Gigabyte and i7 6700K seem great otherwise. Even though the Ripjaws V heatspreader is slightly taller, it shouldn t be a problem since my case can accomodate lifting the Noctua second fan to compensate. Once I installed the cooler I realized I could just clip the fans a little higher to make room for the ram beneath."</post>
   <post id="670fa323-70a2-4ba4-9f46-1b05a9227a7c" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I had to modify the System agent and IO to get stable with 3000mhz Gskills, I didnt go as high as you have listed, well not yet anyway have not completed my CPU overclock testing yet."</post>
   <post id="e8894ddc-1105-4db9-a8c2-730b8b4fb6aa" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I don t mind ram being slightly lower than their rated overclock, it s when the ram can t even run stably at stock speed and voltage (looking at these Corsairs) that I start to worry."</post>
   <post id="0ee9f973-5b7d-45e5-84ec-f1570246058b" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Its a known issue, the resolution has been posted."</post>
   <post id="7a6d975a-9ac0-44be-9906-334d9e13e086" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"nbuubu said: ↑ I don t mind ram being slightly lower than their rated overclock, it s when the ram can t even run stably at stock speed and voltage (looking at these Corsairs) that I start to worry. Click to expand... Agree 100%. FWIW I ve never had a dead or defective gskill dimm. I ve been using them exclusively for some time. One of these builds I m going to try Mushkin though just for the heck of it."</post>
   <post id="2a8f566b-994e-4248-ae9d-6a1aa0e92784" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Nenu said: ↑ Its a known issue, the resolution has been posted. Click to expand... Link? I d like to see it as I m likely building multiple sky lake rigs"</post>
   <post id="f007d55c-2833-4b6c-a566-407d95a7c619" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Heres one of them http://www.legitreviews.com/ddr4-me...finding-the-best-ddr4-memory-kit-speed_170340"</post>
   <post id="fd9f36c6-c849-4875-b6b7-646fcfa30808" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Asus overclocking guide https://drive.google.com/file/d/0Bz2VRRbLPrZnMXBnOXRWeVlHcHM/view?pli=1 VCCIO/System Agent voltage are both important for memory clocking. 1.25V for system agent and 1.20V for VCCIO should be enough to achieve 4 DIMM stability at DDR4-3200. The maximum we have used in-house is 1.30V system agent and 1.25V for VCCIO Click to expand..."</post>
   <post id="53d4a15d-0ff0-43d2-9203-63d0f80c8d36" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Nenu said: ↑ Asus overclocking guide https://drive.google.com/file/d/0Bz2VRRbLPrZnMXBnOXRWeVlHcHM/view?pli=1 Click to expand... Right, that is how you get the RAM to run at its rated timings when OC d but he is saying they would not run at the base clock, 2133mhz unless I misunderstood. I am not surprised at all that XMP failed on its own it didn t work for me either."</post>
   <post id="eda8d6c0-9a30-468d-b5ad-c91e33bc7464" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"He was fine until he used the XMP profile Suspecting the ram, I went in and bumped up the voltage to 1.3, while keeping at stock speed, and everything stabilized. No problems at all, no crashes. But when I activate Corsair s XMP profile (which bumps the voltage to 1.35), I either crash while loading windows or soon after booting in. Click to expand... btw, oc d means at its rated speed. Not clocked any higher. All ram is initially 2100MHz, higher speeds are a manufacturer overclock. He might have another issue, but its a good idea to cover the bases of the known issues. If its still unstable, work from there."</post>
   <post id="e97d4ab9-b29e-408d-834f-2a51d09c1f13" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Actually, I wasn t fine even before using XMP. The Corsair kit is unstable at stock clocks and stock volts, no overclocking at all, that s the second line in my post. When I activate the XMP profile the ram fails on boot. When I run at stock, it freezes intermittently anywhere from 2-10 minutes in to load (and while doing nothing ... not even a web page). Just mentioned that activating XMP made it crash instantly, is what convinced me the issue is ram. The only way to get it to run stable is to up the voltage to 1.3 while leaving the speed and timings at stock ... I m pretty sure that s a sign of bad ram (and my first bad ram from Corsair). Already RMA d and waiting for some G.Skills."</post>
   <post id="22859cf4-cf5a-474a-b408-1a930bfe9542" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"Ran Memtest from USB, and my system froze in the middle of the first test. Didn t get an error, just a full freeze. Hopefully the new G.Skill ram arriving Monday will solve all this."</post>
   <post id="a3fa4633-4bc0-4125-9835-dfc208b4151c" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"nbuubu said: ↑ Ran Memtest from USB, and my system froze in the middle of the first test. Didn t get an error, just a full freeze. Hopefully the new G.Skill ram arriving Monday will solve all this. Click to expand... I d RMA any RAM that caused any issues at all with Memtest when using stock RAM settings."</post>
   <post id="47b57612-4490-490b-a826-e5813427dd97" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"mls1995 said: ↑ I d RMA any RAM that caused any issues at all with Memtest when using stock RAM settings. Click to expand... I agree 100%, memtest is like the minimum it should pass."</post>
   <post id="b365b5b1-5fcc-4ff6-beec-d8ba435a0419" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I tried running each stick of the Corsair CMK16GX4M2B3000C15R kit individually, and while occasionally they can run ~two hours at stock voltages and speeds before freezing Windows, sometimes my system freezes within a minute of booting. This specific ram is listed as compatible on the Gigabyte docs for the Z170 Gaming 7, so I m really hoping it s the ram and not some other issue. The fact it can freeze while running memtest from USB makes me think it s the ram, but you never know. This is my first crack at a Gigabyte board in many years and I m hoping I don t have to RMA it. All my temps for CPU at stock are low (20s while idle, 40s while gaming) and aren t suddenly spiking during a freeze."</post>
   <post id="dcc2900e-8307-4cb3-a4ba-3cfa16118165" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"You guys are right, I terribly misread the op in my post #13. It looks like there is a serious issue, most likely with the memory. If not that, possibly the CPU or mobo. Op have you reset your CMOS in case it has something not so good set or has corrupted?"</post>
   <post id="5741cf48-2684-4023-b23a-d981ac414e1b" section="Memory" discussion="Bad Memory on Z170/Skylake build?">"I m running the exact same stuff Corsair LPX 3000MHZ 2x8GB sticks. I have an Asus Z170 Pro Gaming and I am getting freezes as soon as I enable the XMP profile. I am starting to see many bad reviews pop up on newegg and amazon for this Corsair LPX, as well as many other motherboards being unable to activate the XMP profile. I think there is something bigger going on..."</post>
   <post id="7db1916b-bb4d-44be-a79c-f7eb7739417c" section="Memory" discussion="Would DDR4 future Proof anything over DDR3">"I read about improved latency and that is about it"</post>
   <post id="55b93376-950e-484d-a627-aa6515057502" section="Memory" discussion="old Gigabyte Iram">"for you who don t know this is a 4 Dimm pci card that holds 4 GB of DDR memory as Ram disk. I have one of these but I have not used it in a while. Found it in my junk drawer. Only problem I don t think the lithium Ion battery used to maintain the data is any good. Also is limited to only Sata 1 speeds. Thought I would play with it. Does the Pci bus maintain power in sleep mode? The only real use I plan on is a 4 gb swap file."</post>
   <post id="d1aa782f-9819-4124-9de7-1191c6b1a01a" section="Memory" discussion="old Gigabyte Iram">"Just toss in a new battery. PCI bus shouldn t maintain power in any deep state of sleep to conserve energy, otherwise we d have GPUs and such drawing in sleep (Depending on board)."</post>
   <post id="808f473a-5487-4314-83ca-c5c2bcdecdf7" section="Memory" discussion="G Skill F3-12800CL9S-4GBNT">"I am trying to use a 4 gig chip of F3-12800CL9S-4GBNT on an Asrock Z77 Pro4 motherboard. Won t Post. Same speed memory I have in the machine. Just got this chip on eBay."</post>
   <post id="715264d0-1c56-44c9-a1a3-4652182a1080" section="Memory" discussion="G Skill F3-12800CL9S-4GBNT">"Did you tested the stick separately?"</post>
   <post id="a154ac49-3cf5-45ec-a468-f27ecaa35d94" section="Memory" discussion="G Skill F3-12800CL9S-4GBNT">"flatty said: ↑ Did you tested the stick separately? Click to expand... Yes."</post>
   <post id="0e3294ea-6a3d-4c9e-83ed-558b38a9b021" section="Memory" discussion="G Skill F3-12800CL9S-4GBNT">"try some tricks: rub the contacts with normal paper (some people use a rubber, im "paper fan"), switch modules between them, (BTW, be sure all the RAM slots are working), (other question, did u see the board and the CPU (RAM controller is in CPU) "mastering" 4 sticks of RAM?"</post>
   <post id="5d1dd0b5-f46b-4484-bb89-f91367d8edc6" section="Memory" discussion="G Skill F3-12800CL9S-4GBNT">"First mistake was not buying an identical stick. But since you already did: Some boards are really picky about having matching CAS latency, timings, and actual RAM chip MFGs (Not as in G.SKILL or Corsair, but as in Hynix or Nayna who actually make the little black chips on the stick). Make sure they match, and if they don t, that could be your issue,"</post>
   <post id="5969be36-4564-4100-ae3f-d160644b9e42" section="Memory" discussion="G.SKILL TridentZ 3200MHz 32GB DDR4 Review">"Those crazy crustaceans over at MadShrimps rubbed a few sticks of G.SKILL s TridentZ 32GB 3200MHz DDR4 together to see what would happen. Once the smoke cleared, the memory was still standing so, if you are memory shopping, you ll might want to read this review. The 32GB dual-channel Trident Z kit from G.SKILL is carefully binned to work at the rated 3200MHz and comes with a XMP 2.0 profile, which should be compatible with the latest high-end motherboards. The tested kit comes with Samsung ICs and sports the 15-15-15-35 CAS latencies; the kit does barely get warm during operation and G.SKILL has incorporated a very fancy heatsink on it, which should fit with most motherboard color schemes."</post>
   <post id="f6d4a24a-2b6e-4964-95f5-2e9eb9af589a" section="Memory" discussion="G.SKILL TridentZ 3200MHz 32GB DDR4 Review">"I love how quickly DDR4 is maturing. Only a few months ago, you got 2133 MHz with 15-15-15-35 timings. Now there s 3200MHz with the same timings. Very impressive indeed."</post>
   <post id="3d4ada2e-2e83-4d4f-a759-4407b5e12cc1" section="Memory" discussion="G.SKILL TridentZ 3200MHz 32GB DDR4 Review">"Good stuff. I m looking forward to testing out the TridentZ 16GB 3200Mhz DDR4 kit I got with 14 CAS soon."</post>
   <post id="37ebf8f1-255d-4c92-8685-10537f6d01e4" section="Memory" discussion="G.SKILL TridentZ 3200MHz 32GB DDR4 Review">"I m lost, where is the improvement over DDR3? My ram is running DDR3-2000, on a 8350 with 250Mhz CPU bus speed, 8,8,8,24 That DDR4-3200 at 15,15,15,35 is faster how? On an Intel with a 100Mhz bus speed? The 16GB stick size is sweet though."</post>
   <post id="3be72ed8-6430-4f80-86d8-415ddf866bce" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"The review crew at Overclockers Club just published a review of G.Skill Trident Z DDR4-3400 16GB memory kit. If you are memory shopping, you ll want to read the full review. In every test run, the Trident Z modules finished first in every test but three. In those three tests the performance gap was minimal at best between the top two sets of high speed DDR4 modules. When overclocked, the Trident Z modules followed the Patriot modules in only three tests. Again with margins small enough that you could call it a draw. All in all a very impressive performance from this set of memory from G.Skill."</post>
   <post id="c5637a9d-955e-440f-aafb-dcc391af23c9" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Cool. I m getting these in the build I m planning now. Thoughts?"</post>
   <post id="5d15e6bf-e8ae-4cf8-bfb9-efc74ca24186" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"hard forum has even existed for 46 years...i find that hard to believe. What did it run on? AFIK first forums to even exist were late 70s ~40 years ago."</post>
   <post id="33c0841e-74dd-4776-8aaf-7a364330c9d6" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Hard Forum ran on carrier pigeons back then, DUH!!"</post>
   <post id="f9d96b1b-de17-4084-868b-3202718f3ab6" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Undercover_Man said: ↑ Hard Forum ran on carrier pigeons back then, DUH!! Click to expand... hahaha...i thought they just met at taverns or used the pony express?"</post>
   <post id="17517f12-035d-4a63-bc6c-7118570156df" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Exactly, used carrier pigeons to communicate, held meet ups at the taverns to get tipsy, and ended up at the local pony express for post-gaming activities."</post>
   <post id="6a6012a6-7eb1-48cd-88a1-c40e19b0a122" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Undercover_Man said: ↑ Hard Forum ran on carrier pigeons back then, DUH!! Click to expand... I Lol d at this.."</post>
   <post id="66d89309-3549-4c36-98cb-580b78ed836d" section="Memory" discussion="G.Skill Trident Z DDR4-3400 16GB Memory Review">"Undercover_Man said: ↑ Exactly, used carrier pigeons to communicate, held meet ups at the taverns to get tipsy, and ended up at the local pony express for post-gaming activities. Click to expand... IP over Avian Carriers"</post>
   <post id="dc07887d-fcbb-42e8-8bc8-f3eede49a06a" section="Memory" discussion="192GB = 196600MB ??">"Hey all, Just installed 12x16GB sticks of registered DDR3 in my server (Supermicro X8DTE with dual Xeon L5640 s). so, 12x16=192GB, and 192GB should (if my math is correct) be 196608MB. My BIOS reports in as 196600, so there are 8MB missing. This strikes me as being odd. I wanted to check in to see that I m not dealing with some sort of defective RAM. Odder yet, in th eOS, this is reported as 188.97GB, which is odder still as it doesn t match up with either of the numbers above (maybe this is due to the on board Matrox G200eW graphics maybe?) Unfortunately I don t have enough time to run a memtest on all 192GB right now before the machine needs to be up again, (this could take days) so I just wanted to check in and see if you guys found this to be a little fishy or if it is perfectly normal. Much obliged!"</post>
   <post id="0cecefb2-4175-4744-acfe-83cfe6c212f9" section="Memory" discussion="192GB = 196600MB ??">"If you had a defective RAM stick you would be missing a hell of a lot more than 3.03GB. I m fairly certain the entire stick would be out and you would lose 16GB. My guess is the same as yours. It s being reserved for Bios functions and the onboard video card for VRAM purposes. The old Matrox G200 PCI and AGP card shipped with 2MB and later 8MB VRAM. Why the board is reserving another 3GB, I do not know. However, I would suspect that the the larger the memory pool and amount of onboard devices increases the amount the bios reserves for itself. Hopefully someone more knowledgeable can answer."</post>
   <post id="e05ca80c-4b5b-44e6-88fc-1e3eec5395df" section="Memory" discussion="128 GB DDR4 question">"Is 128 GB of DDR4 ram that tricky to get running right? A computer guy told me that not all cpu s etc work right with that much ram. Anybody have exp with that much ram on a x99 MB?"</post>
   <post id="dcd5d7d9-bb7e-40e0-a1b6-5d489dd03aef" section="Memory" discussion="128 GB DDR4 question">"Possibly slightly off topic, but that much memory almost necessitates ECC / Buffering. Single--bit errors occur as a function of memory size, that much memory means random little corruptions will occur more likely on a per-system basis than on a more "normal" system with 8 or 16GB of RAM. On a more on-topic note, occasionally occupying all DIMM slots requires looser timings and possibly not even using the memory at it s highest rated speed. Aside from that, it should be plug-and-play. Checking the manufacturer s recommended/tested memory list helps with applications like this."</post>
   <post id="f44651b0-6d6e-4278-bb2a-04ef5004806d" section="Memory" discussion="128 GB DDR4 question">"We deploy a LOT of Win7/10 Enterprise workstations at work, but they re all running ECC ram in HP workstations. So far we haven t had any issues with that amount of ram or getting it to work properly, but we re also not using the X99 platform &gt;_&gt;"</post>
   <post id="2d83ae6e-8aa1-4b63-ad18-f2f637ede0ba" section="Memory" discussion="128 GB DDR4 question">"I ll scale back to 64 GB then. Glad I asked about this before I bought that much Ram. Thanks"</post>
   <post id="bbd31526-b39f-4dcd-9d0a-a111cb6ad9a7" section="Memory" discussion="128 GB DDR4 question">"X99 is designed for it. Overclock will likely be limited having all the channels populated with the largest supported non-ecc sticks though."</post>
   <post id="3b9d447b-bb94-4b70-a8ee-4aaefa6f3857" section="Memory" discussion="What are optimal specs?">"Hello HF community! I am upgrading from an Asus P6T with i7-920 @ 3.8Ghz. I am currently getting a new GIGABYTE GA-Z97X-UD5H with a 4790k. I chose this motherboard because I like the protected features it offers for longevity and this cpu for its single thread performance. 6 years ago I was told that the optimal memory you would want is 1600Mhz because going any higher meant looser timings and little performance difference. I haven t been following the PC hardware fads. I mainly use my PC for gaming. Can someone tell me, if I could have made a better choice by going to DDR4? And what are the optimal memory module specs for gaming and overclocking as of now? P.S I m looking to buy new memory modules that s why I m asking these questions, and any suggestions are very much welcomed!"</post>
   <post id="fbbcbbd4-194f-4067-9eab-4c53fa3e724f" section="Memory" discussion="What are optimal specs?">"You can not go DDR4 unless you upgrade to Haswell-E or Skylake. You want 1.5V or lower DDR3 1600 or DDR3 1866 UDIMMS. These days I would get 8 GB dimms. Soemthing like this: G.SKILL Ripjaws Z Series 16GB (2 x 8GB) 240-Pin DDR3 SDRAM DDR3 1866 (PC3 14900) Desktop Memory Model F3-1866C9D-16GZH - Newegg.com"</post>
   <post id="1c523be1-c56a-4b2f-bcb0-d1b508786796" section="Memory" discussion="What are optimal specs?">"drescherjm said: ↑ You can not go DDR4 unless you upgrade to Haswell-E or Skylake. You want 1.5V or lower DDR3 1600 or DDR3 1866 UDIMMS. These days I would get 8 GB dimms. Soemthing like this: G.SKILL Ripjaws Z Series 16GB (2 x 8GB) 240-Pin DDR3 SDRAM DDR3 1866 (PC3 14900) Desktop Memory Model F3-1866C9D-16GZH - Newegg.com Click to expand... Wouldn t lower voltages be better like 1.35v from crucial ballistix tactical LP?"</post>
   <post id="c5134c24-15ac-473d-bfde-ef0f8cb68dfe" section="Memory" discussion="What are optimal specs?">"ASRock Extreme 6 is what i got and its nice. It also comes with this awesome debug feature that tells you where an issue is....saves lots of guess. For optimal memory is an odd question. Ideally this would be one of the best memories you can get but anything comparable will be good. G.SKILL Trident X Series 32GB Desktop Memory Model F3-2400C10Q-32GTX - Newegg.com Fair notice: I have this set and I am struggling with it but it might be something i have done wrong. I still got to trouble shoot. I have OCs and custom settings and lots of stuff so don t take my case as a common issue with this set. I personally would get anything over 2100 MTs. I also have 16GB of Gskill sniper that i would be okay with selling you. I have no use since i replaced them. 2133 CL 10 (F3-2133C10D-16GsR). Its a decent set of RAM but i wanted the best so i upgraded to the above. As i said i wouldn t go with less than 2100MTs RAM if this is a new build. You want this to last. Also if your going new build why not get 6700K? epscially if single thread is the issue....I am Single thread limited too. I went with an SL 4.8GHz chip since I already had a Z97 board already...was kinda waste to do a whole new build. (so waiting for Kaby Lake) Also you have a few misconceptions about RAM speed and latency. I use this calc I made to see the actual latency of RAM. It ll be easier to compare RAM using this Calc. Excel file to find 1st, 4th, 8th word Latency! SomeGuy133 said: ↑ timings are only relevant when put into perspective/context as i keep telling people who keep missing the major point that timings is literally only half of the equation. 2133MT/2=1066.5Mhz (1/(1066.5mhz*10^6))*1000000000=0.937646507ns (cycle time)*10 CL=9.376465073 ns, which is the true latency of the RAM. The red number is the only number you should care about. CL is meaningless without considering the MTs. You can have a 4000 CL for all i care as long as the MTs is freakin gigantic. It is simpler to just use my excel sheet. Click to expand... Fair note my Calc only does CAS latency. there are several other factors in latency. I haven t gotten a chance to expand it yet but this well help you compare RAM. from different MTs to different CL Also as stated above. Anything 2400MTs or above is solid according to Anandtech but 2133 is still even decent but 1600/1866 are fairly slow for today even for gaming. Not the end of the world by any means but there is a small tangible difference."</post>
   <post id="2ea746c2-ee24-4cb4-9357-b143dea1a273" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ Wouldn t lower voltages be better like 1.35v from crucial ballistix tactical LP? Click to expand... Yes. However that will limit your speed since it will be harder for manufacturers to overclock the ram and retain 1.35v."</post>
   <post id="ec514c2a-8abc-4157-b3bf-b9aa8771d9d9" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ ASRock Extreme 6 is what i got and its nice. It also comes with this awesome debug feature that tells you where an issue is....saves lots of guess. For optimal memory is an odd question. Ideally this would be one of the best memories you can get but anything comparable will be good. G.SKILL Trident X Series 32GB Desktop Memory Model F3-2400C10Q-32GTX - Newegg.com Fair notice: I have this set and I am struggling with it but it might be something i have done wrong. I still got to trouble shoot. I have OCs and custom settings and lots of stuff so don t take my case as a common issue with this set. I personally would get anything over 2100 MTs. I also have 16GB of Gskill sniper that i would be okay with selling you. I have no use since i replaced them. 2133 CL 10 (F3-2133C10D-16GsR). Its a decent set of RAM but i wanted the best so i upgraded to the above. As i said i wouldn t go with less than 2100MTs RAM if this is a new build. You want this to last. Also if your going new build why not get 6700K? epscially if single thread is the issue....I am Single thread limited too. I went with an SL 4.8GHz chip since I already had a Z97 board already...was kinda waste to do a whole new build. (so waiting for Kaby Lake) Also you have a few misconceptions about RAM speed and latency. I use this calc I made to see the actual latency of RAM. It ll be easier to compare RAM using this Calc. Excel file to find 1st, 4th, 8th word Latency! Fair note my Calc only does CAS latency. there are several other factors in latency. I haven t gotten a chance to expand it yet but this well help you compare RAM. from different MTs to different CL Also as stated above. Anything 2400MTs or above is solid according to Anandtech but 2133 is still even decent but 1600/1866 are fairly slow for today even for gaming. Not the end of the world by any means but there is a small tangible difference. Click to expand... 4790k scored the highest in single-core cpubenchmark, so I just decided on that. I didn t know the specs I was reading were MT/s. I thought it was Mhz. It seems to me that in a handful of CPU-intensive games you will see at most a 10fps difference. Does ram speed contribute to loading times or rendering in-games? Is there a reason to get 32GB over 16GB?"</post>
   <post id="1121e3aa-8bd2-4105-9752-0269a4b9fe0a" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ 4790k scored the highest in single-core cpubenchmark, so I just decided on that. I didn t know the specs I was reading were MT/s. I thought it was Mhz. It seems to me that in a handful of CPU-intensive games you will see at most a 10fps difference. Does ram speed contribute to loading times or rendering in-games? Is there a reason to get 32GB over 16GB? Click to expand... the standard in my eyes is min of 16GB no matter what. Only certain people need 32GB like me. 16GB is solid. You should know if your having issues with 16GB. higher bandwidth aka more MTs can help loading and FPS but it is fairly minimal once your pushing 2133+ MTs. 2400+ is ideal but not a big deal in terms of gaming. Other programs that can be different so case by case of course. SKL has ~6% better IPC so a 4.8GHz SKL vs a 4.8GHz HW will be faster by 6% on average. going from a 920 to HW/SKL will be night and day especially in older games. If you play older games with bots or large units there will be a massive FPS difference. Source engine, Total War, RCT3, NS2, and others are heavily single thread limited. So yea anything 2133MTs or faster you will be fine. Faster is better but nothing major. (we are talking 1-3% difference assuming RAM has the same over all latency) 2400 CL10 ~ same as 2133 CL9 in terms of latency. 3200 CL 14 ~ 2400 CL 10 but one has better BW, which again only affects a small sample of games and programs."</post>
   <post id="dbc96762-6938-49df-881e-032397ce69bd" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ the standard in my eyes is min of 16GB no matter what. Only certain people need 32GB like me. 16GB is solid. You should know if your having issues with 16GB. higher bandwidth aka more MTs can help loading and FPS but it is fairly minimal once your pushing 2133+ MTs. 2400+ is ideal but not a big deal in terms of gaming. Other programs that can be different so case by case of course. SKL has ~6% better IPC so a 4.8GHz SKL vs a 4.8GHz HW will be faster by 6% on average. going from a 920 to HW/SKL will be night and day especially in older games. If you play older games with bots or large units there will be a massive FPS difference. Source engine, Total War, RCT3, NS2, and others are heavily single thread limited. So yea anything 2133MTs or faster you will be fine. Faster is better but nothing major. (we are talking 1-3% difference assuming RAM has the same over all latency) 2400 CL10 ~ same as 2133 CL9 in terms of latency. 3200 CL 14 ~ 2400 CL 10 but one has better BW, which again only affects a small sample of games and programs. Click to expand... Where did you get that 6% difference in single-core performance?"</post>
   <post id="dacb595c-711f-4d6a-9255-d6d903c80aa3" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ Where did you get that 6% difference in single-core performance? Click to expand... The Intel 6th Gen Skylake Review: Core i7-6700K and i5-6600K Tested you need to do the math. HW-BW-SKL 1.00*1.033*1.027=1.060891=~106.1%"</post>
   <post id="c83a5bd0-99f2-4b7c-af36-8530621570af" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ The Intel 6th Gen Skylake Review: Core i7-6700K and i5-6600K Tested you need to do the math. HW-BW-SKL 1.00*1.033*1.027=1.060891=~106.1% Click to expand... Thank you. The game I am focusing on is using the unreal engine 3. The game is well known to be cpu-intensive because of the unreal engine. Can you recommend me a site that shows benchmarks of 6700k vs 4790k relative to this game engine? If I decide to get 6700k and return the 4790k, I have to research for another motherboard, heatsink and RAM.. I would like to overclock the 6700k if needed by the game."</post>
   <post id="0cba96cf-ab12-482f-9788-4f698cd766cf" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ Thank you. The game I am focusing on is using the unreal engine 3. The game is well known to be cpu-intensive because of the unreal engine. Can you recommend me a site that shows benchmarks of 6700k vs 4790k relative to this game engine? If I decide to get 6700k and return the 4790k, I have to research for another motherboard, heatsink and RAM.. I would like to overclock the 6700k if needed by the game. Click to expand... if you already got Z97 there is no reason to scrap your system. Thats why i spent 350 on a binned 4.8GHz from SL..its close enough and was a small price to pay."</post>
   <post id="9f0ea845-764d-446e-ae73-6e163e4cb49f" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ if you already got Z97 there is no reason to scrap your system. Thats why i spent 350 on a binned 4.8GHz from SL..its close enough and was a small price to pay. Click to expand... They re still new in the box. I think I will exchange the setup for 6700k. I saw some real world performance for a few games. I can get a similar mobo with the new cpu around the same price. I have a hard time choosing a mobo that is known to OC well with the 6700k. Any suggestions? I like the Gigabyte z170x gaming 7, but I don t see any ESD protection features, so I m going to assume that s a given for modern boards? Please correct me on this. What would be the trident x equivalent in DDR4?"</post>
   <post id="cfc6144e-e36d-4693-b61f-56beb75951b2" section="Memory" discussion="What are optimal specs?">"ASRock over clock formula is supposedly good. its like 230 though. one of the best DDR 4 you can get ATM. G.SKILL TridentZ Series 32GB (2 x 16GB) 288-Pin DDR4 SDRAM DDR4 3200 (PC4 25600) Desktop Memory Model F4-3200C14D-32GTZ - Newegg.com"</post>
   <post id="95a2bbd7-87ff-4ef7-a290-991b882d745c" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ ASRock over clock formula is supposedly good. its like 230 though. one of the best DDR 4 you can get ATM. G.SKILL TridentZ Series 32GB (2 x 16GB) 288-Pin DDR4 SDRAM DDR4 3200 (PC4 25600) Desktop Memory Model F4-3200C14D-32GTZ - Newegg.com Click to expand... hmmm I m not willing to shell out $254 for ram unless its somehow justified for gaming."</post>
   <post id="ccda889f-5df6-41fb-afee-31dd43e8f868" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ hmmm I m not willing to shell out $254 for ram unless its somehow justified for gaming. Click to expand... you dont need to. Its just the best. Also thats 32GB. get 16GB. thats ~120. Also Get anything that is 2400+ but with low latency. Use my excel sheet to compare latencys. So you might find some 2400 with comparable latency...at least close. Anything under 10ns is good enough for first word."</post>
   <post id="9bdd9b17-e47d-446a-9f78-c96dc6ddadef" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ you dont need to. Its just the best. Also thats 32GB. get 16GB. thats ~120. Also Get anything that is 2400+ but with low latency. Use my excel sheet to compare latencys. So you might find some 2400 with comparable latency...at least close. Anything under 10ns is good enough for first word. Click to expand... excel sheet? ur referring to the equation u posted on this thread right?"</post>
   <post id="1d677f66-3fc4-4283-876b-fa6ccc60158d" section="Memory" discussion="What are optimal specs?">"element72 said: ↑ excel sheet? ur referring to the equation u posted on this thread right? Click to expand... ....look where it says in yellow....a link....to a thread......called....excel file......"</post>
   <post id="81ca04f6-eca9-4432-acce-1f59621f6a1c" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ ....look where it says in yellow....a link....to a thread......called....excel file...... Click to expand... LOL, sorry about that. It was late when I was reading those post. Thank you so much for the calculator. Look what I found CORSAIR Dominator Platinum 16GB (2 x 8GB) 288-Pin DDR4 SDRAM DDR4 2400 (PC4 19200) Desktop Memory Model CMD16GX4M2B2400C10 - Newegg.com That s comparable to what you showed me right? It weird that it is out of stock but no reviews!"</post>
   <post id="12b065fa-cb7a-4031-83a0-3d53de9fc8d5" section="Memory" discussion="What are optimal specs?">"its comparable in CAS but not the other latency. If it was 10-10-10 vs 10-12-12 yes. The other latency is in the 10ns range so its on the boarder in my opinon either save a few bucks and get this $90 HyperX Savage 16GB (2 x 8GB) 288-Pin DDR4 SDRAM DDR4 2400 (PC4 19200) Desktop Memory Model HX424C12SB2K2/16 - Newegg.com or spend a little more and get this. its entirely up to you. I doubt there is anything major in terms of games for your use. For me I would go with the 120 option but i am picky $105 DDR4 3000, 14, 16GB (2 x 8GB), Desktop Memory, Memory, Components - Newegg.com $120 DDR4 3200, 14, 16GB (2 x 8GB), Desktop Memory, Memory, Components - Newegg.com"</post>
   <post id="38a3bbbf-645c-4f05-b890-eb6b8d14b21f" section="Memory" discussion="What are optimal specs?">"SomeGuy133 said: ↑ its comparable in CAS but not the other latency. If it was 10-10-10 vs 10-12-12 yes. The other latency is in the 10ns range so its on the boarder in my opinon either save a few bucks and get this $90 HyperX Savage 16GB (2 x 8GB) 288-Pin DDR4 SDRAM DDR4 2400 (PC4 19200) Desktop Memory Model HX424C12SB2K2/16 - Newegg.com or spend a little more and get this. its entirely up to you. I doubt there is anything major in terms of games for your use. For me I would go with the 120 option but i am picky $105 DDR4 3000, 14, 16GB (2 x 8GB), Desktop Memory, Memory, Components - Newegg.com $120 DDR4 3200, 14, 16GB (2 x 8GB), Desktop Memory, Memory, Components - Newegg.com Click to expand... The TridentZ ram you showed me has 14-14-14-34. Would I see any real difference if I got the same tridentZ ram you suggested, except it has 15-15-15-35? The cycle time is the same, but I don t know why I should care about 1st word, 4th word, and 8th word. I guess bigger question is would you able to see a difference in practical sense?"</post>
   <post id="43967663-e55f-405b-8954-2fb50a86878b" section="Memory" discussion="Performance problems from using 4 memory slots on a Triple Channel chipset?">"Hi all. Need some help, maybe some schooling. It s a Dell Precision T3500, Dell X58 MoBo, Xeon X5560, 4 X 2GB ECC DDR3. It s a triple channel chipset, yet I m running 4 memory modules. Everything runs fine, but I m thinking that I might be screwing up with this config. I guess what I d like to do is replace the 2GB modules with 3 X 4GB modules. It seems that ECC or non ECC is fine, as long as I don t mix them. Again, everything is working well, but I m sure it could be better. But I can t spend money right now to make things better. Any thoughts from you Masterminds? Any help would be much appreciated. \Wyo PS: From Speccy: RAM Memory slots Total memory slots 6 Used memory slots 4 Free memory slots 2 Memory Type DDR3 Size 8192 MBytes Channels # Triple DRAM Frequency 666.3 MHz CAS# Latency (CL) 9 clocks RAS# to CAS# Delay (tRCD) 9 clocks RAS# Precharge (tRP) 9 clocks Cycle Time (tRAS) 24 clocks Command Rate (CR) 1T Physical Memory Memory Usage 49 % Total Physical 8.00 GB Available Physical 4.06 GB Total Virtual 9.87 GB Available Virtual 2.96 GB SPD Number Of SPD Modules 4 Slot #1 Slot #2 Slot #3 Slot #4"</post>
   <post id="5b34c633-b93d-4b0b-9fa4-cfaecf21230b" section="Memory" discussion="Performance problems from using 4 memory slots on a Triple Channel chipset?">"Yeah, I know that to a lot of you this is pretty basic stuff. I m trying to do what I can with what I have, which, I know, ain t much. But I enjoy what I have immensely. Please indulge by curiosity."</post>
   <post id="b8a8f99a-c9cd-473f-ba42-daa5469c60e5" section="Memory" discussion="Performance problems from using 4 memory slots on a Triple Channel chipset?">"Yes, I could remove one stick of 2 GB. But I don t want to go from 8 to 6, and I can t afford to buy what I want right now, which is a triple set of 4, or 8. Just isn t gonna happen any time soon."</post>
   <post id="e5a56117-d938-477f-8485-73d806d49c0f" section="Memory" discussion="Performance problems from using 4 memory slots on a Triple Channel chipset?">"A single 4GB unbuffered ECC stick of DDR3-1333 is $18. Kingston Value RAM 4GB 1333MHz PC3-10600 DDR3 Non-ECC CL9 DIMM SR x8 Desktop Memory (KVR13N9S8/4) at Amazon.com"</post>
<post id="353da336-5757-4175-821f-a2e3ceb81bbf" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"The Corsair M65 Pro RGB gaming mouse is on the test bench today at ThinkComputers. If you are in the market for a new gaming mouse, and you want one that has RGB lighting, give this review the once over. Corsair keeps the ever popular design of the mouse, but adds a brand new 12000 DPI optical sensor that provides pixel-precise tracking and advanced surface calibration support. On top of that you have the awesome aircraft-grade aluminum frame, 3 different RGB lighting zones, advanced weight tuning system and more."</post>
   <post id="1a37019d-1eff-4186-ac5d-077ee47ec654" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"I have one of the older models at home and at work. Love them."</post>
   <post id="eaacff20-fcfd-4b05-b70c-03a1090ee660" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"Does it click? Check Does it scroll? Check Is is comfortable? Check Is it affordable? No. Fail. It s just a mouse. I still love my Logitech MX518 s."</post>
   <post id="070e9fa0-fd81-4adb-9314-17cf6fb2c3e0" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"I m just glad they got rid of the stupid "tramp stamp tattoo" looking "gaming" logo clearly everyone including myself hated. Sadly, they put it on my otherwise very nice keyboard before coming to their senses and going back to the sails. Happy enough currently with my original M65, though I may pick up one of these eventually and hand down the M65 to a friend. Nukester said: ↑ Is it affordable? No. Fail. It s just a mouse. I still love my Logitech MX518 s. Click to expand... Honestly, $60 isn t even "bad" for a high end gaming mouse. Not sure what you re complaining about."</post>
   <post id="7cf48b43-78d5-4c93-a341-90a164af6bae" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"I am sure everyone makes a pretty good gaming mouse these days, but I will always use Logitech mice. I have the G402 now, and it is a dream. But I only got that one because after a couple of decades of hard labor my MX510 was gross."</post>
   <post id="1f2ecea5-16d6-4cf1-90c8-68b23a7f363b" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"silent-circuit said: ↑ I m just glad they got rid of the stupid "tramp stamp tattoo" looking "gaming" logo clearly everyone including myself hated. Sadly, they put it on my otherwise very nice keyboard before coming to their senses and going back to the sails. Happy enough currently with my original M65, though I may pick up one of these eventually and hand down the M65 to a friend. Honestly, $60 isn t even "bad" for a high end gaming mouse. Not sure what you re complaining about. Click to expand... Not really complaining, just priced a bit high."</post>
   <post id="f381896e-bb84-477f-8360-b850550167f2" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"Nukester said: ↑ Does it click? Check Does it scroll? Check Is is comfortable? Check Is it affordable? No. Fail. It s just a mouse. I still love my Logitech MX518 s. Click to expand... I got mine 2/$40 2 years ago. Gotta find sales."</post>
   <post id="c95319f1-9d43-488d-a6ca-62118fbe76b4" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"schizrade said: ↑ I got mine 2/$40 2 years ago. Gotta find sales. Click to expand... Agree with that. I still have a stash of 4 mx518 s to burn through. Best damn mouse for my big hand I ve ever used."</post>
   <post id="769aaeff-184d-41f4-846b-503f704379cb" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"seriously whats with the whole RGB trend in PC peripherals..rgb in kb s, mice,case, mobo, ram. Are they so hard up at new ideas that they need to sell this as a feature? I really could care less if it has RGB or not over other more useful features but maybe I m in the minority. And if having RGB means extra bucks I rather have no RGB."</post>
   <post id="3d89e6f0-292f-47e4-bdb7-fc6154ad1322" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"I ve had an M60 forever and it s been awesome... but the one thing it s missing is not RGB lighting, it s wireless. What would it take for Corsair to make an M65 with a Bluetooth 4.0 radio in it and a small USB-rechargeable battery?"</post>
   <post id="76845f47-e9d2-4ee7-80a7-b9bb387d3ffd" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"My biggest complaint with the original is the scroll button. It has this sticky feel that prevents it from returning to its normal position, which is disappointing for someone that likes to keep that button mapped. I m glad to see they moved the sniper button back though, it was impossible to use where it was on the original."</post>
   <post id="fb3b7089-fd4f-4712-8d0b-482a19e95c19" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"I miss my old MX intelemouse explorer they were big and chunky and fit my mits nicely and worked great for long time. I now have an Anker gaming mouse and like it pretty well. I just need a mouse that mouses and not UFO s with all the flashy lights, I also like a good heavy mouse as it just feels proper when I clobber the villains."</post>
   <post id="2e5eb7ed-8a22-426b-92f8-be3ef4072e2d" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"well just came back from best buy and bought this, using it as we speak...gonna game on it and ill post my reactions in a few hours"</post>
   <post id="b0440013-99a6-4961-8f65-95b7ca6d5da6" section="Mice and keyboards" discussion="Corsair M65 Pro RGB Gaming Mouse Review">"This uses the Pixart PMW 3360 sensor. This is supposedly the now mass available version of the 3366 which was exclusive to Logitech (G502, G303, G900)."</post>
   <post id="dac3e274-b987-4cf3-93e3-38d9d958fe09" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"So, it s weird, a few weeks ago my "C" button has an issue where when I press the aforementioned key it will just not register all the time. As in I have to press it multiple times just to register. I am using a mechanical keyboard. Sometimes it will work but it s completely random on whether I can just simply press the "c" key and it ll work or I have to press multiple times."</post>
   <post id="cf851fe9-e120-48c3-a99f-907cf4ee02b5" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"Sounds like it s worn out. Time for a new keyboard."</post>
   <post id="3f3b78ce-2c9d-4078-a541-c69a63f88169" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"I can "C" how that would be a problem. Well, you kould always try typing everything with a K instead. Just kidding... Try taking the keycap off and seeing if there s something underneath it causing interference. I ve had that happen before, and it turned out there was a hair or something causing issues. It s important to clean your keyboard out once in a while... if properly cared for, mechanical keyboards should last longer than membrane keyboards. If the switch itself is damaged or worn out, sometimes the switch can be replaced without replacing the whole keyboard."</post>
   <post id="ac2b5902-c7f3-405f-a231-60508a810b30" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"i c what you did there"</post>
   <post id="f196291f-160f-49f1-a6df-cbe5dd039277" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"What kind of keyboard is this? If it s a shitty old rubber dome Dell or something, just get a new one. If it s a $150 Filco, clean the thing. No idea why you made a thread about it."</post>
   <post id="440a31c2-c7ab-45c6-af64-ed1a45e6808a" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"If only one key is bad, specifically with a mechanical keyboard, I would just replace that switch. Sticky keys on membrane keyboards can even be repaired with some rubbing alcohol and elbow grease."</post>
   <post id="8d6d43f8-b60a-417a-9724-820ad178f6da" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc After exhaustive testing I definitely think it s your c button."</post>
   <post id="9b066a00-3e72-4dce-bdd5-48ba17a66ca9" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"Just yesterday, the  1  key on the mechanical keyboard I use at home had stopped working. It turned out that a solder joint had cracked. Today, I took out my soldering iron and reflowed the solder joints with a little more solder. Works now. 1111111"</post>
   <post id="02a1619d-6177-473f-b476-29bba3f85a4e" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"Plug another keyboard in and just use the C key on that. It will save wearing the other keys out."</post>
   <post id="17a45c62-7364-4410-a580-b029dee97252" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"anyoneknowhowtofixabrokenspacebar?"</post>
   <post id="29a1c600-460e-4845-84cf-4190511b1658" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"There are many other keyboards in the C get one.."</post>
   <post id="80463b1a-d34b-43cd-86df-a69c1491c445" section="Mice and keyboards" discussion="My C button has issues, what should I do?">"If it s a mechanical, you can probably replace just the one switch for the C key. Cherry MX switches can be had for about 90 cents apiece from various vendors on the internet. Probably cheaper if you buy them in bulk somewhere. Edit: As someone mentioned, the problem may just be a cracked solder joint. You may not even need to replace the switch, but rather just reflow the solder."</post>
   <post id="5fa25f58-7add-4d46-b444-71d5aef005a6" section="Mice and keyboards" discussion="Ergonomic mechanical keyboard?">"Anyone use a mechanical keyboard that isn t a plain, traditional rectangle configuration? I like the Microsoft Ergo 4000 keyboard as far as layout, but the keys are not the greatest."</post>
   <post id="da00c37e-9878-43fa-a45d-f50a835320b9" section="Mice and keyboards" discussion="Ergonomic mechanical keyboard?">"ErgoDox"</post>
   <post id="9cddcbd4-2a0a-49bd-a96a-dfbae2d5d72e" section="Mice and keyboards" discussion="Ergonomic mechanical keyboard?">":) said: ↑ ErgoDox Click to expand... I ve followed that thing for a while but it doesn t look right for me. The Kinesis Advantage models look appealing if they only had a less extreme layout for things like up/down/left/right. And the price is a bit prohibitive as well. I guess what I really want is the Microsoft Ergo 4000 with mechanical keys which is probably never gonna happen."</post>
   <post id="e909b08b-3d2a-4012-82ce-8c11a07e7c4d" section="Mice and keyboards" discussion="Ergonomic mechanical keyboard?">"You can remap the keys on the Kinesis Advantage. When I used one, I both remapped the keys and moved the keycaps to get the four arrow keys in one row on the right side. There are mechanical keyboards in more traditional layouts though: There is the Matias ErgoPro which has mechanical Alps-clone switches. The switches are more similar to the ones used by Apple in the early  90s than to Cherry MX. There were quite a few models of ergonomic mechanical keyboards made back in the 1990s when mechanical key switches were still mainstream. However, many of these are rare collectors items these days and are very expensive on the second-hand market unless you find a seller who does not know what he/she has. The ErgoDox came out of the enthusiast community, and it is not the only one. There have been others in more traditional layouts that never reached outside circles of enthusiasts, and there are several in development. Some are on the way to becoming commercial projects though: Do look out for the Ultimate Hacking Keyboard in small form-factor with Cherry MX. Another one with funky layout is the Keyboardio. Kinesis has also been rumoured to work on a mechanical version of the Kinesis Freestyle Do expect prices to remain quite high for mechanical ergo keyboards. Other than those, I would suggest that you try out Microsoft s Sculpt keyboard with low-profile switches. I find the shape and feel to be superior to the MS 4000. It comes with mouse that also has a nice shape but is a bit heavy."</post>
   <post id="f587c4bb-0736-47d1-88af-89f078275962" section="Mice and keyboards" discussion="Ergonomic mechanical keyboard?">"Thanks, that s great info. The Matias ErgoPro is seriously appealing based on a very initial look.... I ll certainly do more research on it. Looks promising. The Keyboardio is also a project with potential. I ll be following them, as it s fun to read about even if the product doesn t work for me in the end. I did try the Sculpt and didn t care for the keys. They remind me of a good laptop which is good but not great."</post>
   <post id="010b23bb-4337-40cb-a30f-f1907e5da7f2" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Here s a review of that new fangled keyboard that was just announced the other day, the Corsair K70 RGB RAPIDFIRE mechanical keyboard. It looks pretty spanky and the reviewer seemed to really like it as well. This is where the K70 RGB RAPIDFIRE gets a twist. Remixing the formula for 2016, Corsair have a timed exclusive deal with CHERRY to outfit their keyboards with the latest MX Speed switches. Featuring a 45cN actuation force and a 1.2mm actuation distance, they are the fastest and most precise switches available from CHERRY. That isn t their only improvement, they are optimised for SMD LEDs with high output luminosities to give a brighter and more vivid experience."</post>
   <post id="983c712b-e7cc-43f3-9044-3b3f803e95e0" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"looks shinier than the razor but I m waiting for a key board that looks cool and does not make so much noise when I m typing... the mechanical keyboards are great in that they generally don t have as many problems as the cheap ones but when typing fast it is clack clack clack... my anasai was really cool looking and I could get to cycle through colors while using or just in time to my screen saver but it was loud too... maybe at work it s not a big deal but when I m writing or gaming late at night it is really loud. here hoping that the next company figures out how to make sound sound and the same translucent keys or plexi tops, sooner or later we will get virtual keyboard that we can swap on the fly that actual can change the image on the key boards... a couple companies tried it... though I think corsair wanted to be metal... sorta... depends on if it was was twenty seconds or licensed... I m guessing not since they are having to try and raise money to pay for stuff right now..."</post>
   <post id="feac7984-8bf0-4cf2-ac18-43e1fdf31bc9" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"The two main issues were not addressed. Poor dispersion of the LED light for keys with multiple characters. That damn software. Sheesh...."</post>
   <post id="a5d3d9de-d3bd-4ba4-aa77-9fecde2dd1b8" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Guys its $170usd + tax for a keyboard. Since when do these revolutionary RGB mechanical switches make you have a better gaming experience? How do you even quantify how much  better  they are vs. old tech in my 6year old keyboard? I spilled juice and shit on this old G110 and its still going. I doubt those clicky keys would do the same. Are these keyboards the golden egg for Corsair? They hand them out to all the e-sports gamers and people eat it up."</post>
   <post id="313e9607-c73b-42e4-a1c4-48dbbe36ced1" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"^Do you know that feeling when you re walking along the nice firm sidewalk and you accidently step in some gooey dog poo? It feels gross, mushy, and you never want to do it again. That s what it is like with mechanical keys going to the plastic membrane kind. The RGB part is just added bling. I haven t really messed with the custom lights passed the first few days, but I needed a new keyboard and it was $140, so why not."</post>
   <post id="6d7c8358-3537-4f46-a15a-e4c41687a9ac" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"These keyboards are way too expensive. I mean yeah its nice but that price is inflated for sure. RGBs and mechanical keys are not that expensive."</post>
   <post id="eb98eb3d-c6d6-495f-9d33-0d170aa87ed3" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Yep, wanker tax for sure. I like mechanical keyboards for their durability but $19 for a wired membrane or even $40 vs this? Haha!"</post>
   <post id="80656ef1-53dc-427f-b9fb-96575a5a466f" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"I bought a Corsair K70 keyboard for my Xmas present. I love it. I think it was $90? It replaced a 10 year old Microsoft ergonomic keyboard. I love the mechanical keys (mine are browns). I have the LEDs disabled - not something I care about to be honest. However, different strokes for different folks. The MSFT keyboard was comfortable to type on, but the if I try using it now - they keys are mooshy. Hard to go back. At work, I use the new MacBook a lot. It has weird keys that I still am not comfortable typing on after 6 months of use. I would not mind a mechanical keyboard for when I m docked...."</post>
   <post id="ac1f5b5b-3f14-44e3-bc63-3ebf6279ba55" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Saki630 said: ↑ Guys its $170usd + tax for a keyboard. Since when do these revolutionary RGB mechanical switches make you have a better gaming experience? How do you even quantify how much  better  they are vs. old tech in my 6year old keyboard? I spilled juice and shit on this old G110 and its still going. I doubt those clicky keys would do the same. Are these keyboards the golden egg for Corsair? They hand them out to all the e-sports gamers and people eat it up. Click to expand... hmm, yea, i thought the same "how good can it possibly be?" until i switched to a mechanical keyboard (cherry blue) from rubber dome keyboards which, ironically, my last one died to to water being spilled on it. holy crap, there is no going back."</post>
   <post id="a824f2a2-8ddc-4786-a6dd-7e9f73ec0bbc" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"I think they are better, just wildly overpriced. Could be quieter as well."</post>
   <post id="b0b6eb04-301a-4ea1-a86a-65a822f5bc12" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Since when does anyone in here bitch about a better product for gaming being too expensive?"</post>
   <post id="677c89ae-55ca-44a5-afdf-e8daf39e9a14" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"Since keyboards jumped in price wildly over the last 8 or so years. The improvement isnt worth the money."</post>
   <post id="025ee77c-3fb2-4ec8-819c-ce204cbfd26a" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"I m glad there are some people who are [H]ard and can support struggling companies like Corsair and Razer by purchasing a few of these keyboards. I can see them on all the tech videos telling everyone to pull out a small loan and increase there pleasure by decreasing their latency. How can I check how much $$$ these companies are making selling these  RGB  golden egg products at high prices? I am just disgusted at all the tech review videos where the same guy (20-30yo) advertises RGB mechanical keyboards every time they are out -- then with a straight face tells you to buy because reasons. I m glad [H]OCP doesn t succumb to the pressure and sell you lies. Dont get me wrong, I ll probably get one of these keyboards when my behemoth dies."</post>
   <post id="23bad526-5b4b-4277-8e1f-fdd66c776005" section="Mice and keyboards" discussion="Corsair K70 RGB RAPIDFIRE Review">"I just picked it up after reading reviews and owning a K70 RGB with Cherry MX Red s. I really like the feel of this keyboard a lot better then I did the Reds. I use really lite touches on the keys and I have found that left me in trouble while gaming on the Reds. If I used blues I would have to actively train myself on my typing strokes to actuate. All in all if the switch matches your typing style this is a great board."</post>
   <post id="48b3f21d-71d3-49e7-854c-aba51bdb2da5" section="Mice and keyboards" discussion="Logitech Performance MX whine">"Anyone else w/a Performance MX notice that it has a constant whine? If so, did it eventually go away? Mine has a subtle noticeable whine at idle that gets louder as the mouse moves; it s very annoying. No difference if used directly on my desk or with a mouse pad. I may return it, but wanted to ask if others ran into this problem. If it s common I may go with a different mouse all together."</post>
   <post id="670214f7-9c33-493d-94fc-7a2cd709353a" section="Mice and keyboards" discussion="Maybe drinking some Kool aid, but I m kinda digging this Logitech G900 wireless in CSGO">"Only tested in CSGO FYI. My initial thoughts after 24 hours of using it FWIW. I previously had used a Logitech G5(older laser mouse), then switched to a SS Rival(bought last year prior to the 100/300 split). I liked the SS Rival, but felt it didn t fit my hand right for whatever reason, my wrist would drag a bit the way I d hold it. Would make flick shots harder. Got this Logitech G900 last night and it took about 4-5 matches and a couple hours of death matching to really get into using this mouse. Wanted several times to go back to my old SS mouse, but tried to keep patient as I wanted to see if the wireless was truly as fast as a wired mouse as they claim. Plus I feel technically, it has some advantages over my SS mouse; It s super light, the skates on the mouse are large and create a very smooth glide, and supposedly it has a better sensor vs the SS mouse I was using. Every little bit helps I figure, as I have to make up for my other shortcomings any way I can lol. The biggest issue was just adjusting my grip and finger positions, hence the "break in period" of dm ing and matches. After that though, I really started digging the mouse. It does seem a bit easier to land headshots. I did need to lower my sens a bit in game though as even at a set 800 dpi(as I used with my SS rival), it felt way faster. So I lowered my sens a bit until it felt like it did before. I ran 800 dpi at in game sense of 1 with the SS rival, and needed to lower my in game sens to .9 with this Logitech. So after using the mouse for a bit; I cannot tell ANY wireless lag in the mouse. Not having a cord is a slight benefit. I used a bungie with my old mouse and I would only rarely run into cable resistence, but I do feel this wireless mouse and my wrist just feel more free. The sensor/tracking feels maybe slightly better, although I could very well see this being a new toy placebo effect. I for sure cannot tell any loss of performance vs my SS rival, and a few tangible positives. The mouse 1/2 buttons are much more tactile in actuating, which is helping my burst control, and using my scopes/alt fire etc... The thumb button seems more responsive vs my SS rival, not sure why that is. Must just fit me better and allow me to depress it slightly faster? I can also macro the right/left scroll tilt onto a key bound to grenades helping me manage grenades better, although I keep forgetting about this in game :/.... Cool option for more buttons though! Anyway, if anyone is dumb enough to throw $150+ at a mouse, u may want to consider this. I am not 100% I m sticking with this, but the initial impressions are very favorable. The negatives I consider. So expensive. I just happened to get a small bonus at work, and wife said I should blow it on something stupid, so I did. This is a very small mouse for me. it may work out in the end for me as now I m full claw grip instead of a hybrid claw/palm as I used with the SS Rival. I would like to have an adjustment so it supported my palm a bit more though. Time will tell! I have very inconsistent aim, so hence wanting to try something different. Excuses for suckage I guess!"</post>
   <post id="6830fcb0-6f66-4eb5-8310-8de839f438fb" section="Mice and keyboards" discussion="Any first hand experiences with the new Corsair M65 Pro">"so i really like the mouse, however, my main concern is hitting the sniper button during intense gameplay. can anyone speak upon that? appreciate it"</post>
   <post id="07a8d9df-6047-4153-97b0-813ff4019c65" section="Mice and keyboards" discussion="Any first hand experiences with the new Corsair M65 Pro">"After looking at a few pictures comparing it with my standard old-model M65, it seems they barely moved the button. I wouldn t expect it to be an issue, though I haven t used the thing hands on. Honestly though, unless you care about the lights, I d just save $20 and get one of these."</post>
   <post id="882c6e45-a659-4483-b433-d246c94c1d4c" section="Mice and keyboards" discussion="Question about Razor mice software">"If I buy the Razor Death Adder Chroma is it required to install their software for it to function correctly? I m interested in the mouse but don t want their software on my PC. I don t care about changing the color of the lights, just so long as the lights work without software."</post>
   <post id="9c37e325-bd26-4691-be69-bfc3e07409f3" section="Mice and keyboards" discussion="Question about Razor mice software">"I know you can get away without using the Razor software, but if your wanting to change sensitivity profiles, set macros, bind extra buttons if the mouse has them, then you will have to use the software. My friend does not use the software, but what he did do was install it, get the sensitivity settings to his liking, and then uninstall. He was able to only keep the sensitivity settings on the mouse, but lost all other functions of what he can use the mouse for for global bindings. If you do game by game bindings on the buttons then you should be fine. Example in COD BO3 my side buttons on my mouse are one for melee/knife and the other is my push to talk."</post>
   <post id="bb399a03-0850-4e0e-89b8-b71661469b8b" section="Mice and keyboards" discussion="Question about Razor mice software">"OK, thx for the info. Most games allow you to rebind basic mouse buttons so that is not an issue for me and the death adder only has five buttons anyway. That is why I want it, it is very similar to my Microsoft Explorer 3.0 but with much higher DPI. In fact, I think the Death Adder copied the classic Explorer 3.0. I don t like the new fangled gaming mice with loads of programmable buttons because I will just hit the wrong button by accident anyway and they are not very ergonomic either. The only other issue is quality control, saw someone post that their Death Adder broke after just six months, I ve had this Explorer 3.0 for many years and still works perfectly. Maybe I should just stick with it until it does break."</post>
   <post id="078119b8-f3c8-4777-ae6c-587331032354" section="Mice and keyboards" discussion="Question about Razor mice software">"rezerekted said: ↑ OK, thx for the info. Most games allow you to rebind basic mouse buttons so that is not an issue for me and the death adder only has five buttons anyway. That is why I want it, it is very similar to my Microsoft Explorer 3.0 but with much higher DPI. In fact, I think the Death Adder copied the classic Explorer 3.0. I don t like the new fangled gaming mice with loads of programmable buttons because I will just hit the wrong button by accident anyway and they are not very ergonomic either. The only other issue is quality control, saw someone post that their Death Adder broke after just six months, I ve had this Explorer 3.0 for many years and still works perfectly. Maybe I should just stick with it until it does break. Click to expand... There are are several other things that separate the two mice. But as for longevity I have had mine for four years without issue up until now its a bit worn. I played a lot of LoL and Diablo 3 which are very click heavy games. On the other hand I had a friend RMA his after 8 months due to it double clicking on single clicks. For the most part they I have yet to come across one with major issues to fast. The rma warranty is 1 year on them, so if it has issues in 6 months you get a brand new one free."</post>
   <post id="244d99bb-4692-4f87-802e-f3877166eb4c" section="Mice and keyboards" discussion="Question about Razor mice software">"This double click issue seems to be fairly common with them though. Was playing BF4 last night and a guy said his Death Adder developed the same issue. My Microsoft Explorer 3.0 has seen so much use the paint has worn off on the left click button. I see you can still buy OEM versions of Explorer 3.0 on Newegg for only $30.00 CAD but they are shipped from China. I think I paid $50.00 CAD for mine when they first came out."</post>
   <post id="d45de912-12c9-4b87-be65-ba6242775800" section="Mice and keyboards" discussion="Question about Razor mice software">"rezerekted said: ↑ This double click issue seems to be fairly common with them though. Was playing BF4 last night and a guy said his Death Adder developed the same issue. My Microsoft Explorer 3.0 has seen so much use the paint has worn off on the left click button. I see you can still buy OEM versions of Explorer 3.0 on Newegg for only $30.00 CAD but they are shipped from China. I think I paid $50.00 CAD for mine when they first came out. Click to expand... The next mouse I am getting will more than likely be the Zowie FK1"</post>
   <post id="a9dc2706-9af2-47b3-b4ce-62150be7f7c9" section="Mice and keyboards" discussion="Question about Razor mice software">"Looks like I would like that one too, similar to Explorer 3.0, except the price is a lot higher and it has higher DPI. Are they reliable? Wait. Just looked at it closer and see it is ambidextrous with two buttons on both sides. The side where my fingers rest will get hit by accident when gaming so don t want that."</post>
   <post id="f35daec0-4718-445c-ac2b-0b24a70d8a38" section="Mice and keyboards" discussion="Question about Razor mice software">"What exactly do you have against the Razer software? Any multi-button gaming mouse is going to have support software."</post>
   <post id="312ebd41-93db-473d-acfd-1c0a75b8247f" section="Mice and keyboards" discussion="Question about Razor mice software">"Well, last time I installed Razor software if was for that audio Synapse stuff and it was buggy, also, I just like to keep start up items to a minimum because in my experience quite a few of them can cause issues with shutdown delay and sometimes even startup crashes and/or delay. I run a lean ship. Anyway, with both my Microsoft Explorer 3.0 and Logitech MX 518 I don t need to install the startup apps because they function fine with the built in drivers in Windows. Only thing is on the MX518 you can t customize the DPI settings but there are three hardware settings anyway. That is what I am trying to determine about the Death Adder but no one is giving me a clear yes or no answer so will go elsewhere to find out."</post>
   <post id="45fffb05-10ce-4100-8571-de2ec9c491d3" section="Mice and keyboards" discussion="Question about Razor mice software">"I ve always installed Synapse 2.0, but disabled it from running on startup. I like having it there to manually start on those rare occasions where I do need to change the profile and the ever-so-rare firmware update. Regardless, I rarely require any of Synapse s on-the-fly capability. The DeathAdder 2013 dropped the profile button from the mouse, so that s a bit of a bummer in that I require Synapse 2.0 for profile change these days. I ve just learned to use one profile. If you don t want the light to pulse, you have to let Synapse 2.0 run at least once. If you re fine with how the mouse works out of the box and don t need profile switching, you can easily skip Synapse 2.0 altogether."</post>
   <post id="7af2e9f6-15e1-4868-9f4d-539474cc8626" section="Mice and keyboards" discussion="Razer mousepad Windows Update requires reboot.">"Razer mousepad Windows Update requires reboot. I just got a driver update for my mousepad | PC Gamer Funny stuff. The author wonders why his video card driver doesn t require a reboot when installed, but his mousepad does. The pad. Not the actual mouse. I’ve seen driver updates for all kinds of things, but this is by far the most ridiculous one I’ve seen. What exactly did this update do? Unless this mousepad is doing something besides driving LEDs, I don’t see the need for a driver update. It lights up. I can select colors in Synapse. I put my mouse, my drinks, and spare change on it. That should be it. This is the kind of thing that just contributes to my ever-growing paranoia that I get from reading technical articles about encryption and electronic espionage. (Seriously, that’s a dark rabbit hole, once you start reading.)"</post>
   <post id="3f0e91af-22b0-41c3-93a1-eb945f8525de" section="Mice and keyboards" discussion="Razer mousepad Windows Update requires reboot.">"I do agree it shouldn t need a reboot, but eh. Probably a polling rate change or some kind of memory leak fix / stability improvement. As he said, it s doing more than driving the LEDs, it also lets you set the colors (and pattern of flashing I think?) so there s a little going on in there."</post>
   <post id="b882e293-630c-452b-9c1d-7ce9d17b818c" section="Mice and keyboards" discussion="Razer mousepad Windows Update requires reboot.">"Wouldn t want to hard crash the mousepad would we?"</post>
   <post id="1a3fc728-5282-43d4-9673-5eeaf2073efc" section="Mice and keyboards" discussion="Razer mousepad Windows Update requires reboot.">"Yakk said: ↑ Wouldn t want to hard crash the mousepad would we? Click to expand... If you unplug it without using the add/remove device shortcut it corrupts all your drives on general principle."</post>
   <post id="a84fe4fe-98d2-421b-b106-81abf2a2a1a4" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"I m currently using a wired mouse for my mobile setup but would like to go wireless. I d like feedback from those who have a wireless mouse. I m looking for a good rechargeable Bluetooth mouse. I ve read some complaints about wireless mice going to sleep too fast and would like one that doesn t do that. I d like to stick with BT so I don t need the external dongle. Also, rechargeable is king so I don t need to keep replacing, and wasting, batteries. I just use a basic Microsoft wired, wheel, IR mouse now and need something comparable. No fancy buttons or performance necessary."</post>
   <post id="24a72635-5c7f-4067-b942-d54a589c8bb1" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"Forgive me, but I don t own any wireless mice. That said, you seem to have three criteria: bluetooth (so no wireless dongle) rechargeable (so no battery replacement) doesn t sleep too soon As is often the case you re probably going to have to pick two out of three. Most wireless mice have an aggressive sleep schedule so that they can closely meet the ridiculous advertised battery life. So using points one and two I d recommend that you take a look at the Logitech MX Master. Retail is $100 but currently $80 via some popular online retailers. Best of luck with your search."</post>
   <post id="53c067d2-efac-46cd-b472-08694efd31fa" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"Daniel_Chang said: ↑ Logitech MX Master Click to expand... bigdogchris said: ↑ No fancy buttons or performance necessary Click to expand... The MX Master is a nice mouse, but does have a lot of fancy features/buttons the OP mentioned they don t need. An alternative is the MX Anywhere 2. This was my choice when looking for a good Bluetooth mouse. I wasn t a fan of the small back/forward buttons on the MX Master...and I wasn t sure I would use the thumb wheel enough to justify the trade-off. Overall the MX Anywhere 2 is very similar to the MX Master (same tech), but smaller, a few less buttons, and cheaper. It also has a built in rechargeable battery with very good life. I am getting a couple of months between charges (Logitech website says 2 months on a full charge). My only real negative on the mouse is the included USB charge cable is very short, so if you do have to charge and use the mouse you will need have a USB connection close by. Either way, I don t think you can go wrong with either the MX Anywhere 2 or the MX Master."</post>
   <post id="01c9db78-ff28-413f-8d88-c34da80c27c0" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"incredadamible said: ↑ The MX Master is a nice mouse, but does have a lot of fancy features/buttons the OP mentioned they don t need. An alternative is the MX Anywhere 2. This was my choice when looking for a good Bluetooth mouse. I wasn t a fan of the small back/forward buttons on the MX Master...and I wasn t sure I would use the thumb wheel enough to justify the trade-off. Overall the MX Anywhere 2 is very similar to the MX Master (same tech), but smaller, a few less buttons, and cheaper. It also has a built in rechargeable battery with very good life. I am getting a couple of months between charges (Logitech website says 2 months on a full charge). My only real negative on the mouse is the included USB charge cable is very short, so if you do have to charge and use the mouse you will need have a USB connection close by. Either way, I don t think you can go wrong with either the MX Anywhere 2 or the MX Master. Click to expand... How long does it take before it idles? The small back/forward doesn t bother me because I don t use that anyways."</post>
   <post id="bf6f7392-d08e-43e0-8861-8afe311710cd" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"bigdogchris said: ↑ How long does it take before it idles? Click to expand... I m not sure if I have ever been in a situation where the mouse went into an idle state. Every time I use it, it is instantly available. I have it on a desk connected to a laptop. When not in use, the laptop is closed. In the time it takes for me to flip open the laptop, the mouse cursor is already moving."</post>
   <post id="5abc2cd5-046a-48a0-a9a9-026b2adc7886" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"I ended up picking up the MX Anywhere 2 a month ago and so far have been exceptionally happy with it. It did take me a while to get use the button rather than wheel click (in Firefox) but otherwise it s been great! Thank you."</post>
   <post id="d3dd28ee-259a-41dd-8b53-2f168877116e" section="Mice and keyboards" discussion="Good Rechargeable Bluetooth Mouse">"bigdogchris said: ↑ I ended up picking up the MX Anywhere 2 a month ago and so far have been exceptionally happy with it. It did take me a while to get use the button rather than wheel click (in Firefox) but otherwise it s been great! Thank you. Click to expand... Glad you like it and happy to help"</post>
   <post id="7d0dc9e8-b606-40b1-9c99-08fd524b64e3" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Currently have a Saitek Eclipse and Logitech MX518. Would like something new but when I went to Bestbuy all they sell is wireless I don t want that. What is some of the best gaming keyboards and mice right now ?"</post>
   <post id="ac485ef6-2c64-42e0-8d7b-4e26d68d5768" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"What games do you play? There are tons of mice for each game type. Also do you want a mechanical keyboard? Whats your budget?"</post>
   <post id="e576b116-2156-44fc-baf6-431a3594c0ae" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Doomero said: ↑ What games do you play? There are tons of mice for each game type. Also do you want a mechanical keyboard? Whats your budget? Click to expand... Left 4 Dead 2, Battlefield 4, Simcity 5, and Garry s Mod mostly. No idea if I want a mechanical keyboard any difference ? My budget is $75 to $150 per a item."</post>
   <post id="f8198295-64b2-450d-830c-841012c5b77f" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Anyone ?"</post>
   <post id="4451faee-b460-49b7-92d8-8dd6c867007c" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Well I think a standard 4 or 5 button mouse is good enough for you. I would check out Zowie FK2 Zowie FK2 Review - Best Ambidextrous Gaming Mouse . It s cheap when considering your budget and the performance its pretty godlke. Great switches, a very nice low lift off distance and the sensor is one of the best out there. A mechanical keyboard has better performance in most cases. You can press all keys down on it and it will register them all, not like a membrane keyboard where the rollover is limited. And also mechanical keyboards have different switches which all act different. There are standard switches like on a membrane keyboard, there are switches that click when pressed, and there are tactile which have a little bump that you feel when the key is activated."</post>
   <post id="319148e2-fa1e-4ad1-827c-343f7e1129f5" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Any decent quality membrane keyboards can do at least 6 NKRO over USB. In my opinion that should generally be enough for most situations. Implementations where you have 11KRO or more can be problematic in some specific instances, such as in UEFI/BIOS menus. There isn t any performance benefit to having a mechanical keyboard. They just have a nicer feel to them and are arguably more pleasant to use during long typing sessions. For gaming they make zero difference unless your playing a game that can some how leverage the macro features of some boards."</post>
   <post id="85145243-78b4-4d13-b9ea-29f9c1b078fe" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"For a mouse, the G502 seems to be one of the best I have used for gaming."</post>
   <post id="9e2d14f3-e4bb-4f21-92f5-4f9e18531853" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"Thanks everyone that solves the mouse I need to get expect what is the difference between these two G502 mice ? g502, Newegg Premier - Newegg.com"</post>
   <post id="8b6ed485-e8a7-4d4d-aefa-5d7b2b5d3819" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"ng4ever said: ↑ Thanks everyone that solves the mouse I need to get expect what is the difference between these two G502 mice ? g502, Newegg Premier - Newegg.com Click to expand... The new more expensive one has RGB lighting."</post>
   <post id="1179f569-dc95-4d7e-9982-d6eed9bfe822" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"sharknice said: ↑ The new more expensive one has RGB lighting. Click to expand... Thank you good to know they are the same except for that difference."</post>
   <post id="bd5a9253-2558-4543-a53f-e2c4365738e5" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"I just got a Ducky Shine 5 RGB LED Backlit Mechanical Keyboard (Brown Cherry MX)!"</post>
   <post id="dee472cb-37aa-4427-b6c0-5f39f5c5a2cc" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"ng4ever said: ↑ I just got a Ducky Shine 5 RGB LED Backlit Mechanical Keyboard (Brown Cherry MX)! Click to expand... Looks like we re in the same boat. I upgraded from --&gt; to: Logitech Illuminated Keyboards (before it was called the K740) --&gt; Ducky Shine 5 Cherry MX Brown (added o-rings as well) Logitech MX518 --&gt; Ducky Secret mouse"</post>
   <post id="dd1bd15f-9366-422f-805b-3480b319d400" section="Mice and keyboards" discussion="Gaming keyboard and mouse">"I have two MX518s, foot fell off one so Logitech sent me a new one but there is a loose connection in the cord of that one now so use my trusty Microsoft Explorer 3.0. Apart from the DPI settings for the MX518 I actually prefer the Explorer 3.0 because it has lighter button clicks and is lighter in weight too, it is more ergonomic IMO too."</post>
   <post id="6b4764d4-3d0e-416e-85f8-4f0366f0e5df" section="Mice and keyboards" discussion="Replacing Cherry switches">"Hi, I accidently bought into the current keyboard hype and bought a CM Storm with red switches because "it was good for both typing and gaming". I dont type much but I code a lot and let me tell you this KB is a nightmare to type on, I am working A LOT slower with this KB than my POS generic membrane KB before and I am 2 weeks in to the new KB with the red switches. Can you buy Cherry switches from somewhere on the net in order to swap them out in the KB? I am thinking maybe some other variant is better than this one."</post>
   <post id="d59158c2-e0b6-472f-9f59-f0c1c4afe603" section="Mice and keyboards" discussion="Replacing Cherry switches">"Yes, you can buy switches to swap out, but at the consumer price you re better off returning the board and trying another type of switch. The cheapest way to go about swapping switches would be to go searching through second hand/thrift stores for old used boards with the switch type you prefer (sometimes you can find them on ebay as well) and harvest them, but you have to get lucky doing things this way. Doing this also requires (de)soldering since the switches are plate mounted and can t be disassembled without removing them from the PCB. Don t buy into "this switch for this" or "this is better for this" it s completely personal preference. I myself enjoy Cherry MX Reds, that doesn t mean that someone else that does similar things will also like them over other switches, it means they work for me. It s best to try the different types before hand, but as this isn t always possible you should try to buy from somewhere that has a good return policy."</post>
   <post id="82d280e0-1b76-44b9-b8ab-f54e4f5e0b82" section="Mice and keyboards" discussion="Replacing Cherry switches">"Good advice!"</post>
   <post id="6f225ca7-b67a-43ea-bfc4-bd295fbc6aa3" section="Mice and keyboards" discussion="Replacing Cherry switches">"try blues"</post>
   <post id="8cc1967d-9a67-4dcd-af26-166a7b5b77a0" section="Mice and keyboards" discussion="Replacing Cherry switches">"Yep, if you type, Blues are great. Was in same boat, also purchased Red-based Aivia Osmium, and typing was nightmare. Now I m using StormTrigger with blues, and it s great feeling. Spent today 8 hours working from hope, mostly editing articles, and compared to my old rubberdome, it s just thing sent from heaven. Less errors, faster typing, Bit loud, when you type fast and bottom down, but when you get used to it, and learn to move fingers away, when you feel tactile bump, it s bit more silent. Still, comparing reds and blues, Blue is the way that I feel (and it s not shabby for MMO gaming too )"</post>
   <post id="1a9fa273-bb71-4561-8685-0f56e8558212" section="Mice and keyboards" discussion="Replacing Cherry switches">"working from hope huh? isn t that where pres Clinton was from?"</post>
   <post id="f3a50659-df96-4e4a-b530-325d3554e817" section="Mice and keyboards" discussion="Replacing Cherry switches">"I found Reds to actuate with too little pressure based on my heavy handed typing. I would recommend Blue, Black, or Brown switches. I myself love Blue s "clicky" feel and would definitely recommend them if you type a lot."</post>
   <post id="68a5842f-bbec-40b0-a8e7-94709b86ef62" section="Mice and keyboards" discussion="Replacing Cherry switches">"If MX Reds feel too light, chances are that Brown also will; using exactly the same spring, the difference in actuation force will be ~5g because of the somewhat tactile bump (barely noticeable if you feel for it). MX Blues would also feel much the same in actuation force if it weren t for their design which makes the tactile point feel larger and slightly (but noticeably) heavier than it is. But, they all use the same weighted springs, be aware that different batches will normally feel different because of the spring rate tolerance allowed by Cherry (around +/-10g). If you need heavier switches I d suggest MX Black (linear) / Clear (tactile) / Green (tactile+clicky) even some form of ALPS (no expert on these though so you ll have to take a look yourself, there are a lot of variants), if that s still a bit too light you may want to check out buckling springs"</post>
   <post id="3517fd8b-18c8-45d4-9f87-7b70f473d6ab" section="Mice and keyboards" discussion="Replacing Cherry switches">"I love Blues personally. They are pretty noisy and the wife hates them but I still like them. I type a lot on forums and game a lot and have no problem with them. I havent tried all the Cherry MX switches so I cant say for definite but Ill stick with Blues for a while."</post>
   <post id="3a8d4e91-ca2b-4fea-9c5b-f8c29f2d1ae5" section="Mice and keyboards" discussion="Replacing Cherry switches">"I was at good local computer store today and they had 4 Keyboards with Cherry switches on display. 2 Browns, 1 Black, 1 blue. Black was awful IMO. I would take a standard Membrane KB any day over this. Very strong springs fighting you with no breakover point until you bottom out. Exactly the opposite of what I would want. I am surprised that many keyboards come with theses. I guess this is for the heavy handed who really like to pound their keys. Blue was nice, but loud. Brown was heaven. light touch, not as noisy as Blue. Just one thing. Echoing one of the above comments. The two browns were quite different. One had noticeably more resistance, it felt closer to the blues."</post>
   <post id="7be80ecd-4fdc-4098-a1c8-9b5d434557a3" section="Mice and keyboards" discussion="Replacing Cherry switches">"As said above it would be cheaper and a lot easier to just get a new keyboard. But if you really want to you can get them from wasdkeyboards.com I would recommend getting the Sampler Kit so you can try every type of switch and o-ring dampener. It costs $8 I actually prefer reds for typing, but I m probably the opposite of you. I barely press keys so if I use something that requires more force I ll get typos from missing keys because I didn t press hard enough."</post>
   <post id="5d5e960f-b8fe-4668-89aa-e7e13b8673e0" section="Mice and keyboards" discussion="Replacing Cherry switches">"I m working on a Cherry MX switch soldering and replacement guide. http://imgur.com/a/UIhf9#0 I had one at Geekhack but the moron moderators there lost it."</post>
   <post id="f69e75f3-d1a3-4329-80d0-3ef767d36434" section="Mice and keyboards" discussion="Replacing Cherry switches">"Ripster55 said: ↑ I m working on a Cherry MX switch soldering and replacement guide. http://imgur.com/a/UIhf9#0 I had one at Geekhack but the moron moderators there lost it. Click to expand... you are everywhere!"</post>
   <post id="e57c2e33-d4c5-4b52-a067-5a82d25f918b" section="Mice and keyboards" discussion="Replacing Cherry switches">"Not sure what your previous keyboard was(hint, hint), but you might want to think before ordering a blue cherry keyboard. If you are accustom to a certain design you might have issues with any cherry keyboard you switch to...Many old school keyboard were based on a slightly different key placement then cherry keyboards. I would love to see a cherry based keyboard with an old school IBM/keytronic design, but I am not sure it is possible as I think even old school cherry boards were all linear which is why IBM and Keytronics tended to greatly outsell them. People just found the curved design caused less fatigue. The question now is if you would prefer blue or brown or find both problematic... without knowing your problem and your old keyboard I find it difficult to wager."</post>
   <post id="00c4857c-190c-4473-bf28-59d1907f0f25" section="Mice and keyboards" discussion="Replacing Cherry switches">"Goodfellah said: ↑ you are everywhere! Click to expand... Mainly at Reddit these days if you have questions."</post>
   <post id="10bf3828-1020-45ef-a0a5-888c25156b28" section="Mice and keyboards" discussion="Replacing Cherry switches">"cv643d said: ↑ Hi, .....I dont type much but I code a lot and let me tell you this KB is a nightmare to type on..... Click to expand... What? So you don t type a lot but you type a lot, alright."</post>
   <post id="7b2bbb04-f5e6-457f-8bdf-c8109fc8f2bf" section="Mice and keyboards" discussion="Replacing Cherry switches">"can you just change the cherry switch spring and stem?"</post>
   <post id="18b9e9df-2556-4abe-9c09-e22c25247ccf" section="Mice and keyboards" discussion="Replacing Cherry switches">"Yes, but depending on the switch mounting, you may still need to desolder the switches to do so. Most current consumer based Cherry MX boards have backplates that aren t designed to allow switch modding, so it s more than likely necessary."</post>
   <post id="a49bcb1a-f93c-422e-8914-5d8c4460867a" section="Mice and keyboards" discussion="Replacing Cherry switches">"Can I install 5 pin Cherry MX switches to PCB what is for 2 pin switches?"</post>
   <post id="fedc7e4d-89ce-43bc-b606-def617a425e1" section="Mice and keyboards" discussion="Looking for a decent bluetooth mouse and keyboard?">"Any recommendations for a descent Bluetooth mouse and full keyboard?"</post>
   <post id="c93ff2ce-b85f-46dd-a055-dc9de5d77985" section="Mice and keyboards" discussion="Looking for a decent bluetooth mouse and keyboard?">"That s a loaded question, because it depends on what you re doing and what your definition of "decent" is. What s your total budget? Do you want quiet keys? How portable does the combo need to be? To me, Apple s Magic Keyboard is the gold standard for Bluetooth designs. It has big, quiet keys with a comfortable feel, it s compact, it looks good and you just have to plug it in to recharge. However, it loses a lot of its lustre on Windows (unless you can memorize key equivalents, anyway) and won t cut it if you want a number pad. If I wanted to go Bluetooth on Windows, I d spring for Logitech s K380 keyboard and Anywhere MX mouse. You don t get a number pad on the K380, but it hits most of the other notes well."</post>
   <post id="47d3fcc2-c4c7-4b84-ae96-034177f19c71" section="Mice and keyboards" discussion="Looking for a decent bluetooth mouse and keyboard?">"A fairly decent mouse is a company by the name of "Blackweb" The one that I had picked up (Blue optical) will work on virtually any surface, where my old mouse (red optical) would fail to work. Keyboards I cant comment on since I use what comes with my laptop."</post>
   <post id="0b856d11-ec7b-4b75-b179-e38a455f3937" section="Mice and keyboards" discussion="Looking for a decent bluetooth mouse and keyboard?">"Not really full, but the magic keyboard is serving me really well"</post>
   <post id="fd30f2a9-b3e2-4bf8-867d-afb1cef957a6" section="Mice and keyboards" discussion="Looking for a decent bluetooth mouse and keyboard?">"I used to have this set back when it was a lot cheaper ($99 at the time): Wireless Performance Illuminated Keyboard &amp; Mouse Combo MX800 - Logitech You might be able to find it a lot cheaper if you get the older model that didn t have an illuminated keyboard. It was okay. The mouse definitely jittered when gaming more than a few feet from the receiver. Never noticed any normal issues with desktop usage, though. The Apple stuff we have at work is simple, but it works and looks great."</post>
   <post id="add15831-0fc6-4398-b34d-7ab07d9d6a5b" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Just built a new desk and I want to protect it and improve my mouse feel and tracking. Looking for an XL or extended size pad, roughly 32" x 12". Some that caught my eye - Glorious PC gaming race extended, Corsair MM200 extended, Aorus extended. I really like what I ve seen of the Aorus, how it cleans up really easy, lays flat, etc. The thing is, the extended one is just too big at 40 inches wide and 15 inches deep. I could get 2 larges, which would be just about the perfect size, but then there s a gap down the middle, and it would be close to $60 (shooting for more like $25-40). Are there any others similar to this that are a bit smaller, but still with the extended form factor? What would you recommend? TIA for the help."</post>
   <post id="408392ae-cc3c-47b3-9366-dc3bb50b65b1" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Perixx DX-2000XXL is only $15 at Amazon. Same dimensions as the Corsair pad."</post>
   <post id="75b443a3-c0a3-4417-acf3-b510a5118a31" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"For that price, I might bite. I was hoping to find something with characteristics similar to the Aorus though - how does this one rate?"</post>
   <post id="eea133a7-a66d-4cc7-9379-ed25a2708c58" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I ve got 2 Perixx pads. One like that 2000 and a bigger, full desk sized one, the 1000. Both are excellent. Smooth, easy mouse movements. No complaints."</post>
   <post id="a49b6479-128d-4119-88b5-c4ced3b85d7c" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I ll give it a try. Thanks."</post>
   <post id="c04dffd0-4546-49a5-b74a-59e91180dd14" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Pad-Zilla What? You did say extra large"</post>
   <post id="bfea4396-2a16-43f2-a3c6-24c1f06bcf82" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"17 FEET x 45" ? LOL, I didn t say 15XL."</post>
   <post id="d683f799-e665-4d7a-b624-42721ca32faf" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I d love to see a Pad-Zilla type mouse pad that curves to fit a Galant desk."</post>
   <post id="f7940d37-a984-41a3-9c3b-70590a3cad9b" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Yeah, well that s the reason I can t have one too deep, because it s going on a curved corner desk. I thought that same thing, and while the Galant might be a good desk to pick to model after, it s also no longer in production, and every curved desk probably has a different radius. If you don t match the radius, it might look pretty janky. I m not sure they would sell very well because of that. If you could get one to match your desk though it would be awesome."</post>
   <post id="62eec269-4326-4662-81c3-9b70fb98a3d8" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"The Padzilla people offer a Custom Mousepad pad option. I d send a pic of my Galant desk, but their $160 price tag just ain t gonna cut it."</post>
   <post id="3bac4bf4-a6e5-4b72-b50e-9d1e8d3d5179" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I ve just been using a trackball for decades now anyway Mice need pads ? Just teasing a bit. I ve still always liked trackballs though, I remember the first one I bought for the house, was funny watching the wife keep trying to slide it around on the desk, just out of habit."</post>
   <post id="428193e8-a0f0-4d16-a545-5e88d16290f5" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"How do you game with a trackball?"</post>
   <post id="0f9aca66-add1-48e6-a601-ae14bfcf4907" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Easily, but I do not game a lot these days. Some of the best gamers used to use trackball/keyboard just in general in the past, I m not alluding to being a stellar gamer, but have been a long shot from being a complete hack for a long time. I even had two keyboards and one trackball at one time in the past gaming just for some macros, on the second keyboard. YMMV of course, depending on what you ve done over time like anything."</post>
   <post id="e6af9a2d-581a-4d2e-b712-039bca2a63b8" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Just got the Perixx pad today. It s the size I wanted, but now after seeing it in person, I might have opted for something a bit taller than 11.5-12 inches. First impressions: The smell. Oh man this thing reeks of a rubber/plastics processing plant. The material feels nice. The sharp edges of my G502 sound like they re catching on it, although it doesn t seem to be affecting the movement at all. It sticks to the desk nice. The stitched edges are a nice touch. It came rolled up, so it doesn t lay flat all the way. It s pretty good, but I m hoping it levels out before too long. Protects the desk It was cheap, but seems of decent quality."</post>
   <post id="c599d45d-2790-4d77-94fa-958f1cf8e324" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"The 1000 is taller and better, IMO. Lays flatter, smoother tracking."</post>
   <post id="cb0fd1b4-d88e-49f9-8740-041422e9a7b5" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I have the Glorious pad. It is better than I expected (no fraying, smooth yet textured (I ve had the monoprice cloth pad, which was smooth and rubbery-feeling...I used it as a wrist cushion with the monoprice aluminum pad on top)). I m using a Logitech g303, and it glides and stops quite well. I was going to use this as a desk pad (it provides very little cushion though) and keep using either my dual-surface hard pad or a new uh... Zowie TF-X series cloth pad... but I like the Glorious pad enough that I m using it...for now. I ve read that the GGing pads are decent as well - but I think they offer control / speed... The Glorious is probably closer to speed."</post>
   <post id="57330b69-6802-4f19-a459-8777359ab228" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"I had the QCK mini. For an extended, I went with the Ducky Flipper. It s 31.5" by 13.8", so roughly near your dimensions. It feels like the QCK, but has the same flaw with the non-embroidered edges. Supposedly, this frays. I got my QCK mini in the summer of 2008 and no fraying yet. Threw it on my other desk and it still gets daily (ab)use. Also available in a Combo with the excellent Ducky Secret mouse."</post>
   <post id="938ab12b-dd50-44bc-a3a3-c21429e31b68" section="Mice and keyboards" discussion="need an XL mouse pad recommendation">"Daniel_Chang said: ↑ I had the QCK mini. For an extended, I went with the Ducky Flipper. It s 31.5" by 13.8", so roughly near your dimensions. It feels like the QCK, but has the same flaw with the non-embroidered edges. Supposedly, this frays. I got my QCK mini in the summer of 2008 and no fraying yet. Threw it on my other desk and it still gets daily (ab)use. Also available in a Combo with the excellent Ducky Secret mouse. Click to expand... This - the QCK line is fantastic, I have a smaller one at work (and have had this since 2009, it s on its 4th office now!) and the larger version at home"</post>
   <post id="de6ae750-dcda-4b7e-a84f-de65f1064766" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"If you want a mouse that not only looks good but performs great as well, the crew at Vortez say the ASUS ROG Spatha might be the mouse for you. The Spatha has been turning heads since it was unveiled at Computex last year and it is easy to see why. It is a large, wired/wireless mouse based on a magnesium alloy frame that features a total of 12 programmable buttons, of which the 6 side buttons are arranged in a way that represents the ROG eye logo. To finish of the final aesthetic, there is a 3 zone customisable RGB lighting system."</post>
   <post id="def43d06-9665-4f71-9942-d8cb5620cb0f" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"Too many buttons on the side, good luck gripping it properly without pressing one. These mouses with all these buttons are fucking stupid, nobody uses them. Its just a marketing thing, uneducated people think "OMGZ MORE BUTTONS MORE BETTERS""</post>
   <post id="0b2f04e1-61b9-46d5-a087-dbcf5c2106f6" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"leeleatherwood said: ↑ Too many buttons on the side, good luck gripping it properly without pressing one. These mouses with all these buttons are fucking stupid, nobody uses them. Its just a marketing thing, uneducated people think "OMGZ MORE BUTTONS MORE BETTERS" Click to expand... When I still played WoW, and as a resto shammy, I used all the buttons. I forget what mouse I had at the time, but it had 12 or 13 buttons. I used every single one of them. Since I broke from mmo addiction, six seems to be a good number."</post>
   <post id="fe1641e2-1686-4955-b4af-6d2a1be052e1" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"The Spatha, ah good memories of 2004 and Final Fantasy XI"</post>
   <post id="d7354e7d-f5e1-4bfb-b671-f8b2b671a902" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"leeleatherwood said: ↑ Too many buttons on the side, good luck gripping it properly without pressing one. These mouses with all these buttons are fucking stupid, nobody uses them. Its just a marketing thing, uneducated people think "OMGZ MORE BUTTONS MORE BETTERS" Click to expand... It depends on how you grip the mouse. My place my thumb on the bottom of the mouse, so my hand wouldn t even be on the button. As for extra buttons, I really don t care. Left/Right click, scroll wheel, scroll wheel button, and 2 side buttons is all I need. I have the MS Sidewinder mouse, so it has the 3 extra buttons for DPI changing and weights. I bought it when it was first released and then it started dying 2 years ago. So I picked up another one off ebay. I stuck with it, cause I liked how it felt. This mouse may become a replacement, as it appears to have a similar shape. I never liked the feel of the Logitech mice, Razer mice, etc. Some ppl use a mouse with their wrist up in the air, while I keep my wrist planted on the table. So I like the hump on the back, as it goes right into the palm of my hand. As for more button, it depends on who s using it. I could have gone this route, but I bought a nice Razer keyboard and ended up going with macros on the keyboard. Instead of macros via the mouse. I could have gone either way and ended up with a more barebones keyboard and a mouse with tons of buttons. If the drivers allow me to program like the G key to the mouse, it d be very useful. Nothing more annoying than trying to randomly strafe and toss a grenade using the G key on the keyboard. I d probably only use 3 side buttons on the mouse at most. Side button locations are always too forward for me, so I have to adjust my hand forward to use them. So most times, I never use them. With this mouse design, it appears I can easily reach the 3 rear side buttons. The 3 front side buttons would end up being useless for me. The Spatha has an okay design. I m not a fan of the scroll wheel. I don t imagine that rubber crap will last very long. I wish I could try it out first. The weight seems heavy, but I run 156g on my Sidewinder, so I don t think that ll be a big deal. The price is quite heavy though, but I guess that s pretty normal nowadays for a high end gaming mouse."</post>
   <post id="2076a7fe-241c-4653-be41-8f4f883f44ff" section="Mice and keyboards" discussion="ASUS ROG Spatha Review">"I like the setup of the extra buttons and general layout of the mouse, but it is way too large and heavy for my personal tastes. Still waiting for a good claw mouse to come and replace my G9x."</post>
   <post id="acde7c65-24ca-475d-8af4-726b88257009" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"I have a logitech g602 which I like very much but its no longer working well, seems that clicks are not registering well and I can even highlight text with it sometimes. What would be a good mouse to replace it with?"</post>
   <post id="9d4bb142-b1fc-457b-84ff-6ace9999d375" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"The Logitech G900 Chaos Spectrum is easily the best gaming mouse, but it costs $150."</post>
   <post id="89e4c9ea-efb4-48a4-960e-cd7acb538c1a" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"I still have yet to see anything that tops the G700/G700S. The G900 might be better when it comes to sales bullet-points, but I don t think it s that great in the real world. It s definitely not as ergonomic. The button placements are also very odd. Once you get used to having 4 thumb buttons, you ll wonder why all mice don t have that. Battery life is the only major knock on it, although I just keep a set of rechargeable Eneloops I use for everything anyway. Prices range from $50-75 depending on where you look and if it s on sale."</post>
   <post id="ec6eeb4f-f901-4c3b-936b-0a36045d9da9" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"Domingo said: ↑ I still have yet to see anything that tops the G700/G700S. The G900 might be better when it comes to sales bullet-points, but I don t think it s that great in the real world. It s definitely not as ergonomic. The button placements are also very odd. Once you get used to having 4 thumb buttons, you ll wonder why all mice don t have that. Battery life is the only major knock on it, although I just keep a set of rechargeable Eneloops I use for everything anyway. Prices range from $50-75 depending on where you look and if it s on sale. Click to expand... I went from a G700 to a G700S to a G900. The G700s is great, but the G900 is absolutely better. The biggest problem with the G700 is the sensor placement, it is up towards the front instead of center. The G900 s is right in the center. The second biggest problem with the G700 is the weight, the G900 is much, much lighter. Those two problems with the G700 make it so that you are slightly less accurate when moving the mouse side to side do to the uneven resistance on the front and back of the mouse compounded by the sensor being toward the front. It isn t quite bad as the uneven resistance from a cord, but it is still there. These 2 improvements on the G900 actually make a much bigger difference than you would think. Everything else on the mouse is also improved but isn t quite as big a deal. The lack of 4 thumb buttons on the G900 is really the only downgrade and I do miss them a little, but the thumb buttons themselves are better. They use the same switches as the left and right click buttons."</post>
   <post id="6c0cdfb2-bc66-4efb-9cfb-8638c5c5bf01" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"The best mouse I have used so far is the G700S. The only downside is that it must be charged daily and the batteries must be changed every 6 months or so before the battery life is less than 6 hours. I ve tried Eneloop and Duracell 2400 mAh with the same results. It isn t really a problem as long as you don t mind replacing the battery periodically. That is one thing I miss about the M705 - a single AA battery would last over a year."</post>
   <post id="cadd6337-7d57-4388-8bf7-dcc68d832a49" section="Mice and keyboards" discussion="What is currently Logitech Best Wireless Gaming mouse?">"I actually like the weight of the G700S. If it were up to me, I d actually like more weight. It s been a few years, but there used to be a mouse that had a little bin and weights you could add to it. I ended up putting some lead fishing weights in there, too In most games I m making pretty minor movements, so I like when it isn t so light and twitchy. The sensor actually used to be quirky for me on an old setup, but I found that raising my mousepad slightly fixed it. It s now just sitting about 1/2 inch higher than it used to. Granted, I ve never actually used one, but the G900 doesn t feel right to me based on gripping one. It felt like a step backwards in ergonomics and I don t care for the button placement on the top of the mouse. I never use those odd buttons on the G700 and wish they were on the side instead. If they were to make an ideal mouse for me, they d take the G700S and actually remove one of the buttons sitting on the left click side (there are 3) so I don t hit the wrong one. From there, give me better battery life and moving the sensor is a fine idea."</post>
   <post id="2f43499f-e8f1-450a-8489-cf46c0d24075" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Logitech today announced its best gaming mouse yet, the Logitech® G900 Chaos Spectrum™. The new professional-grade wireless gaming mouse features industry-leading wireless technology, an advanced optical gaming sensor, a flexible ambidextrous design, customizable lighting, mechanical pivot button design and lightweight construction, for maximum performance and comfort over long gameplay sessions. The Logitech G900 Chaos Spectrum delivers a lag-free wireless performance and long battery life that’s trusted by professional eSports gamers."</post>
   <post id="5abf1de6-05db-468f-9b2a-cf62755809e2" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"$150? Ohhhhh my. Maybe I m getting to far out of the loop but that price is too rich for my blood for a mouse. Guess I ll still stick with my trusty G5 until it quits on me."</post>
   <post id="8607e19e-a659-47f6-8797-dbc0ac7dae2c" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"A review Logitech unveils professional-grade G900 Chaos Spectrum wireless gaming mouse Oh dang it. I thought this one would be my next mouse. Battery only lasts for 24 hours? So if you forget to charge it, you re screwed. I don t see how this would work for my HTPC. I can t sit next to the HTPC to use the mouse... How am I supposed to use it across the room if it s charging?? fail! If it had batteries you could swap out, I would be sold. Plus it requires TWO usb ports - one for connectivity and one just for charging. Ugh. Then, it s $150. fail... I was hoping to find a replacement for my Logitech G7. I guess I ll pass on this one I thought I had found one from Razer: I bought the Razer Mamba Chroma wireless laser mouse. It was also pricey - $130 local. It had an awesome feel to it. By default, it comes with rainbow coloring... really?? If you want to do ANY customizing of the mouse (turn off rainbow or change optional mouse buttons), you have to sign up for an account! wtheck? epic fail! So, you have to register an email account with them (that they can sell to other companies for spam), plus now you have to remember yet another password and which email you used. Plus if you are somewhere without any internet connectivity, you can t change your settings... Epic fail. Next, the battery was lasting about 7 hours! Only 7!! So, if you fall asleep or forget to plug your mouse in every day, you are screwed. EPIC FAIL! I contacted Razer about these issues and they pretty much ignored me. I will not ever buy a Razer product until they get rid of the stupid email sign-up and make the battery last longer than less than a day. Whoever is responsible for product design at Razer isn t too bright... Sorry for the rant. I m still on the hunt for a wireless mouse that holds a charge for more than a few days (or has swappable batteries like the G7). It needs to be squared and not flare out wildly like the G700 s. My G7 isn t doing so well right now."</post>
   <post id="d0f5e4c4-f1dd-4b7e-a479-d21421d80523" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"ShagnWagn said: ↑ A review Logitech unveils professional-grade G900 Chaos Spectrum wireless gaming mouse Oh dang it. I thought this one would be my next mouse. Battery only lasts for 24 hours? Click to expand... The review I read said that s is 24 hours of activity and there s a cable the charges and converts it to a wired mouse. I don t like the ambidextrous design."</post>
   <post id="ff95cf75-8b6d-45c4-a462-40f9f2289733" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"I was waiting to see what this mouse would be like, and no good for me First is the wacked out price, and second no index finger buttons which I use heavily. So Roccat Tyon it will be for me I guess."</post>
   <post id="c0c0ba03-f094-4169-84ef-8db2250f4fa8" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Until they make a wireless mouse than never needs its batteries changed (inductive charging, solar or whatever) I m not buying one. That s the "feature" that I care about over all, the fact that wired mice are cheaper and still better in every other way is nice too. Although Logitech already makes a mouse that s perfect for me so I guess I can t complain. I m using a Logitech G502 right now."</post>
   <post id="61e49d5f-7e6a-4b66-9327-ffff050bfaae" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Corvette said: ↑ The review I read said that s is 24 hours of activity and there s a cable the charges and converts it to a wired mouse. I don t like the ambidextrous design. Click to expand... Yes, that is what I said. My HTPC is 10 feet away. How am I supposed to use the mouse if it s charging? I can t use a wired mouse. I thought that was the whole point of going wireless. I can swap batteries on my current G7. Or if the mouse lasted a week or more that would be fine because I would have enough warning if I forget to charge it one night. Only lasting 24 hrs is too often to have to recharge."</post>
   <post id="7aa8207b-e00d-4fd1-be35-5d9d34b63d94" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"So in the middle of fast and furious gaming action, you can expect a "Please charge your mouse." message every day? This mouse has a lot to like but I think they included a few features too many. AA batteries are cheap and fast to swap. If you are in to rechargeables, one set can be charging while you are using the other set. Swap time is a minute or so, at least on my M310. I do like the left-right swap feature as I took up left hand mousing years ago due to RSI pain in my right hand. So used to it now that right handed mousing seems odd. I wonder if they brought back Middle Wheel = Double Click as a driver option or will you still have to manual edit the config file?"</post>
   <post id="2d6d1c48-59be-4981-8fa0-5b2961c69565" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"I have a mouse addiction so I m sure I ll check this out but I do not like wireless mice that much. The G700 was great and all but when the battery died you were kinda screwed. Yeah you could plug in the cable and still use it but the supplied cable was as thick as a garden hose! Maybe it s just me but I don t get the allure of wireless gaming mice. For mobile applications I get it but aren t most PC gamers sitting at their desk very near their tower? Is a wire in the way that much? Like I said, I m sure I ll check it out but not sure it ll replace my beloved G502 as "the greatest gaming mouse of all time"."</post>
   <post id="9475655f-2044-4db8-9b80-914e0f560523" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"MacLeod said: ↑ I have a mouse addiction so I m sure I ll check this out but I do not like wireless mice that much. The G700 was great and all but when the battery died you were kinda screwed. Yeah you could plug in the cable and still use it but the supplied cable was as thick as a garden hose! Maybe it s just me but I don t get the allure of wireless gaming mice. For mobile applications I get it but aren t most PC gamers sitting at their desk very near their tower? Is a wire in the way that much? Like I said, I m sure I ll check it out but not sure it ll replace my beloved G502 as "the greatest gaming mouse of all time". Click to expand... It doesn t really have anything to do with the wire being "in the way", it is the little bit of resistance the wire causes when moving the mouse. That resistance changes depending on the position of the cord and won t be 100% consistent no matter how light or little friction the cord has. Getting rid of that inconsistency is a big deal."</post>
   <post id="b2b0f39e-806a-4c98-9077-5706f2710ea9" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"when you don t have anything new, might as well advertise it as "professional grade""</post>
   <post id="b5d8a496-b267-4af9-85e6-1c05f88361b2" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Been using a wired MX518 for almost a decade. Exactly what is wrong with a cord? That way you can be assured that its not getting any performance loss because someone started up some microwave popcorn. Have this mouse with a cord, give me the money back on the difference of a battery, and I will think about buying it. All you have to do to get rid of 99% of cable drag is to make a nice loose loop in front of the mouse. It can t be putting more than a few grams of force on the movement."</post>
   <post id="a8bd1ce8-06c2-40d7-bdde-afea0070c65e" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Hope it s WAY better than the G700."</post>
   <post id="e3daab27-305e-46d6-b5c4-c67f0567470a" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"NickelFinger said: ↑ Been using a wired MX518 for almost a decade. Exactly what is wrong with a cord? That way you can be assured that its not getting any performance loss because someone started up some microwave popcorn. Have this mouse with a cord, give me the money back on the difference of a battery, and I will think about buying it. All you have to do to get rid of 99% of cable drag is to make a nice loose loop in front of the mouse. It can t be putting more than a few grams of force on the movement. Click to expand... The last couple generations of Logitech gaming mice have had perfect wireless performance. Even their wireless gaming mice from 10 years ago were lag free with very rare cases of interference. The whole point of this mouse is getting rid of the cord and all the inconsistant resistance it causes. Logitech already has a wired mouse with the same sensor for half the price. The small amount of resistance a cord causes might not seem like a big deal to you but it actually matters, and a normal person is more than capable of feeling the inconsistencies no matter what you do with the cord."</post>
   <post id="8beaa124-c641-4c9a-b0ca-121a4bba6e3e" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"ShagnWagn said: ↑ Yes, that is what I said. My HTPC is 10 feet away. How am I supposed to use the mouse if it s charging? I can t use a wired mouse. I thought that was the whole point of going wireless. I can swap batteries on my current G7. Or if the mouse lasted a week or more that would be fine because I would have enough warning if I forget to charge it one night. Only lasting 24 hrs is too often to have to recharge. Click to expand... What part of "24 hours of activity" are you not understanding? Unless you re jerking the mouse around the entire time you re watching TV shows and movies, a single charge should last weeks. If you re also gaming with your HTPC, then yeah, the charge won t last as long. But even then, just recharge it when not using the HTPC."</post>
   <post id="47406e20-50da-4391-9222-d4d9ebfc695d" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"Bah, I ve got a desk with one of those keyboard trays under the main part of the desk. Ghetto mod: Take a breadloaf tab an sticky it under the desk holding the cable, along with a bit of slack. Wireless is never lag free, its why the current generation VR headsets are wired. Besides, I ve never used this particular main computer mouse off the mouse pad. A mouse pad that has not changed place in decades. I could see a wireless for a laptop, but for a main stationary gaming rig? Wired all the way (and at least 1000hz polling rate too)"</post>
   <post id="08003280-71e7-4968-ac8a-db021bf85433" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"I don t want a better mouse than the G602, otherwise I may get banned from other servers for aiming too well."</post>
   <post id="36d56048-2d04-4bc9-9178-2be22fe63dc2" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"NickelFinger said: ↑ Wireless is never lag free Click to expand... So many people believe in this false myth. Are there wireless mice that lag? Of course. Are there wireless mice that don t lag? Yep, and there have been for a long time. Logitech even did an experiment where they had professional gamers test a wireless mouse, then a wireless mouse with a fake cord. The subjects said the wireless mouse lagged and wireless mouse with the fake cord didn t."</post>
   <post id="df74a01d-b4a8-4eda-910c-414f05c22517" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"That s correct. The "lag" is just due to crappy electronics and is quite independent of the signal transmission medium."</post>
   <post id="cccf8d6f-a50c-4bae-9875-349df5c7372c" section="Mice and keyboards" discussion="Logitech G Introduces Its Best Gaming Mouse Yet">"As much as I m not a big fan of wireless mice I have to agree that lag is not an issue at least on quality mice. My G700 is lag free. Maybe if you hooked up some high dollar measuring device that can measure down to the nanosecond you could find some but I ve used one for years and never experienced any lag at all even when the battery was getting low. Now I m sure the $25 Walmart wireless mice will lag but a $100 high end gaming mouse will be free from it."</post>
   <post id="dd01e4d8-76ab-489a-a3a8-0faf1f5f231e" section="Mice and keyboards" discussion="has anyone try Bloody infrared mechancial keyboard?">"B328 - Bloody I don t believe this dust resistant bull shit. But what s the deal w/ this infrared mechancial deal? This brand was in an article of Computer Power User, May 2016"</post>
   <post id="dc4e268f-e5b1-4d32-b2d1-789c4247b54f" section="Mice and keyboards" discussion="Asterisk key on numpad not working correctly in Win10">"Having this random problem with my Logitech G710 keyboard where the * key on my numpad only works when holding the shift key. Driving me nuts since I use Excel a lot and multiplication is something I often use. My troubleshooting thus far: Moved to another USB port. Uninstalled Logitech drivers; rebooted. Reinstalled Logitech drivers; rebooted. Uninstalled HID keyboard drivers; rebooted. Reinstalled motherboard chipset drivers; rebooted. Moved the keyboard to another PC; works fine. Tinkered with Ease of Access settings (e.g. turn on/off mouse keys, turn on/off toggle keys) At this point it s gotta be something I m missing in Windows 10. Any ideas?"</post>
   <post id="54bf51d4-356b-4065-ae05-ee6567072291" section="Mice and keyboards" discussion="Nixeus Moda Pro Mechanical Keyboard is available on Amazon. Key caps poll.">"Nixeus Moda Pro Mechanical Keyboard is now available on Amazon for $74.99. Comes in your choice of Kailh Blues or Browns. Amazon.com: Nixeus Moda Pro Mechanical Switch, Soft Tactile Feedback Keyboard for Windows &amp; Mac (MK-104BN16): Computers &amp; Accessories It was announced via their Twitter. Nixeus Technology (@Nixeus) | Twitter This is the same company that made the first 144hz FreeSync monitor with a 30hz to 144hz range. Linking a review for the monitor just to show that they are the real deal. Nixeus NX-VUE24 24″ FreeSync 144Hz Gaming Monitor Review. Nixeus NX-VUE24 24″ FreeSync 144Hz Gaming Monitor Review | Pure Overclock What we need to do is convince the Nixeus rep peter@nixeus on the Hardforum and above on Twitter that we would like to be able to buy custom key caps from them. He tweeted this image to me of custom key caps on the new Moda Pro keyboard and I thought it was really neat! Of course the keyboard comes with a key cap puller. Here is the basic keyboard. Here is the one with custom key caps installed. I love when manufacturers think like me. They already were experimenting with it as you see. I guess they need to judge the market and see if it is something that people want. You know you want custom key caps! Say so! Also Nixeus announced that their tenkeyless keyboard is on MassDrop for $49.99. Nixeus Technology on Twitter Nixeus Moda V2 TKL Mechanical Keyboard on MassDrop. $49.99. Note: At checkout, you have your choice of Kailh mechanical switches in Blue, Brown, or Red. Massdrop: Bringing Enthusiasts Together At any rate take the time to vote on the key caps. I think they are really nice addition to a keyboard. Thanks for perusing my post."</post>
<post id="496a6a43-595d-420e-8960-e41e7cc5460d" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"Apparently there s only one in existence, the Sabertooth 990FX Gen3 R2.0 which came out back in 2013: SABERTOOTH 990FX/GEN3 R2.0 - Overview I recently purchased a Samsung 950 PRO NVMe 512GB M.2 drive, along with a Lycom DT-120 adapter to use in my older Asus M5A97 R2.0 motherboard, which uses PCIe 2.0. I verified from a fellow user that this will work; however, I will not be getting the full 20Gb/s data transfer rate. The Gigabyte GA-990X-Gaming SLI (rev. 1.0) "claims" that it can do up to 20Gb/s (they put in the ad a * which indicates this is  theoretical ) on a board that only has PCIe 2.0: GIGABYTE - Motherboard - Socket AM3+ - GA-990X-Gaming SLI (rev. 1.0) First, I think the Gigabyte page above will mislead people to believe that getting the full 20Gb/s on a PCIe Gen2 x4 M.2 will be possible on this board. I could be wrong. Can anyone verify this? I ve seen some AMD FM2+ motherboards that have PCIe 3.0, but my understanding is that the AM3+ processors are far superior. Can anyone verify this for me, as well? The biggest question I have is, are there any other AM3+ motherboards out there that have PCIe 3.0? Or are there going to be any coming out in the near future? If not, this may have convinced me to go with an Intel board/processor for my next upgrade."</post>
   <post id="401033a3-40a1-4f48-b3eb-bc10aee4f1ac" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"MSI 970A SLI Krait Edition AM3+ only one I can find that specifically says pcie 3 GIGABYTE GA-990FX-Gaming AM3+ this says the 20GB/s but not if its pcie 3 so idk... those are ALL I could find... AM4 is around the corner, maybe this fall and it will have pcie 3, ddr4 and is supposedly(not so sure after googling) backwards compatible."</post>
   <post id="c8317fc1-957f-48c6-95ca-7eeead0517ec" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"No point, the HyperTransport connection is the bottleneck."</post>
   <post id="6d9e11b9-a0c0-46dc-9683-364bb53784a2" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"PCIe 2.0 x1 = 5 GT/s (500 MB/s) PCIe 2.0 x4 = 20 GT/s (2000 MB/s) That s the facts. The Gigabyte board states it s "PCIe Gen2 x4 M.2". Now they say it s 20 Gb/s. 2000 MB/s x 8 bits/byte = 16000 Mb/s ~16Gb/s (a little less) My guess is since the M.2 connector includes both PCIe x4 and SATA: SATA3 = 600 MB/s 600 MB/s (SATA) + 2000 MB/s (PCIe) = 2600 MB/s ~20800 Mb/s 20800 Mb/s / 1024 = 20.3125 Gb/s So the slot can do ~20Gb/s across all the interfaces... Marketing... As far as HyperTransport goes (numbers from here: Everything You Need to Know About the HyperTransport Bus - Page 4 of 5 - Hardware Secrets) An AM3+ FX chip will run the HyperTransport link at 2,600 MHz = 5,200 MT/s = 10,400 MB/s = 83,200 Mb/s = 81.25 Gb/s An AM3 (Phenom II) chip will run the HyperTransport link at 2,000 MHz = 4,000 MT/s = 8,000 MB/s = 64000 Mb/s = 62.5 Gb/s On paper, I don t think HyperTransport is the bottleneck, but I could be wrong. Would need to find some benchmarks - I m sure there s a slight performance hit. Can you post benchmark results of your drive? Advertised sequential read/write of that drive is around 2,500MB/s and 1,500MB/s respectively. I m guessing you re maxing out at PCIe 2.0 x4, so around 2,000 MB/s."</post>
   <post id="1cb21015-16d2-44c9-aeea-fcadfa73f852" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"I was able to setup the Samsung 950 as a boot device on my old board, no problem. The bios; however, takes a while before it recognizes the SSD (it hangs at the RAID controller), but man, once it gets past the post, Windows comes up in about 15 seconds or less. After installing the Samsung Magician software and the Samsung NVMe Controller I m getting the following results. Samsung Magician Samsung 950 PRO M.2 2x 2TB 7200 RPM Drives on RAID0 CrystalDiskMark Samsung 950 PRO M.2 2x 2TB 7200 RPM Drives on RAID0 ATTO Disk Benchmark Samsung 950 PRO M.2 2x 2TB 7200 RPM Drives on RAID0 Despite the fact that I m not getting the full 20Gb/s, I m still a pretty happy camper. Thanks for the responses. I m disappointed that AMD board manufacturers aren t including PCIe 3.0 on their AM3+ boards. I think I ll probably be joining the dark-side (Intel) for my next upgrade unless by weird coincidence they come out with one here in the near future."</post>
   <post id="27db67a4-a202-4d05-94cf-eff46d848388" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"Those pictures are tiny. twright70 said: ↑ I m disappointed that AMD board manufacturers aren t including PCIe 3.0 on their AM3+ boards. Click to expand... Not much to do with board manufacturers, the AMD 900 series chipset just doesn t support PCIe 3.0. Obviously, at least one has added in some type of bridge chip to supply GPUs with PCIe 3, but this isn t a cheap or native solution. The benefits it has are also questionable - would need to see a block diagram of the motherboard to really know what s going on. The platform has been mostly end of life for some time now, so there s been little development put into it. Your average PC user isn t even saturating PCIe 2.0 yet, but you re definitely in the 1% with a SSD like that."</post>
   <post id="fce4d778-e085-4dac-b71e-48cfe0f2f7d9" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"Track Drew said: ↑ Those pictures are tiny. Click to expand... Awww, man...I thought it would allow you to enlarge them. I ll update the post with images you can actually see. Yeah, I m not an expert when it comes to the technology behind the motherboards. I m no computer scientist or engineer. I saw another SSD from Kingston - the HyperX Predator Gen2 x4 SSD: The Samsung 950 Pro is only like $16 more, plus $25 for the HHHL adapter. So, I figured I can spare another $40-50 to get the good stuff. Although, I m pretty sure they re going to have something better before long - might should ve waited until I get a board that can handle PCIe 3.0 before splurging. Only reason I got it is because the wife was complaining that her computer was too slow (she was using 5400 RPM drives in her computer). So I gave her my old Samsung 850 EVO SATA III drive. Win-win."</post>
   <post id="6ac24980-7332-4d74-8073-06f61cb95612" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"The connection to the southbridge is basically a PCI-E 2.0 4x connection. That will bottleneck any connection you make on the southbridge side of things (slots that are not designed for GPUs). As for a PCI-E 3.0 based chipset, there s no point. First being that the HT connection is a bottleneck (for x16 PCI-E 3.0, aka GPU) purposes, and that it is a dead end socket. The latest CPUs for AM3+ were released 4 years ago (I don t count the refreshes of the same architecture as a new CPU), and there won t be a new one for AM3+. It s all about Zen, which will be on a new socket. As far as FM2+ processors vs AM3+... AM3+ only has the advantage due to the number of cores. FM2+ has newer architectures (latest is Excavator), which while not major, still has IPC improvements over the latest AM3+ architecture (Vishera)."</post>
   <post id="eb872f7d-1639-4f6d-af3e-b291bbebc919" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"Tsumi said: ↑ The connection to the southbridge is basically a PCI-E 2.0 4x connection. That will bottleneck any connection you make on the southbridge side of things (slots that are not designed for GPUs). As for a PCI-E 3.0 based chipset, there s no point. First being that the HT connection is a bottleneck (for x16 PCI-E 3.0, aka GPU) purposes, and that it is a dead end socket. The latest CPUs for AM3+ were released 4 years ago (I don t count the refreshes of the same architecture as a new CPU), and there won t be a new one for AM3+. It s all about Zen, which will be on a new socket. As far as FM2+ processors vs AM3+... AM3+ only has the advantage due to the number of cores. FM2+ has newer architectures (latest is Excavator), which while not major, still has IPC improvements over the latest AM3+ architecture (Vishera). Click to expand... Thanks for the insight! So, what I got out of this is M.2 SSD s running on PCIe 3.0 slots is not ideal. However, what about motherboards with NVMe M.2 sockets on the board itself? They still say PCIe 3.0 x4. Will there still be a bottleneck issue on those boards, as well? Is this specifically true for just AMD boards, or will Intel boards experience the same bottleneck? I m actually very pleased with the performance, so far...I haven t experienced any issues...yet. But then again, maybe I m not sure what I m looking for."</post>
   <post id="824c59c4-05e3-478b-af27-2be081beac0f" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"It depends on how the motherboard makes the connections. It also depends on the technology in play. With Intel s DMI 3.0 that is on Z170 chipsets, the connection between the chipset and the CPU is faster than AMD s. The Z170 chipset can do approximately 40 GB/s from chipset (Intel processors do not have a northbridge, so the southbridge is the only chip) to CPU. Compare that to AMD s HyperTransport 3.0 (which is the connection between CPU and northbridge, which provides the PCI-E connections for the GPUs), which does about 10 GB/s in the 9xx chipset, and you see why it is a huge bottleneck. For reference, the UMI interface used for AMD FM2 chipsets (FM2 does not have a northbridge either) is basically a PCI-E 2.0 x4 interface, which does about 2 GB/s. The technology gap between Intel and AMD is not just in CPU performance, it is almost quite literally in everything else as well."</post>
   <post id="b615f272-66fc-4fa9-9f31-46b993f510ab" section="MotherBoards" discussion="AMD AM3+ Motherboards with PCIe 3.0?">"Thanks for your help! I think you just convinced me to go Intel for my next upgrade. I may wait to see what happens when the new Zen processor comes out."</post>
   <post id="b9e0b386-a499-4772-a653-37405b70b7d7" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"I just bought (Kingston Server Memory w/TS Model KVR16E11K4/32 - Newegg.com) hoping to add ECC memory to my server. Server is running Asus Crosshair V Formula with AMD Phenom II x6 1100T CPU. MB states it supports ECC. Phenom II I believe should support ECC, right? Yet CPU-Z is not showing ECC next to "Correction" in SPD tab and memtest86+ 5.01 is recognizing (via SPD) that the ram is ECC capable but it is not showing ECC next to the RAM type in the middle of the window. Last time I run ECC memory was in an Asus M2N32-SLI Deluxe MB and I believe I saw ECC in memtest in the line where it indicates the RAM type. Would Win7 show me "ECC enabled" somewhere as a final check? I have enabled ECC, the only option that I saw, in the BIOS. Ideas?"</post>
   <post id="7af4e07b-aa7b-4469-a56b-18f876d277e4" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"That CPU only support ECC Unregistered and unbuffered, there may be your issue."</post>
   <post id="35e00583-63c8-4c3e-b274-8aa9a90647a7" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"Araxie said: ↑ That CPU only support ECC Unregistered and unbuffered, there may be your issue. Click to expand... The RAM in the link is standard ECC, so that is not the problem. CPU-Z and memtest86+ may not show ECC properly depending on exactly what they have it specifically programmed to detect. You could always try Sisoft Sandra and Aida to see if ECC shows up on them. In any case, if the option is in your BIOS and it is enabled then it should be working."</post>
   <post id="111a0d76-09ee-430b-bdeb-8df4c95bb9eb" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"Installed Sisoft Sandra. Under "Computer Overview", when ECC is enabled in BIOS this screen shows ECC in multiple locations. Like: Chipset -&gt; Memory Controller, Computer -&gt; Total Memory and Memory Modules -&gt; Memory Module When I turn ECC off in BIOS, ECC is nowhere to be seen in "Computer Overview". So there is a change in what Sandra reports. Also, under Mainboard -&gt; Logical/Chipset Memory Banks it shows ECC. I think when I turn ECC of in BIOS it did not show ECC there. All this seems like a good sign, still I ll see if I can find a program that can test for ECC. I found something that can be run in linux but I can t seem to be able to run Knoppix on that PC. Runs fine on my other PC."</post>
   <post id="b0db6973-2288-42c0-aad3-bad564d9658c" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"Aida shows ECC in both cases, on/off in BIOS."</post>
   <post id="d72da1e4-0a69-4a12-933d-0e87e04e4751" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"Asus tech responded saying things which to me indicate he/she completely failed at reading comprehension. Did not address a single of my questions and went on talking about things that are related but don t address a single of my issues. AMD tech responded saying that my CPU does not support ECC! I believe Phenom II 1100T falls under the Family 10h of processors and if so, according to this data sheet it should support ECC. http://support.amd.com/TechDocs/46878.pdf I responded with the above link to the AMD tech and will see what he says. I was looking for that data sheet for two days and found it today."</post>
   <post id="90b2b68f-615e-4274-9878-7e92fd484b57" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"No follow up response from AMD. Either to proud to admit mistake, don t care or perhaps my e-mail didn t reach them somehow. I am surprised that AMD tech support would be this clueless about their own products. (I know, these people are probably outsourced to the lowest bidder and don t care a damn bit. Just want to spend the least time possible to produce some response to the inquiry regardless of its truthfulness.) For people looking for a conclusion to this, I m 98% certain that I have ECC enabled in my system based on the AMD data sheet and what I observed in Sandra software while toggling ECC enabled option in BIOS."</post>
   <post id="73e08a89-f4f1-47e1-8e0b-afed03ef6d8f" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"Try their Twitter accounts. Robert Hallock (@Thracks) | Twitter AMD (@AMD) | Twitter AMD FX (@AMDFX) | Twitter AMDGaming (@AMDGaming) | Twitter AMD Radeon Graphics (@AMDRadeon) | Twitter AMD Care (@AMDCare) | Twitter Terry Makedon (@CatalystMaker) | Twitter Raja Koduri (@GFXChipTweeter) | Twitter Roy Taylor (@Roy_techhwood) | Twitter"</post>
   <post id="e52d4b9e-a7c3-4490-9a6e-39f7245a3c1f" section="MotherBoards" discussion="Asus Crosshair V Formula + AMD Phenom II x6 1100T = no ECC support?">"It appears I posted to hastily. At 6:40 AM local time I did receive a response basically congratulating me on a job well done finding the datasheet, because they were too lazy to do so themselves, and confirming that based on said datasheet my CPU does support Unbuffered ECC and that I should install this type of memory if I want to enable ECC. They seem to have missed the fact, that I already installed it and was inquiring precisely about this Unbuffered ECC that I purchased. If your customer service operates in such a way that your customer does 98% of the research, then why have it in the first place OK, so after all that, it seems I m running ECC Btw..thanks cageymaru for the twitter links, though I did not make use of them"</post>
   <post id="e9b7a9b5-b986-4549-a9df-3ed39be040a4" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"My computer has been built for nearly 2 years and everything worked fine until today. I usually leave my computer on for weeks at a time and shut it off once in a while. Yesterday, Windows 10 told me there was an update so I just "Update and Shut Down" the computer when I went to bed. This morning, I tried opening the computer but the computer turns on but the monitor does not detect any signal so it displays a black screen. Current Symptoms: Computer turns on (Lights, fans all turn on fine) Keyboard and Mouse that are connected to computer does not turn on (I assume they do not detect signal from computer as well) Stuff I have done so far: Tested with multiple different monitors (that are working fine with another computer) Reseated all components and replugged all connectors Plugged monitor into onboard graphics (Monitor still doesn t detect computer) Is there anything else I should do? Thanks for your help!"</post>
   <post id="e5ccac7d-5591-4a29-bec5-bc864f7b2ba9" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"So you don t get a POST screen or EFI setup prompt?"</post>
   <post id="3ef54c89-8072-49bb-b6ec-76686ef467f7" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"KazeoHin said: ↑ So you don t get a POST screen or EFI setup prompt? Click to expand... Nope, I don t get anything. The screen remains completely black"</post>
   <post id="16916a1f-1943-4e5b-9e39-d2c925b51c82" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"What port of the video-card is it plugged into? which ones have you tried?"</post>
   <post id="7cc31e9c-3f0b-4489-84cf-1e2b715464c3" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"KazeoHin said: ↑ What port of the video-card is it plugged into? which ones have you tried? Click to expand... I have a GTX970 that has 2 DVI, HDMI, and Display Port. I have tried both DVI and the DVI on my motherboard but nothing works."</post>
   <post id="41c3eb15-adfb-403d-bf72-87ea1052148e" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"Strange Strange indeed. The only thing I can suggest is try removing the GPU from the PCI-E slot and plugging into the onboard DVI. See if that at least allows you to get video for diagnosis."</post>
   <post id="f503ae27-d365-4961-a1ad-32856562ea99" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"Do you have any alternate bootable media like a DVD or USB stick with Linux on it? I keep a DVD of Linux Mint around just in case I have a problem booting from the primary SSD. Also, are you saying that you get nothing and can t even enter the bios or get a bios screen? Alternately, do you have any spare power supplies around that you could temporarily swap connections with? It could be that your power supply is borderline but you got by because you rarely shut it totally down and now you can t get enough power to restart. (I once had a power supply that was more than 10 percent low on the 5 volt line which caused boot problems.) Removing the GTX970 with its power draw might drop your total power load to a bootable point."</post>
   <post id="57c62703-d3a0-469e-85d1-8d082379cc1a" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"KazeoHin said: ↑ Strange Strange indeed. The only thing I can suggest is try removing the GPU from the PCI-E slot and plugging into the onboard DVI. See if that at least allows you to get video for diagnosis. Click to expand... Just tried that still no video. Thanks for your help"</post>
   <post id="3ec719c4-2bd8-41d6-94f3-495012293a47" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"dwd999 said: ↑ Do you have any alternate bootable media like a DVD or USB stick with Linux on it? I keep a DVD of Linux Mint around just in case I have a problem booting from the primary SSD. Also, are you saying that you get nothing and can t even enter the bios or get a bios screen? Alternately, do you have any spare power supplies around that you could temporarily swap connections with? It could be that your power supply is borderline but you got by because you rarely shut it totally down and now you can t get enough power to restart. (I once had a power supply that was more than 10 percent low on the 5 volt line which caused boot problems.) Removing the GTX970 with its power draw might drop your total power load to a bootable point. Click to expand... Unfortunately, I do not have an alternate bootable media. The monitor is like completely not recognizing the computer so I cannot enter bios. I don t have a spare power supply but this power supply is enough to power GTX970 SLI. I made sure to get it higher in case I want to upgrade.. of course it might be defective. Also, following KazeoHin s advice, I just removed the GPU to test the on board DVI but the monitor still doesn t recognize the computer."</post>
   <post id="b4400795-b428-4a51-8cf2-a53e8233df12" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"clear you cmos/bios. if that doesn t help you WILL need parts to trouble shoot, at minimum a new psu."</post>
   <post id="8a603b46-9b0b-47dc-a654-d2945a552a3c" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"So I have done a few more tests Borrowed a working PSU and tested it in my system. Still the same problem. Put my SSD into friend s system and it booted fine. His SSD in my system still black screen. Removed GPU and tested onboard graphics Have 2 sticks of RAM so removed one at a time to test each RAM. Nothing changes. Resetted CMOS via Jumper Out of ideas, what else should I test next?"</post>
   <post id="b24ff83f-83a3-4096-a50e-c7c1f0326060" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"ShadovvKiIler said: ↑ So I have done a few more tests Borrowed a working PSU and tested it in my system. Still the same problem. Put my SSD into friend s system and it booted fine. His SSD in my system still black screen. Removed GPU and tested onboard graphics Have 2 sticks of RAM so removed one at a time to test each RAM. Nothing changes. Out of ideas, what else should I test next? Click to expand... Reset CMOS via Jumper?"</post>
   <post id="3ae7a2c2-4318-4fac-896c-35c1736c8fd2" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"KazeoHin said: ↑ Reset CMOS via Jumper? Click to expand... Sorry forgot to add that. Yes I also reset the CMOS via Jumper as stated in Manual"</post>
   <post id="efb2fcf3-7820-4be1-b6d7-0e8f208b760b" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"Wow. This is a real pickle. It s highly likely there is a Mainboard issue. Please tell me it s not a Gigabyte mainboard..."</post>
   <post id="639c26dd-8843-4e72-8fd4-c48b2c9c254d" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"Do you have a speaker on the mobo? If so, remove both sticks of ram and or the gpu to see if it gives no ram/gpu beeps. Next step is another gpu to test with. Edit: Speeling"</post>
   <post id="fc12c810-2411-479d-8f61-22e1d34860c7" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"My motherboard is the Asus Z97-A. I have removed RAM and GPU at some time during my tests today. I never heard any beeps. So at this point, I am guessing the motherboard is the most likely culprit? (Think its not GPU because the onboard graphics doesn t work either)"</post>
   <post id="f495970c-07d9-45b3-a702-4583778eab79" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"ShadovvKiIler said: ↑ My motherboard is the Asus Z97-A. I have removed RAM and GPU at some time during my tests today. I never heard any beeps. So at this point, I am guessing the motherboard is the most likely culprit? (Think its not GPU because the onboard graphics doesn t work either) Click to expand... If you removed all the RAM and the system (with BIOS speaker installed) doesn t make a peep, its most definitely the Mainboard."</post>
   <post id="45956ab5-7ec6-4c47-9ab7-fa2fd3265427" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"KazeoHin said: ↑ If you removed all the RAM and the system (with BIOS speaker installed) doesn t make a peep, its most definitely the Mainboard. Click to expand... Do all motherboards beep when there is something wrong? Because after all the tests I have done today, I have never heard the Mobo beep at all. Thanks"</post>
   <post id="e68751b5-ccbe-4e07-991f-8c65c7451735" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"only if it has a speaker install. which is why I asked..."</post>
   <post id="26ed15f7-9f2b-493e-8635-195d744e40b8" section="MotherBoards" discussion="Computer turns on but Monitor doesn t detect signal">"When you open up your mainboard box, there should be a little F-key BIOS speaker that you can plug into the board."</post>
   <post id="2f224766-7c91-436f-91f6-c4b179eb66a7" section="MotherBoards" discussion="Asus RMA sent back the same board">"sent them the z97-a motherboard because it wouldn t POST. 2weeks later i get the same motherboard, still no post. has anyone had something like this happen to you?"</post>
   <post id="61758281-ce18-41f7-85e5-87146b0e2175" section="MotherBoards" discussion="Asus RMA sent back the same board">"Raja, the resident ASUS rep should be able to help. And yes, this has happened to myself as well as others here."</post>
   <post id="41161fe9-15f1-48f4-a676-e91d5b014aeb" section="MotherBoards" discussion="Asus RMA sent back the same board">"This has happened to my company. In fact our office has stopped using ASUS motherboard/other products because of this happening (We build hundreds of PCs). We ve also sent in boards that were DOA and received them back with bent CPU socket pins and a note saying "bent pins". It got to a point where we were secretly marking all the ASUS products we sent in for RMA as well as taking pictures of the CPU sockets... ya that bad."</post>
   <post id="89213961-e90e-443c-85d3-b1c6a89779fa" section="MotherBoards" discussion="Asus RMA sent back the same board">"yea, spoke to raja and emailed the specified person. lol Easius, that sounds awful xD"</post>
   <post id="89f9e9ef-0bf4-4437-9c1a-73aa788bbbd9" section="MotherBoards" discussion="Asus RMA sent back the same board">"ASUS has garbage RMA support sadly. It is too bad, since they make great products in general. I personally use ASUS boards (now that Intel doesn t make them anymore) and I view it as a gamble with pretty good odds: Odds are the board will work with no issues, and I m happy. However if it doesn t, I probably have to eat the cost and get a new one. I also make sure to buy them from Amazon. That way if it fails right away, I just have Amazon replace it since they never give you any hassle about anything."</post>
   <post id="ce0bc5f4-6ae7-454d-b6f2-ecbbf006b4d4" section="MotherBoards" discussion="Asus RMA sent back the same board">"OP, are you sure they didn t reject the RMA after inspecting? Receiving the same board back w/out a fix sounds like they that may ve been the case."</post>
   <post id="8a2df067-5bad-4b19-a285-0b9c79ced470" section="MotherBoards" discussion="Asus RMA sent back the same board">"null said: ↑ OP, are you sure they didn t reject the RMA after inspecting? Receiving the same board back w/out a fix sounds like they that may ve been the case. Click to expand... They re also awful about not sending paperwork with explanations of their findings. There s a reason why I now prefer MSI."</post>
   <post id="6bb89c5f-3aaa-4923-b1ef-29f9658fea34" section="MotherBoards" discussion="Asus RMA sent back the same board">"Shaca said: ↑ yea, spoke to raja and emailed the specified person. lol Easius, that sounds awful xD Click to expand... Did you get a response back? I have emailed Santos twice about my issue and no response. My thread is in the display section."</post>
   <post id="7307b9f4-842e-4cbe-87b6-5bb1dcd9ddf2" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"I ve got a HTPC with a ASRock AMD E350 Dual Core 1.6GHz Mini ITX with 4Gb of Ram and a 64GB Crucial OS Drive running Windows 7 Pro (in my signature). Up until recently I ve only used it to stream local content from my WHS 2011 server and the HTPC hasn t given my any issues. But I ve been trying to move towards cutting the cord and streaming media online. I have another thread posted in the Home Theater PCs &amp; Equipment section and from posting back and forth there I m 95% sure that my router, modem, switch, wiring and internet connection are good enough to be able to stream media online. I ve used various browsers and done multiple speed tests and things seem good enough to be able to stream shows online without them constantly stuttering / pixilating, etc. So I m wondering if anyone could give me some opinions on my ASRock motherboard. I did a quick search online today and there were some comments that the video performance with this motherboard wasn t good enough to stream media to a large TV. I d ideally like to put a video card in, but don t think that it s possible with a setup this small. Also not really sure if a video card would fix the video stuttering issues that I m having. And then, if the mother board isn t good enough for streaming, could I get some suggestions for a new mini ITX motherboard. I d like to keep the price (as cheap as possible) ideally around $100 and be able to reuse the case that I have so I d want a board that is the same size. Also need a HDMI port and at least 2 USB ports. Thanks in advance."</post>
   <post id="785e3bb6-8062-4935-9e67-c3f86f5d934c" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"The problem the AMD Bobcat platform had was it had a limited list of accelerated video formats, and even then some standard format videos didn t play back smoothly at 1080p. The CPU is too weak to do it for you in software, so you need a faster CPU. This Haswell Celeron can decode h.264 at 4k resolution: Intel Celeron G1820 Haswell Dual-Core 2.7 GHz LGA 1150 53W BX80646G1820 Desktop Processor Intel HD Graphics - Newegg.com And unlike the E-350 the CPU is fast enough to handle 1080p software decode of stranger formats like those used for Anime rips. Here s an H61 miniITX motherboard with HDMI, SATA 6 and USB 3. ASRock H81 Pro BTC LGA 1150 Intel H81 HDMI SATA 6Gb/s USB 3.0 ATX Intel Motherboard - Newegg.com Together they re $110, and use the same DDR3 you already have. The Celeron will likely use 5-10w more at idle."</post>
   <post id="800fe45c-3cea-431b-bfe3-cd52fe28078c" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"Awesome, thanks defaultuser!!! Just the info that I needed. Will the current power supply that I m using now work with this new board / processor?? I can get some of the numbers / info off of it if needed. It s an external cord, kinda like a laptop power supply. Thanks again"</post>
   <post id="1e9c82d2-f4dd-44f1-8d62-51e8335cd57a" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"dar124 said: ↑ Awesome, thanks defaultuser!!! Just the info that I needed. Will the current power supply that I m using now work with this new board / processor?? I can get some of the numbers / info off of it if needed. It s an external cord, kinda like a laptop power supply. Thanks again Click to expand... It should be okay, but let s double-check things just to make sure It looks like your ASRock AMD E350 takes an ATX 24-pin connector to me. So if you re using a laptop external PSU, either the case has an integrated voltage converters, or you re using a PicoPSU. Which is it? If it was included with the case, what is the case brand and model number? If it s a PicoPSU, what s the rating and the laptop power brick information?"</post>
   <post id="3533037e-d535-4c99-8333-b85584140c80" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"defaultluser said: ↑ It should be okay, but let s double-check things just to make sure It looks like your ASRock AMD E350 takes an ATX 24-pin connector to me. So if you re using a laptop external PSU, either the case has an integrated voltage converters, or you re using a PicoPSU. Which is it? If it was included with the case, what is the case brand and model number? If it s a PicoPSU, what s the rating and the laptop power brick information? Click to expand... Hopefully this will be enough info for you. The case is a Habey 800B enclosure. Here s a link to it: http://www.habeyusa.com/products/em...itx-pc-case-with-12v-dc-fanless-power-supply/ And a handful of pics."</post>
   <post id="622d051c-1ac1-4e31-8d87-2ba6648dffac" section="MotherBoards" discussion="ASRock AMD E350 Dual Core 1.6GHz Mini ITX questions">"Yeah, that should be fine. The Celeron plus motherboard plus ssd should use 50w or less at full load. Numerous reviews of the faster-clocked Pentium show 70w at the wall maxed-out, which means 55-60w after PSU losses. This thing is clocked 500 MHZ slower, so should be 5-10w less."</post>
   <post id="3f536568-bcaa-4f35-8bcf-8f4f62e79d59" section="MotherBoards" discussion="best mini itx h170?">"hi guys. i want to upgrade my pc, actually it has a maximus impact vii i7 4790k 16gb corsair 2133 ram. I want to switch to skylake and i decided to stop doing oc. which mobo do you suggest me with i5 6600 or i7 6700 for gaming? i ve seen gygabyte h170n-wifi or msi z170i pro ac. which of them is the best?"</post>
   <post id="274f75b5-eea5-4e2d-ae94-6e88277867d6" section="MotherBoards" discussion="best mini itx h170?">"I ve set up a small living room PC using the ASRock H170M-ITX and I m very happy with it. Setting it up was super easy and zero problems so far and you cannot beat what your getting for that price."</post>
   <post id="135144c8-f6e4-4cd3-b90e-a5b4429b5923" section="MotherBoards" discussion="best mini itx h170?">"SliceT said: ↑ I ve set up a small living room PC using the ASRock H170M-ITX and I m very happy with it. Setting it up was super easy and zero problems so far and you cannot beat what your getting for that price. Click to expand... i alaways had asus rog series and a msi gaming z97...what do you tell me about gygabyte quality?"</post>
   <post id="19f8a700-8e95-4262-9f6b-d3f361f2889b" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"Hey everyone, I was just wondering what the preferred app is not for monitoring CPU and GPU temps and fans, etc? I used to use HWmonitor. Is that still the best one to use? Thanks!"</post>
   <post id="5441b31a-a3b2-4f30-b941-6378308ec3ae" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"I use HWInfo64, been using it for years without issue, covers all aspects of HW monitoring for me."</post>
   <post id="43c3ceb1-03bc-4286-9317-5c0d256a0ba3" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"I ve been using this for awhile.. Gives alot of info.. Here is the link: Open Hardware Monitor - Core temp, fan speed and voltages in a free software gadget"</post>
   <post id="8d9a992a-ae99-495a-b84c-a84c3529f34f" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"I second the open hardware monitor vote! gives a literal shit ton of info and it can control fans too! HWInfo64 is good too. I actually use these two together as OHM does not see voltages on my gpu. so that is really all I use it for and its handy "up time" counter that I use like a stop watch."</post>
   <post id="96f4048f-dd07-45cf-81bf-f6192bf01620" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"I have a problem with Open Hardware Monitor, ever since I upgraded to a 6700K from my 2500k it only shows fan speeds, voltage and usage. There aren t any temps listed."</post>
   <post id="f2dc6345-1198-4b1c-80b8-da0d2bd6390a" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"oh guess they need to update it"</post>
   <post id="7f7d60a6-4c5e-4d03-8036-7ee78e099759" section="MotherBoards" discussion="CPU/GPU temp and fan monitoring utility">"I ve always used speedfan"</post>
   <post id="38dd9d74-94f1-4345-935c-13bb1beeaf72" section="MotherBoards" discussion="What would your choice of MB be in this situation?">"I am trying to assemble a "hybrid" HTPC/gaming rig for my TV. The setup will be used for watching movies/DVDs, surfing and some gaming (ex: World of Warships). I have decided to build as small as possible centered on an oldie but goodie, the i5-2500K. After doing a ton of research I have decided that the M-ITX MB form factor is probably the right choice because the case I need to use is unsupported by ATX and only a few at the M-ATX level. Here is an example of some of the cases I am considering: http://www.newegg.com/Product/Produc...82E16811163231 http://www.newegg.com/Product/Produc...82E16811119286 http://www.newegg.com/Product/Produc...82E16811139033 The problem I am having is that the LGA 1155 is not being produced much anymore and finding a used MITX MB is getting more difficult. Prefer USB 3.0 headers on the board as well as HDMI. I desire to have at least some OC abilities whether I actually use it or not. Please recommend a board or boards for this build. If YOU were building a similar system what MB would you use? Thank you ..."</post>
   <post id="df149ccd-fadb-4901-8ab8-23d323430ab5" section="MotherBoards" discussion="What would your choice of MB be in this situation?">"There unfortunately aren t that many options. I d probably use this one, which seems to have all the features you asked for. ASUS P8H61-I R2.0 LGA 1155 Intel H61 HDMI USB 3.0 Mini ITX Intel Motherboard with UEFI BIOS - Newegg.com Edit: Crap, I just realized that s an h61 chipset. It would probably serve you well, but you can t overclock with it. You might look on ebay for a used z77 chipset one, but having been in a similar position to you recently, I was surprised to find that everyone wants to basically scalp the 1155 boards. Apparently, the 1155 CPUs never die and are still perfectly capable, but the motherboards are starting to fail, so there s good money to be made selling working ones."</post>
   <post id="73ad8a18-c5fd-4f34-ad04-e26afcbff32a" section="MotherBoards" discussion="What would your choice of MB be in this situation?">"Are you tied to that 1155 chip? I feel like it would cost a similar amount to sell your 2500K (assuming you already have one) and pick up a comparable 1150 socket chip with a H87/97 or Z87/Z97 mini ITX board than to buy a Z77 board. That said, I haven t really looked at pricing/availability of those older mini ITX boards or at used Haswell i5 pricing. I just know that I ve bought clearance/open box H97 ITX boards for as low as $30 and Z97 ITX for around $50-70. I feel like Z77 boards go for enough of a premium these days that it would be worth considering newer platforms."</post>
   <post id="f9bad2e6-e093-4e9b-b7b3-8d51fc1a3e60" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"I upgraded from 3770k to 6700k and decided to try another mobo manufacturer. I fell in love with Gigabyte Gaming G1 since it s beautiful, has support for water cooling and even have integrated Sound Blaster ZxR (a €200 sound card!). It s the best and most expensive 1151 motherboard Gigabyte has to offer. Before that I had Asus Maximus V Extreme, which back in the day was the best and most expensive 1155 motherboard Asus had to offer. The problems I have with Gigabyte Gaming G1: 1) To be able to reset BIOS, you have to short a jumper. Which feels so 2002. And also, it s so badly placed and covered by my second video card so I have to remove it every time I want to reset BIOS. Asus: Has a reset button in the I/O side. VERY handy! 2) The above problem would not be such a big issue if BIOS would not just hang up if I go too low voltage for the overclock (ocing to 4.7ghz at 1.300v would for some unknown reason hang up the whole BIOS). There was no way to fix it but force reset BIOS. 3) BIOS hangs up randomly both in BIOS and after reporting unsuccessful overclocks. What s up with that? It is not however as bad hang up as just going low voltage, it can still boot but I need to swap USB ports on my keyboard since it won t respond. 4) Compared to Asus, Gigabyte have really confusing and weird laid out BIOS menu. 4) Prior to upgrading to integrated ZxR, I had a PCI-E ZxR card. For some reason, the interface in the integrated one is different, very confusing and doesn t offer as many options as the PCI-E one. It is the same sound card. Because of that I am unable to simply use the software to switch between headphones and home cinema system. I have to go to playback options in Windows and change devices. Besides the jumper problem, the rest is more of a software issue. However I don t see Gigabyte fixing them anytime soon. Probably not ever. I do regret not buying Asus motherboard, but still, I don t want to complain much since this motherboard is doing its job well, but for a €550 motherboard I expected more. I do like it s WIFI antenna though! Really sweet and is magnetic. But I m an overclocker, I got spoiled by Asus who actually does a great job when it comes to overclocking and gives attention to detail. Those who worked with Asus and that BIOS reset button know what I m talking about."</post>
   <post id="60704d16-957c-4bd1-acbf-671bf5425819" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"Worse than that, I find many Gigabyte boards like to die right outside of warranty, boot loops and sleep/resume issues are common, and more. Their BIOS support tends to be shit, and a lot of boards need beta BIOSes to fix common issues... that Gigabyte never releases to the public, instead requiring you contact them, explain the issue, troubleshoot (pointlessly) and then they ll send you the damn thing. In short, I don t recommend Gigabyte to anyone any more. If it s not too late I d return the board and get something from MSI or Asus, even ASRock."</post>
   <post id="1202361c-e379-435a-8476-dffe38ba31de" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"at least GB has an RMA program, unlike ASUS where they just send your broken board back, send you somebody elses broken board, or mash your socket and mark it "customer damage""</post>
   <post id="c7411850-04a6-4251-bd4f-28e676305b57" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"i suggest you write to gigabyte and ask them to bring the features you want to see, if they don t, vote with your wallet and buy asus or whatever has the features you like, spending €550 on 1151 motherboard is not very smart, you d be better off getting a x79 or x99 mobo, you can fix the hard to reach jumper problem, either use an extended jumper, or glue a straw or something to the jumper, or attach wires to the pins and use a 3way switch or just connect the right wires together"</post>
   <post id="2e08bfd2-f919-429f-81df-b33f172db7b1" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"the dual bios, ez reset on the back and no cpu/ram bios reflash features on asus motherboards are simply awesome, love it"</post>
   <post id="c9d691c6-51ab-4070-a2df-3b740a1d3f9c" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"One could argue that the reset button on Asus boards is there because you will need it more often. haha"</post>
   <post id="e50f7129-f953-449a-bd57-40c9d87c572d" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"all mobos have their share of problems, it just depends how cheap they want to make them"</post>
   <post id="9b8f22fb-9077-402d-972d-c0134cd76b37" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"Asus software isn t that great. AI Suite on my Z97 Gene, return from sleep will sometimes have it ignore my fan profile and just stick on full. Annoying EZ Update has never picked up an update that was available from the Asus driver webpage. Not so  EZ "</post>
   <post id="de5d958e-0578-48bd-af30-579e6b86568a" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"i don t use any asus software besides the drivers, try SpeedFan for fan controlls, updates are overrated, besides asus hardly ever updates anything, so it s just a waste of harddrive space"</post>
   <post id="83cf89c9-94ac-40a9-a7af-8dc1ae313502" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"I build a PC around a Gigabyte motherboard in 2007 or so. The board had good reviews... only thing is, I accidentally got the G version instead of the D version when I wasn t paying attention. Even though I didn t use the Integrated Graphics and didn t overclock, the board (GA-965G-DS3, I believe) died within a year. I mean, it smelled like it was melting or something, and then just gave out. It wasn t the CPU because that was fine. It was obviously the board. That really was upsetting, because my father then came around (doesn t live with us) and offered me a new computer with a Q6600 and a GTX 8800. Told me that I wouldn t get it unless I let him throw out all my old ones. I ended up talking him into letting me keep an Athlon XP system for my Mom, and I also hid an old Toshiba laptop under a tablecloth so he couldn t find it... but everything else was tossed, including an old K6-2 system I d just built for old games. If that board hadn t failed on me, I would have been able to tell him I didn t want or need that new computer, but when he saw my newest working computer was Athlon XP and I had a dead Core 2 lying around, he just circled like a vulture... he knew he had me. Sigh. I still regret that decision, because that new one was running Windows Vista and didn t feel any faster than my Athlon XP. I barely enjoyed it the whole time I owned it. I got maybe one good year out of it after upgrading it to Windows 7. Then when it came time to replace the video card, it turned out it had a cheap board that couldn t handle the power draw in addition to a cheap power supply. So I ended up having to basically replace the motherboard after just 3 years, which effectively means I had to build a new computer inside the same case with most of the same components outside of RAM/CPU/Motherboard. Worst lifespan of any computer I ve ever owned (aside from the Gigabyte machine). Needless to say, I m never buying anything from Gigabyte ever again. LOL. ASUS and MSI are the only vendors I trust now."</post>
   <post id="8e7c887a-ee25-4913-8ae3-23219ba513a3" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"i bought one of msi high end boards, i think it was around p35 time, it had so many problems i sent it back and never bought another msi board, i still think dfi and abit made the best motherboards, no idea why they are gone"</post>
   <post id="a3be8151-443b-49f2-99ac-8303438df88c" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"buhbuhfet said: ↑ i don t use any asus software besides the drivers, try SpeedFan for fan controlls, updates are overrated, besides asus hardly ever updates anything, so it s just a waste of harddrive space Click to expand... Cheers for tip. I will try speedfan"</post>
   <post id="0a9b4706-6e11-41eb-bb44-eacc57227f7a" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"buhbuhfet said: ↑ i bought one of msi high end boards, i think it was around p35 time, it had so many problems i sent it back and never bought another msi board, i still think dfi and abit made the best motherboards, no idea why they are gone Click to expand... I buy MSI almost exclusively now. They have never let me down. DFI boards were garbage, they just let us do things that no one else was letting us do at the time."</post>
   <post id="c4fab529-2876-4fb2-8b7f-ac1774bd0642" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"This is a funny thread. I ve had GREAT experiences with my Gigabyte boards and "meh" with Asus. In fact, I m in the midst of a build on a Gigabyte board, chosen over Asus and MSI. To each their own."</post>
   <post id="1861948f-1bcb-4dd0-8231-c1d6eb601f18" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"buhbuhfet said: ↑ i suggest you write to gigabyte and ask them to bring the features you want to see, if they don t, vote with your wallet and buy asus or whatever has the features you like, spending €550 on 1151 motherboard is not very smart, you d be better off getting a x79 or x99 mobo, you can fix the hard to reach jumper problem, either use an extended jumper, or glue a straw or something to the jumper, or attach wires to the pins and use a 3way switch or just connect the right wires together Click to expand... Nice tip, thanks! I don t see the motherboard as €550 since the integrated sound card costs almost €200 if you buy it separately. jojo69 said: ↑ at least GB has an RMA program, unlike ASUS where they just send your broken board back, send you somebody elses broken board, or mash your socket and mark it "customer damage" Click to expand... Well, I have had no issue with Asus RMA. One of my 670 failed and Asus wanted to replace it with 950 (that s when I decided to go with 980Ti). I ve even sent their Vulcan Pro ROG headphones back and got new ones. But those broke as well, real crappy quality on their headphones. And even my tablet (TF810c) was sent back and got it back but they replaced the charging adapter. I remember that once I had to buy a new motherboard from ASUS since the one I used was DOA, but I did not send it to Asus but to the company that sold it to me, not sure what happened there, but they blamed it on me, those bastards. silent-circuit said: ↑ Worse than that, I find many Gigabyte boards like to die right outside of warranty, boot loops and sleep/resume issues are common, and more. Their BIOS support tends to be shit, and a lot of boards need beta BIOSes to fix common issues... that Gigabyte never releases to the public, instead requiring you contact them, explain the issue, troubleshoot (pointlessly) and then they ll send you the damn thing. In short, I don t recommend Gigabyte to anyone any more. If it s not too late I d return the board and get something from MSI or Asus, even ASRock. Click to expand... It s too late now, but I m not regretting it THAT much I can t comment on how long it will last, but the reason why I m keeping it is it s fully packed with features. It has pretty much everything. That s why I m willing to overlook the software/jumper issues it has. And it overclocked my 6700k to 4.9ghz Now I just need to do some tweaking and see if I can actually hit 5ghz. 4.9ghz is not stable on Prime95 but I don t care about Prime95, no issues at all while gaming, doesn t go over 75c (usually around 50-60c while gaming) and those two things are most important to me."</post>
   <post id="9f63e869-f21f-452f-b385-25643ec5cc70" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"ryan_975 said: ↑ I buy MSI almost exclusively now. They have never let me down. DFI boards were garbage, they just let us do things that no one else was letting us do at the time. Click to expand... My only real problem with MSI is their insistence on puting those stupid "Killer" NICs on everything. Gimme a nice, dependable Intel NIC, rather than something that gives microscopic gains in just games and shit performance in everything else."</post>
   <post id="5da947af-b1ff-40a3-9b44-dc2f5b3d2be2" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"Nebell said: ↑ I fell in love with Gigabyte Gaming G1 since it s beautiful, has support for water cooling and even have integrated Sound Blaster ZxR (a €200 sound card!). Click to expand... /me looks at Gigabyte Gaming G1 spec sheet, notices Sound Blaster ZxRi. I guess that i at the end of the name makes some diference as Gigabyte and Creative don t agreee on driver name or release dates for Sound Blaster ZxR and Sound Blaster ZxRi."</post>
   <post id="ed0e5901-9a57-491f-8ba6-793c2a2625aa" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"runs2far said: ↑ /me looks at Gigabyte Gaming G1 spec sheet, notices Sound Blaster ZxRi. I guess that i at the end of the name makes some diference as Gigabyte and Creative don t agreee on driver name or release dates for Sound Blaster ZxR and Sound Blaster ZxRi. Click to expand... My guess is that i at the end means integrated But yeah, ZxR and ZxRi are the same sound cards. I m not sure what happened to the software. Most of the functions are the same, just missing a few of them and the interface is even similar, just not 100%. I wonder if I could install the original software. Gonna try that once I get my hdd next week."</post>
   <post id="633722aa-0044-4f55-b95a-81aa4528928a" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"Last three builds are all Gigabyte, no issues. They are around 6 years old, 3 years and 2 years. No board will be perfect with layout and features. When I did have a glitch with one I wrote them and explained the issue. They worked with me to resolve it. I d say their customer service is pretty good."</post>
   <post id="85927095-1d01-4294-aa78-92cae801a73d" section="MotherBoards" discussion="Gigabyte motherboards are outdated compared to Asus">"I have tons of Gigabyte boards. Only one that died did so after being on for 6 years straight as either my gaming rig or file server."</post>
   <post id="7e51331e-4037-4b9b-b3b8-a6bc187112e2" section="MotherBoards" discussion="Anyone using a Dark Rock Pro 3 with the MSI X99A motherboard? Will memory fit?">"So I just got the motherboard in the mail and looking at it and where the memory slots are I am worried that the memory won t fit once I put on the cooler (which I don t get until Tuesday). I watched a video on YouTube (video all the way at bottom) about the cooler, and the guy mentioned possibly needing low profile memory. Anyone else know or has advice? Ram clearance will definitely be an issue. I have pictures of the components below, but the products are as follows: Motherboard: X99A SLI PLUS | MSI USA | Motherboard - The world leader in motherboard design Memory: Corsair Vengeance LPX 16GB (4x4GB) DDR4 3000 Vengeance® LPX 16GB (4x4GB) DDR4 DRAM 3000MHz C15 Memory Kit - Black (CMK16GX4M4B3000C15) CPU Cooler: be Quiet! Dark Rock Pro 3 be quiet! Virtually Inaudible Hardware"</post>
   <post id="f784082f-1bf9-4e1c-8234-0dcc7fff4f5c" section="MotherBoards" discussion="Anyone using a Dark Rock Pro 3 with the MSI X99A motherboard? Will memory fit?">"It looks awesome, I wish I could have one!"</post>
   <post id="47406ce5-b138-47aa-9813-c41bf0c24a80" section="MotherBoards" discussion="Gigabyte D3H vs D3H GSM?">"I m looking to pick up a motherboard for an Intel based server build. I ve worked with the G1-B150M-D3H GSM before and was going to pick one of those up. However, in searching, I also see a GA-B150M-D3H which is about $30+ cheaper. Comapring the specs, it appears they are nearly the same motherboard. So what s the deal with the GSM designated boards? Is the only difference being that they will keep them in supply for at least 2 years and they have advanced RMA? Thanks!"</post>
   <post id="ef48017d-4c8e-4351-b3da-93aeac970821" section="MotherBoards" discussion="Gigabyte D3H vs D3H GSM?">"Does anyone know what the differences are??"</post>
   <post id="a228b57e-da44-4a90-a9cc-a4081a0999e4" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"I have done it once. And the DEL key during boot up does NOT get me to the BIOS screen. Gigabyte said I have to eject the battery in order to go back to the BIOS screen. But if there is a way to work around it, I would like to enable fast boot. Meanwhile, in this CNET article, this guy said he can get his PC to boot up in 75 ms. If I enable fast boot, I think the best I can do is 7 sec. Getting a Windows PC to boot in under 10 seconds"</post>
   <post id="17a82bd9-e992-4bb1-8738-867633b38855" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"My MSI board boots up stupid quick with fast boot enabled... but it s prone to MCE BSODs so I leave it off and it still boots up more than fast enough for me. However, with fast boot on, the only way I get into the UEFI settings is to tell Windows to boot the system to it. You ll have to have Windows 8 or higher for that though."</post>
   <post id="fdca7187-1936-4305-a9b1-3ddf0eb8022e" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"what s MCE again? and why would you get BSOD? Ultra Fast Boot, Fast Boot is at the machine level, we haven t get to the windows software part yet. On the BIOS, even at Legacy, it gives me the option of Ultra fast, and Fast, and I wasn t using UFEI"</post>
   <post id="45f84616-a0e6-459e-8af4-3e36d10cbf7e" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"You re using UEFI regardless of whether you booting Legacy or not. Legacy is just a compatibility module that emulates a more traditional BIOS so non-UEFI aware OS s can still function. MCE = machine check exception. I get the BSOD while Windows is loading. Fast boot skips a lot of hardware initialization and testing steps, opting instead to use previously saved settings and assuming the hardware will still be set up as expected, to make booting faster. Apparently, something in my set up is not quite right without proper initialization, so I get an MCE when Windows tries to interact with that hardware during boot."</post>
   <post id="88324ff0-ad5b-4770-b4cd-d91d8dad7950" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"I forgot how to do it exactly as I m not in front of a Win 10 computer but it does have an option to  boot into BIOS  in one of the recovery/restart menus."</post>
   <post id="9a63cb80-2d30-4d0f-b087-e314413014f3" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"Holding shift when you click restart is what you re looking for. This is applicable to Windows 8 and Windows 10. On my MSI board, the Fast Boot utility has an option to reboot into BIOS."</post>
   <post id="1a9036f5-7331-41ee-ae11-f8320ef818ea" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"ryan_975 said: ↑ You re using UEFI regardless of whether you booting Legacy or not. Legacy is just a compatibility module that emulates a more traditional BIOS so non-UEFI aware OS s can still function. MCE = machine check exception. I get the BSOD while Windows is loading. Fast boot skips a lot of hardware initialization and testing steps, opting instead to use previously saved settings and assuming the hardware will still be set up as expected, to make booting faster. Apparently, something in my set up is not quite right without proper initialization, so I get an MCE when Windows tries to interact with that hardware during boot. Click to expand... In the days when UFEI wasn t invented, then Legacy is just Legacy. Regardless, to be fair, most PC doesn t change hardware much. So if it uses the saved setting of the prev. boot up, it should be fine. Anyhoo, my boot up time is about 8 sec. How many sec. do you shave off w/ ultra fast boot?"</post>
   <post id="0e83b797-ba17-4482-a8e4-e31632c34170" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"Happy Hopping said: ↑ In the days when UFEI wasn t invented, then Legacy is just Legacy. Regardless, to be fair, most PC doesn t change hardware much. So if it uses the saved setting of the prev. boot up, it should be fine. Anyhoo, my boot up time is about 8 sec. How many sec. do you shave off w/ ultra fast boot? Click to expand... So are you talking about a board that is pre-UEFI then? With MSI Fast-boot enabled, and as long as I didn t get a BSOD, I was booting to the log on screen in less than 5 seconds. That s with a 512GB Samsung 950 Pro, though."</post>
   <post id="305676de-57da-43d3-a701-3843a2f3f670" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"I don  t use MSI. And I would never use Samsung. There are other members here who lost their Samung SSD and Magician can t even find it. It s like the Intel 8 MB bug. A 1 TB SSD becomes 100 MB"</post>
   <post id="12701aba-0f2f-40c5-a49a-5dd60ee6da2e" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"Happy Hopping said: ↑ I don  t use MSI. And I would never use Samsung. There are other members here who lost their Samung SSD and Magician can t even find it. It s like the Intel 8 MB bug. A 1 TB SSD becomes 100 MB Click to expand... They only person I keep seeing say anything about this bug is you. Can you provide any links, because a search is showing nothing. (BTW, there is no 950 Pro 1TB drive yet)"</post>
   <post id="ac0c4c5d-88bf-4aaa-8e14-67982d7174ec" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"samsung 840 pro 256GB not recognized any longer"</post>
   <post id="4fdf5bce-d0e6-4cc7-9dfa-ebc6237ba5da" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"Happy Hopping said: ↑ samsung 840 pro 256GB not recognized any longer Click to expand... So one person who was running a 3 year old device with a very old firmware version had a failure and got it RMA d is proof enough for you that Samsung makes junk despite selling millions of SSDs with few people having any issues? Come on now. You said 1TB SSDs are becoming 100MB bricks, that s what I wanted to see proof of, not one-off cases of defects that have been long since fixed by the manufacturer."</post>
   <post id="7b2ee09a-a16f-4a61-9a5d-f7fd410d9864" section="MotherBoards" discussion="what are the disadvantage of Enable Fast Boot on Gigabyte Motherboard?">"There is far more than 1 members. I randomly pick that one because the hardforum search engine shows that one at the top of the search"</post>
   <post id="dc58d640-0ed2-481f-b076-86e4cc95a6a0" section="MotherBoards" discussion="Computer not booting">"Hi all, I recently purchased an ECS X79 AX motherboard - ECS &gt; X79R-AX (V1.0) And a Xeon 2760 CPU - Intel Xeon E5-2670 2.60 Ghz 20 Mb 8-Core CPU Processor SR0H8 115W What s happening is that when I powered it on nothing is coming up on the screen. I can get a display (only on VGA, HDMI nothing) for about 1-2secs showing the motherboard logo then it will go black, making a single beep sound every ten seconds. Has anyone ever come across this before? It very strange. The vid card, RAM and PSU are known working (using them now) and cannot for the life of me think what it could be. i have tried the below- Reset CMOS and removed battery for 20mins Used known working video card, ram and PSU Tried inside and out of pc case in case it was a short Tried all ram slots with either one dimm or full Re-seated CPU and made sure its in the correct way. Also checked for bent pins Tried CPU in another motherboard; works correctly. Tried all PCI-E slots for vid card Re-seated 24pin and 8pin connectors Any suggestions? Thanks in advance."</post>
   <post id="05bd7a9b-7431-4de6-9c07-347d94489dea" section="MotherBoards" discussion="Computer not booting">"Update: I can now get into the BIOS when I have my GTX670 plugged in but not my 970.... 970 shows display for 1sec then nothing. Very strange"</post>
   <post id="793ff951-fb91-4d0a-a235-55d857ef75ce" section="MotherBoards" discussion="Computer not booting">"BAC said: ↑ Update: I can now get into the BIOS when I have my GTX670 plugged in but not my 970.... 970 shows display for 1sec then nothing. Very strange Click to expand... Check the RAM settings in BIOS"</post>
   <post id="2fa29491-1789-4b26-a202-a2d44ac5ff66" section="MotherBoards" discussion="Computer not booting">"Try updating the BIOS."</post>
   <post id="121530df-e5d8-486a-b01c-c25eba745f48" section="MotherBoards" discussion="Computer not booting">"BAC said: ↑ Update: I can now get into the BIOS when I have my GTX670 plugged in but not my 970.... 970 shows display for 1sec then nothing. Very strange Click to expand... Oh well, ugh, your issue may have something to do with uefi/legacy BIOS related.. and that s why your 670 post and the 970 does not.. I think the gtx 970 is uefi only while IIRC most of the gtx 670 had legacy bios by default. So nothing is strange at all if the issues are related to GPU bios support and/or compatibility.. similar issue presented another fellow member here at [H] with an old mobo resulting in him buying a new GPU with hybrid bios solving his motherboard uefi compatibility troubles. You may want to check: Installing gigabyte GeForce 960gtx on Evga 790i So yes as I always say, be sure to check for BIOS update for your motherboard and to check for UEFI/Legacy switch..."</post>
   <post id="a87c267b-2a22-4f2a-afe5-94ded796dc3d" section="MotherBoards" discussion="Computer not booting">"The latest bios added additional sandy bridge support. Sadly there are only 2 bios listed on the website with no mention of ivy bridge. BIOS Name BIOS for X79R-AX V1.0 Version 11/29/2011 Update Description Release Note: 1.Fix screen garbled problem when NV Graphic driver not install yet. 2.Fix Multi-language cannot switch problem when clear CMOS *Support eBLU(BIOS Live Update Utility) *Support eOC BIOS Name BIOS for X79R-AX V1.0 Version 2/6/2012 Update Description Release Reason: 1. Support Sandy Bridge C2 and M1 stepping CPU 2. Improve Gear Ratio overclocking function 3. Improve the compatibility of USB3.0 4. Fix Win8 install BSOD issue 5. Improve compatibility of PCIE X1 slot *Support eBLU(BIOS Live Update Utility) *Support eOC"</post>
   <post id="2c7b83e2-a33e-48c2-9cab-68f7bce48691" section="MotherBoards" discussion="Computer not booting">"I dread the day a video card becomes UEFI only. So I ll just ignore this scary thought for now. Okay so you have a Xeon. And you can get it to show stuff, so the power is right and the CPU can work. It s a 32nm part, so it should (in my experience) work fine in a X79 scenario. Suddenly, memory. Xeons like ECC memory, don t they?"</post>
   <post id="b9638eb5-6840-4f3a-bfd5-58453fb99829" section="MotherBoards" discussion="Computer not booting">"Thanks for your help guys. With the 670 plugged in everything works normally, although for some strange reason i had to plug it in vga to the monitor first to get a signal, then switch back to hdmi. Windows installs correctly, can run games, Prime, 3dmark etc. all fine. I ve had a look through the Bios but cant see anything legacy boot..."</post>
   <post id="4deb7a1e-d9fa-4e40-8dbb-721795395762" section="MotherBoards" discussion="Computer not booting">"Oh and the Bios was already the latest version."</post>
   <post id="0384e632-149e-4159-a641-451511f32d7f" section="MotherBoards" discussion="Computer not booting">"Araxie said: ↑ and that s why your 670 post and the 970 does not.. I think the gtx 970 is uefi only while IIRC most of the gtx 670 had legacy bios by default. Click to expand... araxie is right, this is your problem."</post>
   <post id="6e370ca4-4f87-42bc-843f-5b39c927a198" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I m not a fanboy nut ASUS has served me well with its P8P67-Pro M these years. I want to upgrade to Skylake and holy crapola does ASUS has a crapload of Mobos to choose from. I have spent a lot of time trying to figure it out, but I can t make heads of tails. ASUS SABERTOOTH Z170 S LGA 1151 ASUS SABERTOOTH Z170 S LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 USB 3.0 ATX Intel Motherboard - Newegg.com This one looks good, its only $189. ASUS Z170-A LGA 1151 Intel Z170 ASUS Z170-A LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 USB 3.0 ATX Intel Motherboard - Newegg.com This one also looks good for $154. Then you have the ASUS ROG MAXIMUS VIII HERO ALPHA for $288! http://www.newegg.com/Product/Product.aspx?Item=N82E16813132699 and http://www.newegg.com/Product/Product.aspx?Item=N82E16813132586 ASUS ROG MAXIMUS VIII RANGER $195! Dunno, I thought Rangers were Heros...oh well. There are a ton more, but I don t have the time or the patience to list them all...and I m not married to Asus...I don t mind Gigabyte or Asrock..or whatever. What I do want is intense gaming performance, moderate overclocking ability. I don t care what color it is, I don t care if it has LEDs flashing all over the place, just want it to work... Advice? Thanks in advance."</post>
   <post id="ce730703-99f9-4fc6-8784-47f02b70a92e" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"Sabertooth boards are meant to be rock-solid in terms of reliability, the others are various degrees of overclocking/gaming boards."</post>
   <post id="08310424-1974-48d0-ab2c-fb225c37ce50" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"Thanks for the response. So, if you had to choose one for gaming/moderate overclocking, but I would like durability..which would you choose?"</post>
   <post id="d2debae4-e6c9-4bb4-b1cd-6660f9ef8ea8" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"Sabertooth all the way... 9 out of 13 of my machines are built with sabertooth Boards from intel x58 all the way to my lastest Z170, and even my AMD platforms are Sabertooth 990FX. always reliable, great overclocking, great features. Im a truly Sabertooth fanboy."</post>
   <post id="93258cae-65d6-4a2f-88a4-274039557fba" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I m planning to go z170 once the new Pascall cards are announced. Already decided on the Sabertooth for my mobo."</post>
   <post id="73634edd-0501-45fa-83ec-2d798ce847ea" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"why do Asus boards only carry one m.2 Drive? I really want a minimum of 2."</post>
   <post id="4502fcaf-558a-45d4-9ae4-0ac08cf1f592" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"In the market for a Z170 board myself. You re right their are too many! But I have narrowed it down to that Sabertooth Z170 S or the Asrock Extreme 7+."</post>
   <post id="005a4b5d-1134-4789-bb85-e4dbccfc78a1" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I m just going to assume you re limiting yourself to ASUS, because there s even more motherboards that you re not considering. Plus, if I start listing MSI motherboards with military grade components, you re going to be even more confused. LOL. For overclocking? Well, how extreme is your OC going to be? I d say the Maximus boards are great for extreme overclocking... they can handle LN2 (Liquid Nitrogen, I think) and they re also packed with tons of features that few people need. The cheaper Maximus Ranger is probably good for overclocking too, but maybe less expensive. Here are the differences between those two Maximus models, if you re interested. This is based on the Newegg specs list. I d be pretty confident in the OC ability of both boards. Hero advantages: Wi-Fi and Bluetooth connectivity built-in U.2 SSD interface support RGB LED headers (for case decoration) Ranger advantages: Price SATA Express Thunderbolt header TPM module header Other than that, they seem to be very, very similar boards. I don t think you could go wrong with either one. I would personally guess that it will come down to whether you want Thunderbolt or U.2 SSD support more. Those seem to be the only features differentiating the two boards, and that s assuming the guy typing up the specs at Newegg didn t miss something. The other board that s much cheaper is more of a standard model... probably still good enough, but it might not handle Liquid Nitrogen and might give you a slower OC by 100MHz. I think other OEMs have better offerings at this price point, though. It s very competitive down there, while ASUS has the ultra high-end $200+ area sewn up pretty well."</post>
   <post id="4197e934-6540-4375-8d14-504174b3acd2" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"That Asrock Extreme 7+ is quite the board. I don t have much experience with Asrock though and from my perspective at least, they seem like a low tier brand."</post>
   <post id="cd9330ba-be61-4252-a3be-818c3189656e" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"athenian200 said: ↑ I m just going to assume you re limiting yourself to ASUS, because there s even more motherboards that you re not considering. Plus, if I start listing MSI motherboards with military grade components, you re going to be even more confused. LOL. For overclocking? Well, how extreme is your OC going to be? I d say the Maximus boards are great for extreme overclocking... they can handle LN2 (Liquid Nitrogen, I think) and they re also packed with tons of features that few people need. The cheaper Maximus Ranger is probably good for overclocking too, but maybe less expensive. Here are the differences between those two Maximus models, if you re interested. This is based on the Newegg specs list. I d be pretty confident in the OC ability of both boards. Hero advantages: Wi-Fi and Bluetooth connectivity built-in U.2 SSD interface support RGB LED headers (for case decoration) Ranger advantages: Price SATA Express Thunderbolt header TPM module header Other than that, they seem to be very, very similar boards. I don t think you could go wrong with either one. I would personally guess that it will come down to whether you want Thunderbolt or U.2 SSD support more. Those seem to be the only features differentiating the two boards, and that s assuming the guy typing up the specs at Newegg didn t miss something. The other board that s much cheaper is more of a standard model... probably still good enough, but it might not handle Liquid Nitrogen and might give you a slower OC by 100MHz. I think other OEMs have better offerings at this price point, though. It s very competitive down there, while ASUS has the ultra high-end $200+ area sewn up pretty well. Click to expand... You seem quite knowledgeable in the two brands i ve been looking at for that past two weeks. Frankly I m a creative director so a lot of what I do is graphics, rendering and such. After many years I ve recently decided to build myself a PC that can handle serious prosumer software as well as gaming to the full potential available today. For this I ve settled on a single 980 ti coupled with say 6700k, 32GB of 3200 dominator kit, 512 sammy m.2. etc... I ve been bouncing back and forth between Asus and MSI (glancing at Gigabyte from time to time), and I ve almost settled on the Asus Z170 deluxe despite it having only 1 M.2 drive slot (I want 2 minimum) and despite some of the negative reviews I ve read that I think could be attributed to how new these NVME and M.2 configurations are. What really sold me was that keyboard feature this board has with the macros. Is there a better option for my money? TIA!"</post>
   <post id="fd5e4a44-54b4-44e0-8967-09bae8aec47a" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"theDeviL said: ↑ You seem quite knowledgeable in the two brands i ve been looking at for that past two weeks. Frankly I m a creative director so a lot of what I do is graphics, rendering and such. After many years I ve recently decided to build myself a PC that can handle serious prosumer software as well as gaming to the full potential available today. For this I ve settled on a single 980 ti coupled with say 6700k, 32GB of 3200 dominator kit, 512 sammy m.2. etc... I ve been bouncing back and forth between Asus and MSI (glancing at Gigabyte from time to time), and I ve almost settled on the Asus Z170 deluxe despite it having only 1 M.2 drive slot (I want 2 minimum) and despite some of the negative reviews I ve read that I think could be attributed to how new these NVME and M.2 configurations are. What really sold me was that keyboard feature this board has with the macros. Is there a better option for my money? TIA! Click to expand... Well, if you re sure you want M.2 rather than U.2, then I can safely suggest these very similar boards: MSI MSI Gaming Z170A GAMING M5 LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 ATX Intel Motherboard - Newegg.com MSI MSI Gaming Z170A GAMING M7 LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 ATX Intel Motherboard - Newegg.com The M7 and the M5 have military class components and are very durable. I ve been using an MSI board on a computer I ve been leaving on almost 24/7 for the past three years and it s still very stable. MSI boards are known for stability, and that was what was important to me when I was picking a board. I haven t tried overclocking on it, but a lot of other people say these boards rival ASUS boards in that department as well. In your case, they both have two M.2 ports. ASUS is a great OEM, I usually go with them when I want to spend more than $250 on a motherboard or I m considering extreme overclocking. But MSI is who I go with for the sub $200 motherboards. Just a personal preference, not something I d inflict on someone else. The M5 is pretty much the same board as the M7, but for $30 less, you only lose the following features: 1 fewer HDMI ports on the board No DisplayPort built into the board One fewer USB 2.0 ports. The type-C USB 3.1 port (you get a regular Gen2 in place of it). Game Boost/Power/Reset buttons for automatic overclocking. But really, most people use the video I/O on the back of their video card anyway, and those buttons are a convenience feature. Notice how they don t really take away anything substantial from the design? Oh, and the M5 claims it supports U.2 through a special host card that s not included... I didn t look into that, but it might be something you want look into."</post>
   <post id="96a3661d-34d0-4319-8edf-9a6875541562" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"First thing I look at for board is the expansion slot configuration. I usually see what will actually work for what I need and then go from there. Reviews and specs come after that. Truth be told is that most motherboards have a really crappy expansion slot configuration. Limit it down to the ones that don t and you are left with not nearly as many choices."</post>
   <post id="362a0157-5f48-4dbc-b30f-a5717275dfe4" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"athenian200 said: ↑ Well, if you re sure you want M.2 rather than U.2, then I can safely suggest these very similar boards: MSI MSI Gaming Z170A GAMING M5 LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 ATX Intel Motherboard - Newegg.com MSI MSI Gaming Z170A GAMING M7 LGA 1151 Intel Z170 HDMI SATA 6Gb/s USB 3.1 ATX Intel Motherboard - Newegg.com The M7 and the M5 have military class components and are very durable. I ve been using an MSI board on a computer I ve been leaving on almost 24/7 for the past three years and it s still very stable. MSI boards are known for stability, and that was what was important to me when I was picking a board. I haven t tried overclocking on it, but a lot of other people say these boards rival ASUS boards in that department as well. In your case, they both have two M.2 ports. ASUS is a great OEM, I usually go with them when I want to spend more than $250 on a motherboard or I m considering extreme overclocking. But MSI is who I go with for the sub $200 motherboards. Just a personal preference, not something I d inflict on someone else. The M5 is pretty much the same board as the M7, but for $30 less, you only lose the following features: 1 fewer HDMI ports on the board No DisplayPort built into the board One fewer USB 2.0 ports. The type-C USB 3.1 port (you get a regular Gen2 in place of it). Game Boost/Power/Reset buttons for automatic overclocking. But really, most people use the video I/O on the back of their video card anyway, and those buttons are a convenience feature. Notice how they don t really take away anything substantial from the design? Oh, and the M5 claims it supports U.2 through a special host card that s not included... I didn t look into that, but it might be something you want look into. Click to expand... Thank you for the very insightful feedback, I have my work cut out for me. You mention U.2 vs M.2, I don t favor one over the other but I do think m.2 is the future at least for boot media. I ve had an intel nuc as a media center box since it was first made available and that thing is still running strong, I ve turned is off maybe once of twice a year for the past few years and its rock solid."</post>
   <post id="76ebcbee-2e83-4389-87bd-6cda99caaf7c" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I d recommend ASRock or MSI over ASUS any day. Similarly avoiding Gigabyte these days."</post>
   <post id="20300f50-cb91-4811-9f93-fc62adac3a59" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I like the spacing between the big PCIe slots on the MSI m5; good for air airflow while computing with GPUs. Not sure if I like the 16/0 vs 8/8 option with two slots. Limit of the chipset ?"</post>
   <post id="1e0c181c-55cd-4fae-8aec-800cb511789f" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"ChristianVirtual said: ↑ I like the spacing between the big PCIe slots on the MSI m5; good for air airflow while computing with GPUs. Not sure if I like the 16/0 vs 8/8 option with two slots. Limit of the chipset ? Click to expand... Limit of the CPU. For current generation, unless you go with an x99 setup, you are going to only have 16 PCIe lanes total for GPUs. Z170 vs Z97: What is the Difference?"</post>
   <post id="c8a5f65b-300c-4418-828e-027bad12157f" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I recently started searching fora z170 board as well. So many options to choose from. I really like several of the suggestions posted in this thread. Once again the [H] community really shines ."</post>
   <post id="9554d887-e340-45c9-b2f1-1e3deec6299e" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"+1 for Sabertooth. I bought a Maximus series board for OC but found it has a ton of features most of which I disable for better OC. It has a lot of "feature adds" but also costs more. If I could do it all over again, I d pick a Sabertooth for just OCing and gaming."</post>
   <post id="9be58e5b-9e21-4c5b-8669-d31f7b56bc20" section="MotherBoards" discussion="Too darned Mobos to choose from!!!">"I just purchased my second sabertooth board. You definitely get what you pay for."</post>
   <post id="593e9a0e-28f5-47ce-a4f2-61974be56377" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"Leaving for Microcenter in about 1 hour and they have these open box x99 boards. Providing everything looks good on them (no damage) which would you get? I was going to get the Asus Deluxe, but the GA-X99M would be nice to go to smaller case size. The first AsRock on the list does have USB 3.1, however, I don t have any devices that would use it. Thank you for any input."</post>
   <post id="a668f69e-7c73-4f53-98b5-7366977b0e27" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"That s actually a really good price for the x99 deluxe. I d go with that."</post>
   <post id="e7e704b6-8ef5-4d60-8af7-d063fa5a2a31" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"Yep, I d go for the X99 deluxe. If that one is gone grab an Extreme4"</post>
   <post id="9c3b92d1-35af-499c-8283-03c9905075f8" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"Asus x99 Deluxe."</post>
   <post id="dfbc4c04-602c-4478-8291-1a876946a8cf" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"99.9% of the "Open Box" boards I look at in Microcenter have bent CPU pins (bent up by the idiots at Microcenter who handle the boards) and are usually missing the I/O plate. That said if the X99 Deluxe is complete I d buy that myself."</post>
   <post id="7c571293-37c0-44fa-b15b-5fa471b4d8c9" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"They had the x99 Deluxe.. hidden away in the back. I had to ask for it. I checked out the pins and they looked fine. It also had everything as far as I could tell minus SATA cables. It has the manual, DVD with drivers, M.2 Card, M.2 bracket, fan extension card, extra pin jumper things(?), I/O plate, and wireless antenna. Even the cashier was surprised it had the I/O plate. I also got 2x8GB DDR4 3200 for 65$. It says on the box it tested "Good" but I won t have a 5820k for a little while to test it (such a tease). Hopefully it is in fact good. Here s a picture of the pins: Another view Going to go great with the current color scheme: Plastic is still on the side panel. Anyways, pretty excited. Not as exciting as that 80$ MSI board, but still exciting."</post>
   <post id="a3fe47d6-1cbb-49dc-ba14-e325c111ed3e" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"Every now and then you do find a gem at Microcenter. Looks like you got one !"</post>
   <post id="8e051ca9-e297-4e17-86cd-c9b78b79077c" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"mothman said: ↑ Every now and then you do find a gem at Microcenter. Looks like you got one ! Click to expand... Yea the X99 Deluxe for that price is a great deal. I would have gotten the Gigabyte UD5 or Gaming 5 as those are very good choices too but the X99 deluxe would have been the first one I would have asked for. I wish we Canadians could get hardware at those prices we have to deal with like 2-3 higher than that and all sorts of other fees that empty our wallets."</post>
   <post id="250eac90-b24f-46bb-b567-eda7fba12999" section="MotherBoards" discussion="Out of these 7 x99 Boards which would you choose?">"Wish we had a microcenter in upstate NY. Glad you got a great deal."</post>
   <post id="7f4c6f3f-f143-49db-bc1b-1e4248a50b7e" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Weird thing happened, Uguru lost my hour count and I don t understand how. At first I thought it was the urugu program but that just relays what s in bios. I reinstalled it just to make sure, nothing changed. I had roughly 65533 hours last check, it reset to zero. No corruption, board is still rock solid. Kinda sucks, like having your odometer roll back when you are about to hit 300K miles. Seems petty but it was a cool feature to keep tabs on all the stats. Not sure if flashing the bios resets it as I never have, still using the original from 2007."</post>
   <post id="03ec683f-d163-4928-b0fc-112d20ce5cb8" section="MotherBoards" discussion="Anybody here still have a Abit board?">"It probably reset at 65535 since that is the max for binary in 16 bit."</post>
   <post id="32c17ff3-a316-4903-8c2c-96dfbfe7c841" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Interesting, I somewhat assumed maybe it hit the max allowed as everything still works great. No idea why it s 16bit but the original program is a good 10 years old. Wiki says 65,536 so I have my answer. Least I know where the end point is. Thanks."</post>
   <post id="cf3a927e-5aae-4616-81d3-beebe0faf73e" section="MotherBoards" discussion="Anybody here still have a Abit board?">"That app is written in C++ so it s pretty easy to just not think about it and us a 16bit int, especially if you re used to C# or Java where int is 32bit. I bet they never ran any copy of it for 65536 hours in testing . I have an Abit AN7, but it s in a box, retired years ago along with my Athlon XP 2500+. If Abit was still around I would be buying boards from them, that was the best board I d ever bought at the time."</post>
   <post id="2929329e-a117-4521-8697-34a925460ca0" section="MotherBoards" discussion="Anybody here still have a Abit board?">"I really miss Abit. Had a few MoBo s. Even had the BP6, but never got around to getting a second Celeron. Them were the days."</post>
   <post id="64874955-5a58-451b-911e-ca68ad7d9a9b" section="MotherBoards" discussion="Anybody here still have a Abit board?">"ramrod126 said: ↑ It probably reset at 65535 since that is the max for binary in 16 bit. Click to expand... This. Nice job pointing it out. Like others, I had great experience with Abit. Wish they were still here."</post>
   <post id="5e1fa9e9-f668-466f-859d-4869bf902055" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Wyodiver said: ↑ I really miss Abit. Had a few MoBo s. Even had the BP6, but never got around to getting a second Celeron. Them were the days. Click to expand... I owned the BH6, BX6 Rev 2 and the mighty BP6. All served me extremely well."</post>
   <post id="2ac56efa-3ee0-4bbd-9bed-9eb211ebfa15" section="MotherBoards" discussion="Anybody here still have a Abit board?">"I have an ABIT KT7A with a modified BIOS to work with Socket-A Barton CPUs. Pretty much the fastest Socket-A setup that still had an ISA slot. Bought it brand new in the box around a year ago and the first time I powered it on, a bunch of the capacitors exploded. Fun times. After replacing the capacitors it works great."</post>
   <post id="b0d12ed2-ba89-45c8-b79e-05ab576ba68b" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Almost all my rigs we exclusively Abit based. I had the BX6 rev2, BE6, BF6, SH6, SE6 (my favorite), NF7-S rev2, KD7-G, KR7A-133R, KT7A-RAID, and AN8-SLI. It was after this point that I switched over to Asus boards. Definitely the good old days. I think I still have that NF7-S in the closet somewhere."</post>
   <post id="d1151910-ebb4-430c-833f-eebec21b0d2e" section="MotherBoards" discussion="Anybody here still have a Abit board?">"I got rid of my IP35 Pro after putting up with the double-boot nuance for a couple of years. It left a bad impression on me. No motherboard bios should be released with a flaw like that. Prior to that, I think I had an Abit KT133A board, but I can t remember for certain. it s been too long."</post>
   <post id="4c529fc0-e380-49bd-8508-8b229385fa2d" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Ah, Abit was my favourite motherboards, (along with BFG for gfx cards) and the last one I had was the Fatal1ty AN8 which I loved. When I built a new computer in 2008 I switched to Gigabyte, and used the GA-EX58-Extreme v1.0 which was their flagship board at the time, along with the Intel i7 920 cpu. Which is serving me well since November 2008."</post>
   <post id="f0e7be5c-122e-4b64-ab73-c29a586204cc" section="MotherBoards" discussion="Anybody here still have a Abit board?">"I still have a IT7-Max2 Ver.2 around here somewhere. Got a 3.06Ghz HT P4 for it for like $8 off ebay to replace my original P4 2.53 Ghz Non-HT CPU. First computer I ever built myself."</post>
   <post id="af8de6dc-8a08-4171-9f9b-5300b3b02415" section="MotherBoards" discussion="Anybody here still have a Abit board?">"I still have my IP35Pro it s working as a home server rig in my basement. It still has a bug in it where if you populate all 4x8GB ram slots memtest will have errors in the later tests. I contacted ABit but they went out of business when I finally isolated it was a hardware or bios issue. IIRC Someone wrote me back but they couldn t do anything to help me out. So now i have 3 sticks installed since it was the workaround I found."</post>
   <post id="9b8a4d5b-df83-4c8c-a4e5-552bbd2ad15e" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Wyodiver said: ↑ I really miss Abit. Had a few MoBo s. Even had the BP6, but never got around to getting a second Celeron. Them were the days. Click to expand... Yea Abit was very popular back in the days. Looks like their last motherboard was LGA1366/X58 and then they got out of the business in 2009 as far as I could recall. Imagine if they had continued and made Z170 and X99 motherboards."</post>
   <post id="c046e8c7-7d6b-48c7-90f5-d21d376285c9" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Wyodiver said: ↑ I really miss Abit. Had a few MoBo s. Even had the BP6, but never got around to getting a second Celeron. Them were the days. Click to expand... Long live the Abit BP6 - It was the first motherboard I purchased myself (with every penny a Grade 9 student could scrounge). Paired with a Celeron 366@550Mhz, I was the coolest kid in the school (who am I kidding, I wasn t even the coolest kid in math club)"</post>
   <post id="a17d13ed-b073-46b1-a59f-3b6f6baab410" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Just realized the other day that I have a second working Abit board. The model is UL8, a socket 939 board with AGP that also has support fro Windows 98."</post>
   <post id="d1828455-109c-4437-86ca-f5e93712de1c" section="MotherBoards" discussion="Anybody here still have a Abit board?">"i have a IP35pro/6600 quad core/8GB ram that works. only thing wrong with it is if i let is sit unpowered for any length of time i need to remove 3 of the ram sticks to get it to boot, and check the memory voltage, then power it down, re-install other rams and it will run fine and dandy. man what a workhorse that system was"</post>
   <post id="63b7714d-8665-4d8c-8104-691b50f4e505" section="MotherBoards" discussion="Anybody here still have a Abit board?">"the snake said: ↑ i have a IP35pro/6600 quad core/8GB ram that works. only thing wrong with it is if i let is sit unpowered for any length of time i need to remove 3 of the ram sticks to get it to boot, and check the memory voltage, then power it down, re-install other rams and it will run fine and dandy. man what a workhorse that system was Click to expand... Sounds like it has some bad capacitors."</post>
   <post id="050b0030-9eed-44fa-b4c4-26ef75c077e1" section="MotherBoards" discussion="Anybody here still have a Abit board?">"Odd man out here I guess. My Abit days are ones I am very thankful for being behind me. As much as I miss the Celeron/Alpha heatsink days, I don t miss Abit at all."</post>
   <post id="8fa184bd-bf2f-421f-8e11-6a736f04b838" section="MotherBoards" discussion="Anybody here still have a Abit board?">"cyclone3d said: ↑ Sounds like it has some bad capacitors. Click to expand... will have to check on that"</post>
   <post id="487a01cc-72e7-435a-a7db-1dbe0ff5bbd2" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"I have an Asus Rampage II matx with 3 PCIe slots, &amp; 1 PCI slot. Here is my setup: Slot 1 &amp; 2 ---GPU card Slot 3---Empty 16x slot being saved for PCIe -&gt; m2 SSD (since I have sata 2) Slot 4--Legacy PCI card with Soundcard I have my mATX board in a FULL tower case, so I have extra expansion slot spaces on the case, but no PCI slots. The only thing I can think is getting a riser card, but I don t know if it can fit underneath the graphics card (or if you can bend it around). Can you convert extra Sata 2 slots into USB 3.0 slots?"</post>
   <post id="b4ae0575-3075-4cb4-be99-f18dc184d6b3" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"No"</post>
   <post id="e60d3f75-cd25-4cae-937b-a28b0e0aece4" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"If you want the faster speed for external drive, you re only choice will be eSATA, provided you have unused SATA port on your mobo."</post>
   <post id="82cc6bba-5dde-494c-b27a-0f5f220bba35" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"Satummoo said: ↑ I have an Asus Rampage II matx with 3 PCIe slots, &amp; 1 PCI slot. Here is my setup: Slot 1 &amp; 2 ---GPU card Click to expand... So is that one GPU in a x16 slot and covering a x1 slot that could be otherwise usable? It d be a bit interesting to cable up but you could get one of those x1 riser cables to hook up to something you want."</post>
   <post id="be700a5a-31f4-4dc9-bfdc-b64f1ea62a80" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"You might be able to use a cable like this. It just depends on if there is enough space. If not, you might always be able to trim the shroud for the one GPU to make it fit. Flex Ribbon PCI Express PCI-e PCIe Riser Card Extender Extension Ribbon Cable"</post>
   <post id="d7774870-68f2-4647-9dce-8a17fdfe23ad" section="MotherBoards" discussion="How to add USB 3.0 to x58 without extra PCIe slot?">"I m kinda in the same boat, think I may give that Extension ribbon cable a try.."</post>
   <post id="5e340b27-b19a-4a76-a9f6-01a31665baeb" section="MotherBoards" discussion="Random lockups- motherboard related?">"Edit: Correction to the title: Random reboots. (I don t see an option to edit the thread title) My system has begun resetting itself apparently randomly. There are no error messages of BSOD of lockups, just hard resets. When it resets, the mouse and keyboard aren t responsive, so it looks like a USB port failure. It takes another hard reboot to wake those back up. This sounds like a mobo issue. Do you have any thoughts/troubleshooting suggestions? There s no clear pattern to what actions I m doing when this happens. I m also noticing some stuttering in terms of mouse movement, and when I check task manager, I m not maxing out system resources. Here s my system info: OS Name Microsoft Windows 10 Home Version 10.0.10586 Build 10586 Other OS Description Not Available OS Manufacturer Microsoft Corporation System Name BEN System Manufacturer ASUS System Model All Series System Type x64-based PC System SKU All Processor Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz, 4001 Mhz, 4 Core(s), 8 Logical Processor(s) BIOS Version/Date American Megatrends Inc. 2601, 8/17/2015 SMBIOS Version 2.8 Embedded Controller Version 255.255 BIOS Mode Legacy BaseBoard Manufacturer ASUSTeK COMPUTER INC. BaseBoard Model Not Available BaseBoard Name Base Board Platform Role Desktop Secure Boot State Unsupported PCR7 Configuration Binding Not Possible Windows Directory C:\WINDOWS System Directory C:\WINDOWS\system32 Boot Device \Device\HarddiskVolume3 Locale United States Hardware Abstraction Layer Version = "10.0.10586.0" User Name Ben\Ben D Time Zone Eastern Daylight Time Installed Physical Memory (RAM) 16.0 GB Total Physical Memory 15.9 GB Available Physical Memory 7.80 GB Total Virtual Memory 45.9 GB Available Virtual Memory 35.2 GB Page File Space 30.0 GB Page File C:\pagefile.sys Hyper-V - VM Monitor Mode Extensions Yes Hyper-V - Second Level Address Translation Extensions Yes Hyper-V - Virtualization Enabled in Firmware No Hyper-V - Data Execution Protection Yes"</post>
   <post id="bd396505-4198-41d2-a082-9cf97ba53966" section="MotherBoards" discussion="Random lockups- motherboard related?">"I d try updating to the latest BIOS AND restoring defaults to see if this still happens."</post>
   <post id="a492d5fa-dcd7-43ca-b6a6-1cf719ec127a" section="MotherBoards" discussion="Random lockups- motherboard related?">"Could be ram, but no bsod makes me think PSU. When does it reboot randomly or under stress? I d be interested to see what happens under a stress test. Try prime and a memtest wouldn t hurt."</post>
   <post id="caa7b6c8-cfea-4246-a5b0-e214f447d804" section="MotherBoards" discussion="Random lockups- motherboard related?">"My guess would be something up with the motherboard/power supply.. Maybe try to reseat memory.. If you have access to a different power supply give that a try.."</post>
   <post id="2820b0e9-c1bb-42c7-9dac-a2be72a161f3" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"Anyone get there Nvidia chipset board ruining on Windows 10? I have a XFX 680i Lt board that still crashes to black screen randomly. I have tried custom Nforce drivers, but can t get SMU and SMBUS dirver to install."</post>
   <post id="7adca1e4-b42b-4f59-bae8-226de782c3ec" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"There are no good working drivers for these boards. Nvidia got out of the chipset game long ago and never was very good at drivers."</post>
   <post id="baca3286-6b10-46b0-86fe-f76be4a03f35" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"Wow, you still got a working nvidia chipset board? Nice."</post>
   <post id="d2aaa272-e5db-45d4-afbf-f474d70d4faa" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"I have at least 1 here at work still being used as a linux fileserver (although these days it is a very limited role): Code:"</post>
   <post id="datastore0 samba # uname -a" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Linux datastore0 4.5.1-gentoo-20160412-datastore0 #1 SMP PREEMPT Tue Apr 12 19:38:54 EDT 2016 x86_64 AMD Athlon(tm) 64 Processor 3200+ AuthenticAMD GNU/Linux" section="##2##" discussion="##3##">"##4##"</post>
   <post id="datastore0 samba # lspci" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:00.0 RAM memory: NVIDIA Corporation MCP55 Memory Controller (rev a1)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:01.0 ISA bridge: NVIDIA Corporation MCP55 LPC Bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:01.1 SMBus: NVIDIA Corporation MCP55 SMBus Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:01.2 RAM memory: NVIDIA Corporation MCP55 Memory Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:02.0 USB controller: NVIDIA Corporation MCP55 USB Controller (rev a1)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:02.1 USB controller: NVIDIA Corporation MCP55 USB Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:04.0 IDE interface: NVIDIA Corporation MCP55 IDE (rev a1)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:05.0 IDE interface: NVIDIA Corporation MCP55 SATA Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:05.1 IDE interface: NVIDIA Corporation MCP55 SATA Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:05.2 IDE interface: NVIDIA Corporation MCP55 SATA Controller (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:06.0 PCI bridge: NVIDIA Corporation MCP55 PCI bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:06.1 Audio device: NVIDIA Corporation MCP55 High Definition Audio (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:08.0 Bridge: NVIDIA Corporation MCP55 Ethernet (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:09.0 Bridge: NVIDIA Corporation MCP55 Ethernet (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0a.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0b.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0c.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0d.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0e.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:0f.0 PCI bridge: NVIDIA Corporation MCP55 PCI Express bridge (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:18.0 Host bridge: Advanced Micro Devices, Inc. [AMD] K8 [Athlon64/Opteron] HyperTransport Technology Configuration" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:18.1 Host bridge: Advanced Micro Devices, Inc. [AMD] K8 [Athlon64/Opteron] Address Map" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:18.2 Host bridge: Advanced Micro Devices, Inc. [AMD] K8 [Athlon64/Opteron] DRAM Controller" section="##2##" discussion="##3##">"##4##"</post>
   <post id="00:18.3 Host bridge: Advanced Micro Devices, Inc. [AMD] K8 [Athlon64/Opteron] Miscellaneous Control" section="##2##" discussion="##3##">"##4##"</post>
   <post id="01:0b.0 FireWire (IEEE 1394): Texas Instruments TSB43AB22A IEEE-1394a-2000 Controller (PHY/Link) [iOHCI-Lynx]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="06:00.0 SATA controller: JMicron Technology Corp. JMB363 SATA/IDE Controller (rev 02)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="06:00.1 IDE interface: JMicron Technology Corp. JMB363 SATA/IDE Controller (rev 02)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="07:00.0 VGA compatible controller: NVIDIA Corporation GT218 [GeForce 8400 GS Rev. 3] (rev a2)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="07:00.1 Audio device: NVIDIA Corporation High Definition Audio Controller (rev a1)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="4ae9040d-008e-4391-bdfd-176e91bfc2ca" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"IIRC Nvidia got sued for infringing on chip patents ... that s why they got out of the mobo chipset game. I remember having a bunch of NForce boards back in the day and they worked great - never had a problem."</post>
   <post id="4382dcff-a739-4da9-8d9b-006c357474c8" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"dvsman said: ↑ IIRC Nvidia got sued for infringing on chip patents ... that s why they got out of the mobo chipset game. I remember having a bunch of NForce boards back in the day and they worked great - never had a problem. Click to expand... Back then, all chipsets were just about as crappy as the Nvidia ones. I think maybe you are remembering with rose colored glasses."</post>
   <post id="d0681868-80d9-4063-abb0-81b6a1d6ccfa" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"Nope not at all. I don t crazy OC anything (just a couple hundred mhz here or there - nothing crazy) so they worked great out of box for what I needed. I just downloaded the latest nvidia drivers from their website and everything was up and running. It didn t even matter if I had an AMD card at the time either."</post>
   <post id="2ee7bede-9651-475e-9aba-836ef63e376d" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"I am glad you had a positive experience but they were bad boards regularly."</post>
   <post id="a2363248-a6c3-44ee-a214-6b476c214f2c" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"I ve had two nForce boards, neither of which lasted until Windows 10 was released. One of them was really good... the nForce2 Ultra 400, in a Shuttle AN35N Ultra. I ran the Athlon XP 3200+ in it for roughly 10 years. Eventually the fans on the CPU and the GPU started dying, and I couldn t find a decent fan to replace them with... everything that fit the CPU had the lubricant all dried out or else wasn t fast enough to cool the darn thing, so it got to the point that I had to run it with the side off and a box fan pointed at it to keep it from crashing in games. Near the end, I got a few more years out of it by going from 512MB to 2GB, and upgrading to Windows 7 from XP. I actually did try to get Windows 8 32-bit on there for fun, but it wasn t compatible because the Athlon XP didn t have the appropriate SSE3 instruction set or something. Wasn t the chipset s fault, though. The other one sucked, badly. nForce 650i SLI, in an ASUS P5N-E SLI board. It had a Q6600, but I ditched the machine after just 4 years and retired it before my Athlon XP rig. It came with a Velocity Micro computer, and I was stuck with Vista because it had 4GB of RAM and hardware that was just new enough not to have XP drivers. It was basically unusable for the first year of its life until Vista got a few service packs, and I still found myself using the XP machine more often. I didn t really start enjoying the machine until Windows 7 came out, so I only got 2 years out of it. I tried overclocking it by just 100MHz, and instability occurred right away, so I gave up (but I think it fried something on the board). When it came time to upgrade the aging 8800 to a 560Ti, the PSU proved inadequate despite appropriate labeling. So I swapped out the PSU for an Antec unit and it was better, but still lost power during some intense portions of the games. The board just didn t seem cut out to handle any excess power delivery beyond what the manufacturer had put on it initially. Replacement boards with decent chipsets were through the roof expensive. I finally got frustrated and bought the cheapest 2600k and Maximus IV motherboard I could get on eBay, broke the drive cage installing it into the case, and sold off all the old parts that I could salvage."</post>
   <post id="bdbfd105-52fd-4769-855d-c5bca3372d66" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"I only have one nforce system still in operation, and it is running Windows 10. I don t honestly remember the exact chipset number but it is an nforce. It s a system with an Athlon II x4 chip, currently being used as my HTPC. The system was given to me because it wouldn t boot. After doing some diagnostics, I found that the internal SATA controller had shit itself. I disabled the onboard SATA in the bios, put a PCI-E SATA controller in there and was able to get the system working again. Then I ran into another issue where the system would freeze at what appeared to be random intervals. Eventually I found that one of the smaller heatsinks on the motherboard was getting burning hot, and that is when the system would freeze. I installed a custom fan and the system has been working great ever since. It is really lame that I had to deal with and fix/bypass onboard components dying and others overheating in order to make the system actually work. If they had not given the broken system to me, I have no doubt that it would be sitting in some landfill right now - that s probably where it should be."</post>
   <post id="290729a2-8f71-4849-b0a7-4dbd9656cbd6" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"cyclone3d said: ↑ Back then, all chipsets were just about as crappy as the Nvidia ones. I think maybe you are remembering with rose colored glasses. Click to expand... Depends on which era you are referring to. NForce 1 for AMD socket A sucked. At best it was on par with Via chipsets of the time. NForce 2 for AMD socket A was amazing. Best chipset designed for Socket A. NForce 3/4 for AMD Athlon 64 was decent, but not as good as NForce 2. NForce 4 for Intel was ok, but nothing special. After NForce 3 was about the same time AMD bought ATI and started making their own enthusiast chipsets based on the ATI tech. The ATI/AMD 480 and 580 were decent enough to catch on. AMD had their own chipsets previously, but they were terrible for enthusiasts but did well for servers/workstations. As a result, Nvidia started making Intel chipsets starting with NForce 4. That s when things started to go south for Nvidia. NForce 5 was mediocre feature wise and Nforce 680i was when things started to fall apart with SATA issues. After that, Intel and AMD both surpassed anything Nvidia could build in features and quality."</post>
   <post id="244cf292-7522-470d-90a2-b1d106c256e5" section="MotherBoards" discussion="Anyone have a Nvidia chipset board running stable on Windows 10">"Actually some issues with nvidia board. It don t support fully for windows 10. New up-gradation is done so far. now need to check once again..."</post>
   <post id="f1dbf2e5-8390-44aa-ba80-0df7db814254" section="MotherBoards" discussion="Small build for optical drives">"I m gonna build a small pc with a bunch of optical drives. Going to burn some masters, need to scan then, etc. Main work will be done on my current Z87 machine, so no need to power, just something that can run win7/8/10 and maybe the next one(s) in the future without hassle. I found a cheap case with 6x 5.25 external slots so I m good. (Cougar Evolution) Mobo/CPU-wise is where it is getting harder though. I need something cheap which can accomodate 2-3 PCI cards for IDE, as well as 2-3 PCIe cards (for IDE interfaes etc.). At least 2 of each, 3 would be great I guess. Will run on onboards graphics, and need DVI. Locally, this seems to be the current choice (ordered by price ascending and limited to what I m willing to pay): ASUS H110-PLUS, Intel H110 (90MB0PQ0) Intel Socket 1151 • Dual Channel DDR4 (2133MHz) • DVI-D/VGA (D-Sub) • 2x PCIe x1, 3x PCI • 4x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 2x USB 2.0, 2x USB 3.0 • ATX MSI H81-P33, Intel H81 (7820-010R) Intel socket 1150 • Dual Channel DDR3 (1600MHz) • DVI-I • 2x PCIe x1, 3x PCI • 2x SATA 3Gb/s, 2x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 4x USB 2.0, 2x USB 3.0 • ATX ASUS B150-PLUS, Intel B150 (90MB0PD0) Intel Socket 1151 • Dual Channel DDR4 (2133MHz) • DVI-D/VGA (D-Sub) • 2x PCIe 3.0 x16 (Quad CrossFireX), 2x PCIe x1, 3x PCI • 6x SATA 6Gb/s, 1x M.2 (M key) • 1x 10/100/1000Mbps LAN • 4x USB 2.0, 2x USB 3.0, 1x USB 3.1 (type C) • ATX ASROCK B85 Pro4, Intel B85 Intel socket 1150 • Dual Channel DDR3 (1600MHz) • VGA (D-Sub)/DVI-D/HDMI • 2x PCIe 3.0 x16/PCIe 2.0 x16 (Quad CrossFireX), 2x PCIe x1, 2x PCI • 2x SATA 3Gb/s, 4x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 4x USB 2.0, 2x USB 3.0 • ATX MSI B85-G41 PC Mate, Intel B85 (7850-003R) Intel socket 1150 • Dual Channel DDR3 (1600MHz) • HDMI/DVI-D/VGA (D-Sub) • 2x PCIe 3.0 x16/PCIe 2.0 x16 (CrossFire), 2x PCIe x1, 2x PCI • 2x SATA 3Gb/s, 4x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 4x USB 2.0, 2x USB 3.0 • ATX MSI B85-G43, Intel B85 (7816-003R) Intel socket 1150 • Dual Channel DDR3 (1600MHz) • HDMI/DVI-D/VGA (D-Sub) • 2x PCIe 3.0 x16/PCIe 2.0 x16 (CrossFire), 2x PCIe x1, 3x PCI • 2x SATA 3Gb/s, 4x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 6x USB 2.0, 2x USB 3.0 • ATX ASUS H81-GAMER, Intel H81 (90MB0K20) Intel socket 1150 • Dual Channel DDR3 (1600MHz) • DVI/VGA (D-Sub) • 3x PCIe x1, 3x PCI • 2x SATA 3Gb/s, 2x SATA 6Gb/s • 1x 10/100/1000Mbps LAN • 4x USB 2.0, 2x USB 3.0 • ATX I ve stayed out of the game since Haswell in 2013... So no clue on the differences between all those chipsets. Also preferable would be a chipset for which CPU is cheaper. (RAM as well actually, prolly will go for 2x4GB value ram or so) EDIT: price wise it would seem the best deal is for a Haswell Pentium G3260. Suitable with those B85/H81 mobos and what I want to do? 1151 equivalent would be the G4400. Or is that totally stupid and I should look at least at an i3? So what do you think? Any suggestions, advice, opinion?"</post>
   <post id="216c4e68-ac59-4f85-908e-8e39ab286472" section="MotherBoards" discussion="Small build for optical drives">"I m just curious as to why you need IDE at all. Current DVD burners on a SATA interface have come down in price tremendously. It is also hard to find a blue-ray burner that isn t SATA. I like the ASUS B150-PLUS, Intel B150 (90MB0PD0) option. Have an M.2 SSD for your OS, and then have 6 SATA DVD burners (blue-ray burners?) plugged directly into the motherboard. Are you strictly burning, or are you doing any encoding? If you re just burning, the G4400 will be just fine. If you re encoding.... look at a much more serious CPU."</post>
   <post id="8af679bf-d0a5-4587-98b0-f2b3070eb3e8" section="MotherBoards" discussion="Small build for optical drives">"IDE is for some older CD drives like Plextor premiums, and for the BenQ DW1640 DVD scanner. It will be structly burning/scanning, all audio and video production will be done on my current i7-4770 machine, so no worries there"</post>
   <post id="d15ca19c-d9d8-4394-a5fb-1767c16191ab" section="MotherBoards" discussion="Small build for optical drives">"You could save some money and just get a couple of external burners. You can have 20 or so of them on a USB 3.0 bus no problem."</post>
   <post id="fc5d3b2b-cab8-42f9-8422-452b9abad7bb" section="MotherBoards" discussion="Small build for optical drives">"I ll submit a pointer of my own. When burning optical media, I have found that I get much more reliable burns when I burn the media at 1/2 the speed the drive is rated at. Basically, the slower the burn speed you use, the better the burn will be. I ve never had to go below 1/2 speed though so that is what I use to make sure the burned media can be read by pretty much all drives."</post>
   <post id="da924b79-5a33-48e2-90e6-cd8f2fe3e1e5" section="MotherBoards" discussion="Small build for optical drives">"These experts all agree that deep disc quality scanning is completely worthless. So stop putting your faith in ancient mumbo jumbo disc scanner software. Checking the quality of a burned DVD: the best software? Just get used to testing out every disc you burn, or just giving up on verification beyond the TRT scan suggested (no special hardware required). Buy yourself a couple of USB DVD burners, and call it a day And I ll agree with cyclone3d: if a high quality result is important, cut the write speed down. It gives the laser more time to imprint on each pit. Also, you can t expect to verify a DVD disc with a single drive. So quit pretending your current test set is bulletproof or some shit. Just throw those old IDE drives in the bin where they belong"</post>
   <post id="3a875aac-49bc-472f-b57f-628cd8d1770f" section="MotherBoards" discussion="Small build for optical drives">"well I already got all the cd and dvd drives anyway so... and I need a project so don t be a downer please I also agree on the 1/2 speed comment, I did the same observation. And an IDE interface for a plextor premium is a must anyway. That thing could rip some old scratched cds no other drive could. At the moment it s in a box running in a P4, but since a RAM slot failed it has issues with running win 7 so I need the new machine. Might as well make the most of it."</post>
   <post id="3a274d83-b882-4c9f-9b45-c553862eec10" section="MotherBoards" discussion="Small build for optical drives">"Then just buy a Celeron system. I ll recommend Haswell since you seem to have more PCI choices there, and the Skylake celerons are still mostly MIA. Intel Celeron G1820 Haswell Dual-Core 2.7 GHz LGA 1150 53W BX80646G1820 Desktop Processor Intel HD Graphics - Newegg.com Anything going through an IDE bus, you won t be processor-limited on. This one will work with any of the H81/B85 boards you listed above And just grab 8GB ram, because it s cheap."</post>
   <post id="4275ac3a-66c7-444a-bc78-681e9b52256b" section="MotherBoards" discussion="Small build for optical drives">"Lebowsky said: ↑ well I already got all the cd and dvd drives anyway so... and I need a project so don t be a downer please I also agree on the 1/2 speed comment, I did the same observation. And an IDE interface for a plextor premium is a must anyway. That thing could rip some old scratched cds no other drive could. At the moment it s in a box running in a P4, but since a RAM slot failed it has issues with running win 7 so I need the new machine. Might as well make the most of it. Click to expand... It sounds like you re going to do whatever anyway. Why are you even asking for advice, if you re going to disregard it by saying "don t be a downer" to begin with ?"</post>
   <post id="13d33a4a-7bd6-4113-bea4-58e2535547f1" section="MotherBoards" discussion="Small build for optical drives">"MongGrel said: ↑ It sounds like you re going to do whatever anyway. Why are you even asking for advice, if you re going to disregard it by saying "don t be a downer" to begin with ? Click to expand... huh? I m listening to the advice. yes I m going to get a box. I already have the drives, they re in a 15yo P4 box, in which 2 ram slots are dead and can t run anymore. I just want a new box to put them in. I m not going to spend loads of money on new USB drives, when I already got what I need. Why the agressivity? I should that I always had funny things happening with those USB optical enclosures... Finding the right one can prove difficult. And on my current system, the SATA controller is set to RAID for my hard drives which messes up my optical ones badly. alright then I ll consider the Celeron option as well. What could be interesting in any case is that the box could be easily be upgraded to a more powerful workstation in the future."</post>
   <post id="b9c0557f-ca54-42cb-9fb4-8624ee7e3eb9" section="MotherBoards" discussion="Small build for optical drives">"MongGrel said: ↑ It sounds like you re going to do whatever anyway. Why are you even asking for advice, if you re going to disregard it by saying "don t be a downer" to begin with ? Click to expand... You should re-read the second sentence he typed. He said "And an IDE interface for a plextor premium is a must anyway. That thing could rip some old scratched cds no other drive could." I can completely understand that sentiment. I ve kept around a few CD/DVD drives because they could read something when nothing else could. And sometimes that one thing you want to read is an old music album you can t find anywhere anymore or it s got old photos and files. From personal experience, my drive of choice for this happens to be an old 52x CDRW Plextor drive also. Those old plextors were god like in this regard and they used to be the go to optical drive over a decade ago.Something about the build quality and firmware programming, I m not sure which. I m not sure I remember what happened to change this, maybe they got bought out. =============== To the OP. Which of the drives can you ditch? I understand the need to keep at least 1 Plextor. As far as the others... not so much. Can you can explain? You could set this up keeping 1 Plextor Drive and the BenQ DVD scanner, then replace the rest with generic SATA DVDRW drives. Do you honestly need more than 1 Plextor IDE drive to run simultaneously? If not, I would keep the extras in a box as spare parts. The main reason to ditch the rest is because SATA optical drives are actually cheaper than the PCI/PCIe IDE adapter cards you need to run them. I can pick up DVDRW SATA drives in bulk OEM (no box, cable, or documentation) at my local Microcenter for $10-15 each."</post>
   <post id="ec16dbf9-ef65-4b1a-9f0e-a9c66308c848" section="MotherBoards" discussion="Small build for optical drives">"CaptNumbNutz said: ↑ Which of the drives can you ditch? I understand the need to keep at least 1 Plextor. As far as the others... not so much. Can you can explain? You could set this up keeping 1 Plextor Drive and the BenQ DVD scanner, then replace the rest with generic SATA DVDRW drives. Do you honestly need more than 1 Plextor IDE drive to run simultaneously? If not, I would keep the extras in a box as spare parts. The main reason to ditch the rest is because SATA optical drives are actually cheaper than the PCI/PCIe IDE adapter cards you need to run them. I can pick up DVDRW SATA drives in bulk OEM (no box, cable, or documentation) at my local Microcenter for $10-15 each. Click to expand... Thanks. I guess I could stay just keep the Plextor and BenQ as IDE, and I already got the Silicon Image card flashed to IDE for them anyway. I like the idea of the Asus B150-PLUS suggested by iamwhoiamtoday in that regard, as I could spare a SATA port with an m.2 SSD. That gives my 8 drives, and then if ever needed, I could add either a SATA PCIe card or a second IDE... doubt it ll be the case though. Thanks a lot everyone for the suggestions and thinking out loud.. I know in which directions to go now."</post>
   <post id="b3bd9584-a442-4e82-8a7d-821388240264" section="MotherBoards" discussion="Small build for optical drives">"Lebowsky said: ↑ Thanks. I guess I could stay just keep the Plextor and BenQ as IDE, and I already got the Silicon Image card flashed to IDE for them anyway. I like the idea of the Asus B150-PLUS suggested by iamwhoiamtoday in that regard, as I could spare a SATA port with an m.2 SSD. That gives my 8 drives, and then if ever needed, I could add either a SATA PCIe card or a second IDE... doubt it ll be the case though. Thanks a lot everyone for the suggestions and thinking out loud.. I know in which directions to go now. Click to expand... Keep in mind that some motherboards will use a SATA port if you put a SATA interfaced m.2 drive in there."</post>
   <post id="6d3278f1-a6e5-4dd8-89f3-e6195d2363fb" section="MotherBoards" discussion="Small build for optical drives">"yep saw that when I read the manual... 2 ports even. I also remembered another reason for wanting another board was to set the SATA controller to IDE as I m having issues with optical drives in AHCI mode on my current machine. And it seems all newest chipsets don t support IDE mode anymore. So an Haswell mobo it will be. And that leaves the SSD out as well... but which will also be cheaper"</post>
<post id="fe7c2d39-62ad-4ac8-9e15-aa16c461a4c2" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Some niiiice (drool) setups in this thread, may as well add mine... Images are clickable. Dual AMD XP 2500+ @ 2200Mhz 512 DDR GIGABYTE GA-7DPXDW-P WD 80GB HDD GF2 MX 2 x Maze 4 Hydor L30 DTek Pro Rad I also have: Dual AMD XP 1700+ @ 2000Mhz 512 DDR Tyan 2460 Maxtor 40 GB HDD ATI AIW 2 x Thermalright SLK700 s 2 x TT SmartFan 2 (Pics when I get the digi cam back from the g/f)"</post>
   <post id="7e62396f-a94b-4695-a0c3-90ad8f890f7c" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Well here goes my rig Its not 100% cleaned up, but it was nice enough for a pic I think. Asus PC-DL 1002 BIOS 2x 2.8 XEONs @ 3.09 so far 2x WD360GD in Raid0 on Fasttrack 378 1x 80GB Maxtor 2x512 Corsair 2700LL Radeon 9800 Pro 474core and 360 mem 21" Sony Trinitron Complete Aqua Computer Cooling Toshiba DVD Burner Windows Server 2003"</post>
   <post id="80eae913-88d3-404e-8e40-e18fac10a9c5" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Just finished my system up and will be writing an article about it including temps and such over at LinuxHardware.org . So what do you think? Anything you d change? Still have to get my side panel on with the window and dual cold cathodes. SPECS: Dual Opteron 248 2GB Corsair PC3200 Register Low-Latency DDR Tyan Thunder K8W Motherboard Quadro FX 3000 Adaptec 39320D SCSI Controller Seagate Cheetah 15K.3 73GB Hard Disk Sound Blaster Audigy Sound Lite-On DVD+RW PC Power and Cooling Turbo-Cool 510 Deluxe EPS12V All running Gentoo Linux"</post>
   <post id="86bea642-4e94-4c39-b698-b6b74751fcc8" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"aah that is one hell of a setup. I love it!"</post>
   <post id="f7970063-9dea-4581-a2eb-6e95169e24ef" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Yea, that really is one hell of a setup I didnt realize that they had already made Opteron waterblocks. Its a shame how you can t overclock those suckers. nuclearsnake, is 2000mhz the highest stable speed for your 1700+ s? I cannot reach anything higher with mine, not even 2070mhz"</post>
   <post id="718e4809-f097-4d7a-906c-23e95818d9ad" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by pduan87 nuclearsnake, is 2000mhz the highest stable speed for your 1700+ s? I cannot reach anything higher with mine, not even 2070mhz Click to expand... What stepping are your 1700s ?"</post>
   <post id="d73c7ab8-9b41-4977-adff-4875b6734adc" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"New Pics of the Dually (probably the last before it s sold to fund a dual Xeon). Specs in Sig. Any my 1700+ s enjoy 2100mhz@150mhz FSB"</post>
   <post id="8f06e99c-cc44-483f-b398-0f06d5cf472e" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by Anarchy What stepping are your 1700s ? Click to expand... JIUHB. Tbred B s. eighteen, why would you sell that off? I would just wait until opterons get cheaper rather than getting a slight upgrade to xeons from that rig."</post>
   <post id="24efc953-ea2e-4b21-b2b5-71d2c948d757" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by pduan87 JIUHB. Tbred B s. eighteen, why would you sell that off? I would just wait until opterons get cheaper rather than getting a slight upgrade to xeons from that rig. Click to expand... I m selling mobo/cpu/hsf...not the rest. And I have a couple reasons: First, I m getting a killer deal on this intel board. Second, even though on paper, the 2.0 or 2.4 xeons I ll probably end up getting will be slower than my current setup, a single xeon beats my beast in a lot of graphics apps (thanks to heavy SSE2 optimizations). Third, the platform has more headroom and Fourth, its a far better resale value towards an opteron later."</post>
   <post id="3d3e6513-a7c6-4851-bedf-4409d5c89f9e" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by eighteen_psi I m selling mobo/cpu/hsf...not the rest. And I have a couple reasons: First, I m getting a killer deal on this intel board. Second, even though on paper, the 2.0 or 2.4 xeons I ll probably end up getting will be slower than my current setup, a single xeon beats my beast in a lot of graphics apps (thanks to heavy SSE2 optimizations). Third, the platform has more headroom and Fourth, its a far better resale value towards an opteron later. Click to expand... Ahhh i see, as long as your eventually return to AMD Btw, are those 1700s DLT3C?"</post>
   <post id="7bfff55a-301b-4f08-bd47-4422c8db8823" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by pduan87 Ahhh i see, as long as your eventually return to AMD Btw, are those 1700s DLT3C? Click to expand... That depends on what Intel has at the time....all else equal, I have had a better track record with my Intel boxes but they always cost a lot more. I have no brand loyalty that will permit me to sacrifice a better system but then again, its hard to beat a stock-speed Intel chipset/mobo/cpu combo for solid reliability. We ll see. And yes, quite right. They may have more in them but the board doesn t (and I don t want to remod them to a higher multipler). Good case-in-point: These chips cost me $47 each! Thats some serious horsepower for the buck. The deal on the intel board tempted me but damn those xeons are expensive."</post>
   <post id="933c18e7-551a-4bac-8958-f251d90206ff" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by pduan87 JIUHB. Tbred B s. Click to expand... My DLT3C chips (1.5V default) do bout 2050 on default voltage and 2300 with 1.75V ... dunno bout DUT3C (1.6V default) cuz i never had one ..."</post>
   <post id="79193f21-36f8-437e-912e-909c8147f13d" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Mine are the DUT3C s, and they are on air, so Im not going to push them to far."</post>
   <post id="26468ce5-250f-40b3-8b5d-da67952923c5" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"More Pics can be found at http://setup.kori.us"</post>
   <post id="e695c9b2-987d-414f-b410-c139291feea9" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"Originally posted by KORI man these damn things where the bigest pain in the ass to put on i thought i was going to crack a core or something but they are so pertty Click to expand... uh...you have an airplane in your case, i d get that checked out if i were you..."</post>
   <post id="c4d0a001-31bd-405b-95ae-3c17cd7d3fc6" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"uh...you have an airplane in your case, i d get that checked out if i were you... Click to expand... Ya.. it looks like your MOBO is ready for liftoff. Here is my Dually Xeon 3.0@3.4 stuffed into a Koolance case:"</post>
   <post id="895291f7-f7f3-4492-862c-e322209ae795" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"----------------- It is for sale BTW. HERE"</post>
   <post id="8b9ace9e-d70b-4ef6-a40b-50e45f867791" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"My new server (RobBSDserver v2) is the following specs: Tyan Thunder LE-T 2x Pentium III 1GHz 1GB Registered ECC SDRAM 18GB U160 HDD 4x 120GB IBM HDD the mobo too"</post>
   <post id="a83079e5-7dd9-4d93-b877-caff1826b1f5" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"sfsfsa"</post>
   <post id="3c4f2d17-13f3-4792-a61a-e7f5f6296e44" section="Multiprocessing Systems" discussion="Pictures Of Your Dually Rigs!">"@roberttran : I HATE YOU ... you can t imagine how much i hate YOU /me wants rack too ... and a dually PIII ... but i have no space for that ... _________________________ Click ME !!!1 Dually Xeon 2.4GHz, Tyan Thunder 860, 4*128MB PC800, 36GB Raptor for OS and 4*160GB in RAID5 on RAIDCore 4852 ... But i have a lil problem - i hit a wall @ 100-120MB/s seq. reads A 4 drive RAID0 should do bout 160MB/s ... looks like my 66MHz/64bit Slot is runnin 33MHz/32bit Help"</post>
   <post id="c70ccc68-01ba-46e0-8979-73215ee72f0b" section="Multiprocessing Systems" discussion="chune s house build">"Long time lurker, potential first time thread starter. Here is my build. I am running esxi 5.5 on a ga-7pesh3 with donk s unlocker which allows for mac guests to be run on PC hardware (with GPU passthrough!!). This is all backed by a ZFS-powered NFS datastore (omniOS VM + nappit + onboard SAS2008 IT mode pci-passthrough). This started as just a windows + mac gpu passthrough rig and has slowly sprawled throughout my entire house. I am currently running a dual monitor win 8.1 workstation VM, Mavericks OSX dev VM, SteamOS arcade VM, and a win10 HTPC VM (Plex HT) all with individual GPUs passed through. I just realized how much shit i chained off one mini-DP port and had to document it. Yes, the dual apple cinema displays all work great from 100 feet away running through all the adapters with no relics or signal degradation. The DVI KVM Matrix allows me to mix and match any input to any output on my cinema displays. It comes with a cat-5 remote (not pictured) that allows me to select a source per monitor. The SnapX allows me to change my secondary monitor over to a local macbook laptop if needed. _Gea should get a real kick out of this one =)"</post>
   <post id="f54553be-0acc-41e1-9834-9334498803c0" section="Multiprocessing Systems" discussion="chune s house build">"lol pretty cool, like a mac/pc zombie parasite."</post>
   <post id="f92f4b3e-606f-4915-8e99-94a9edccb28c" section="Multiprocessing Systems" discussion="chune s house build">"So, How does this work in terms of running multiple users simultaneously, without little niggling problems like end users accidentally closing their VM, or dragging their VM window to another monitor, recovering from crashes... or even something as basic as rebooting the whole system without having to re-set-up all the screens and hardware. I m not being snarky, this is a SERIOUS interest of mine to have the entire house essentially run off of one supercomputer and simply have everyone using monitors, keyboards, controllers, etc. connected via wireless/wall plugs. Everyone I ve asked said it was impossible, citing the issues above among others..."</post>
   <post id="7806df3b-d6d6-4067-964b-387d6fc4ba67" section="Multiprocessing Systems" discussion="chune s house build">"KazeoHin said: ↑ So, How does this work in terms of running multiple users simultaneously, without little niggling problems like end users accidentally closing their VM, or dragging their VM window to another monitor, recovering from crashes... or even something as basic as rebooting the whole system without having to re-set-up all the screens and hardware. I m not being snarky, this is a SERIOUS interest of mine to have the entire house essentially run off of one supercomputer and simply have everyone using monitors, keyboards, controllers, etc. connected via wireless/wall plugs. Everyone I ve asked said it was impossible, citing the issues above among others... Click to expand... So it sounds like you are talking about a ghetto setup that has everything running off one machine that uses eyefinity and some third party software to enable concurrent sessions and mouse/keyboard mapping. This setup uses an enterprise grade hypervisor and each VM is completely isolated from the other. Each VM has its own dedicated video card and memory. The way I overcome the USB issue is using a four port, four controller USB 3.0 card that allows me to pass through individual USB ports to each VM. The 65 foot active USB repeater cables then carry the USB port to wherever the endpoint resides. This setup is extremely stable and works great for gaming. A user cannot accidentally "close" their VM, but they can shut it down. This can be disabled by local security policy if it is an issue. There is also esxi cron scripts that check for non-running VMs every so often and turn them on. When performing a host reboot, you can have the VMs auto power on/off using guest shutdown in an orderly fashion. Everything persists across host reboots and all VMs will remember their monitor layout. The monitor(s) at each workstation plug directly into the GPU dedicated to that VM so it is physically impossible to "drag your VM to another monitor". The worst thing a user could do is accidentally enable the console monitor in which case they will notice really poor graphics performance but it won t lock them out or anything."</post>
   <post id="e9bef276-ca58-466a-846e-2f7ffd31ab86" section="Multiprocessing Systems" discussion="CUDA specific setup..">"I am beebopp n around this Monday at work looking into parallel processing problems with CUDA from NVIDA. It is moderately more appealing to me than, say, a multi processor cluster or setup just based on space/power requirements/cost vs uptick in performance. From what I gather all I need is a moderately okay CPU and one to many NVIDA cards tossed in a machine and the CUDA libraries deal with making the same/different cards all play well? That seems deceptively.. simple. If I whip up a Monte Carlo simulator or something along those lines I should be able to see a performance gain between running it on my regular CPU versus shoving it off onto my NVIDA card? Just a reality check for me looking into investigating applying a few random NVIDA cards in the closet to this build before investing something substantially more."</post>
   <post id="723bb0fe-91e8-4fef-a413-b0b44b5dd6c4" section="Multiprocessing Systems" discussion="CUDA specific setup..">"For a deep learning setup to train neural networks. A Full Hardware Guide to Deep Learning - Tim Dettmers What I m in the process of putting together, it is certainly the mostest for the leastest at this point in time. Building a 32-Thread Xeon Monster PC for Less Than the Price of a Haswell-E Core i7 Joseph"</post>
   <post id="0d877da9-4fe6-47ba-9f77-8374aabf9724" section="Multiprocessing Systems" discussion="CUDA specific setup..">"I built a system around dual e5 2670s 128GB ddr3 and a Titian X. I couldn t be happier."</post>
   <post id="24b9a148-bb51-45af-9cda-5ac28bf1fd90" section="Multiprocessing Systems" discussion="CUDA specific setup..">"When you get the hang of it, you might try out the Amazon GPU cloud servers. The smaller GPU instance is $0.65/hr and the larger one is $2.60/hr."</post>
   <post id="ee2307cd-781a-4854-9697-33964922111f" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"My current SR-2 set up is approaching 5 years and I m getting the refresh bug. I was thinking of getting this board, ASUS Z10PE-D16 WS, and was wondering if it only accepts ECC memory. I d prefer to use non ecc since its cheaper and I don t need that kind of memory stability since I m not using this as a server role. I ve searched around but it doesn t state anywhere that if it could use non ecc. Any help would be appreciated. Thanks."</post>
   <post id="3bbaf3a3-2037-44b3-ae10-019e7fe6b42e" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"SR-2 is still no slouch. I would go with a Supermicro X10DAX. Not a huge fan of Asus with all the RMA horror stories. The approved memory list is only ECC so would not use non-ecc. Buy ram as server pulls off ebay saves a bunch."</post>
   <post id="0df1e09a-c826-465a-87c8-fcc853a328c3" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Why not ask Asus?"</post>
   <post id="0071792d-2c29-47cd-9404-27a602e86757" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"op id wait till next year samdung might release a unlocked zen flagship 16 core or intel will finally unlock xeons to compete with samdung if samdung is competitive and gives them a run for their money,"</post>
   <post id="1059c471-bf54-4598-90ff-142bb569c2b1" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Deathroned said: ↑ op id wait till next year samdung might release a unlocked zen flagship 16 core or intel will finally unlock xeons to compete with samdung if samdung is competitive and gives them a run for their money, Click to expand... Intel Xeons are unlocked, single-socket that is. Dual-socket Xeons will never be unlocked due to stability problems at overclocking."</post>
   <post id="3a515cb8-0f97-44f7-8b56-da4095aa607c" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Ok, so I finally bit the bullet and bought this Asus board with 2 Intel Xeon E5-2699 V3 chips and now I m having an issue with booting and was wondering if anyone might have some insights on the problem. I have only 1 CPU socket occupied right now with 1 ecc ram stick in the recommended slot and it s giving a B0 error (Runtime Set Virtual Address MAP Begins), and 1 long beep 2 short beeps. I tried googling the B0 error but I can t find any solid leads. I tried some different ecc memory and it still does the same thing. Any ideas?"</post>
   <post id="6acdb334-652d-487a-a287-3a733de34e90" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"op try to find venturi on hardforum or google dual xeon quad sli titan x venturi and you will find him on other sites like overclock.net, evga etc but he is here on hardforum try pm him, here is one of his build logs on hardforum www.hardforum.com/showthread.php?t=1849002"</post>
   <post id="8ee4cce1-6dd3-49a1-9389-8f985f5faaff" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Venturi posts here profile is here http://hardforum.com/member.php?u=96193 Not sure about the Asus but the Supermicro boards need 2 sticks of ecc ram inserted into the appropriate slots for CPU1."</post>
   <post id="bb4a3c18-7116-4e0b-b1a9-70e7539eaae1" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Thanks guys. I ll contact him shortly. Hopefully I get this figured out soon."</post>
   <post id="c4f2dea0-0a8b-44f0-97e1-53c1df2aa0d9" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"One of my friends had this problem. eventually he figured out you need to have a keyboard and mouse plugged in for the mobo to boot. This can be disabled in the BIOS, but is required for first boot. I also had one of these mobos that was DOA. RMA d it and everything worked great."</post>
   <post id="e4200e89-babc-4ff1-b72e-44aba0528d12" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Concentric said: ↑ Why not ask Asus? Click to expand... Definitely contact ASUS. I found out that these WS mobo s get pretty good support. Had similar problems and their advice fixed it for me... my mobo is the Z10PE-D8 WS with 2 E5-2699v3: Dear SpeedyVV, Thank you for your trust in our ASUS support. My name is Alex and it is my pleasure to help you with the issue. Feel free to rate our service according to the solution provided in the questionnaire that will be sent to you shortly after our reply to your inquiry. I recommend a CMOS reset in this case. Please unplug the power cord and remove the CMOS battery for 3 minutes. Then place it back in. While the power cord is still unplugged, press the power button down for 10 seconds to power discharge the unit. Check if all the power and sata cables are properly connected and after this plug the power cord again and restart. Also try to power up the motherboard with minimum configuration: 1 single RAM (on A1, or B1, try swapping), one HDD, take out the CPU carefully and inspect the socket, look for bent/damaged pins, ensure that the CPU is re-inserted correctly, the VGA (if you have a dedicated graphics card, make sure it is correctly inserted in the PCI-E slot) and make sure that the PSU functions and its powerfull enough to start the system. If you have any further questions, please do not hesitate to contact us. Best Regards, Alex ASUS Technical Support, ASUS USA http://vip.asus.com/eservice/techserv.aspx Please keep the history of your e-mails sent to you by our Support Staff. Otherwise, we won t be able to analyse your case properly. ---------- Original Message ---------- To : "techsupport@asus.com" Subject : Server Z10PE-D8 WS [Product Information] Product Type : Server Product Model : Z10PE-D8 WS Product S/N : E8S1YZ001230 Place of Purchase : Amazon Date of Purchase : 2015/02/12 [CPU Specification] CPU Vendor : Intel CPU Type : Intel Xeon E5-2699 v3 CPU Speed : 2.3G [Memory Specification] Memory Vendor : CORSAIR Memory Model : CT4C16G4RFD4213 Memory Capacity : 64 GB [HDD Specification] HDD Vendor : WD HDD Model : Red HDD Capacity : 6TB [Add-on Card Specificatio] Add-on Card Vendor : EVGA Add-on Card Type : VGA Add-on Card Model : GTX 680 Operating System : Windows 7 64bit [Problem Description] When I turn on the system for the first time, the system hangs with Q-code 67. The screen does not turn on. This makes it impossible for me to check the BIOS version or any other info. I tried booting with just 1 CPU, swapped CPUs, with same result. Please advise. Thank you, SpeedyVV Click to expand..."</post>
   <post id="b63d4392-6e1c-4e7e-aeff-a1c2048b7cb5" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"Any progress on this system ? I m curious about the whole  dual cpu motherboard  debate .... I do like ASUS but I m new to the  workstation  class.... I m on the  wait  list for a pair of Xeon e5-2687 v4 s . For what I m gonna pay for those , I m not interested in a shitty mobo. I want the best one on the market."</post>
   <post id="629f4598-677f-4afa-a704-229d199399f9" section="Multiprocessing Systems" discussion="ASUS Z10PE-D16 WS">"All I can say is I ve been running this sucker pretty much 24/7 for over a year and no complains so far."</post>
   <post id="08cc92b6-7235-49d1-8347-0f31ca042309" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"Cost me 100 bucks. I wasn t expecting much but it s in excellent shape and is fully functional. Came with 2 Xeon dual core @ 2.66ghz, 4gb of ECC ram, 2 147gb SAS 10k drives and a P400 controller and 2 PSU s. Just loaded Win 2008 R2 and it went in without a hitch. For 100 bucks delivered, I m a happy camper. And now to go play some more. Gotta figure out what I m going to use it for. It s server loud so it ll have to be in an unpopulated area, lol."</post>
   <post id="dfd7b063-7184-4012-b6d6-28384cc8c638" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"haha yeah loud being an understatement I was actually afraid when I first cold-booted mine for sure. I do have a question though: are your PSU s hot even if the server isn t running? I had to unplug mine until I figure out if that s normal or not."</post>
   <post id="a05247e1-c608-46d7-95b2-7c188d3f7aed" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"Mine has been running all day updating Server 2k8 R2 so I don t know about when it s off but running it isn t anywhere near hot, in fact, it s cooler than my desktop. At the moment I have only one PSU running tho. I popped the top and it s squeaky clean on the inside, looks like new in fact. I just ordered 6 HD caddies for future expansion. It s got 12 small fans that scream like a tortured witch. It s gonna be anti social for sure. And yea, when it first comes on it sounds like a 747 revving for takeoff. Was thinking this is actually too loud to keep in the house but then it quieted down a good bit."</post>
   <post id="f5b8b54e-44d4-42be-b547-70518d375cc7" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"I ve got 2 of those machines laying around, one with 2 Quad cores E5450 @ 3.00Ghz and 32GB RAM, and one with 2x Quad Cores E5420 @ 2,5Ghz with 20GB RAM. Pretty fun stuff until you notice the electric bill.."</post>
   <post id="277d3188-be48-494c-ba72-ce413c53bdaa" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"Yea, I think it pulls about 400 watts. No gonna be running it 24/7 but it is fun to play with. HP s management tools are awesome."</post>
   <post id="481977c7-eced-4da3-ad26-1c1799032940" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"The Gen6 s (and later) come with the quiet mode fans where they don t sound like a rocket 24/7 on a daily basis. Plus the Gen6 s also come with Hyperthreaded CPU s for better VM performance."</post>
   <post id="97e9dc04-e66e-480b-90a5-e1a2da104fbe" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"The Cobra said: ↑ The Gen6 s (and later) come with the quiet mode fans where they don t sound like a rocket 24/7 on a daily basis. Plus the Gen6 s also come with Hyperthreaded CPU s for better VM performance. Click to expand... My now-rattletrap long-in-the-tooth ML370 G6 is actually quite quiet most of the time. However, when you install a discrete video card and then load the CPUs up to full, I found the fans cycle hard...going from a low speed and then to 100% and back again...over and over as if the fan tuning for that scenario hadn t been tuned properly or the system was over-reacting to the video card s presence."</post>
   <post id="6988eb77-f794-4f0b-b3d6-3fd7996d9ebe" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"The racks at my job that have the G6 s and G7 s are pretty quiet in comparisons to the other racks with Super Micro s and Dell s from those days. Also been the most stable servers that we ever brought. 3-4 years up time never shut down, never had a hardware problem. If the Gen 5 are just like the Gen 1 (Dual P3 s) they are loud like you are in a airplane during take off.."</post>
   <post id="ef3aed29-a8df-4c78-a18e-1c7185e5cc85" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"LOL, just picked up another server to play with. A Supermicro CSE 815TQ with a X7DWU, 2 3.0ghz Xeons 16gb of ECC Ram, 4 Seagate Cheetah 15k 300gb Drives (all 4 in perfect condition according to HD Sentinel). Just loaded Win Server 2008 R2. It s fully functional. Total cost, delivered was $105. $80 for the server and $25 for shipping. The HD s alone are worth more than that. Now the HP G5 is collecting dust."</post>
   <post id="1401130d-08c4-459d-808e-665a168e3e8f" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">""</post>
   <post id="7532d9d0-3281-4b13-a7f4-170f0b322227" section="Multiprocessing Systems" discussion="Just picked up a Proliant DL380 G5">"I did a round of server upgrades for a hardware chain few years ago and I pulled out a ton of those old units that just screamed and put in new hp g6s. so much quieter! during signout in the AM several of their onsite "techs" had to ask if everything was running. they had never heard the rooms so quiet. on a side note, I have at least a dozen hp G6 rail kits still kicking around. anyone know what to do with them?"</post>
   <post id="fef399f9-4fa8-4398-b777-612ebeb64b6c" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Recently I happened across 26 sticks of 4GB ddr3, 12 i5 2400 CPUs and a single i7 2600 from decommissioned computers (all motherboards or power supplies were bad in them). Basically all I d need is a lot of LGA 1155 motherboards and power supplies to get them up and running. I would likely sell or donate most of the computers after I m done learning Beowulf and keep a few as servers or something useful. so to me it seems like it will be worth my time to learn My goals for the build itself? -Find decent motherboards that I wouldn t mind keeping for myself. I don t want bottom of the barrel boards, but at the same time I don t want to spend a ton on them. -Find a sub $50 case for each of them (or no case if I can figure out a way to mount the boards safely together). -Good power supplies that don t break the bank. Goals for the uses? -discover how to build a Beowulf cluster, DUH! -folding nodes? -Likely boot off the network from a "master server" I may set aside one of the i5s for this. I also have a couple of older ITX computers one with a AMD integrated APU and the other with a atom. -VM cluster? -suggestions that don t involve anything illegal?? When it s broken down I ll be keeping 1-3 of them for some uses... NAS, file server, VM server, epic router? And more uses that I can t think of at the moment. First things first however... I gotta make sure that the CPUs &amp; RAM work before I really get to business I m open to any suggestions..."</post>
   <post id="addd919a-80de-4c68-bd56-729f9872fc75" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Render farm!"</post>
   <post id="110c336d-68c1-4583-a901-7fa0b88ce747" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"http://www.linux.org/threads/building-a-linux-cluster.7858/ Might want to look at mATX and higher density solutions for ideas for casing."</post>
   <post id="bf7971ad-6af5-470b-ad97-44ba58afdfd7" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Shameless Liar said: ↑ Render farm! Click to expand... Winning! Chas said: ↑ http://www.linux.org/threads/building-a-linux-cluster.7858/ Might want to look at mATX and higher density solutions for ideas for casing. Click to expand... Thanks for the link... This will surely be a nice learning experience for me Yep, looking to get mATX or even a ton of ITX boards..."</post>
   <post id="6e962346-d225-4960-a537-96446e7bbfd5" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Folding ! And kick cancers butt [H]ard"</post>
   <post id="949e2357-a0c2-403f-8f6a-f334489aa387" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"If you plan to sell those i5 2400 CPUs let me know. I got a F@H farm I need to add to and 2400 CPUs match perfectly with two GTX 970s."</post>
   <post id="147e998d-2fd5-4e28-9fcb-c3efc78f6e80" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Just ordered a couple ASUS P8Z77-V Pro off eBay. Church needs a couple new PCs to replace some older C2D PCs. Since they are already in full ATX cases I figured this can t hurt. One of my favorite 1155 boards too That s 2 CPUs and 4 ram sticks clamed Going to see what else I can find for motherboards. Looking for ITX or mATX boards. ChristianVirtual said: ↑ Folding ! And kick cancers butt [H]ard Click to expand... I like this idea Skillz said: ↑ If you plan to sell those i5 2400 CPUs let me know. I got a F@H farm I need to add to and 2400 CPUs match perfectly with two GTX 970s. Click to expand... Will do! Gotta make sure all the CPUs work though since I have no idea what kind of abuse these things had in their former homes"</post>
   <post id="625ec4b6-b901-4ebf-ac79-d479118ca11c" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Any update on this?"</post>
   <post id="34502e5d-12c8-4f80-95b7-b651a01b37d0" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Skillz said: ↑ Any update on this? Click to expand... Yep! Two i5 2400 s and 8 sticks of ram now claimed (2x4GB &amp; 2x2GB for each PC) by the new builds at church. Just got them buttoned up today. More updates on the Beowulf: I tested all the ram with mem test. It s all good with no errors. Also tested all the CPU s. again all good! Right now I m looking for suggestions on decent power supplies that won t break the bank. I currently have a spare Corsair CX430 that I ve been using to test the motherboards and ram with. I m watching the local microcenter ads to see if any power supplies go on mad markdown. Hopefully black Friday nets a few really good deals either locally or online. Also looking for some decent motherboard lots on ebay. I had one I was about to pull the trigger on but it sold just beforehand. As for what s left? The main group on the right are all i5 2400s. The two on the left are 1x i7 2600 and a i3 2120 The ram count is 20x4GB sticks (enough for 10 PC s):"</post>
   <post id="9ecb4425-4b4a-403a-ab51-522a29df53b1" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"To anyone still following the thread... It has begun! Firstly I have decommissioned my HTPC and will be using that as etheir a file server, media server or VM test box. It had a i3 in it. I put the i7 in it. before and after: Behold! I can hear you asking... "So... what of the cluster build? why are you showing me your cute little cube server?" Answer: I found some good motherboards, HDDs, heatsinks and power supplies at a local microcenter... I d like to do something to involve the members following along: I need three cases... must all be mATX or better checking the local microcenter I found only one case that comes close to what I m looking for and that s the spec01 by corsair. I have some amazon gift cards that I wouldn t mind tossing at the project So let me know some good ideas on cases that aren t total crap!"</post>
   <post id="071e5e16-6483-40a1-9086-82d1c9b21bfb" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Why not zip tie the little buggers to a crate? http://justbrewit.net/trstuff/crate2/mbmount.jpg https://techreport.com/forums/viewtopic.php?f=16&amp;p=1257239"</post>
   <post id="206057fe-61d5-47c9-8ce5-4a8cefd8c060" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"modi123 said: ↑ Why not zip tie the little buggers to a crate? http://justbrewit.net/trstuff/crate2/mbmount.jpg https://techreport.com/forums/viewtopic.php?f=16&amp;p=1257239 Click to expand... HAHAHA!!! More then likely they ll end up going to folks that need a basic computers so they ll need cases eventually anyway. I m looking at the Thermaltake Core V21 now ($39 after MIR at newegg, wondering if I can have amazon match that price)..."</post>
   <post id="caf384cf-f5d8-4510-80b6-2ee0bf543a22" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Unfortunately the EVO 212 doesn t fit in the core 1100 case. The good news is that I had a nice HSF from a old HTPC that I dismantled, That works great in the rig! Another thing I d like to point out is that the hard drive was touching the fan so I had to snip a corner off the fan to avoid excess case resonances from the hard drive: One of the motherboards that I bought "open box" and "certified" had bent pins and thermal goop in the socket. That I m NOT happy about at all. So it s going back. Soooo... Here s the deal. Budget constraints are putting a bit of a damper on the build. I m going to use the older HTPC as PC #1 and the one I just got done building for PC #2. They have similar specs (same CPU in each). So I should still be able to learn a bit about Beowulf clusters The rest of the hardware is going back so I can get some cash back in my pocket"</post>
   <post id="fbefc7ce-d901-44d9-8d3a-ea0aa7209dfb" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Soo... all is not lost afterall. I jave a couple of lga 775 boards with c2d chips (exact specs elude me atm) one has 2gb the other has 4gb. I m going to include them in with the cluster as well to see if having slower computers hinders the cluster or not. I ll just need to grab a couple of ATX cases and a El cheapo video card since they don t have built in video..."</post>
   <post id="59d7d048-974a-434f-9063-bcd59f568f8e" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Update I got a thermaltake Versa H22 for the two ATX boards that I had... For $40 a pop is was a easy choice! Micro Center - Computers and Electronics"</post>
   <post id="6b1becfc-2539-4104-8a1b-3b4131394986" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Back in high school Cisco Networking class  04, we built a 24 node Beowulf cluster. We downclocked some nodes, left some at stock, and did mild OC on others. Throughout the experiment and various clocks, we found the best results were yielded when every node was running at the same clocks."</post>
   <post id="63bfe0b1-1e95-4fb0-860a-bb0e911022b5" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Good thing is all the CPUs are going to likely be I5 s Sorry for leaving this thread pretty quiet... Life happens sometimes. Lack of job has put things on hold until I can find another job"</post>
   <post id="1c35fac7-40ba-4a8a-937a-2d342e2f3b00" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Skillset?"</post>
   <post id="c8abc446-683f-492f-9acc-593e16f2bc4b" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Very brief overview: 8 years help desk working my way from level 1 to my last job as level 3. I m trying to get into system administration or network administration. Just trying to ring in some certs to ensure the employers know I know what I m doing"</post>
   <post id="90fb70cb-fbad-4d08-b30a-1b68579cb48f" section="Multiprocessing Systems" discussion="Modern Beowulf cluster build...">"Location?"</post>
   <post id="d491fee3-e821-4d67-ac70-76aa95820061" section="Multiprocessing Systems" discussion="Adobe Rendering Machine">"My current workstation is an i7-4930X (not overclocked), 64GB DDR3 and a GTX 670 GPU. I ve recently noticed how cheap the e5-2670 processors are and I m wondering how rendering times compare to what I currently have. System 1 1x i7-4930X not overclocked 64GB DDR3 Nvidia GTX 670 System 2 2x e5-2670 Unsure how much ram, enough to get quad channel No GPU (or maybe a cheap $100 Quadro) I d leave the timeline editing on System 1 and then set up System 2 to be an Adobe network renderer for premiere pro. Right now I see hours of rendering time on my current system, sometimes I just let it run overnight and check it in the morning. Would building the second system to do all the rendering be a good idea?"</post>
   <post id="abc236d1-7291-4ded-a040-c188c8f7ccfe" section="Multiprocessing Systems" discussion="Adobe Rendering Machine">"Rendering with the GPU tends to be a lot faster than by CPU with Adobe CS(or whatever incarnation it is now). My gal s i5 with no GPU rendering went from HOURS to mere minutes simply by adding a nVidia GTX 950 and push rendering to it."</post>
   <post id="1cbd131d-291e-4a94-86d9-5af35bd374c7" section="Multiprocessing Systems" discussion="dell speedstep slows down system">"I was playing around with a few laptops and it seems that allowing speedstep in the bios always makes the computer run slower... was wondering if anybody might know why"</post>
   <post id="52b944e5-ad98-46f5-b325-acbaad547c78" section="Multiprocessing Systems" discussion="dell speedstep slows down system">"That s the whole point of Speedstep. Slow down the CPU when it s not being used to save power and reduce heat output. It increments the speed up as CPU demand increases until the max speed is reached."</post>
   <post id="dd9ba10e-ba43-4c3a-88c3-5640769140fc" section="Multiprocessing Systems" discussion="dell speedstep slows down system">"That is normal.. and It isn t a DELL thing, it is an Intel AND AMD thing. And yes, some stuff will perform better if you disable speedstep or set the CPU to always run at 100% in the power settings in Windows."</post>
   <post id="14faaa99-8627-4c12-8ba6-a8bae143ac8b" section="Multiprocessing Systems" discussion="dell speedstep slows down system">"System responsiveness is really where speedstep can be seen negatively. Intermittent bursty workloads can be helped by disabling it. Here s a recent article talking about improvements and a renaming in Skylake CPUs. Examining Intel s New Speed Shift Tech on Skylake: More Responsive Processors"</post>
   <post id="a6008bee-ffae-4066-911f-53831ac857eb" section="Multiprocessing Systems" discussion="dell speedstep slows down system">"ochadd thanks for the link!"</post>
   <post id="57f8310e-9e5f-4008-9e52-b8ceadc0d8f0" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"I am a newbe to video-encoding. Will opening two instances of the software  Handbrake , speed up transcoding of two videofiles simultaneously (1 file in each instance) on a processor with 4 physical cores (intel atom z3775)? I need to know because I need to decide on a (cheap) new laptop without spinning fans."</post>
   <post id="d0e0339a-3936-4bd9-b5c7-fd551a75f1a9" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"I believe handbrake utilizes all cores. One instance with 2 videos in queue is the way to go. It showed 90+ % usage on my 6 core xeon which was good enough for me. I forget exactly, but I found 1 instance with queue to be just as fast, and 2 made the computer essentially unusable."</post>
   <post id="884af793-43ac-462b-ba67-db664c40fa52" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"You do realize most laptops especially with an atom cpu is going to be PAINFULLY SLOW doing handbrake work.....if its the only way then get the most high end intel cpu with as many cores possible. If your buying a pc for the office only DO NOT get a laptop....just dont. For traveling then you have no choice btw good luck getting a laptop without spinning fans...and for handbrake? its just no possible"</post>
   <post id="1c95cbc1-31d2-40b0-ac46-abc9c4f2065b" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"one instance and queue the files."</post>
   <post id="dec793e4-05ed-4e9e-bbd5-e789445eee6b" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Zepher said: ↑ one instance and queue the files. Click to expand... And someone is going to do that on a laptop with no fans trying to keep the thing from literally melting ? I have to see that"</post>
   <post id="6fdcf5a1-c05b-4b61-a6bf-083b0b676f80" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"primetime said: ↑ And someone is going to do that on a laptop with no fans trying to keep the thing from literally melting ? I have to see that Click to expand... I ve done it on my HP laptop, although I didn t do so many at one time, maybe 2 or 3 20 minute videos when I was converting them from .flv to .mp4. The example I posted above was when I was converting 22 personal Home Video DVD s to MP4 for a client so that they could be put onto a thumb drive and played on any PC. I just used the file server machine to do the work since it sits idle 99% of the time."</post>
   <post id="fe80ea63-da21-4047-9bee-f07b350551c7" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"If I had to guess, 2 Handbrake instances, each working on a single job, will be faster then 2 videos in the queue of a single instance of Handbrake."</post>
   <post id="5fa0e95f-9171-45e1-b2eb-96f84ced3dfa" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"SpeedyVV said: ↑ If I had to guess, 2 Handbrake instances, each working on a single job, will be faster then 2 videos in the queue of a single instance of Handbrake. Click to expand... Why would you guess that? besides the processing, it now has to read and write twice as much to the disk or disks."</post>
   <post id="fe821984-e759-4a54-a558-87b3d9d54d76" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Zepher said: ↑ Why would you guess that? besides the processing, it now has to read and write twice as much to the disk or disks. Click to expand... In speedyVV s case its probably true.....but he has a 32 core monster Xeon setup --unlike most people"</post>
   <post id="455fd644-1722-4b8f-be8a-442589303e21" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"primetime said: ↑ In speedyVV s case its probably true.....but he has a 32 core monster Xeon setup --unlike most people Click to expand... Well, that too, but the real answer is that theoretically, to parallelize you need to divide the job in smaller chunks, process in parallel then merge. edit: not 32... 36... but who s counting."</post>
   <post id="69413329-3e01-4f53-8606-0ecd3211bdfa" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"SpeedyVV said: ↑ Well, that too, but the real answer is that theoretically, to parallelize you need to divide the job in smaller chunks, process in parallel then merge. edit: not 32... 36... but who s counting. Click to expand... Except that video processing is already one of the ideal parallel loads, and will generally use 100% of CPU cores to their fullest. There is no real benefit to running dual instances and you would probably have more resource collisions that way, and unnecessary duplication of some resources. The best way to do this is one instance and a queue."</post>
   <post id="5eecf542-fa1f-49a7-82ae-2e6ce4affb3b" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Snowdog said: ↑ Except that video processing is already one of the ideal parallel loads, and will generally use 100% of CPU cores to their fullest. There is no real benefit to running dual instances and you would probably have more resource collisions that way, and unnecessary duplication of some resources. The best way to do this is one instance and a queue. Click to expand... Uhmmmm, looks like it is time to do a test..... results to follow tomorrow."</post>
   <post id="e382a4d4-b85a-4f76-aa7a-f2dbf0c5186e" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"It only hits 91% usage."</post>
   <post id="8fc5e1e0-51cf-4a8b-800d-f2602b3c0861" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"holy dog shit, i had to break out the calculator to figure it out! 16*16"</post>
   <post id="8bd2f8d4-d223-4d4d-8a97-488b29300100" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Snowdog said: ↑ Except that video processing is already one of the ideal parallel loads, and will generally use 100% of CPU cores to their fullest. There is no real benefit to running dual instances and you would probably have more resource collisions that way, and unnecessary duplication of some resources. The best way to do this is one instance and a queue. Click to expand... That s not necessarily true. x264 does not scale indefinitely and quality will suffer if it spawns too many threads. How many threads are too many is a function of the vertical resolution of the video and a few other things. x264 is also not NUMA aware, so things get messy when you start trying to use multiple NUMA nodes at once."</post>
   <post id="0ba54926-250f-4f49-a87e-59c9c4095f07" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"I was wrong. Did a test. Two instances was slightly faster (~3%) on my old quad core. It keeps the CPU pegged at 100%, where running them sequentially there are small dips in the CPU usage. The difference isn t big enough that I would ever bother doing that way. Might be more dramatic on a monster 32 core system."</post>
   <post id="ecec4f2f-5aea-4446-a8d3-ab9957e2d690" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Running handbrake, encoding bluray from flash to flash on a 5930k. Normal settings, quality set at 20... 1080p with 5.1 HD audio... 109.7FPS encoding speed... I m pretty sure a single copy can max any normal amount of desktop cores you may present it."</post>
   <post id="cd161df7-a6d8-4e6c-be7a-913d5445d088" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Orange Marmelade said: ↑ I am a newbe to video-encoding. Will opening two instances of the software  Handbrake , speed up transcoding of two videofiles simultaneously (1 file in each instance) on a processor with 4 physical cores (intel atom z3775)? I need to know because I need to decide on a (cheap) new laptop without spinning fans. Click to expand... The fastest laptop you can get with no moving parts is this one: Buy ASUS ZenBook UX305FA-USM1 Signature Edition Laptop - Microsoft Store If you get a crappy Atom, you ll get much worse performance. Not to mention crappier keyboard, trackpad and screen."</post>
   <post id="a78f77c5-2fdc-4839-b1fc-229d64464172" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"defaultluser said: ↑ The fastest laptop you can get with no moving parts is this one: Buy ASUS ZenBook UX305FA-USM1 Signature Edition Laptop - Microsoft Store If you get a crappy Atom, you ll get much worse performance. Not to mention crappier keyboard, trackpad and screen. Click to expand... Some might get confused if you didn t mention this is indeed a dual core and it is a solid 30% faster than the atom quad core because it much more advanced and newer than the older atom models...lol i hope someone didn t run out and buy a atom quad core based on posted advice"</post>
   <post id="74fd8f04-114f-4a3b-b062-0edf8a4239cd" section="Multiprocessing Systems" discussion="Handbrake video-encoding and 4x core cpu s?">"Zepher said: ↑ It only hits 91% usage. Click to expand... What the hell is your setup?????"</post>
   <post id="e117e5a9-a396-4ed4-9e25-907e1aeb8ffd" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"I decided since this is  murica and I just like the looks of gobs of cores and ram for no other reason than "because", I want to put together a budget (hahahah I know right!) multi-core system. Now, since I haven t put together a system since socket 1155 and lga2011 (the original), I m looking for feedback. I m in he tire kicking phase so I have time to browse and see what kind of numbers I m looking at and let that guide the direction I go. So, with browsing eBay, I ve seen several dell quad socket amd g34 boards for around $100, but my concern is all the extras I ll need to make it actually run. Does anyone know what I d be looking at picking up extra if I try to use one of these cheap quad g34 boards? Special psu? Specific risers? VRMs? (I know, lol but they were needed in the ppro era!) There are also super micro dual socket boards which are likely to run better out of the box without extras, but they are dual not quad which is a buzzkill. I ve seen many amd opteron 16 core CPUs for $50 each which for a brag box, is plenty over a more powerful and exponentially more costly Intel system and pretty much what got me thinking I could build something many core for not a giant cost. I d be happy with mounting it in a cardboard box (yes, I have a build thread around here somewhere of my old server in a cardboard box), tossing in as much ram as I can find with whatever psu I need and calling it done if I can get away with that. It s only gonna run win server and some flavor of Linux dual boot so it really won t be tasked with doing any real work other than bragging about core and ram count to those who care. I mean, you need 64 cores for Facebook and freecell right!!! I just don t want to try the amd/dell route if it ends up nickel and diming me to death. If I decide all the small parts/pieces are gonna add up to too much, I may just scrap the idea and go for a single socket multi core Intel powerhouse. Heck, I may opt to try a single amd g34 16 core and see how well it performs even if it isn t a powerhouse, granted it can be built on the uber-cheap."</post>
   <post id="333bf228-c8a2-4093-abb2-20f32b2aca53" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"What is the purpose of this build? Just personal use and you are looking at server boards?"</post>
   <post id="be7c2a53-0a57-41cb-8082-4bac2b4d1ca8" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Rav3n said: ↑ What is the purpose of this build? Just personal use and you are looking at server boards? Click to expand... Yeh, just looking at wasting money on many cores and gobs of ram mostly. And most of my fears have been confirmed via Google, that board is a blade style and requires a proprietary backplane for power. I m not opposed to soldering, but without knowing what I need to do it may be a bust already. There doesn t seem to be much info out there on this board unlike many of the other blades out there."</post>
   <post id="3436cd93-0634-430f-bc78-8304d963db3b" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Gillbot said: ↑ Yeh, just looking at wasting money on many cores and gobs of ram mostly. And most of my fears have been confirmed via Google, that board is a blade style and requires a proprietary backplane for power. I m not opposed to soldering, but without knowing what I need to do it may be a bust already. There doesn t seem to be much info out there on this board unlike many of the other blades out there. Click to expand... How about you build a high end Skylake system and just send me the difference. Better results, same waste of money."</post>
   <post id="c71eac06-e5dd-4b20-83f5-103b134eb4d6" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"I was wondering how long it was gonna take for these posts to show up. New record, you win."</post>
   <post id="a687e59f-f3de-4d68-b478-787dc32bbd3e" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Gillbot said: ↑ I was wondering how long it was gonna take for these posts to show up. New record, you win. Click to expand... I bit the bait. It was clear from your OP it was a troll thread. I enjoy fun here on occasion You had me at I decided since this is  murica and I just like the looks of gobs of cores and ram for no other reason than "because" Click to expand..."</post>
   <post id="ff890dd2-5ada-47fb-870e-b997f76f41a6" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Not a troll thread by any means. My old rig was an x58 with a 990x and 48gb of ram only because I got a great deal on the chip. Just trying to duplicate that fun because  Murica. http://forums.2cpu.com/showthread.php?t=98698 Edit to correct ram amount &amp; iPad autocorrect typos. I just like to tinker really: http://hardforum.com/showthread.php?t=1782946&amp;highlight= http://hardforum.com/showthread.php?t=1775045&amp;highlight= http://hardforum.com/showthread.php?t=1777910&amp;highlight="</post>
   <post id="b8667de4-774f-4d5b-bbb0-ea136cff3cda" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"2x Intel XEON E5-2670 8 Core Each ($90-110/each) 1x SuperMicro 2P 2011-r1/2 motherboard (150-250) 8x 16GB DDR3 RDIMM ($65-75/Each) Now if you want to go all out with cores I have a 4-Node AMD system each node consists of 16 Cores.... that I m no longer using. If you want to go "new" then get a supermicro board with warranty, and get some used ES/spicy 2011-v3 chips $350-450 will yield 14 Cores per-CPU. DDR4 16GB RDIMM ~85-95$ for RAM on the "list" of working."</post>
   <post id="50f4d47b-1418-458e-8b0c-8d713d878ebd" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"ToddW2 said: ↑ 2x Intel XEON E5-2670 8 Core Each ($90-110/each) 1x SuperMicro 2P 2011-r1/2 motherboard (150-250) 8x 16GB DDR3 RDIMM ($65-75/Each) Now if you want to go all out with cores I have a 4-Node AMD system each node consists of 16 Cores.... that I m no longer using. If you want to go "new" then get a supermicro board with warranty, and get some used ES/spicy 2011-v3 chips $350-450 will yield 14 Cores per-CPU. DDR4 16GB RDIMM ~85-95$ for RAM on the "list" of working. Click to expand... I d love to go crazy with cores and ram, just don t see it as being feasible. If you get a lower cost board, they are typically for a blade and the chassis will kill you or require too much effort to get it to power up. If you get a better board, they are just insanely cost prohibitive. It looks like I may be able to do something lower core count with a super micro board dual lga2011 and maybe some luck of the draw Es chips from eBay. Still researching though and looking for feedback. I m leaning towards sticking to ddr3 since I ve seen 16gb sticks buy it now at $50 each. Just pairing them to a board and CPU seems to be the challenge thus far. Well, the board and CPUs are cheap if you go amd and blade board, but there is no info on the chassis and nothing I ve found out there on how to solder and power them on without the chassis. I had an old blade board that was lga2011 and I made my own power connector and used a 1u 800w psu to run it since I couldn t get a chassis. I m not afraid to do that again, but these newer boards don t seem to have the pin out info readily available, or at least I haven t found it yet. I d guess they are typical 12v power with a proprietary connector, but without the info I m not willing to gamble."</post>
   <post id="2dccbb6d-dc93-4e0a-8cb4-f68d68a9ec62" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Gillbot said: ↑ Yeh, just looking at wasting money on many cores and gobs of ram mostly. And most of my fears have been confirmed via Google, that board is a blade style and requires a proprietary backplane for power. I m not opposed to soldering, but without knowing what I need to do it may be a bust already. There doesn t seem to be much info out there on this board unlike many of the other blades out there. Click to expand... Literally just looking to waste money on cores and RAM, no specific purpose beyond that?"</post>
   <post id="c3cb49d0-bd71-44e9-99d9-98e08f42879e" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"zadillo said: ↑ Literally just looking to waste money on cores and RAM, no specific purpose beyond that? Click to expand... Other than learning and tinkering, no. I may make it do VMs and learn about more of that. Use it to setup network stuff and play/learn in a "safe" environment. I may put it to work since many cores and loads of ram takes fractions of the time my work laptop takes to crunch data, but that s few and far between plus I d be doing it on my own since they won t chip in towards it any. I m leaning towards a lower cost R415 or R715 now. Dual socket instead of quad but it seems to be much more reasonable cost wise."</post>
   <post id="f0d106d8-9e87-4f1f-b78b-d74f9a6cf938" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Gillbot said: ↑ I d love to go crazy with cores and ram, just don t see it as being feasible. If you get a lower cost board, they are typically for a blade and the chassis will kill you or require too much effort to get it to power up. If you get a better board, they are just insanely cost prohibitive. It looks like I may be able to do something lower core count with a super micro board dual lga2011 and maybe some luck of the draw Es chips from eBay. Still researching though and looking for feedback. Click to expand... I ve purchased over 2 dozen various supermicro E5 boards in the last 12 months, used and new. 2011-r1/2 and 2011-r3. I can safely say I ve purchased more than a half dozen ~$100 (2P E5 r1/r2) and many more 200-250. Anything more than that was 2011-r3 and/or had 10Gig/LSI/24DIMM etc type high-end board. E5 1P boards are another store, cheapest I ve gotten them $170-200, only a couple of those though as i mostly do 2P builds. Ironically you complain about my suggestion and then end with: "It looks like I may be able to do something lower core count with a super micro board dual lga2011" Why would you do a SM board after you TOLD ME it was too hard and would kill me? Why would you say a LOWER CORE when I suggested a $100 CPU that has 8 Cores? Do you think you can buy a 4 Core E5 for $100 or less?? You re wrong. You cannot do better than an E5-2670 for the $$$"</post>
   <post id="23e84137-ce39-4932-87d5-cdf6d2bc8fd9" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"ToddW2 said: ↑ I ve purchased over 2 dozen various supermicro E5 boards in the last 12 months, used and new. 2011-r1/2 and 2011-r3. I can safely say I ve purchased more than a half dozen ~$100 (2P E5 r1/r2) and many more 200-250. Anything more than that was 2011-r3 and/or had 10Gig/LSI/24DIMM etc type high-end board. E5 1P boards are another store, cheapest I ve gotten them $170-200, only a couple of those though as i mostly do 2P builds. Ironically you complain about my suggestion and then end with: "It looks like I may be able to do something lower core count with a super micro board dual lga2011" Why would you do a SM board after you TOLD ME it was too hard and would kill me? Why would you say a LOWER CORE when I suggested a $100 CPU that has 8 Cores? Do you think you can buy a 4 Core E5 for $100 or less?? You re wrong. You cannot do better than an E5-2670 for the $$$ Click to expand... I didn t complain about your advice, but at the time I thought the 16 core amd using the Dell board was going to be the cheapest and easiest option. After more research, I see that was VERY incorrect. Also, I have yet to find lower cost super micro boards out there. Most ive been seeing were single socket and 300+. I m not saying they don t exist, I just lack the knowledge and am not sure what to look for just yet. As I said early on, I m in the tire kicking phase and we ll see where this leads. I had my eye on a ~$150 Dell R715 complete rack mount server that I should be able to upgrade to two of the 16 core amd chips. it comes with 32gb of ram and a pair of quad cores. If the bidding stays low, it may be an option that I can upgrade to more cores and ram later. If not, I ll lean towards the super micro e5 and see what I can get for the $."</post>
   <post id="45868b72-a9fa-45b5-8624-27e9a96b7b2e" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"AMD Cores != Intel Core When you buy things used on ebay for a  good price  you need to have time, if not you pay more for not being patient and waiting for the deal you want I never went out looking for a board and got a deal, I waited and waited Find the part #s you want and wait"</post>
   <post id="d813a552-b31e-4f29-97f4-1d04a697720f" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"ToddW2 said: ↑ AMD Cores != Intel Core When you buy things used on ebay for a  good price  you need to have time, if not you pay more for not being patient and waiting for the deal you want I never went out looking for a board and got a deal, I waited and waited Find the part #s you want and wait Click to expand... I know Intel pretty much destroys amd in performance, but after being in the Intel camp up into lga2011, I d like to try amd and see how they stack up. Even if it takes 32 amd cores and 64gb+ of ram, I m curious to see how it stacks up against my old lga2011 system. Now don t take that as me dismissing Intel at all! Ideally I d like to super budget the amd rig and play but at the same time snag an Intel with patient shopping. Then I could eventually migrate over to the Intel for better performance as I aquire enough parts. Ddr3 can be used on either system so I can save by swapping that back and forth, and with the 16 core amd chips coming in at $50ish each, that s $100 for 32 cores and a good start IMHO. I just need to snag that elusive cheap board, but if that doesn t come to fruition, I ll also be keeping my eye open towards the Intel camp. Let s just see which rolls across my plate first, that ll likely decide which direction I start. FWIW, I m on board with the patience camp. I usually search the sold listings first to find good targets but I haven t seen any that deviated from my short term research. I did see a couple hp barebones that went pretty cheap on the amd side so I m looking that way first. I mean, one had 64gb of 1333 ddr3 in a 8x8gb config paired with dual 8 core amd chips and sold for under $150. I would have snagged that in a heartbeat since the ram alone was nearly worth the asking price! That would be a good tinker toy while I source an Intel board and CPUs, then when that happens steal the ram from the amd and swap over. I know I seem like I have horrific adhd (I prob do) but there is some method to my madness I think. Oohhhh, look shiny stuff, brb!"</post>
   <post id="e9e61718-2754-4475-a522-279cf6e06488" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"ToddW2 said: ↑ AMD Cores != Intel Core Click to expand... Also, care to expand more? Are we talking pure performance? Ghz per ghz? I know traditionally that ghz per ghz, Intel does far better but what I m looking for is say $/$ and core/core, is there some point that you can equal the playing field? Say compare a $50-75 e5 Intel to the opteron 16 core 6272 (or whatever it is) that can be had for the same $50-75. I m not trying to justify amd, just trying to learn and understand."</post>
   <post id="895bf802-733d-4c5f-afe7-6a26828acaed" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"Ok, more reading leads me to believe that the Intel 8c/16t still outperform the amd 16core CPU, correct? So dual 8c Intel with ht will still likely outperform two 16c amd chips? Since amd doesn t have ht, or am I mistaken there?"</post>
   <post id="a3425dde-ca96-4838-b901-a80954c8a4e4" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"You re correct."</post>
   <post id="8f8b6003-bdb0-4d28-8b9d-876d2419f12c" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"silent-circuit said: ↑ You re correct. Click to expand... Yeah, the more I read, the more I learn. I still am going to keep an eye on the amd camp and if I see one like the last I saw, I d be silly to pass it up as to me it s like buying the ram and getting the amd system free. Aside from that, I think I m going to try my best to aim for an lga2011 setup and shoot for the Xeon e5 as suggested."</post>
   <post id="d78333dd-0fbb-48ee-b40a-052208f79e09" section="Multiprocessing Systems" discussion="Project Money Pit (need help/advice)">"You may find this thread useful - list of xeon s and their compatibility is linked in the first post http://hardforum.com/showthread.php?t=1755445"</post>
   <post id="29c20320-e2b3-448a-8875-9fd5009745b0" section="Multiprocessing Systems" discussion="Dell r900">"I recently acquired a Dell r900 with 4 x7460 cpus and 32GB ram and no hard drives. I installed a 160GB WD Black drive and Windows 2012 R2 onto it and I can t get the fans to spin down at all. I installed Dell OpenManage and it shows all 4 fans running at ~5500RPMs and I find no option to lower that, or to have the 2 redundant fans off, which I am told is the normal operational mode. BIOS is 1.2.0 and I see no option in there either. So far not impressed by the performance I ve seen. x264 Video encoding isn t on level footing with an i5 3570k since they tend to only use 25~50% of the CPU depending on the input file, unless I run 3 or more instances, and even then it barely tops 110% of what the 3570k outputs before CPU use is at 100% and I expect not much else at that point. But I would hope that I could at least get the volume down to where I can only hear it from 5 rooms away if that s all it s going to do..."</post>
   <post id="d162a07e-049d-41f3-9e60-6b1e6adde4de" section="Multiprocessing Systems" discussion="Dell r900">"I don t think 264 encodes can very efficiently use that many cores. I could obly get my dual Xeon workstation to about 75% with one encode and it had 1/3rd the cores you do. That said, keep in mind it s a very old architecture, on a per core basis modern stuff is light years faster."</post>
   <post id="0f93ed39-b20e-4753-87fd-4cc0f384cb8b" section="Multiprocessing Systems" discussion="Dell r900">"X74xx Xeons are Core 2 based, so they perform accordingly seeing as they re nearly 8 years old. 130W each, so lots of heat and noise is expected. Only good thing about quad 604 systems is that RAM is dirt cheap, but that s about it. I ve had a similar system (same CPUs) in colo for years now and have been thinking about replacing it with something newer just on account of how much power it eats up."</post>
   <post id="0db4707a-1f71-4a3f-abd8-d6b7875ad2f3" section="Multiprocessing Systems" discussion="Dell r900">"I reseated the power supplies and the fans finally spun down. I guess that maybe all I have is a new doorstop that I can use to toast bread. I find that I can run multiple instances of x264 and it ll use all the CPU, I just wish I could get it to use all that  power  on a single encode."</post>
   <post id="bf630d3c-6599-41c2-9556-bef2d9563c89" section="Multiprocessing Systems" discussion="Dell r900">"I would never pay to power that thing -.- oh my god."</post>
   <post id="bb4c8069-3bf7-489f-a28e-b4c56a9301aa" section="Multiprocessing Systems" discussion="Dell r900">"host some vms for people(for a fee ;-), stick it in a closet with the door barely cracked open, profit"</post>
   <post id="d0ad7655-1aba-4c5a-8233-54694b9e98cf" section="Multiprocessing Systems" discussion="4P ge4 opteron seemingly high base power consumption">"So I hooked up a kill a watt to my 4p Opteron server and it seems like the base power usage is really high? Were talking like 500 watts or more with just a SSD in it. Is this normal or is there something I should look for? Quad opteron 6172, 80GB ddr3, quad port NIC, HP P810 and u.s. 3.0 card installed. The really odd thing is that when I peg the processors power usage only goes up maybe 50w? This seems odd to me.."</post>
   <post id="b3fe74e9-de00-4e01-a9b2-f5e02dc78085" section="Multiprocessing Systems" discussion="4P ge4 opteron seemingly high base power consumption">"something is definitely not right... What OS are you using? Windows Server 2008R2? i use some Magny Cours ES chips with a stock 2.1 GHz speed on my quad system - just idling they run around 375 or so watts. i normally don t run at 2.1 GHz... though... i up the clocks to 3 Ghz... and set windows Performance Mode (all cores running at constant 3 Ghz). Consumption is still below 500 watts just idling even in that state. At 3 GHz the processors require 1.175v, and quite a bit less at 2.1 GHz. if i run something that utilizes all the cores... say Cinebench... consumption jumps to 880-920 or so watts. Intel Burn Test is slightly higher even. i ll get the exact readouts from the kill-a-watt later on tonight. edit: 351w in "power saving", and 390 in "performance mode" at 2.1 GHz, and 448w in "performance mode" at 3 Ghz... PowerNow disabled... at idle. one thing to note... i updated the dual 1000w power supplies in my SC748 case to 90+% 1400w units... this saved about 30-40w if i remember correctly."</post>
   <post id="851335e3-2a16-452b-ab88-9669aa200890" section="Multiprocessing Systems" discussion="4P ge4 opteron seemingly high base power consumption">"I m running ESXi 6.0 right now; I ve got a windows 8.1 vm acting as my emby server also MCE Buddy etc. With everything plugged in: Server, SE3016 16-bay storage expander (with Intel expander card), 24-port Dell switch, cable modem, HDHR Prime etc etc At bootup, idle, I consume 650-700w at the wall plug for all that stuff. Could the storage expander, when placed under load, pull a lot of power?"</post>
   <post id="932a1285-20bf-43b3-a906-1b29947b82ed" section="Multiprocessing Systems" discussion="4P ge4 opteron seemingly high base power consumption">"I think mine are less than that at idle but it s been a while since I checked. I have to assume the CPUs aren t going idle. Check the BIOS settings that relate to power usage."</post>
   <post id="5a945c92-537a-49b1-9017-1fb741b51125" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"I bought an SR-X a few years ago to build a system for a buddy but never got around to it until recently. I got all the parts together, Xeon E5-2680 ES CPU s, 48GB of memory, EVGA 970 GTX. The system turns on fine, but sits at the logo screen with a B2 or B4 error code displayed at the bottom right and on the LED on the board. It also say s CMOS Checksun error. Yes, it says "checksun" not checksum. Thinking it was the cmos battery since it sat there for so long, I swapped it out with a new battery and still the same issue. Thinking it might be a problem with the ES CPU microcode, I obtained a retail E5-2620 from a friend to test it with and I still get the same message. Right now, I m stuck and out of ideas. Any suggestions would be appreciated. Thanks."</post>
   <post id="8636fdd3-2ef1-4284-9cf3-b806f41523dc" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"Try booting the board with only CPU0 and minimal memory installed. What do you have plugged into your USB ports? See here for error codes and this SR-2 thread that goes through much of the troubleshooting, many things should be similar."</post>
   <post id="8a0866dc-37c8-4530-a59b-31f5eece18d6" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"I have only CPU 0 enabled. Disabled CPU 1 using the jumper setting at the top of the board and only 1 memory stick installed in slot 1 tried using both ECC and Non ECC memory. I can t even get into bios. I cleared CMOS and it does the same thing. The only thing plugged into the usb port is my keyboard. It recognizes keyboard commands like ctrl alt delete and beeps if you push buttons too many times. But beyond that, that is it."</post>
   <post id="2fe0db70-b6f1-4f00-9a52-188b5df9db05" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"According to the FAQ, a B2 error code indicates a Legacy option rom initialization error and is can be due to the bios on the GPU. I guess its time I go find an old GPU to update the bios on the motherboard and see if that will work."</post>
   <post id="5d73f8f6-5a8a-4d56-b382-33fb860d7fd0" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"Yup, its the video cards. Had to drive to a buddies place to pick up an old 8800 GTX to put it in and it worked! System loaded past bios and everything. Thanks KMac, for the help."</post>
   <post id="6c7f9d37-e872-486d-a784-cf7b7c5725e2" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"redmasc said: ↑ I bought an SR-X a few years ago to build a system for a buddy but never got around to it until recently. I got all the parts together, Xeon E5-2680 ES CPU s, 48GB of memory, EVGA 970 GTX. The system turns on fine, but sits at the logo screen with a B2 or B4 error code displayed at the bottom right and on the LED on the board. It also say s CMOS Checksun error. Yes, it says "checksun" not checksum. Thinking it was the cmos battery since it sat there for so long, I swapped it out with a new battery and still the same issue. Thinking it might be a problem with the ES CPU microcode, I obtained a retail E5-2620 from a friend to test it with and I still get the same message. Right now, I m stuck and out of ideas. Any suggestions would be appreciated. Thanks. Click to expand... Will that Xeon overclock on the SR-X? I always wondered about my own ES, and if 2 of them on a SR-X would work."</post>
   <post id="1adda2e6-a6f3-4dda-8880-778ef607bd6d" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"If he is lucky he will get a bclk of 104 or maybe 105."</post>
   <post id="2ad4ec7c-0385-4f0b-8927-7dc252161742" section="Multiprocessing Systems" discussion="EVGA SR-X problem">"I haven t tried yet. I did see that you can change the bclk in the bios menu, but I m more concerned with trying to get the system online at the moment. I ll give it a shot once I get everything up and running."</post>
   <post id="88dce4c4-a271-4711-af88-93a10f953d74" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Hi everyone! Hoping I might be able to get some help from the knowledge vault that is horde . I have a 4p opteron build here that I bought a little while ago second hand. Running a supermicro H8QGi+-f board and 4 opteron 6170 chips. The board had one cpu socket with a snapped pin (memory channel pin). I tried repairing it but didn t really get anywhere. Anywho, I m finding the whole system is powering down after around 18 hours running full load. (boinc). Sometimes it ll last 24 hours, other times it will do it in less than 12. So instincitevely I pulled the cpu from the borked socket but still did it running 3p :/. Knocked it down to a 2P. and it took nearly 48 hours but it still powered down. Checked the bios, there s no alarms set or anything like that. IPMI is disabled. She passes memtest on all sticks of ram, windows logs show nothing except an unexpected shut down when I power it back on. Board logs are also empty. I m just about out of ideas! I ve tried a 1200w silerstone Strider and also a 1200w Antec quattro psu, both of which should easily power this. Was running the OCNG5 bios but have since flashed back to factory and it did it on both. I can t really check the temps unfortunately because all it shows is Low/Medium/high instead of the actual temp . The only temperature value I can see is the system temp which hovers around 30c. This I also find odd as my other H8QGI showed actual temperature values! I ve just booted up linux with boinc to see if it does it in that too (Currently have been running server 2008R2). Any help with this is much appreciated!! Thanks"</post>
   <post id="f4934780-fcb7-465d-87fa-507c754421cf" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"My first thought goes to proper cooling. Can you describe how you are currently cooling the board? I would recommend blowing air over the entire board. Both top and bottom."</post>
   <post id="84272c0e-b61d-4349-9c83-349258df9e18" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Hi Gilthanis, I m currently running 4xCM 212 s for CPU cooling, the board was kept open air (not in a case) in an air conditioned office, so I assumed that was enough. But you could definitely be right, maybe it needs more airflow across the board. I will add a couple of 120mm fans on the bench blowing across it and report back! Thanks for your help"</post>
   <post id="e0ea7ca1-f013-4dbc-8ec8-843377337181" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Yeah.. the mosfets and other components can get really hot. Especially if OC d. I would raise the board off the table with some kind of standoffs and blow the air past both portions."</post>
   <post id="5370e748-a797-4761-898d-0ecf4b19592c" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"You ve ruled out PSUs, I d think. My next guess would be motherboard component(s) overheating. Have you observed the same problem if the system is just idling?"</post>
   <post id="572950a4-d974-441c-ab8b-eb91fa498325" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Also a great idea Linden thanks. I haven t actually tested it idling. I have added some 120mm fans blowing cross ways over the board. Not sure if it s quite enough airflow. Will test like this, then I ll try the idling. And if it doesn t do it I might try and find a desk fan to blow over the entire board. Thanks for the ideas guys, just frustrating testing when it s sometimes 24+ hours each time testing something new! edit: Should also mention, chips are @ stock speed, and tested in linux and it does the same thing, so definitely hardware related and not OS."</post>
   <post id="057c32bf-9253-46ff-abad-5674a206b119" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"frustrating testing when it s sometimes 24+ hours each time testing something new! Click to expand... I don t envy you, that. The computer s configuration: Do you have it sitting flat? If it s a naked system, do you have the motherboard elevated from the resting surface? Airflow is critical."</post>
   <post id="75c2554e-376e-4746-8ecf-9f3e29896f33" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"I m guessing you are running with all the memory slots populated. do you know which memory slot is associated with the broken cpu pin. ? If you do try removing that stick of memory. Also I would recommend you flash back to OCNG and use the tools that come along with it, there are several tools in there that are well worth it when it comes to diagnosing problems. and you will be able to see your temps again"</post>
   <post id="99ffbc12-9332-4e17-b504-04f065b29d5e" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Hi Grandpa, I actually pulled that CPU and all memory and it still did it, so I don t think it s an issue with that socket. I lifted the board off the desk with some CD cases and added 3x 120mm fans blowing around the board. Still no dice . Shut down overnight. Next step I ll try Linden s suggestion and just leave it idling and hope it doesn t shut down. If that s the case I might try a pedestal fan blowing across the whole thing! Thanks for the help everyone! edit: Also does the OCNG bios turn on detailed CPU temps? I thought when I was running it, it still showed the system temp instead of individual CPU s?"</post>
   <post id="1dd5c963-c811-4038-bfaa-3e2280fc3342" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"When you install it and the tools run (sudo tpc -temp) it will give you the cpu temp s (sudo tpc -dram) will give you the memory speed, size and timings of the individual sticks. (sudo clockspeed) will give you your current cpu clock speed (sudo voltcheck) will give your cpu voltage."</post>
   <post id="960467ac-0ea9-49f0-afdf-b447ec687403" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Boards dead . Won t boot at all now. Powers up for half a second and switches off with CPU installed . Tried both psus same thing. Well I guess I m on the lookout for a new opteron board"</post>
   <post id="29b1d950-6b34-40a7-ac1c-c34216160ff3" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Sorry to hear that."</post>
   <post id="f7ce3e70-0bce-4908-8424-f4fa537bfbac" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Umm there is a good chance SM will repair it for a reasonable price, they replaced a cpu socket on one of my H8QGi+-f for $50 so you may want to give them a call."</post>
   <post id="8f53e0a4-cfcb-41f9-b340-efbad9334131" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Thanks for the suggestion grandpa, but unfortunately now that the whole board is dead I have no idea what else would need replacing as well as the CPU socket. Also the shipping costs would probably kill the value New board arrived yesterday! Another H8QGi+-f. Currently load testing it! Fingers crossed this one is fine. I m running on the assumption the last board had a fault though. Hopefully will get back to some regular DC production now The only odd thing is I m still not getting proper cpu temps. Even with the ocng5 bios loaded it s still showing around 30c per CPU. Which definitely isn t right when it s at 100% load! I think it s just using ambient temp sensors on the board or something edit: Oh yeah I still have these to go on at some point hehe"</post>
   <post id="428af50b-4946-4231-98b8-00b1274f94f2" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"the screws that came with mine water blocks do not fit the supermicro board. searched high and low for compatible screws to no avail, ended up finding some obscure old screws for a guetto solution."</post>
   <post id="3251cf21-ce00-40ff-b2fe-db16b890fd66" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"Sorry for the late reply! That s dissapointing if that s the case with mine too. But luckily I have all the studs from the current 212 heatsinks that I can reuse if need be"</post>
   <post id="8bc2b16f-ab0c-4b4b-ba85-9be0f3c38ce4" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"terrabyte89 said: ↑ Boards dead . Won t boot at all now. Powers up for half a second and switches off with CPU installed . Tried both psus same thing. Well I guess I m on the lookout for a new opteron board Click to expand... Hi, any chance of rma? Never had a duallie so imagine how I d like to have a quad . The best I had were 7x dual 1366 servers ( in a datacenter ) with 1 gbit shared connection ( each) for a project @Grandpa_01 your signature is awesome."</post>
   <post id="181c0f7c-bbf1-4d8e-8f84-9eef0813fa99" section="Multiprocessing Systems" discussion="Help with 4p opteron shutting down">"elvis1 said: ↑ @Grandpa_01 your signature is awesome. Click to expand... Yep - nothing better than an overclocked 4p machine"</post>
   <post id="c65c0572-7e76-4e15-ac54-79c9703e80e7" section="Multiprocessing Systems" discussion="first double-CPU build">"This machine is going to be used for rendering CGI and post-production. There are some small details I m not too sure so a little advice would be great. Mobo: ASUS Z10PE-D8 WS CPU: Xeon E5-2630 v3 2,4 GHz Memory: Kingston ValueRam DDR4 PSU: Seasonic X-1250 HSF: NOCTUA NH-12DX i4 GPUs are already covered from my old build, as well as the Samsung 840Pro. I would like to know if I need additional cables for connecting the PSU with the mobo, since there are 2 CPU power connectors (8-pin EPS 12v) Or would someone suggest a different PSU altogether? Any suggestions on a case, can t really find on that explicitly says EEB the only one to specify is the Cooler Master Cosmos 2. I already have the Cosmos S but looking at the specs of the ASUS mobo I doubt the holes are going to align. Although EEB standards are the same than EATX but there are secondary placements that don t align. Puget Systems use a Fractal Design Define XL R2 for the same build but again EEB not mentioned. The only thing left are some HHDs for a RAID1 setup to store work. Does not have to be super fast or fancy. I foud some TOSHIBA 4TB MD04ACA400 cheaper than WD or HGST. Any advice is appreciated"</post>
   <post id="28d4d57a-cd5c-49cd-a422-8123bca9b6a4" section="Multiprocessing Systems" discussion="first double-CPU build">"Moflo said: ↑ This machine is going to be used for rendering CGI and post-production. There are some small details I m not too sure so a little advice would be great. Mobo: ASUS Z10PE-D8 WS CPU: Xeon E5-2630 v3 2,4 GHz Click to expand... Let me play a role of a Nasty and question about basics of this design. Why using dual processor mobo and two processors of low basic frequency? One can use single processro mobo with 8-core single socket Xeon or i7-5960X and overclock it to get the same or even much better performance. For example, I have Asus X99-E WS mobo with Xeon E5-1680 v3 which overclocks without any problems to 4.3 GHz and I have 128GB ECC RAM in it. Simple calculation shows that my 8 cores @ 3.6 GHz is roughly equivalent to 2x6 cores of E5-2630 @ 2.4 GHz and it will leave it in dust at 4.3 GHz. The dual Xeon processors with low frequency are made for data center servers where the number of threads is more important than speed. For your types of loads it is better to have a combination of bit less threads but much higher speed. Dual pocessor mobos are useful for workstation type of loads if it is clear that no single processors can do tasks and/or there is a need for more than 128 GB of RAM."</post>
   <post id="2d77da98-c163-4261-bb4f-6d913c775a2e" section="Multiprocessing Systems" discussion="first double-CPU build">"Sorry wirk, but the E5-2630 is 8 core hypertreding just like your E5-1680. So if you make your calculations I ll have 16 cores and you just have 8. Although it is preferable for most applications to have a higher clock than the number of cores, this is not exactly true for a render engine. Right now I m also taking a look at the 2660 10 core. Btw, I don t want to overclock because I have done that and now I m building a reliable Workstation to render high end images for print, which takes a few hours"</post>
   <post id="d27ed02c-de0a-4e67-be3d-c1bce545927a" section="Multiprocessing Systems" discussion="first double-CPU build">"True, I looked at the E5-2630 but not v3, the v3 has eight cores. Overclocking ot the E5-1680 v3 to 4.2-3 GHz is no problem at all. But is this really so that your applications are more dependent on the number of cores?"</post>
   <post id="eea92572-fa71-40ea-80ad-a02ac01572b0" section="Multiprocessing Systems" discussion="first double-CPU build">"In my experience well optimized software that can utilize all the available threads and can give huge performance improvements over higher clock speeds. This is not an area that I do much work in professionally however work loads that can be broken down into may parts and executed in parallel can use many cores very successfully and can yield huge speed improvements. I see the benefits of a multi-core/multi CPU system when using software such as handbrake for video encoding and adobe premiere. I suggest that you look online for some benchmarking results for the software that you plan on using to confirm how well it can utilize multiple cpu s When you are looking around be aware that a multi-core cpu is different compared to a multi cpu system. multi cpu system use a technology called SMP (symmetric multi processing) I think it stands for and software must be written to take advantage of this other wise the 2nd cpu is wasted. This limitation does not exist for multi core cpu s. This is because in a multi-core CPU the CPU itself handles the distribution of jobs over the cores in hardware independently of the operating system or software. Where as a multi cpu system the OS and software schedule the tasks over the CPU s. This means that unless the software is SMP capable you will see no advantage to a 2nd processor."</post>
   <post id="e895025f-ec9e-434d-8c59-a00cfcc235ba" section="Multiprocessing Systems" discussion="first double-CPU build">"Juda$ said: ↑ In my experience well optimized software that can utilize all the available threads and can give huge performance improvements over higher clock speeds. .... This means that unless the software is SMP capable you will see no advantage to a 2nd processor. Click to expand... It is obvious that well optimized multithtreading/SMP software will be always better. The problem is there is not much of such software. This is due to the fact that developers mostly produce software for the lowest common denominator hardware used by people. Typically one sees multicore/SMP as big advantage in servers/data centers where lots of threads are good since they run huge number of different tasks. Let s take simple practical example of a PC with graphics cards in SLI. Adding second card results in almost doubling the graphics performance. Adding third and fourth card brings very little. Why it is so? The current model of graphics operation is such that graphics cards are served by single core in single thread which is nonsense for the SLI. Only the soon coming DirectX 12 will solve this problem by allowing multicore multithreaded model. This can be bring huge performance gains - if developers will use the tools they will get. But anyway, this will be a huge progress since until now they could not do anything to improve the SLI even if they wanted. Here is another example in the direction of apps mentioned in this thread: Adobe Photoshop illustrating my point. Adobe is generally considered as one of the best in multithreading/SMP but results are mixed at best. One can see that performance increases up to 4 cores and gets flat, dual procesor test is just laughable since performance drops in many cases(!). Why? They optimize for the common 4 core single processors and do not bother about more since it is a niche market. I suppose that fully optimized software can be found among those which cost tons of money for ultrahigh professional segment."</post>
   <post id="145ddf6e-00ea-4f85-ac91-580f2e48b501" section="Multiprocessing Systems" discussion="first double-CPU build">"I have this mobo and you should be aware that the ASUS Z10PE-D8 WS, has a combination of current and legacy mounts, specifically, H  Y  and J , so even mobo trays that are EBB might not support the mobo. You definitely need a PSU that provides 2 CPU eps cables. That is why I ended up getting the Corsair AX1500. Overkill but oh well."</post>
   <post id="7e7ea55b-0e5c-4f87-8496-3bfb7cc8ddc2" section="Multiprocessing Systems" discussion="first double-CPU build">"This article s a bit old, but still spot on. http://www.fxguide.com/featured/the-state-of-rendering-part-2/ Again, while having gobs of threads is great, the fact is, many rendering packages simply don t take advantage of all of them. Most deliver the best performance improvement with 4-8 threads and nothing after that. Seriously, you could get a bunch of 14-core CPUs, and 20-24 of them will effectively sit idle. You really are better off with 4-8 physical cores running at the highest possible speed. http://www.newegg.com/Product/Product.aspx?Item=N82E16819117499 A single 1650 v3 will wind up delivering better overall performance than the pair of 2630 s."</post>
   <post id="031ef325-2944-434d-aa5c-dee4e25507b9" section="Multiprocessing Systems" discussion="first double-CPU build">"Chas said: ↑ This article s a bit old, but still spot on. http://www.fxguide.com/featured/the-state-of-rendering-part-2/ Again, while having gobs of threads is great, the fact is, many rendering packages simply don t take advantage of all of them. Most deliver the best performance improvement with 4-8 threads and nothing after that. Seriously, you could get a bunch of 14-core CPUs, and 20-24 of them will effectively sit idle. You really are better off with 4-8 physical cores running at the highest possible speed. http://www.newegg.com/Product/Product.aspx?Item=N82E16819117499 A single 1650 v3 will wind up delivering better overall performance than the pair of 2630 s. Click to expand... My workstation has plenty of cores, and I can confirm that 95%+-5% of scenarios, single application performance does not scale at all after 12 cores, and even 8 cores. Unless you are running bunch of VMs it really is much better to have GHz."</post>
   <post id="a258fe60-3c65-4b03-baf7-c84838f76894" section="Multiprocessing Systems" discussion="first double-CPU build">"Pre-ZACTLY!"</post>
   <post id="e7af3598-7fef-4ee2-9dc5-6b86eb0206a7" section="Multiprocessing Systems" discussion="first double-CPU build">"SpeedyVV said: ↑ My workstation has plenty of cores, and I can confirm that 95%+-5% of scenarios, single application performance does not scale at all after 12 cores, and even 8 cores. Click to expand... Just wondering, is there any example of software which scales up well with the number of threads/cores in any reasonable amounts?"</post>
   <post id="b75928c9-fa1c-4c3a-90ff-e215e93ddd9a" section="Multiprocessing Systems" discussion="first double-CPU build">"Basically unless you re running virtual machines or folding/cracking clients (Distributed.net, etc), after a certain point, the extra cores net you bupkiss."</post>
   <post id="9f8b848a-65cb-4165-af2a-5c594382f4e7" section="Multiprocessing Systems" discussion="first double-CPU build">"basically except for soft image and light wave all of the professional render software can make use of multicore / hyper threading if you use the 2014 or later version. Renderman just came out with a new version that is actually faster on virtual cores than multiple cpus. The fastest setup currently is a blade server followed by dual i7 hex or octo core with a nvidia telsa setup. From there it breaks down to how fast you can feed the cores from ram. Most systems are not optimal at that. So 128GB of ram, an i7 hex core or octo core and a tesla or titan to offload the simple calculations make sure you get the old double precision titan if you go that route. Speed is much better when you are rendering as often times the later pieces need info from the early calcuations unless you makes you buckets like 5k each or a grid of a thousand pieces but then it can not reuse the lighting math and will look funny. https://www.spec.org/gwpg/downloadindex.html"</post>
   <post id="5e8575d8-0b8d-4a75-a62a-9ced6ad0e15e" section="Multiprocessing Systems" discussion="first double-CPU build">"drakken said: ↑ basically except for soft image and light wave all of the professional render software can make use of multicore / hyper threading if you use the 2014 or later version. Renderman just came out with a new version that is actually faster on virtual cores than multiple cpus. The fastest setup currently is a blade server followed by dual i7 hex or octo core with a nvidia telsa setup. From there it breaks down to how fast you can feed the cores from ram. Most systems are not optimal at that. So 128GB of ram, an i7 hex core or octo core and a tesla or titan to offload the simple calculations make sure you get the old double precision titan if you go that route. Speed is much better when you are rendering as often times the later pieces need info from the early calcuations unless you makes you buckets like 5k each or a grid of a thousand pieces but then it can not reuse the lighting math and will look funny. https://www.spec.org/gwpg/downloadindex.html Click to expand... Do you have specific render software that can make use of 30+ cores?"</post>
   <post id="9a4f67eb-0c32-4b79-8de2-b93bed7bddb0" section="Multiprocessing Systems" discussion="first double-CPU build">"drakken said: ↑ basically except for soft image and light wave all of the professional render software can make use of multicore / hyper threading if you use the 2014 or later version. Renderman just came out with a new version that is actually faster on virtual cores than multiple cpus. The fastest setup currently is a blade server followed by dual i7 hex or octo core with a nvidia telsa setup. From there it breaks down to how fast you can feed the cores from ram. Most systems are not optimal at that. So 128GB of ram, an i7 hex core or octo core and a tesla or titan to offload the simple calculations make sure you get the old double precision titan if you go that route. Speed is much better when you are rendering as often times the later pieces need info from the early calcuations unless you makes you buckets like 5k each or a grid of a thousand pieces but then it can not reuse the lighting math and will look funny. https://www.spec.org/gwpg/downloadindex.html Click to expand... SpeedyVV said: ↑ Do you have specific render software that can make use of 30+ cores? Click to expand... I made quick look and found that there is now available free noncommercial version of Renderman. Renderman could be then an extremely good test of performance of eight core machines plus graphics cards (unfortunately I have Titan X which does not fit as I see from above). Is there any demo of Renderman which could be used for this? How about using Renderman without graphics cards to test the CPU/multithreaded/multicore performance? Nevertheless the question if Renderman scales well beyond 8 cores is still valid."</post>
   <post id="b30676f5-c515-4d2e-9938-b22610d50c2a" section="Multiprocessing Systems" discussion="first double-CPU build">"Moflo said: ↑ This machine is going to be used for rendering CGI and post-production. There are some small details I m not too sure so a little advice would be great. Mobo: ASUS Z10PE-D8 WS CPU: Xeon E5-2630 v3 2,4 GHz Memory: Kingston ValueRam DDR4 PSU: Seasonic X-1250 HSF: NOCTUA NH-12DX i4 GPUs are already covered from my old build, as well as the Samsung 840Pro. I would like to know if I need additional cables for connecting the PSU with the mobo, since there are 2 CPU power connectors (8-pin EPS 12v) Or would someone suggest a different PSU altogether? Any suggestions on a case, can t really find on that explicitly says EEB the only one to specify is the Cooler Master Cosmos 2. I already have the Cosmos S but looking at the specs of the ASUS mobo I doubt the holes are going to align. Although EEB standards are the same than EATX but there are secondary placements that don t align. Puget Systems use a Fractal Design Define XL R2 for the same build but again EEB not mentioned. The only thing left are some HHDs for a RAID1 setup to store work. Does not have to be super fast or fancy. I foud some TOSHIBA 4TB MD04ACA400 cheaper than WD or HGST. Any advice is appreciated Click to expand... Depending on the gpu s you are reusing I would say that that psu might be overkill, you would probably get away with a 850-900watt version of the above, or a corsair ax860. They will still have 2 psu connectors for the cpu s. I have your mobo s older cousin, the z9pe-D8 WS and I run it 24/7 with a pair of e5 2665 v1 s on an ax750 no problem - I do not have any gpu s to speak on it though"</post>
   <post id="f9584457-ebf9-4798-8d21-6a2c70cefe9f" section="Multiprocessing Systems" discussion="Need advice">"Hi everyone, I need advice into building a rendering machine. This is mostly used for editing and rendering 4k video with after effects. I m just looking for the best performance per dollar. Motherboard: ASUS Z10PE-D8 Processor: 2x Xeon E5-2660 (8core 16 threads) &lt;-- Is there a better value processor? I found these on ebay hovering around $275 each. Ram: ECC Ram (any recommendation?) Video Cards: EVGA GTX 980 SCs"</post>
   <post id="d2df04b2-3a5b-47da-b85f-3a3bdfb2baaa" section="Multiprocessing Systems" discussion="Need advice">"You don t need a 980 for a render box(?) After effects CS6 only uses the GPU for the ray tracing. you can save a couple hundred by going back to the 970. (newer version maybe different though double check that) The 2660v3 is 10core/20 thread. for an 8/16 check out e5-2630 about half the price give or take."</post>
   <post id="2d2a2b4f-2401-4557-9aea-8e5bbb70ce37" section="Multiprocessing Systems" discussion="Need advice">"Here you have a list of Intels Xeon E5 v3 dual CPU s so you can compare them. http://ark.intel.com/compare/81061,81060,81059,81057,81713,81909,81055,81908,81709,83361,81706,81705,81900,83359,83358,83356,83354,83352,81897,83349 As for memory Kingston ValueRam 16GB DDR4-2133 Registered Quad-kit. If you get 2 you ll have 32 GB of RAM Certainly don t need more than that. But you could use Crucial EEC memory, they are a bit cheaper and work fine. And there is some Samsung LRDIMM memory to if you need that. As for GPU I don t use After Effects Do you use anything else? like Premiere. Because than you do need a good GPU card. They mostly recommend Quadro because of their bigger RAM if you read the latest article on the Fury her on HardOCP you ll see that the Fury fails because of it s 4GB memory limitation."</post>
   <post id="045e68e0-3cd2-42b6-ad4d-99922f95e88c" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"So I came into possession of 10 x5670 chips for $250 from a local company that shutdown. I would like to put together some workstations that would have at least one full size high powered graphics cards(r9 290) sorta cards. Taking a look a lot of the really cheap ones take odd ball power supplies. So basically I am looking for dual socket boards, ATX power or easy to find cheap converter plugs, 1 full size pci-e slot that can take a high end graphics card, and a bonus would be regular DDR3 ram like a x58 board would use. I know this is kind of a long shot but just checking around for suggestions."</post>
   <post id="1ecb8c3d-0d02-4845-b963-2e6bce19e77a" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"Xeon X5670? I think the X8 series of SuperMicro should do: http://www.supermicro.nl/products/motherboard/Xeon1333/#1366 Specifically I d go for this one: http://www.supermicro.nl/products/motherboard/QPI/5500/X8DAL-i.cfm Other than that, here s Tyan s range of Xeon DP boards for 1366 socket: http://www.tyan.com/product_motherboards_dp_intel_xeon_5500.aspx Dual LGA1366 boards are not exactly targeted towards consumer markets so I d guess they will not be a bargain. For single CPU workstation systems (remember, 6 cores, 12 threads!) however, pretty much any X58 chipset based board will do nicely. Do you happen to sell one of the CPUs? If so, I d be interested. I currently hava a X5550 in my box, so a X5670 would be a nice little upgrade to it."</post>
   <post id="b97a53a9-78e3-422c-af64-be53097906f6" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"You could also try and find an Asus Z8NA-D6 or D6C, they take regular DDR ram and have a full length PCIe slot"</post>
   <post id="a571ab17-bf73-4160-b69a-0601ab10c10d" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"http://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2050601.m570.l1313.TR11.TRC1.A0.H0.XX8dti.TRS0&amp;_nkw=X8dti&amp;_sacat=0 Supermicro X8DTI...looks like you can grab them for about $150 or less. Can used unbuffered ECC up to 48GB. Used to sell a ton of those boards when they were in their prime."</post>
   <post id="12840173-e746-4d26-b71d-399371643aa6" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"Tyan S7002"</post>
   <post id="da8f676b-9238-455d-8bba-3c34870c4d60" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"10 x5670 for $250 is good value. After a few myself but they are all expensive on ebay. With the Z8NA regular D6 version I had two of those boards and both didn t last long and ended up with dead PCI Express slots."</post>
   <post id="46519eef-1474-4148-9e93-e24185799090" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"I have three X8DTI s, and can confirm that they run wonderfully with L5520 s / L5640 s + 48GB of unbuffered ECC. Great motherboards, and IMPI is the best thing ever."</post>
   <post id="ce2b6318-c4dc-4be5-95e4-a2535898ece3" section="Multiprocessing Systems" discussion="Cheap dual 1366 boards">"So, uh, looking to unload any of those x5670s? Aside from various used Supermicro X8*** boards that you may find on eBay for ~$70, your best/cheapest bet may just be to buy a used Dell T5500 with either no CPUs, or base model CPUs. There are lots of them on the market, and you don t need to worry about finding a power supply, case, and motherboard that work together (which can be a pain for dual CPU rigs). Here s one for $135 shipped- http://www.ebay.com/itm/Dell-Precis...796?pt=LH_DefaultDomain_0&amp;hash=item1ea05d6f5c"</post>
   <post id="f659cd17-bf6e-4d67-a141-52f34a9b2c24" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"This is a wild stab in the dark, but anyone sitting on a Tyan s8230 I/O shield they d like to sell?"</post>
   <post id="0c5d7e60-a823-4194-b34b-12e17897b890" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"What s even a wilder stab is someone having one and knowing what it is. I have hundreds of them but don t know what board they go with unless they are physically with the board and most aren t. Good luck."</post>
   <post id="02fd4f5b-a905-47e3-a2af-5f8142872d5f" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Good point! Here s an image of the connectors:"</post>
   <post id="36008ff2-0f4b-468a-afd1-0691bcba7b11" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"I ll dig through my collection and see if I have one. On a related note, I recently bought a SC846 storage case and a SM X8DT6-F motherboard without the shield. As luck would have it, the case came with the correct shield already in place. They came from 2 different sellers so it was pure luck."</post>
   <post id="86cb2f73-7b4a-4595-a149-a4bfdc279600" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Ha, that s always nice! I d definitely appreciate it. If you do happen across one, let me know - I ll happily pay you for it."</post>
   <post id="241058c6-1769-4d8d-8d7f-a94192ce6a09" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Any luck, Deadjasper?"</post>
   <post id="cfb3e888-5b14-4113-99ce-40c11dc457ae" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"No, sorry. That appears to be rare config. I ve checked ebay a couple of times and found nothing that s even close enough to mode without looking ghetto. Have you tried contacting Tyan? That s a long shot too but and email is cheap."</post>
   <post id="fb91e933-89cd-49dd-8a83-f3201094e6e3" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Sure did, no luck there. May be time for me to start thinking about making one"</post>
   <post id="78a456aa-2f01-4b6b-84e4-599b33e41059" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Or you could just run without one. It doesn t serve any purpose other than looks and maybe airflow control to an engineer. I have one system that s been running for years without one because I couldn t find it when i was putting it together. Found it after the MB was already in the case but didn t feel like going thru the trouble of removing it again. Never missed it. But if it s for somebody else, that s a different story. Good luck."</post>
   <post id="fa0b3ee8-8172-4f99-ae75-ff8f7333f395" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"Engineer here, I couldn t bear to leave it open, due to, as you note, airflow control. I do appreciate you looking, though!"</post>
   <post id="2f59fa97-0bed-4afe-899b-fef4275a0274" section="Multiprocessing Systems" discussion="Looking for a Tyan s8230 I/O Shield">"If you want it for aesthetics, that s fine ... but running without it won t make a bit of difference."</post>
   <post id="0d54722d-3a9e-4437-9f99-8cd30a776f26" section="Multiprocessing Systems" discussion="HP Lefthand P4500 / Proliant DL185 ?s">"Been doing some research trying to figure out if these are worth using. What they were sold as is Lefthand P4500 SAN units. After doing some research I found out that they are just DL185 with Lefthand SAN/iQ installed on them. I have 2 of them, each with 12x 250GB SATA drives. I know from experience that swapping out a drive with a different sized one while running, the system will simply not even detect the drive. Not sure if this is because all drives must be the same size or if it only supports certain specific drives when running the SAN/iQ software. It looks like they support up to 1TB drives per bay. If they support 2TB, that would be even better. I will have to look up the specs on the RAID card to see what I can find out. The question I had was if I would see any noticeable performance increase when using them as a SAN if I added a second CPU or added more RAM. The processor should be a Quad core Opteron at 2 - 2.3Ghz from what I could find out about the stock setup. They also only have 2GB of RAM installed each. I am guessing this is why it used to take so long to delete snapshots when I had them in a production environment. Anybody have any experience with upgrading these when running the SAN/iQ software?"</post>
   <post id="e0da05b2-9b68-450b-b678-aca1768c9521" section="Multiprocessing Systems" discussion="HP Lefthand P4500 / Proliant DL185 ?s">"So I did a bit more searching and from what I can find, if I replace the P400 RAID card with a P410 RAID card, I can use drives up to 6TB in size. Not sure what the max size the lefthand software will recognize though."</post>
   <post id="f08711a1-21cb-443e-87c3-c8ab6de94acf" section="Multiprocessing Systems" discussion="HP Lefthand P4500 / Proliant DL185 ?s">"We have P4300 s with two different flavors of drives. One has 750GB drives, the other has 1TB. I can t really help you out though, as anytime we have had to replace drives, they are always replaced with the same density."</post>
   <post id="c993c9ed-5362-4e70-b357-20dd61bd69be" section="Multiprocessing Systems" discussion="HP Lefthand P4500 / Proliant DL185 ?s">"Ok, getting somewhere. 1. The "enterprise" SATA 250GB drives are actually 250.1GB, and the consumer drives are 250.0GB. so when you try to replace a drive with a regular 250GB, it thinks that the drive is too small... 2. If you want to use a larger drive, you must boot with a monitor and keyboard hooked up and tell the RAID card to rebuild. If you just do a hot swap, the Lefthand OS can t even see the drive. If you boot without a monitor and kb hooked up, it will just auto bypass the rebuild since you didn t offer any input and it won t work. So now it is rebuilding with a 500GB in place of the failed 250GB. Edit: The second unit had a bad drive as well. I swapped it out with a 500GB drive and it picked it up without rebooting. Very strange. Anybody have access to the newest P4500 (DL185) BIOS? Lame HP has locked down BIOS upgrades to users with active warranty contracts. I have the second newest, and from the release notes I probably don t need the latest but it can t hurt."</post>
   <post id="12be15b6-d119-43be-8a22-ece091a340c7" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"What is a good AMD LGA1944 motherboard that supports overclocking Opterons through the BCLK? Are there any boards that can overclock via the multiplier when used with unlocked ES chips? I also need the board to support 2-way SLI."</post>
   <post id="acd80ade-ec82-48f6-b494-c55b525ed4b7" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"The only way you will get one that overclocks is with a hacked BIOS. You also will not find one with SLI support."</post>
   <post id="6a2187f1-5789-4cc7-9250-69908d0df7ff" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"What are some good boards with nodded BIOSes?"</post>
   <post id="6c36a896-75eb-4349-9685-3dea384633c2" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"Have a look at these: http://www.overclock.net/t/1437860/c32-vs-g34-vs-x58-options http://area51dev.blogspot.com/p/ocng5-installation.html"</post>
   <post id="6558d326-9b3c-40c1-b89c-5f0de420c6c0" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"Is 6 VRM phases the most that is available? 6 phases seems a bit weak, considering the power consumption of these chips..."</post>
   <post id="4d7eb37b-cbb6-4445-963a-972e8dc010d9" section="Multiprocessing Systems" discussion="LGA1944 Boards for OverClocking">"Given that these boards were never designed to overclock, 6 was probably deemed enough. Given that you are "only" going reach a speed of 3.8 max with a 61xx chip your main concern will be heat from the VRM s. All of them will need to be cooled, and preferably have a fan blowing over the VRM heastsinks"</post>
<post id="182ce8fb-8e38-490c-a6aa-0575cc1446a3" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review - The Arctic Cooling Liquid Freezer 120 All-In-One CPU cooler is not exactly anything new, but it is a whole lot of very good existing technology put together into a single package. A proven cold plate, push pull fans, and a huge single radiator come stock, likely how you would spec your own water cooling system."</post>
   <post id="6893d0be-daea-44f0-b630-52f2d1be8c76" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"The review lists 1366 compatibility but the Amazon page does not. Please confirm. Also, link to the 240mm version."</post>
   <post id="dbf5ca4f-7a03-4418-b995-2799694398d6" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"jfreund said: ↑ The review lists 1366 compatibility but the Amazon page does not. Please confirm. Also, link to the 240mm version. Click to expand... Arctic does not list compatibility with 1366 on its website, so I have removed that from our review. YMMV."</post>
   <post id="291288b9-4ccd-4123-9bb3-5f3af328aeb6" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Holy hell. If the 120mm model performs that well I wanna see what the 240mm one does."</post>
   <post id="0cd14157-acf5-4f19-9325-942057368cd9" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"BELTED AND DEEP...GOING BACK...BACK THIS ONE IS OUT OF HERE!!"</post>
   <post id="d873e709-fb2a-41fb-97d1-54309808c09c" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Wow, the dollar / performance ratio is impressive and the low noise makes it better."</post>
   <post id="e4dcb67f-813e-4fae-bd61-9102df2c40ca" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Impressive, very good performance and very quiet at a sweet price, definitly going on the shortlist. Will be interesting to see if the same holds true for the 240mm version."</post>
   <post id="9ea28e7c-02bc-4ee4-af51-9207760675cd" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Thinking Marc should send me this to replace my H80i with.... Maybe."</post>
   <post id="d9b15ce4-001a-42c3-b874-ce0c25e4fb8a" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Like what everyone else are saying, can t wait for the 240mm"</post>
   <post id="7a9fd142-e0ff-4bc1-9b76-c3d2137f21de" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"That s awesome for $70! And the 240mm version is only $80 on Amazon with Prime shipping. Yeah...I ve been looking for something to replace my H80i, Think I found it."</post>
   <post id="ef0501d1-335e-4f0b-a155-7b5416a691e7" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Wow. I ve basically ignored AIO coolers to date- spend my limited budget elsewhere. The performance of this might finally change my mind. Will definitely keep an eye on these."</post>
   <post id="82477b75-110c-4fb4-b73c-49da85b195da" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Very impressive performance for sound volume . One question on back plate, looks like that crossbar is back plate for Intel but how does it clear the stuff on back of Intel socket (center) ? To bad no pic of back, that would of cleared it up I think ."</post>
   <post id="976b226d-4a5e-429c-af9d-dd53a7344137" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Wow, impressive technology. I hadn t considered AIOs before but that could change. Question for you - I currently have an older system with a Thermalright TRUE Spirit cooler and will be building a new system this year. Is this good enough to justify replacing the cooler in the new system? Edit for speeelungg"</post>
   <post id="130daa1a-3ca0-46b1-86e4-e289d163f1a7" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"THis was the most hilarious review I ve ever read. I m going along and with each result, I m going "huh, that s really good." Then the dbs, and I was really impressed. Then I hit the price. $70 for damn near the best cooling on the market?! Seriously laughed out loud and threw my hands up in the air. I ll be looking for these to be available locally, and then I m finally jumping on the AiO bandwagon for my main rig!"</post>
   <post id="9f7d34aa-d56e-4f6a-9e79-2b60a4ade2e6" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"It s $95 now. The 240 variant is actually cheaper."</post>
   <post id="0ec09ed3-d0cf-4599-87eb-f8350c4eafd8" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"ianken said: ↑ It s $95 now. The 240 variant is actually cheaper. Click to expand... WTF? List on the thing is only $85. Amazon screwing us?"</post>
   <post id="88a5dcf7-44be-4205-bf98-4b7f96b3479a" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Kyle_Bennett said: ↑ WTF? List on the thing is only $85. Amazon screwing us? Click to expand... If a pile of readers read the review and bought them I can see some back end automation jacking up the price due to demand."</post>
   <post id="48958c15-0053-4e7e-9a04-dbc4b2ee7d99" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Amazon sold out. Only 3rd pary sellers right now."</post>
   <post id="6fc4a08f-29d7-4b64-a814-bbb1689170cb" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"The 240 for only $79.99? *jaw hits floor* *schwing factor 10 Mr. Sulu* Also, is it me or do the retention rings look very very very exactly like the original Corsair H50 retention rings? (I had a few H50s)"</post>
   <post id="fa371bc3-06bd-478f-bce9-b6b4c4b269fe" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 120 AIO CPU Cooler Review @ [H]">"Damn, should have read this review earlier, I missed earlier price, now the 240 is cheaper. Hopefully Amazon will order more and the price will go back down."</post>
   <post id="2f87dbab-f9f7-4c56-a4f0-0f998313241f" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"SilverStone Argon Series AR07 CPU Air Cooler Review - The Argon Series AR07 CPU air cooler is billed by Silverstone as being, "For users looking for a no-nonsense top performing cooler without the premium price, the Argon AR07 is the perfect choice." Three heatpipes, some fins, and a 140mm fan is no-nonsense in our book, so how does it cool?"</post>
   <post id="4df4d191-3964-4e75-aafd-8ec1b54aa407" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"The AR07 can be purchased for $0 with Free Shipping."</post>
   <post id="b3b72c1c-89c2-4e45-ac5b-0fa48423eb90" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"Looks like a value buy. But I think there are better values on the low end. Why are Cooler Master Hyper 2 EVO s off the list? I KNOW they have been on the market for YEARS, but they are still compatible with today s sockets. And My Overclocked 4.4GHz IvyBridge never passed 70C with these. (Linpack and Prime95)"</post>
   <post id="d0007109-c588-4ebc-9186-e96bc6353472" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"DigitalGriffin said: ↑ Why are Cooler Master Hyper 2 EVO s off the list? Click to expand... We have never reviewed those that I see. FWIW, CoolerMaster will no longer sample us."</post>
   <post id="99191dc7-db6a-4cb3-8b7a-7d8e4d7d5a9a" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"Shame on the CM 212 EVOs. They are currently (and have been for years) my default HS for systems that I build for friends and family. Would love to see how it stacks up against more modern systems."</post>
   <post id="f9355fc4-80bd-47d1-b297-54ec966910b9" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"Sweet cooler for the price. And though this is not likely to matter for the cases it will end up in, that is one dorpy looking fan. It s like someone recycled R2D2 into fan parts."</post>
   <post id="769042bc-baae-4ef7-a99a-69b3ebf66c4c" section="Overclocking and Cooling" discussion="SilverStone Argon Series AR07 CPU Air Cooler Review @ [H]">"Modred189 said: ↑ Sweet cooler for the price. And though this is not likely to matter for the cases it will end up in, that is one dorpy looking fan. It s like someone recycled R2D2 into fan parts. Click to expand... Ha. That s exactly what I thought. Also, once I saw the design of the fan, I immediately wondered if that fan can be re-used as a case fan for giggles. The mounting holes look to be located differently than a typical 140mm fan. Any comments on that Kyle?"</post>
   <post id="bc7417da-771c-4f64-9a4c-8dd094c6afd8" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review - Arctic Cooling claims its new Liquid Freezer 240 is "Extremely Powerful yet Quiet," "Designed for Extreme Cooling Performance" and that it has "Optimal Heat Dissipation." This All-In-One CPU cooler has a 240mm radiator that is poised to do great things with a stock Push/Pull 4-fan configuration and excellent cold plate."</post>
   <post id="a42087c7-9e50-4917-a70e-d2341936f03f" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Perfect and directly reflects exactly my experience with this cooler. Keeping my i5 4670K overclocked to 4.6 at ~60c under load blows me away. And it s damn quiet while doing it. It s a shame, but not all that much of one, that they raised the price as I bought mine off Amazon for $80 shipped with Prime. Still, at $100, this is a must buy for anyone looking for an AIO cooler to get the most out of your CPU. Something to keep in mind if you have a mid-tower case, like my Antec GX700, is that you won t be able to fully mount it internally. I had to move two of the fans to the outside of the case in order for the radiator and other two fans to clear RAM and mobo power plugs. She stacks deep with the push/pull config."</post>
   <post id="c68da3b9-8c3d-4f5a-aa08-69ffefd53f88" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"JUST as i was looking for a review of this thing, [H] delivers. thanks! back when i was still using air coolers i exclusively bought AC units (and still do in my server). they ve always been quiet, cheap, and high-performance. glad to see this one falls in line, too."</post>
   <post id="822491a1-ab53-433c-aae3-211747980cc2" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Tempting. Any idea if it s compatible with the NZXT G10? Looks like it from the pictures, but might be of slightly different size."</post>
   <post id="9d91e4cd-f2e2-4472-a81b-127481846d1f" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Any chance that this thing can be mounted to an LGA1366 motherboard?"</post>
   <post id="1111a21b-2431-42a0-b11a-cd5744aba3ac" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"caltech31 said: ↑ Any chance that this thing can be mounted to an LGA1366 motherboard? Click to expand... Read page 2 of the article."</post>
   <post id="b793e4b8-f144-407d-bd84-a05bd959c4b7" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"caltech31 said: ↑ Any chance that this thing can be mounted to an LGA1366 motherboard? Click to expand... You ll need a threaded 1366 backplate. The water block will attach to it easily."</post>
   <post id="33868143-be05-4485-90a3-ef79e43a3916" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"gathagan said: ↑ Read page 2 of the article. Click to expand... The reason I ask is that the spec sheet on the Arctic web page does not specify support for LGA1366 motherboards (nor does the Amazon listing). Just looking for confirmation that it can indeed be attached."</post>
   <post id="ddb6c8ae-65bc-49ce-9a11-ce88bdd5c7e1" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"caltech31 said: ↑ The reason I ask is that the spec sheet on the Arctic web page does not specify support for LGA1366 motherboards (nor does the Amazon listing). Just looking for confirmation that it can indeed be attached. Click to expand... If the specs say no, then assume no. Although, anything can be made to work depending on how good you are at modifying or have an existing threaded back plate."</post>
   <post id="70be2358-0e37-4ec3-b135-bfd9346caf32" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"I have both the 120 and 240 versions. I have the 120 on my i7 930. The top mounting bracket will fit both 115x and 1366. The backplate only fits 115x. I recycled the 1366 backplate from the TRUE 120 I had on the board, and the AC mounted perfectly."</post>
   <post id="c8ac15fc-133f-4775-8c01-3d713579d699" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"jfreund said: ↑ I have both the 120 and 240 versions. I have the 120 on my i7 930. The top mounting bracket will fit both 115x and 1366. The backplate only fits 115x. I recycled the 1366 backplate from the TRUE 120 I had on the board, and the AC mounted perfectly. Click to expand... Awesome. I think the Corsair H60 I have on it now required a threaded back plate. While it probably doesn t make sense to put more money into an older platform, those hexacore Xeons are just so much fun to overclock."</post>
   <post id="02f3f0c1-6c0e-4a4e-8ed7-f401e47eb6ab" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Questions: I did not see anything on the fan speeds. Did you just run the fans at the default setting? Also - for the fans and the pump, did you use the fan headers on the MB for power and to control the fan speeds? I currently run a Corsair 100i but I really don t like the the software. Plus, this cooler should be a lot quiter."</post>
   <post id="5b2df34d-fc19-480b-b0e9-22ba276fee5b" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"Odd off-the-wall question: If one buys this and their case can t handle the extra room of two layers of fans, how much worse would this honestly run with just one layer of two fans?"</post>
   <post id="cdf92106-61f0-4f85-9bef-ebea4be708a0" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"twzTechman said: ↑ Questions: I did not see anything on the fan speeds. Did you just run the fans at the default setting? Also - for the fans and the pump, did you use the fan headers on the MB for power and to control the fan speeds? I currently run a Corsair 100i but I really don t like the the software. Plus, this cooler should be a lot quiter. Click to expand... I think the fans are 1200 RPM, and I run them full speed off a mobo fan header. Pump is run off a fan header as well. ir0nw0lf said: ↑ Odd off-the-wall question: If one buys this and their case can t handle the extra room of two layers of fans, how much worse would this honestly run with just one layer of two fans? Click to expand... Not sure it would be as efficient. I couldn t find all 4 inside my case and had to mount two on the outside of the case."</post>
   <post id="a5d5d28f-fabf-4b6d-a1eb-fff39696c3df" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"This is essentially a Corsair H105. Both are 38mm thick radiators."</post>
   <post id="4a9810e1-1a51-44d6-a35d-db9dd8d27866" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"savagepagan said: ↑ This is essentially a Corsair H105. Both are 38mm thick radiators. Click to expand... Yeah, same thickness, so they must be exactly the same...."</post>
   <post id="becb28e7-f86f-4daa-aa2f-49d403434bc1" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"are those sound levels at full bore and at idle? or an average? 40db is nice but would like to know what the worst and best case sound levels really are. Any whine or mechanical noise from the pump?"</post>
   <post id="682692bb-ab6b-4abd-8506-6afe8ce25494" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"gigatexal said: ↑ are those sound levels at full bore and at idle? or an average? 40db is nice but would like to know what the worst and best case sound levels really are. Any whine or mechanical noise from the pump? Click to expand... Fans only run at one speed, max. At like I said they re like 1200 rpm fans. So, at full bore they are quiet. No noise at all from the pump that I can hear."</post>
   <post id="06e1da2e-8e61-4269-9d06-ecb3df7a69e1" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"I think I just might buy one now. Thanks."</post>
   <post id="fc26a2e0-aece-4cae-8784-9347b6963211" section="Overclocking and Cooling" discussion="Arctic Cooling Liquid Freezer 240 AIO CPU Cooler Review @ [H]">"I m interested in this. (I have a Kraken x60 (replaced by the newer x61)), and it s either this or the Kraken x61 for my new build. Kraken is good, but mine has a problem in that the pump stays at full rpm. I ve had it for ~2 years running that way. The Arctic Cooler is cheaper and just as good (or better?), but I am curious about the fan and pump. Looking at the install manual from the AC website, it seems like you need two PWM headers on the mobo: one for the pump, one for the fans (which are daisy-chained together). As long as your mobo PWM fan headers can sustain the current requirements. So, given a CPU FAN and a CPU OPT header, you can use the BIOS fan controls to set the pump and fan profiles. Does that work? Thanks."</post>
   <post id="ec6c26df-0300-4d10-9c8d-56ed4002e452" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Thermaltake Pacific RL240 Water Cooling Kit Review - In a world now filled with All-In-One CPU coolers, Thermaltake takes it old school with a water cooling kit that has everything you need from A to Z. If cutting your hose to length and perfecting the layout and presentation of your cooling loop appeals to you, Thermaltake makes it easy with a one stop shop."</post>
   <post id="f45df13a-2f9e-43a0-8e58-0ad032c775c8" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Interesting, but yeah the fact that it doesn t include push pull from the get go is sorta lame. It d be interesting for someone a bit more versed in custom loops to give a ballpark for these parts sold separately. edit: Like mister Nicepants said above, seems like this is the same sort of compromise with buying a system vs. building it. Yeah the flashy parts (CPU/GPU) might be the same, but all the supporting parts are not going to be as high quality, but it might be a bit more affordable in the short term. edit edit: His comment seems to have vanished...."</post>
   <post id="231aff0a-f462-4ea4-ad09-bd43dc2fb9e8" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"It looks nice..."</post>
   <post id="3569f10c-47b1-405b-ac3f-8e8cd188c0f6" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Apparently my original comment was removed. I removed your comments due to use of profanity and how you directed it at the system. It was just simply not needed in a review thread. Since you have PMs turned off, I did send you an email explaining my actions and asking you to please post again without the profanity. - Kyle I realized after I wrote it that I never really paid attention to the other AIO system reviews, and it looks like pretty much all of them appear to have the same problem - i.e. aluminum radiator with copper CPU block. In the reviews I checked, [H] doesn t specify if it s just the fins that are aluminum (and maybe the tubes are brass) or if the tubes are in fact aluminum. Corsair s review at least notes copper microchannels - does that mean the rest of the AIO s listed with  aluminum radiators  are 100% aluminum? Regardless, guys, there s no reason to risk your system on such a stupid design decision. TT, NZXT, Silverstone, Aquacharger, just don t. Seriously. Some would say I m nit-picking and that an anti-corrosive cooling fluid or nickel plating makes everything ok - maybe it does - but I ve seen what happens when nickel plating quality isn t up to snuff, and when there are good alternatives available that do not have this problem, and in many cases cost the same or less... [H], you need to beat up these manufacturers if they re putting any metal other than plain or nickel plated brass or copper, or silver, in contact with our water. No-brainer. This goes for integrated water blocks on motherboards/gpus/etc also."</post>
   <post id="0a186653-07cd-4bd1-9a3f-331a9b66c32f" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"I m sure that I m the type of noob that this review was aimed at. Scared to build a custom loop because they haven t done it before, but runs an AIO water cooler all day without a care in the world. Thank you very much for the information on the kit and how it performed. I don t have my custom loop detailed in my signature yet, but may I ask how do you get all the air out of the system? This is one article that I wouldn t mind watching a video about. Like a common water cooling rookie s mistakes to look out for. And I want to add that all of the helpful tips and images detailed in the article are getting ordered from Amazon this weekend. I was wondering how to get those pesky compression hoses to stop aggravating me. Wish I knew that the grease a week ago! Thanks again guys! [H]ardocp / [H]ardforum is the best place for a hobbyist to hangout at."</post>
   <post id="7af47400-6b60-4f65-b2e7-8428a2fcdc2c" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"As long as it s cheap I don t see a OMG $280.. Also Aluminum radiator? Seriously? Especially for just cooling the CPU I could build a much better setup for $100. In fact, lets try. 2x120mm copper radiator for $53 $17 copper water block. I actually use this on my FX-8350. $40 water pump, similar to the kit. Not my first choice, but whatever. Buy car coolant and some cheap tubing and you re done. Ok not exactly $100, but more like $150, but at least it s copper."</post>
   <post id="4856a76b-884a-419f-a838-9a50ba91bd2c" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"DukenukemX said: ↑ As long as it s cheap I don t see a OMG $280.. Also Aluminum radiator? Seriously? Especially for just cooling the CPU I could build a much better setup for $100. In fact, lets try. 2x120mm copper radiator for $53 $17 copper water block. I actually use this on my FX-8350. $40 water pump, similar to the kit. Not my first choice, but whatever. Buy car coolant and some cheap tubing and you re done. Ok not exactly $100, but more like $150, but at least it s copper. Click to expand... Or for not using ebay: Laing D5 - $95 on Amazon MCR220 or whatever - $50 at swiftech Name your top of the line CPU block - $65 (again using Swiftech as reference) $70-ish left for fans, whatever reservoir you want based on case layout, tubing, fittings, and a silver coil for your distilled water. Aluminum radiators are the norm. Out of curiosity - if this AIO wasn t made by Thermaltake, would you have read the review? I freely admit that I didn t really pay attention to any of the previous AIO reviews because I didn t need one, and I assumed that they were all basically the same with decent parts. It was the Thermaltake name that made me look at this review, thinking in the back of my mind "I wonder if they managed to [censored] this one up". After I let loose in a manner much less polite than you, I realized that there are really only 2 companies (maybe) that HAVEN T [censored] this up. I also learned that apparently I have no idea how to enable PMs on this forum."</post>
   <post id="934ee2e1-8cd6-4c1d-b18f-bee6d09fa5c1" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"sure have come a long way since the Aquarius 2 kits! that was the first kit I ever installed, home brew was still much better. Thermaltake Aquarius II Liquid Cooling Review » Page 2 - Closer Look"</post>
   <post id="f01be435-6101-44ab-9511-8ded061c8b96" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Nicepants42 said: ↑ Or for not using ebay: Laing D5 - $95 on Amazon MCR220 or whatever - $50 at swiftech Name your top of the line CPU block - $65 (again using Swiftech as reference) $70-ish left for fans, whatever reservoir you want based on case layout, tubing, fittings, and a silver coil for your distilled water. Click to expand... $27 for Delphi water pump. That other pump wasn t my first choice, but I was trying to match what the kit had. Aluminum radiators are the norm. Click to expand... Only if you have an aluminium water block as well. Otherwise you get electrolysis, and the aluminium will eat away. Ask me how I know about this? BTW, you could get away with it using car coolant, since it s really good at preventing electrolysis, but why take your chances? Go 100% copper and get better cooling."</post>
   <post id="e56c75db-0505-4ac6-8aaf-b086caaf00c5" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"As a water cooling noobie who wants to breath a little life into his sandy bridge I been debating on a water cooling setup. What I gathered from the review is the hassle and cost of using a kit like this is not worth it when i can just order a Artic Cooling 240 for 99 bucks. But the thought of running it through a video card setup sounds great until i research and discover my msi 970 is not reference so finding a cooler for it is complicated. Some of you guys reference cheap parts on Ebay my concern would be how reliable are these parts?"</post>
   <post id="bb928934-0da3-4659-8356-1f27a0cf69a7" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Erm, would not buy =( But decent effort there TT. Did I miss The Division benchmark review? Going to do one?"</post>
   <post id="e2556a78-c030-4e74-be96-241d2564ac5e" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"That price/performance ratio is the real killer. I know custom watercooling setups rarely make sense on a cost/performance ratio but they re selling this as a one up to an AIO so the fact that you can get an AIO that outperforms it for less than half the price (Galcer 240L or Corsair H110i GT from [H] s own chart) this is a big ask. $199, then they d have a product that might appeal to someone."</post>
   <post id="e332ac9d-6982-4eac-8040-985444eac520" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"DukenukemX said: ↑ Only if you have an aluminium water block as well. Otherwise you get electrolysis, and the aluminium will eat away. Ask me how I know about this? BTW, you could get away with it using car coolant, since it s really good at preventing electrolysis, but why take your chances? Go 100% copper and get better cooling. Click to expand... When I say that aluminum radiators are the norm, I m talking about the fact that nearly all of the AIO s reviewed here have aluminum radiators, and they should thus be dismissed for being disposable garbage. Meanwhile Swiftech and Corsair don t even advertise their radiator material on their AIO product pages - despite being the only two companies I ve been able to find who aren t cutting that corner."</post>
   <post id="c77c087b-a6aa-470e-ad5c-1ff9dffb742f" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"I see a serious flaw in the review methodology. How is it possible that you compare differents kits and only publish temperature data? The reviewed kit features fans @ 1200rpm, whereas the winning kit, Glacier 240, has fans @ 2400rpm, meaning that the noise output is probably 3x on the Glacier. All in all, aooling a pc is not only about performance, but about noise (or lack thereof), and the review doesn t mention anywhere that the product tested might be the lest noisy of the top ten."</post>
   <post id="9575777c-4be0-4dd7-8207-a15e80219764" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Nicepants42 said: ↑ When I say that aluminum radiators are the norm, I m talking about the fact that nearly all of the AIO s reviewed here have aluminum radiators, and they should thus be dismissed for being disposable garbage. Meanwhile Swiftech and Corsair don t even advertise their radiator material on their AIO product pages - despite being the only two companies I ve been able to find who aren t cutting that corner. Click to expand... By all means, please make our thread to DISCUSS THE REVIEW your personal page for an aluminum radiator diatribe. GO MAKE YOUR OWN THREAD. Jeez..."</post>
   <post id="3c0e3717-a904-4942-ad58-4efe23f1544b" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"prava said: ↑ I see a serious flaw in the review methodology. How is it possible that you compare differents kits and only publish temperature data? The reviewed kit features fans @ 1200rpm, whereas the winning kit, Glacier 240, has fans @ 2400rpm, meaning that the noise output is probably 3x on the Glacier. All in all, aooling a pc is not only about performance, but about noise (or lack thereof), and the review doesn t mention anywhere that the product tested might be the lest noisy of the top ten. Click to expand... So would you like us to replace every stock fan with a can rated at a certain CFM so airflow is the same???? We test the units as those are shipped and at the different fan speed settings that are represented. A serious flaw in methodology would be changing the product so that it did not perform as it would out of the box for the consumer. As for noise, I guess a chart with decibel levels and a subjective opinion are not good enough for you? Reading is fundamental."</post>
   <post id="2d0cface-4750-4389-84c9-d4960a71edf8" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"prava said: ↑ I see a serious flaw in the review methodology. How is it possible that you compare differents kits and only publish temperature data? The reviewed kit features fans @ 1200rpm, whereas the winning kit, Glacier 240, has fans @ 2400rpm, meaning that the noise output is probably 3x on the Glacier. All in all, aooling a pc is not only about performance, but about noise (or lack thereof), and the review doesn t mention anywhere that the product tested might be the lest noisy of the top ten. Click to expand... On the contrary this review was very helpful to me why would i spend $280 bucks on a cooling system when i can buy the A.C 240 for 99 bucks basically same noise level and performance for $180 less. I been debating for a week about the Thermaltake kits trying to decide if they are actually worth it or not for me. This review pretty much answered my question. Just my 2 cents...."</post>
   <post id="6c76f999-4e91-4a6e-86f2-0464ce606038" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"Kyle_Bennett said: ↑ So would you like us to replace every stock fan with a can rated at a certain CFM so airflow is the same???? We test the units as those are shipped and at the different fan speed settings that are represented. A serious flaw in methodology would be changing the product so that it did not perform as it would out of the box for the consumer. As for noise, I guess a chart with decibel levels and a subjective opinion are not good enough for you? Reading is fundamental. Click to expand... My apologies. I never said anything about testing the products with different fans than those provided by the manufacturer. It also makes no sense. I did read the article but I didn t see the figures for the noise, I missed them somehow. Still, you do not mention those at all in the conclusions. To me, considering that up to 4ºC is within margin of error, all decent coolers perform the same. Unless, of course, try to mount and test the same product several times, which is a time consuming process."</post>
   <post id="f29a74ba-40de-4683-90c9-f994a0b289a5" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"hakstarr said: ↑ On the contrary this review was very helpful to me why would i spend $280 bucks on a cooling system when i can buy the A.C 240 for 99 bucks basically same noise level and performance for $180 less. I been debating for a week about the Thermaltake kits trying to decide if they are actually worth it or not for me. This review pretty much answered my question. Just my 2 cents.... Click to expand... I would never accept data regarding cooling unless several mounts have been done and tested. Why? Simply put, mounting a heatsink or cpu block does have a huge impact on cpu performance, and it is something you don t know unless you do, test, then re-do it. In any case, I would never consider the A.C 240 or any other AIO for that matter to perform the same (let alone better) than any "decent" watercooling kit (at a similar sound output, of course). But still, it is up to the final consumer to decide if the difference in price (which, by the way, is huge) is worth it. On the AC... keep in mind that since its a push-pull unit, it is very wide... PS: and the point of this "expandable" kits is, precisely, that they can be expanded. IF you will never do it, then there is no point in paying a lot more for features you have no use for."</post>
   <post id="58d84bd7-0f62-46b0-a715-01fe229ecd24" section="Overclocking and Cooling" discussion="Thermaltake Pacific RL240 Water Cooling Kit Review @ [H]">"prava said: ↑ I would never accept data regarding cooling unless several mounts have been done and tested. Click to expand... Yeah, we would NEVER do that. What I take away from your posting here is that you know more about cooling than HardOCP ever will, HardOCP does not know how to test, HardOCP s information is of no value to you. Thanks, go it. Please move along and let us discuss our horrible review with people that actually read it. K, thanks..."</post>
   <post id="ad0a03a8-727c-4edc-b733-a6e7a407408d" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"NZXT Kraken X31 All-In-One CPU Liquid Cooler - NZXT is also moving some of its AIO cooler strategy into the realm of making it smaller and more efficient. The Kraken X31 ticks that checkbox plus a few others, such as software control, variable pump speed, 16 inch tubing leads, and a six year warranty. (Place your own "Release the Kraken," joke here.)"</post>
   <post id="6ba7fa37-f2c5-4fb5-b7dd-ac4a6e94ec1f" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"Added this to my i7-4770 last year since the OEM HSF is a piece of crap (found out one core was peaking at 91C while gaming). In a slightly warmer room I see the same idle temps as in your testing, but slightly lower temps under load while playing games (48-51C). This is with the included thermal compound, but I am going to replace it with Arctic MX-4 shortly. RE the CAM software: I have not updated it to the latest version in a long while. That new version looks horrible, though, so I m glad I haven t. The older version of the software was pretty resource intensive, but it is much better in version 3. I was never required to sign up for anything to get the access to all the features in the older version. RE the LED: The X31 does not actually come with RGB LED in the block, and to my knowledge none of the specifications or marketing material say it does. So the LED was not broken because there is no LED. Why NZXT decided to exclude the HUE lighting feature in this cooler is unknown because I can t imagine doing so saves them or the consumer any money."</post>
   <post id="437cd21f-55de-4369-8cbd-7550249e37c4" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"Nice review. I own an NZXT x60, 2 1/2 years old. I m running CAM software, and everything you say about their software is spot on. Additionally, my LEDs (which should be variable, based on temps, if I so choose) do not change. I guess I should be lucky that they come on. My pump doesn t run at other than full speed, but is silent at that 3,000 rpm, so I m not going to RMA it. I ve been sending in bug reports to NZXT via the CAM feedback options. I ve gotten responses, usually within a week. However, CAM has a LOT of room for improvement. Having said that, I still bought an x61, for a new build, last week. (I run my x60, and will run my x61, with Noctua 140mm PWM fans.)"</post>
   <post id="8225796c-0d8e-43d1-bd4b-22e7a065da46" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"Yea, got one when I did my build last year with a xeon 1231v3. Standard seems to be silent mode, I ve never been bothered by temperatures with this, runs fine. Yea, no led. I m also running an older cam, it has a sign in screen, but it has a "skip" button. While I have the software, I have no use for it, so never use it. Bottom line, it runs cool and keeps my cpu cool. I only occasionally hear some gurgling sounds from it, but nothing to worry about. Does what it s supposed to do. Install and forget. This is my first liquid cooling I ve put in my computer, and for this reason, you can put it in and forget about it. No need to worry about the coolant, etc. I worry about cooling with my car, I couldn t be stuffed worrying about it in the computer either. These AIO solutions are great for set and forget."</post>
   <post id="4df5519e-a002-445a-a655-3d1980102887" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"It s definitely a good performer for a 120mm radiator, although it is priced a little on the high side. If it was closer to $60 this one would be a no-brainer if you didn t have room for a larger rad."</post>
   <post id="8a28a795-7c37-47a3-8364-fb06b5a1ef0f" section="Overclocking and Cooling" discussion="NZXT Kraken X31 All-In-One CPU Liquid Cooler @ [H]">"c3k said: ↑ Nice review. I own an NZXT x60, 2 1/2 years old. I m running CAM software, and everything you say about their software is spot on. Additionally, my LEDs (which should be variable, based on temps, if I so choose) do not change. I guess I should be lucky that they come on. My pump doesn t run at other than full speed, but is silent at that 3,000 rpm, so I m not going to RMA it. I ve been sending in bug reports to NZXT via the CAM feedback options. I ve gotten responses, usually within a week. However, CAM has a LOT of room for improvement. Having said that, I still bought an x61, for a new build, last week. (I run my x60, and will run my x61, with Noctua 140mm PWM fans.) Click to expand... ...and now that the new build is put together, I m regretting the Kraken x61. I have the oft-reported "clicking" bug. It sounds like cavitation or bubbling from the pump. RMA fun... Thanks, NZXT."</post>
   <post id="b291d792-42c4-4f78-8c26-5d03de8b1e85" section="Overclocking and Cooling" discussion="HSF replacement for X5560 in a Precision T3500">"Hi all. I have a Dell Precision T3500 with the "Beefier" HSF. Genuine Dell Precision T3500 T5500 T7500 Heatsink U016F As opposed to: Dell Precision T3500 T5500 WorkStation Processor Heatsink T021F Prime95 kicks up to 95C, way too hot for the X5560. I m sure that the TIM is original, so I ordered some Noctua NT-H1. I would like some advice on what kind of HSF to get. Being a Dell, everything is goofy. The dimensions are what confuse me, and fan headers. I ve tried Folding, but the temps seem too high. If one of you has a HSF that you think will work, X58/1366, I have a few things I can offer in trade. Really just crappy stuff. GT 610 1 GB, Quadro 200 or something, Canon G12, etc. Please, Let me know. Wyo."</post>
   <post id="7e4eb778-965b-4bdf-a1e6-de40a14e12ef" section="Overclocking and Cooling" discussion="HSF replacement for X5560 in a Precision T3500">"Try adding fans, if there are none, to the case itself - a better hsf wont do much if it does not get any outside air."</post>
   <post id="2589d038-bb50-4409-a8d8-fceca8b31517" section="Overclocking and Cooling" discussion="HSF replacement for X5560 in a Precision T3500">"I have added two exhaust fans at the back, both 80 s. I have no problem with the idea of adding a side fan, the noise really doesn t bother me. I just need to find someone with a correct size hole drill-bit. And, of course, get the fan, and guard, that I would want for that application. I would imagine that the TIM is original Intel from 2009."</post>
   <post id="cf99f039-05f2-4e52-a1fc-6374bf0aff4b" section="Overclocking and Cooling" discussion="I really need advice">"These damn Thermaltake Riing fans are noisy. They look great, but at lower RPM, they rattle around like a 3-phase motor being single-phased. I hate it. Anyone have recommendations for 120mm fans that can actually handle their low rpm ratings, and are nice and bright? Looking for green illumination. Thanks!"</post>
   <post id="e9c08bad-083a-4851-9167-07486ec54778" section="Overclocking and Cooling" discussion="I really need advice">"Reported for NSFW. Just kidding. The Aerocool Shark undervolts well in my experience. The Corsair SP should be good as well."</post>
   <post id="839f8bbe-42b1-4a9c-ae89-da53f603eae2" section="Overclocking and Cooling" discussion="I really need advice">"I should also mention they are for my radiator, so static pressure is good"</post>
   <post id="7afb6544-49c3-4e76-a557-4891314e0cd7" section="Overclocking and Cooling" discussion="I really need advice">"One friend bought 6 Noctua Redux 120mm 1100rpms and... he told me that was the best choise ever. He is using the fans at 400rpms, no noise and high airflow. Very recommend!"</post>
   <post id="f2257d55-e123-4454-8773-9e2dd18b57ce" section="Overclocking and Cooling" discussion="I really need advice">"wasn t this the BJ thread? somebody complain? I second the sp series. i have a couple of them and they work great at 30%/680rpm(in OHMon). they take about 20% to get spinning, not sure what these numbers equal in volts but you get the idea."</post>
   <post id="d537490a-b123-4f4d-a5db-59b39312ac99" section="Overclocking and Cooling" discussion="I really need advice">"Panaflo or GTFO. Honestly, best fans ever made. Get a set and be happy. They undervolt beautifully and have stupid high static pressure. Oh -- and they run /forever/. I think I ve had the 4 I m using for like... 7+ years? Still work like new."</post>
   <post id="41cd2bfb-e9a9-4d55-9608-34aa70d97283" section="Overclocking and Cooling" discussion="I really need advice">"Awww, my thread got changed. Now is boring booo"</post>
   <post id="8e1ef88a-2b21-42ce-9c7a-16e8ff8a868e" section="Overclocking and Cooling" discussion="I really need advice">"What are your guys thoughts on the Noctua NF-F12 pwm s? Someone convinced me to use these instead of the Corsair SP series and looking at the numbers, it makes complete sense. Much higher static pressure at a much lower RPM, lower max rpm with higher flow. He said he swears by them. Thought i d give them a go. Not cheap though."</post>
   <post id="8dcdf8dd-f0ff-44da-8b77-08dc5a4e484e" section="Overclocking and Cooling" discussion="I really need advice">"Again, nothing beats Panaflos. Except maybe Deltas if you just really hate your ears. That said, not familiar with that specific Noctua model, but I have a lot of their other fans and have been extremely disappointed with performance. Quiet yes. Airflow? Barely. If that s their "high static pressure" line hopefully they d be better, and you re getting recommendations from someone that already owns the things... hopefully he s not an idiot."</post>
   <post id="3718dde0-8f2c-4a46-b1c1-50e36c38fd6b" section="Overclocking and Cooling" discussion="I really need advice">"silent-circuit said: ↑ Again, nothing beats Panaflos. Except maybe Deltas if you just really hate your ears. That said, not familiar with that specific Noctua model, but I have a lot of their other fans and have been extremely disappointed with performance. Quiet yes. Airflow? Barely. If that s their "high static pressure" line hopefully they d be better, and you re getting recommendations from someone that already owns the things... hopefully he s not an idiot. Click to expand... He explained he had been through a lot of fans throughout many builds and over time ended up with noctua s as everything else has been sub par. These things seem super skookum so I ll give them a go. Hey it s not like I m 90 and this will be my last comp build..."</post>
   <post id="5ffdf35e-cc35-42ba-8f01-be4ddd071849" section="Overclocking and Cooling" discussion="I really need advice">"dabomb6 said: ↑ What are your guys thoughts on the Noctua NF-F12 pwm s? Someone convinced me to use these instead of the Corsair SP series and looking at the numbers, it makes complete sense. Much higher static pressure at a much lower RPM, lower max rpm with higher flow. He said he swears by them. Thought i d give them a go. Not cheap though. Click to expand... The Noctuas pretty much all sound like ass, just like the Riing fans (the Corsairs are just plain loud, but they don t have as much motor noise). I never even consider them, and actively avoid buying Noctua coolers despite their quality just so I don t have to try replacing their stupid fans. People that swear by them usually have never really tried anything else, I mean I have Cooler Master fans with molex power from some case built in 2009 that are quieter, move more air, and have lasted longer than my NF-F12 s (out of 4 I bought, only 2 survived past three weeks). The only Noctua I ve ever had that was acceptable was the Redux 140mm which uses a different motor, ironically to be cheaper and it doesn t have the awful PWM clicking all of the others have. The only fan I ve used recently that was worth its price was the Fractal Venturi. I bought two for my H105 and quickly bought 4 more just to have. Amazingly quiet fans, very heavy with no blade flex. Rubber corners, PWM control with zero motor noise that I can detect. Good static pressure design for the blades. I recommend them to friends all the time who ignore me and buy flashy LED fans and then bitch about the noise ."</post>
   <post id="ed378db9-4823-43b2-8a44-812e2b951f74" section="Overclocking and Cooling" discussion="I really need advice">"Im using Gentle Typhoons on all my rads and I don t regret."</post>
   <post id="6b2f9026-0cbe-4ff7-b88e-dd50b87b580a" section="Overclocking and Cooling" discussion="I really need advice">"Ek vardar. Running F2 at ~ 800rpm. Had sp120, now have ek vardar - just a much nicer fan all round. Also, doesn t look like something from Pimp My Ride, which is a bonus."</post>
   <post id="08f398de-acdc-4ebc-8e89-5e4cd6e2f824" section="Overclocking and Cooling" discussion="Dell Precision T3500 HSF Replacement">"I know it s a longshot, but I thought I d ask. I ve a Precision T3500 with a Xeon X5560. It has the "upgraded" HSF, lower TDP models came with an all aluminum HSF. Anyway, Prime95 is really heating things up, like 90C. That s weird since throttling should kick in by then, but doesn t. Idle is around 40-45C, stress under games, 58 to 75C. There is no way to control fan speeds through BIOS. The fans never ramp up. I ve added one 80mm exhaust fan, through Molex. Everything is pretty much dust-free. As this is an old computer that was donated to me I m sure that a re-application of AS5 is in order. But if that doesn t help, do any of you have any recommendations for a new HSF? The Dell Precision T3500 case is mid-tower, and pretty tight. Thanks!"</post>
   <post id="2d1f208b-4b7d-46cf-985b-ccb6cd21285d" section="Overclocking and Cooling" discussion="Dell Precision T3500 HSF Replacement">"shhh... don t mention AS5 around here. people hate on it so bad! I love it and still use but I just don t tell anyone anymore, my dirty little secret. if there is a bios option to turn off the fan warnings you could always connect it directly to a molex for full rpm all the time. or you could get a fan controller to manually adjust it. as far as replacing the HSF you prob could find something better. you will just have to measure approximate dimensions, especially height. but if the board isn t controlling the fan now you will still have that issue with a new hsf."</post>
   <post id="036b9466-e3bc-4a2a-b1a3-16622935fe4f" section="Overclocking and Cooling" discussion="Dell Precision T3500 HSF Replacement">"Ok, thanks."</post>
   <post id="46a94b12-cbb0-48ef-85c3-bd7aed00683c" section="Overclocking and Cooling" discussion="Dell Precision T3500 HSF Replacement">"I have ordered Noctua NT-H1."</post>
   <post id="a00c24b9-8161-4820-adcb-d57005ac6501" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Hi all. Dell Precision 3500, X5560, with the "better" HSF. Idle: 50c Max: 90C Prime95, after 20 : 90 C Gaming, 100c plus GTX 750 Ti SC Any help would be much appreaciated. It s an older computer, it was donated to me by a wonderful person from the {H}. I don t really much from your input, just cooling ideases. Thanks, in advave. Wyo/Kevin."</post>
   <post id="e29ee9ad-c340-4d96-9d76-0fb375d5c0d5" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"What s your budget? I don t know what the "better" HSF is, but you will benefit with almost any aftermarket tower cooler. Just make sure it comes with LGA1366 mounting. The Nehalem chips were also pretty sensitive to memory settings where adding DIMMs and clocking over the baseline 1333MHz would significantly affect CPU temps. I haven t followed cooling options in the sub-$50 range, but a used unit like this Noctua has terrific value for performance. Unfortunately it won t come with the NT-H1 thermal paste so you ll have to find an alternative elsewhere (or contact the seller for an alternative if they have any of those single use ones lying around)"</post>
   <post id="79eab5b5-3a7e-45b0-a41e-19a8b783f65f" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Well, you may have the "better" tower cooler, but I ve never been a fan of Dell s ducted/ductless passive cooling system. But if you re set on keeping it here are some tips: 1) Are the front fan and heatsink clean of dirt/grime from front to back? 2) Remove the cooler and clean/scrape off the old crusty thermal stuff (it doesn t last forever) and apply something fresh, like Arctic Silver or Noctua s excellent NT-H1. 3) Apparently it will accept 60 or 70 mm fans. Find a quality small fan (something like a 60mm Noctua A6x25 or 70mm Evercool EC7025M12CA) and zip-tie it to the back side as a pull. 4) You might also get more airflow from a new 80 mm (best guess from pics) front fan. If you can stomach the cost of a new cooler, you ll see massive improvement from Noctua s NH-D9DX i4. Height is a huge problem with this case, so don t bother with looking at 120mm fan based coolers, (sorry rastaban, I have 3 of them; fantastic, but way too tall), and even with this one that hard drive bracket will need to be removed (use the drive bays above, and no promises that the side panel will still close. Bust out the ruler, you ll need &gt;110 mm of space between the top of the CPU socket and the side of the case."</post>
   <post id="1eb1d80b-91b1-47e5-87ff-82d26e1f421a" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Grebuloner said: ↑ If you can stomach the cost of a new cooler, you ll see massive improvement from Noctua s NH-D9DX i4. Height is a huge problem with this case, so don t bother with looking at 120mm fan based coolers, (sorry rastaban, I have 3 of them; fantastic, but way too tall), and even with this one that hard drive bracket will need to be removed (use the drive bays above, and no promises that the side panel will still close. Bust out the ruler, you ll need &gt;110 mm of space between the top of the CPU socket and the side of the case. Click to expand... Good call on the height. I should not have assumed it was a standard ATX midtower."</post>
   <post id="c46be861-4651-4799-8532-dfff79a18fd8" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"rastban, Grebuloner, Thanks a lot for the info. But my conundrum is this: how to better cool a Dell T3500 chassis. The X5560 seems to be running way too hot, as originally postet. Space is at a premium. It s just a mid tower. Any ideas? I have zero money to throw at this problem, and as Summer creeps up to us here in Illinois, I ll just have to forgo computer usage. Honestly, Prime95 at 98C, X5560 is rated much lower, an old game, Left For Dead, still above 80C. Can any kind of modern HSF solution help me? Keep in mind, Dell Precision T3500. X5560. Evga 430 Watt PSU. Thanks!"</post>
   <post id="4fe69acc-9056-4565-8206-d1206b70dc00" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"The stock heatpipe cooler should work fine at stock speeds for that CPU. The problem is that the fan setup pretty much sucks. Add a decent fan to the cooler in a pull configuration and it should drop your CPU temps significantly. My recommendation if it will fit is a Rosewill dual ball bearing 120mm fan. $9 with free shipping should take care of your problem. Even if you have to make a duct out of cardboard or something to be able to mount the fan further back so it will fit, I would still go with that instead of a smaller, lower flow fan. Rosewill RFX-120BL 120mm 2 Ball Bearing Blue LED Case Fan with Fan Controller Set - Newegg.com And also make sure to replace the thermal compound. The stock crap tends to separate after a while and cause overheating. No aftermarket cooler will fit as Dell uses a proprietary mounting system"</post>
   <post id="ea0c2263-5529-4471-ae56-1ed494b93346" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"What kind of fans are there in that chassis? Is it just a single 80mm exhaust fan and something similar on thr heatsink? If so, I would cut out all the mesh from where the rear fan mounts, there may also be some mesh and a spot in the front and add a fan in the front as well. Any pictures would be helpful as well."</post>
   <post id="67ef27d1-249d-4dd5-ae1b-cabcf2d8b554" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Wyodiver said: ↑ rastban, Grebuloner, Thanks a lot for the info. But my conundrum is this: how to better cool a Dell T3500 chassis. The X5560 seems to be running way too hot, as originally postet. Space is at a premium. It s just a mid tower. Any ideas? I have zero money to throw at this problem, and as Summer creeps up to us here in Illinois, I ll just have to forgo computer usage. Honestly, Prime95 at 98C, X5560 is rated much lower, an old game, Left For Dead, still above 80C. Can any kind of modern HSF solution help me? Keep in mind, Dell Precision T3500. X5560. Evga 430 Watt PSU. Thanks! Click to expand... We can t help you too much if you don t have the money to spend, because at the absolute minimum, you need to replace the stock paste with a fresh application. If the cooling has never been touched as long as you ve had it, the TIM has long worn out. Even the nice stuff I reapply every few years on my machines. You can buy a tube of the Noctua NT-H1 for less than $7, and it will last you awhile. If you don t address this at the least, summer/winter temps won t matter, the CPU will just fail, and it s already cooking itself. Noctua is one of the few manufacturers of server-grade/compatible HSFs that aren t vacuum cleaners in noise output and still do an excellent job. The D9DX I linked should fit (again, ruler, and I suppose you should measure the distance between the mounting pins on the heatsink and make sure they are the same as the intel spec: 80mm hole to hole around the outside) and is well worth the investment. Replacing the front two fans with spare 80mm fans if you can get them will drastically improve airflow, then moving the old ones to the rear of the case where the open mounts are, or adding a small fan to the stock HSF."</post>
   <post id="5bdeb42d-2dc4-42e6-86de-37487216e2b9" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"NT-H1 is the only paste I ve used for many years myself. Not sure what I can say about the rest, have never owned a case myself that wouldn t take 120 s, but have read over time Noctua makes some nice lower profile air ones, just never had the need to use one."</post>
   <post id="a63751bc-4678-4b5e-8940-368c2d2600d1" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"I m pretty sure the stock heatpipe cooler is enough for that cpu. If that pc has a duct to the cpu cooler you may need to remove it and add fans in the front. Dell seem to have deisgned cases like that to produce the least amount of noise and use least amount of fans while keeping things at "goog enough" temperatures. Unfortunately that means there is barely ant airflow. Probably just removing the side panel would improve temperatures."</post>
   <post id="b3f5449e-d395-443b-b380-816f5cdcf4d4" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Koween said: ↑ Probably just removing the side panel would improve temperatures. Click to expand... This and reapplying thermal paste."</post>
   <post id="1eab1b54-6e79-43dd-96f8-fba06e910a2b" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"There are tons of cheap cases out there -- throw your components in a $30 Rosewill or something, get rid of the tiny, poorly laid out Dell chassis."</post>
   <post id="26163280-e9ed-456d-8d7e-3e6a0c47fbb1" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"silent-circuit said: ↑ There are tons of cheap cases out there -- throw your components in a $30 Rosewill or something, get rid of the tiny, poorly laid out Dell chassis. Click to expand... The T3500 does look like it may use a standard ATX form factor motherboard so that may be an option."</post>
   <post id="0a4b3c88-cf9c-43fc-847d-e5b4c7c9d72b" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"Cooler master hyper 212 evo is an awesome unit. I ve ran that for a while with good results. Really good price too, cant go wrong."</post>
   <post id="867cb687-ac81-436e-8405-f71c065ecd3f" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"dabomb6 said: ↑ Cooler master hyper 212 evo is an awesome unit. I ve ran that for a while with good results. Really good price too, cant go wrong. Click to expand... Again, The Dell cooler mount is non-standard. A custom made mounting system would be required to mount a 3rd party cooler.. or even a stock Intel cooler."</post>
   <post id="aa30c45a-7941-4b08-82ba-f2b76cd46135" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"So. Zip ties."</post>
   <post id="5a2d0f79-7af1-494c-bf6a-067d69669ed0" section="Overclocking and Cooling" discussion="Air cooling question, recommendations.">"silent-circuit said: ↑ So. Zip ties. Click to expand... This. Or build time!"</post>
   <post id="af002647-3846-4a4a-a22a-91bcb51663f9" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"Getting my parts tomorrow and my first water cooler, h115i. How do I check for leaks so it doesn t destroy everything. What should I do?"</post>
   <post id="c992bc0c-0ee5-4696-9eac-4156dfc6888d" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"Don t be so paranoid. There s very very, very low chance it s going to leak."</post>
   <post id="ad875d25-ba7b-4b64-a9eb-48a9ead9691c" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"Could just hook it up to a powers source of another machine and let it run I suppose. If you have no other machine to test you could install your parts with the stock cooler/temporary cooler if you have one and run the AIO outside the case powered by the PSU."</post>
   <post id="e5569ad5-2a2f-4c1b-939a-57658e7364fc" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"that s the easiest way if youre really that worried. but I wouldn t be. did this the other day to fix an airlock in a H60."</post>
   <post id="7239d060-cee4-445f-9806-fa9bf278e3d8" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"The cooler should be filled with non-conductive liquid. Even in the event of a leak, it should not destroy the parts. You just have to deal with the messy liquid/oil."</post>
   <post id="c0c4659f-cb39-407a-9158-63d162351a05" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"the leaks are rare but they do happen, and i really doubt those coolers have nonconductive liquid in them, all you need to test it is turn on the pump, so connect it to another running computer or a 12v battery and let it run for 15-20 min"</post>
   <post id="4f0f4cc8-58d9-4908-8194-e46fa8995f00" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"I was a little paranoid with my H60 when I first got it about a month ago about leaking, constantly looking..But now that is over and I couldn t be happier with the performance..Much cooler now than my old Cooler Master V8.."</post>
   <post id="03205cf7-00cd-4036-a4ea-34b8d02a5786" section="Overclocking and Cooling" discussion="Check AIO for leaks?">"It may be non-conductive while in the loop. As soon as it exits the loop and comes in contact with a contaminant there goes your non-conductivity."</post>
   <post id="0862081e-7367-400e-ab9f-245651ea1592" section="Overclocking and Cooling" discussion="Overclocking woes">"So, I built the following system a couple of years ago: Intel Core i5-4690K CPU Asus Z97-A Intel Z97 Motherboard 2 x Kingston HyperX Blu KHX1600C10D3B1/8G 8GB DDR3 1600 RAM Samsung 840 Evo Series 250GB SSD XFX TS Series XFX TS 550W PSU Corsair Graphite Series 230T Black ATX Case Cooler Master Seidon 120V Liquid Cooling System I have never been able to overclock it and get it to run stable. More to the point, if I change any setting in the BIOS, no matter how minute, my CPU temps will skyrocket and I will get a BSOD within minutes. For instance, just trying to increase the clock speed by .1ghz will run the cores at +20 degrees from stock. Likewise, increasing voltage by 0.1V will do the same. Any ideas why this may be happening? I know I have not given a lot of specifics. I am hoping someone can point me in a general direction of where to begin looking for the problem."</post>
   <post id="6b026ed7-99c3-4a28-8f66-9d4e60241684" section="Overclocking and Cooling" discussion="Overclocking woes">"What are your temperatures on stock? Is the cooler mounted properly? How are you overclocking? There are many settings that sort of automate voltage adjustment etc., if some of them are on they may overshoot any reasonable values and got o a way too high a voltage."</post>
   <post id="762873a5-7aa4-45e1-a719-0f6d12d72841" section="Overclocking and Cooling" discussion="Overclocking woes">"Koween said: ↑ What are your temperatures on stock? Is the cooler mounted properly? How are you overclocking? There are many settings that sort of automate voltage adjustment etc., if some of them are on they may overshoot any reasonable values and got o a way too high a voltage. Click to expand... So I tried again to get some numbers. Default Bios settings, the cores run at about 27-30 at idle and 79-83 at Prime95 load. Changing only the Vcore from stock 0.993 to 0.995, the cores idle at 33-36 and instant BSOD at Prime95 load. In fact, with the slight Vcore modification, I get a BSOD even firing up an internet browser. There is a 6 degree increase in core temp at idle with such a minimal adjustment."</post>
   <post id="241e7e44-ac6e-43f9-9e90-1a25ba5d478a" section="Overclocking and Cooling" discussion="Overclocking woes">"If you re setting a fixed Vcore of 0.995 of course it s going to crash on load it s not enough voltage. Under load the Vcore should be around 1.10 to 1.15 or so stock. Vcore changes with CPU load and 0.995 just isn t enough for full load. With my 4770K idle Vcore is around 0.12 to 0.20 and full load is 1.232v. You re definitely missing or misunderstanding some settings."</post>
   <post id="4b4783c7-5720-4716-8764-d4f7a7656cf3" section="Overclocking and Cooling" discussion="Overclocking woes">"Perhaps your heatsink is not seated properly. I had a i7 920 that got fried from an accidental water cooling leak. At stock settings temps shot up to throttle levels (85+) with little load. Your processer could just be defective."</post>
   <post id="8641df98-7bd1-4307-a66f-9ac3f0c71522" section="Overclocking and Cooling" discussion="Overclocking woes">"MrGreg62 said: ↑ If you re setting a fixed Vcore of 0.995 of course it s going to crash on load it s not enough voltage. Under load the Vcore should be around 1.10 to 1.15 or so stock. Vcore changes with CPU load and 0.995 just isn t enough for full load. With my 4770K idle Vcore is around 0.12 to 0.20 and full load is 1.232v. You re definitely missing or misunderstanding some settings. Click to expand... It think it is a good bet that I am misunderstanding something. I could OC on Award BIOS with not issue whatsoever. It made sense to me. I just cannot figure out the UEFI BIOS. So, when I adjust voltage, I am setting controls to manual and assigning a fixed value. Instead of manual, should I be using adaptive? Instead of setting a fixed value, should I be using offset?"</post>
   <post id="38a97c2d-9cd0-462a-ad16-45fbc539f959" section="Overclocking and Cooling" discussion="Overclocking woes">"I ll check and see if I can download a manual for that m/b tommorrow and see what sense I can make of it. And yes it s definitely a different art to overclocking with a newer system. If you haven t already give the review of the motherboard that [H] did of that board when it came out and see if that helps any. Introduction - ASUS Z97-A LGA 1150 Motherboard Review"</post>
   <post id="3ed1bf9e-8b01-4298-bfe1-2eb6acd551a3" section="Overclocking and Cooling" discussion="Overclocking woes">"MrGreg62 said: ↑ I ll check and see if I can download a manual for that m/b tommorrow and see what sense I can make of it. And yes it s definitely a different art to overclocking with a newer system. If you haven t already give the review of the motherboard that [H] did of that board when it came out and see if that helps any. Introduction - ASUS Z97-A LGA 1150 Motherboard Review Click to expand... That d be awesome. Just out of curiosity, in stock form, is 82c too hot under full load?"</post>
   <post id="ef05138a-2f7b-4e18-81bc-108609f9f388" section="Overclocking and Cooling" discussion="Overclocking woes">"safehaven said: ↑ That d be awesome. Just out of curiosity, in stock form, is 82c too hot under full load? Click to expand... With the cooler you mentioned in the original post it does seem rather high. Having said that if the only thing you re using to test load is Prime95 you should be advised that in standard form it doesn t play nice with Haswell cpu s. Try using Asus RealBench instead."</post>
   <post id="ca19631c-a285-4794-8c37-339ad8327ee2" section="Overclocking and Cooling" discussion="Overclocking woes">"MrGreg62 said: ↑ With the cooler you mentioned in the original post it does seem rather high. Having said that if the only thing you re using to test load is Prime95 you should be advised that in standard form it doesn t play nice with Haswell cpu s. Try using Asus RealBench instead. Click to expand... Will do. Good to know. I think I have been out of the OC game for too long. So many new things."</post>
   <post id="0d7191bb-8d46-44d9-aa2e-cec8e91743eb" section="Overclocking and Cooling" discussion="Overclocking woes">"If you are setting a fixed value then it s probably too high for idle CPU clocks and too low for load clocks. There are things like "adaptive" or "offset" voltages. I suggest you look for an overclocking guide for your cpu, that would be a good start."</post>
   <post id="a62a0b92-433a-4503-8106-1ebf4851c851" section="Overclocking and Cooling" discussion="Overclocking woes">"Koween said: ↑ If you are setting a fixed value then it s probably too high for idle CPU clocks and too low for load clocks. There are things like "adaptive" or "offset" voltages. I suggest you look for an overclocking guide for your cpu, that would be a good start. Click to expand... That makes no sense."</post>
   <post id="d603ae8c-6b2b-4ab9-9adc-4c4d2aa54cd8" section="Overclocking and Cooling" discussion="Overclocking woes">"I ran RealBench on stock settings and am averaging right at 80c. I m thinking thats a little warm for stock. I think I will reapply thermal paste and reseat the sink. Then when I figure out what the heck I am doing in the BIOS, I know heat isn t the issue."</post>
   <post id="87eb511f-6a6e-4f5e-b6cf-23a587a3fec5" section="Overclocking and Cooling" discussion="Overclocking woes">"Good plan change the paste and check the mounting those temps are high for stock clocks with an AIO water cooler. Double check that the fan on the rad is spinning up and make sure the fan and not the pump is connected to the cpu header. Better still your m/b does have 2 cpu headers use them both one for the fan and the other for the pump. I looked over the manual and without having the bios screen in front of me to compare to I m having trouble figuring out the settings. With all voltage settings on auto just upping the multiplier by one should work. You could even try using the O/C function in the Asus Ai Suite from within windows rather than messing with the BIOS. It probably won t be as high as you could get manually setting everything but should get you started."</post>
   <post id="4221c32e-b185-449f-b46f-95341ec7ec96" section="Overclocking and Cooling" discussion="Overclocking woes">"Some AIO loops are just... Bad. I m not familiar with that specific model. As others have said, reseat the thing and stick to offset voltage rather than manual. What GPU are you running? Anything else in the system you didn t list? I doubt this is a power issue since you are clearly dealing with high temperatures, just trying to narrow it down."</post>
   <post id="2baa9655-6aeb-4588-9f7f-4c4bada2e026" section="Overclocking and Cooling" discussion="Overclocking woes">"So, the water cooler definitely was not seated properly. I had the compound on way too thick. Also, eventhough I had complete coverage on the cpu, the cooler had only made contact on about 90%. Whoops... Live and learn... Won t make that mistake twice. So now on stock settings, it is idling at 25c average. At 100% load, 44c average. What a difference! Temperature problem definitely solved. GPU is a Sapphire 7850 1GB. The only other items in my system that are not listed are 500GB HDD, a 1TB HDD, and (2) 4TB HDD. I am going to try and overclock again. I watched a video and it said what settings to change: AI Tuner ---&gt; XMP (Didn t understand why not to use Manual) CPU Core ---&gt; Adjust to desired multiplier CPU Min ---&gt; Set to same as CPU Core CPU Max --&gt; Set to same as CPU Core Core Voltage ---&gt; Adaptive (I think by selecting this, the mobo will adjust voltage as needed???) Additional Turbo Mode CPU Core Voltage ---&gt; The video set this to 1.2. I have absolutely no clue what this setting does or why it was changed? Do those seem like the appropriate settings to adjust?"</post>
   <post id="df622c37-b6ba-402e-8819-cf8f9f53ced0" section="Overclocking and Cooling" discussion="Overclocking woes">"You can leave min to whatever it started if you like - this just saves power when the system isn t under load, though some swear it makes things unstable. Your choice there really. Sadly I m on an older platform than you and haven t kept up with OC methods, so others will have to help with specifics. Your temps were definitely the problem, so just a question of finding the right settings now!"</post>
   <post id="c65285b4-7e67-434c-bfe6-3ea66383e0b0" section="Overclocking and Cooling" discussion="kinetic energy cooler">"what happen to it?"</post>
   <post id="ffba51d9-6467-419e-bcd7-372207992a8a" section="Overclocking and Cooling" discussion="kinetic energy cooler">"It ends up as heat."</post>
   <post id="37938c17-e22b-4940-85d8-0f67fc072d20" section="Overclocking and Cooling" discussion="kinetic energy cooler">"Nenu said: ↑ It ends up as heat. Click to expand... Oh, you mean vaporware?"</post>
   <post id="6fe0f763-1ac8-41a6-8903-9f9bd4270a4e" section="Overclocking and Cooling" discussion="kinetic energy cooler">"arestavo said: ↑ Oh, you mean vaporware? Click to expand... No, the technology works, there s just no fucking reason why anyone would buy one of these. The spec is 35dB, which is pretty sad compared to cheap 120mm fan coolers. Quieter than Intel stock coolers on quad cores, but how often do people stress out a quad core when browsing the web? And with the extra cost, I doubt Intel would use it. And also, the cylinder has to spin at that speed (2000 rpm) or the boundary effect stops working. This means you ll have an annoying on/off/on/off cycle noise, or you ll have to deal with the fan always on. Sure, they CLAIM it s easy to reduce the motor buzz, but did they fucking do it on their reference design they put in front of press everywherer? fuck no! So it can t be cheap or easy."</post>
   <post id="82151b61-fd7a-4c2b-8e87-7f88598053de" section="Overclocking and Cooling" discussion="kinetic energy cooler">"This thing looks legit. I cant wait until one spins off, rips through both GPU s and expels the contents out of the case. If these guys were really trying to market their product, they need to send one to Linus so he can brick another server."</post>
   <post id="da37b64e-0d2a-4060-9199-346039775a44" section="Overclocking and Cooling" discussion="kinetic energy cooler">"And of course the other problem is cost. That free-floating set of fins is soldered to the base, so that piece of metal ain t cheap. Most of the cheaper heatsinks are extruded, either straight or circular like Intel. Or at most have a second cut at 90 degrees to create more fins with more surface area. Then the next step-up in cost is radiator fins with heatpipes. Soldered fins like that boundary layer cooler is somewhere in-between."</post>
   <post id="e27fd64c-2472-4bd5-aa60-ac6bdee71770" section="Overclocking and Cooling" discussion="Question for UV Fan gurus">"Can anyone recommend a green 140mm UV reactive fan? I have been looking around, but they are either noisy with low cfm/pressure, non-existent, or are discontinued. The only one I have found is the Nanoxia CoolForce 140mm, but they are impossible to find. I wish GeLid would make a 140mm green fan . If possible I would like them to have decent air flow as they will be used on a rad, thanks."</post>
   <post id="690ca552-beed-4172-9090-52df03087f74" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"My AIO - Nepton 280 just got 2nd birthday. Since there is no indicator to check, how much fluid is in the loop or how clogged the system is, is there a rule of thumb, how long can it work without issues? Right now the temps are stable, though from time to time, there are some weird noise from pump (usually at startup, then it gets all right)."</post>
   <post id="6683e625-cbc7-4593-9fab-745b77bfcb41" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"Once your CPU starts shutting down or it starts screaming I guess. Got me, is one of the reasons I ve never used one. Still have air coolers that work about as well from 20 years ago still kicking just fine here, on a rig or two."</post>
   <post id="6659888f-0ee4-4871-acf9-547690e9f6bf" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"as it starts to clog you will notice your temps getting higher and higher until you see an instant spike to you max cpu temp. then you know it is clogged. as far a fluid loss, there shouldn t be any lose as it is a sealed system. unless you get a leaky tube or something physically damages it. I was given a corsair h60 that did not work at all. when I installed it on my cpu and started testing the temp would immediately spike to 60c+(amd max is 60-70 not sure which) so i d stop it. what I did was cut off the old tubes and cleaned out the junk(looked like hard water calcium deposits) in one of the barbs on the rad. I flushed it and the pump out really good, refilled it and put on new tubing. since I have my cpu OCd really good and I have read that the h60 could not keep up with my OC I slapped it on my gpu instead. been running great and keeps temps under 50c instead of high 60s low 70c! I was playing apex earlier and it never went over 48c. as far as the noise goes, that could be two things. either air in the pump or an aging pump. air you can fix by tilting the system around to get the pump lower than the rad so the air bubble moves into the rad. I had this issue after refilling the h60. had to get it running and then get the rad higher and jiggle it a bit to get all the air out. temps were fine but it was noisy before doing this. second thing could be the age of the pump. it will wear out over time and will get noisy then the rpm will fluctuate and then it will die. so you will have to listen to it or use something like "open hardware monitor" to watch the rpm of the pump if its on a fan header. if its direct connected with a molex youll have to just listen to it."</post>
   <post id="7d6a7779-6d8c-4a61-881a-1cef01face83" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"I ve always worried about the same things with my AIO. That said, my H50 has been going strong for 5+ years. I ll be swapping it out when I upgrade to a Xeon processor. Replacing it with an Arctic Liquid Freezer 240 based on the excellent reviews. Should be here tomorrow...they re kind of hard to find. Originally purchased one on eBay but the seller flaked out, so I ordered another from Amazon. As far as I know, no one has come up with a way of monitoring the life cycle on AIO units. When they die, you ll know. I had a scare a couple of years ago when the fan header powering my H50 s pump died. CPU temps spiked and my monitoring software started going nuts. I imagine as long as yo have some sort of warning or failsafe in place there s not much to worry about."</post>
   <post id="3a190ff6-f9d3-4027-939b-228932ad0a64" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"Have had a h100i for the last 4 or 5 years. Still cooling well. I think you will obviously see when it is the time to replace. I doubt they have a hard expiration date."</post>
   <post id="cfbe03da-9fe3-4409-8c0d-736d8cc9a6ef" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"How long before a unit begins to leak? that is my concern. that pump going out seems minor because you will usually see that coming. A leak on the other hand of any kind could be disaster for entire rig."</post>
   <post id="d512ecb3-33c0-433a-b2fc-d63dfab28b09" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"Unless you break something it should never leak. Hard hoses can crack with too much force, usually at the barbs on the rad. That s about it."</post>
   <post id="8c54f655-4611-4258-835e-ebde2e074a3c" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"pendragon1 said: ↑ Unless you break something it should never leak. Hard hoses can crack with too much force, usually at the barbs on the rad. That s about it. Click to expand... Good to know. I have a 3 year old unit that seems to be fine so far. Thanks"</post>
   <post id="7e14ae95-d100-4849-a2a3-1b2d793509b8" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"No prob"</post>
   <post id="497f26d7-ad7e-47d8-82d7-6f9c31b55954" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"Still running a 6 year old H50 here. In fact it has been unused for the past two years. I have just pushed it back into service in my new 5820K build (3.8Ghz stock volts). Cleaned it up, slapped a little Noctua paste on the CPU, fitted the new mounting kit and away. Still appears to be coping just fine."</post>
   <post id="f74f68d8-053d-49de-9b81-0f8d03ca1622" section="Overclocking and Cooling" discussion="When should I swap my AIO?">"I have an H60 that has been running 24/7 for 5 years or so with no issues. Just checked my order history and I bought it on 4/26/2011."</post>
   <post id="6612c923-64a3-4adb-989a-6bdbd4dd2263" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Hi Folks! Thinking it s about time for a nice Northeast LN2 get-together/party and you re all invited!! The event should be lots of fun! Meet old and new friends, put faces to the nicks, learn from those with more experience (have people to share the misery if you blow something up), bench like crazy and, am sure, down at least a couple beers together. Everyone from monster benchers to noobs, vendors and just regular folks curious about this hobby of ours  are welcome. Most specifics are still TBD but wanted to float the thought with plenty of advance notice. Once we have an idea of how many people might be interested in attending, we ll start researching, identify venues/hotels (with plenty of power for our needs), arrange for plenty of LN2 to go around and determine actual costs. We re also seeking vendors to come and demo their latest and greatest products as well as any potential sponsors. If any of you have contacts and be willing to try to get them on-board, that d be awesome. When: July 23, 24 (preferred) or September 24, 25 (backup). Where: Harrisburg, PA area If you re interested, please take the poll in the main thread at forum.hwbot (Northeast (USA) LN2 get-together! - HWBOT forum) and/or reply in this thread. Will keep you updated on any details or related info as things progress. The more the merrier ihmo so hopefully we can get a good crowd together. If you have any questions or thoughts, please don t hesitate to post here or reach out to me directly at scbesterman@NOSPAMhotmail.com. Look forward to seeing you all there and stay tuned for updates!!!! Very kind regards, -Stefan PS- Apologies if this is in the wrong place..feel free to move as needed :/"</post>
   <post id="23d1038b-7c21-4564-a9ee-7575a5f2139d" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"*bump* Calling out to all you folks in the Northeast! Doesn t matter if you ve never  gone cold  or even done any benching...this is meant as a fun time for all. Experienced bencher? There ll be mass quantities of ln2 for you. Never benched cold? GREAT time to get that first experience with lots of people around to help out and make sure you get the best results out of your hardware. Never benched? That s ok...you ll be able to do that, check out some demos, socialize, drink a couple beers. It s all in the name of big fun, meeting people and generally having a great time."</post>
   <post id="8758d50e-710c-4c4f-a2b6-9d65dea4d590" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"The poll has now been reset. Please check your calendars (and with your SO s hehe) and cast your votes at the main hwbot thread ! Apologies to anyone who already voted...couldn t see any other way to get it right without the reset. :/ We ll see how it goes but we really need to get this figured out fairly soon so, we ll need to start thinking about setting a deadline (maybe 4/15-ish?). We ll play it by ear for a couple weeks and see where we are at that point. Also...it d be great to have extra pots to lend beginners. If anyone has extras they could bring, that d be excellent. Please let me know in the main thread and I ll put updates in the OP. Getting a little excited! Pretty sure we ll have an excellent time. Tia for votes, ideas, etc!!! -Stefan"</post>
   <post id="8cebaf48-a4c7-4645-a926-ce2083f8b726" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"bump"</post>
   <post id="129ad229-48e6-4da8-a58f-385da3c21039" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Humble apologies folks. The moderators couldn t get the poll working properly so the thread s been deleted and a new one (with the proper poll) added. All the votes have been completely wiped out so need everyone to check their calendars and cast their votes. The new  main  hwbot thread is here: Sign-up here for Northeast (USA) LN2 get-together! - HWBOT forum tia!!!"</post>
   <post id="504e568c-1302-4940-8059-d2af3fd88594" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Getting there...something will definitely be happening If you think you might be able to make it to the party, please cast your vote in the hwbot thread. Also...anything ya ll could do to help get people (attendees, vendors, whatever) interested would be awesome!"</post>
   <post id="70c4172e-15b8-4bc0-93c6-6fc4fb6b77a8" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Hiya folks!!! We re on! Based on poll results to date and pm s with various folks, we re looking at roughly 25 attendees on July 23rd-24th. Next steps are to get the venue and ln2 arrangements made. On the venue...Lochekey and aerotracks have said they d help so if you guys could coordinate with each other, that d be great. Figure Witchdoctor and hotrod might also be able to check places as this is in their neighborhood? Hoping for someplace decent but kinda cheap and think the expandable/sectional room idea is great. If we manage to get more people, we can just add some space. Power and air conditioning (and dehumidification?) are super key. I m clueless on those fronts so hoping someone can vet that out for us. We ll want to make sure they ll give us a nice discount on rooms and stuff, too. If you guys find 1-2 places that would work for us, I have no problem making the phone calls, trying to work the best deal for us and getting it booked. Then there s the ln2. Figure 60-75L/person should be plenty. If anyone has a great contact at a local distributor, it d be great if you could start checking with them for estimates (including gas, delivery, tank rental, price matching, etc). Couple of benchers have reached out to me with pricing around $0.38/L so I ll chase up with them for contacts, account numbers, copies of receipts, etc. Will also speak with the guys I get mine from to see if there s anything they could do with the praxair in the Harrisburg area and start trying to get that locked in. Next is the loaner pool for people interested in trying ln2 but who don t have equipment. If anyone has extra stuff they could bring, please let me know and we can start keeping a list. Finally (at least of what I can think of atm) is the matter of vendors and sponsors. A couple guys have said they ll be able to bring some hardware and another has said that once we have a total estimate (venue plus ln2), they will speak with their rep and see how much they might be able to help offset some of the costs. There s been a suggestion that since having sponsors can be a double-edged sword (having to stream video, results, etc) that we re better just doing everything on our own. As I ve never had any experience getting an event together (or dealing with sponsors, vendors, etc)...am very open to everyone s thoughts on this topic! So...that s where we are atm. Again...any thoughts, ideas, suggestions or assistance with any aspect of the event planning or execution would be hugely appreciated! Getting excited now and look forward to meeting everyone there/then!!!! -Stefan"</post>
   <post id="9ceddb6e-8b81-44d7-8a00-539d8c77560d" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"I would be down to come by and check this out. Its about 90 minutes north of me."</post>
   <post id="e119f439-a479-4a9c-9567-37704063b366" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"That would be awesome! We ll have at least a few loaner pots available so bring a setup and you ll be right in the action!"</post>
   <post id="f7b71661-6816-403b-90f9-47d03bf5ddcb" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Booked our venue yesterday so we are definitely on for that weekend in July! We also have our ln2 supplier arranged. We may also have a sponsor or two willing to participate. Once we have the formal quote for the ln2, will relay all costs to the fine bencher who has kindly offered to try to get his sponsor(s) behind us. Once we know the full details of their support (if any), we will then be able to figure out total costs and attendee charges. If any of you have other potential sponsors who might be interested in supporting the event via helping out with the costs, providing stuff for giveaways or anything else, that would be awesome and very much appreciated by all. Once we know the full story will create a formal sign-up thread. Hoping to have that done by the end of next week (or so). Getting there!! Stay tuned!!!"</post>
   <post id="5df9acdb-b12b-4379-b2c5-d0af53ad7db4" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"We re on! Received confirmation that Corsair will be covering the cost of the venue and 2,300L of LN2. This is a free event!! Official Sign-up page"</post>
   <post id="def5fe1a-9885-4a0d-ac36-cde1d2cbbf98" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"scbesterman said: ↑ 2,300L of LN2. Click to expand... Oh my. Open the window at least or you ll have a bodycount"</post>
   <post id="0d6e3688-ce8a-4871-aecc-c084fa407591" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Should be a great time! Yes...we ll make sure we re well ventilated hehe Thanks to Corsair, this is a free party for all! woohoo!!"</post>
   <post id="6e52870d-bc46-4812-8529-5173296f4778" section="Overclocking and Cooling" discussion="Northeast (US) LN2 party!">"Hiya folks! Hoping some of you can make it to the party!"</post>
   <post id="06b5398a-3272-46cd-8225-570a09d5642f" section="Overclocking and Cooling" discussion="Noctua Expands 5V Fan Line-Up">"After introducing its first 5V 40mm fan 18 months ago, Noctua today presented 5V versions of its award-winning quiet NF-A6x25 60mm model. While the new NF-A6x25 5V runs at a fixed speed of 3000rpm, the NF-A6x25 5V PWM also supports PWM for precise, convenient speed control. Both models feature Noctua s proprietary AAO (Advanced Acoustic Optimisation) frames as well as sophisticated aerodynamic design measures such as Flow Acceleration Channels and come with a 6-year manufacturer s warranty. At the same time, Noctua announced that it will further expand its 5V line-up in the near future in order to meet the growing demand from industrial partners and DIY customers."</post>
   <post id="2158a5c6-8c28-4724-af00-ad89608806dd" section="Overclocking and Cooling" discussion="Noctua Expands 5V Fan Line-Up">"So, are they any different from just taking one of their 12v models, using it with a molex adapter, and switching the 12v and 5v lines?"</post>
   <post id="ea032ca4-b6b7-4716-9d17-9df0be09e78f" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"So my old Corsair H70 gave out the other day. LUCKILY a friend of mine had a Kraken X60 he wasn t using anymore (I know, right???). But the problem is that there is no chance it will fit in my case and I like my Cooler Master N200. Running mATX. I like compact. So having said all this I m considering selling it and going back to a single 120mm. Running my 5820K @ 4.5GHz right now and while stress testing the 120mm couldn t hang, in normal usage and gaming it never went above 70C. So how would something like a H80i compare to something like the X60? TweakTown has the H80i cooling better than the X61 on an overclocked 4770K but that doesn t really compare to a 5820K with two more cores. So, yeah, thoughts?"</post>
   <post id="842c4194-7cae-4bed-a707-51ed0ca369f6" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Wouldn t bother with a single 120mm rad on such a cpu, unless you don t care about the noise. A h100i on my 3570k @4.4GHz is barely enough to keep temperatures low enough at acceptable noise levels. Your case supports a 240mm radiator in the front, why don t you go with that?"</post>
   <post id="262b66f7-f93c-495a-98f9-af351c9f43b7" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"A 280 rad has ~20% more area than a 240, and a 240 has 100% more area than a 120. So you re looking at two different leagues of cooler. A 5820K would be alright at 4.5GHz on a 120 AIO, but it won t be ideal. You d be running high-temps under load. You re better off on the 280, finding a way to MAKE IT FIT. Get out the dremmel, figure it out."</post>
   <post id="4f14f58e-7ac5-400f-b358-b931909f386b" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"How about the Corsiar H105? 240mm x 38mm would be well suited for your 5820K."</post>
   <post id="3cedd128-aa0a-4cf1-aac8-5156497ba13c" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"if the case is able to take a 140mm up top then you can make a 280mm fit in the front. like Kazeo said, youll just need to get creative..."</post>
   <post id="be26557d-853e-464c-8afa-4b054cf33827" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"IMO, always get the biggest radiator that your case will support... always. If big enough, your fans may not even need to spin up when idling, so use the room available to you."</post>
   <post id="3a5315bf-3a37-4c4d-a9dc-0a0efa272e64" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"buy a good air cooler forget the aio"</post>
   <post id="7be52f4c-29bc-4e6d-9a8b-f914f8b413a7" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"KazeoHin said: ↑ A 280 rad has ~20% more area than a 240, and a 240 has 100% more area than a 120. So you re looking at two different leagues of cooler. A 5820K would be alright at 4.5GHz on a 120 AIO, but it won t be ideal. You d be running high-temps under load. You re better off on the 280, finding a way to MAKE IT FIT. Get out the dremmel, figure it out. Click to expand... A 280mm rad is like 35% bigger than a 240mm one. The difference is very, very big"</post>
   <post id="995b22fb-5f47-4b08-92ba-9b3fefb00b53" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Jbort1984 said: ↑ buy a good air cooler forget the aio Click to expand... I ve said that several times myself over the years in many places, but people seem to like them. For awhile , at any rate."</post>
   <post id="0142f33b-0d63-439e-973f-05500725d2a5" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"I bought a 360mm AIO Thermaltake rad for my 5820K build. ...and I m glad I did. $120 with max temps so far topping out around 58 C and a lot quieter than any air cooling system I ve ever had before(including OEM). 4.5ghz at 1.19v to 1.20v. I know I have room to push it higher, just haven t tried yet."</post>
   <post id="e705125d-b764-487f-8e70-ed9f8f3f3d1d" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Curious - Does anyone make a 2x180mm (360mm Rad) AIO closed loop cooler there days? or is 2x140mm (280mm rad) the limit for aio closed loop coolers?"</post>
   <post id="d2e61e82-90e1-4104-a407-9b14980a7147" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Basically there are 80, 120, 140, 240 (2x120), 280 (2x140) and 360 (3x120) AIO units out there. I have a 280 on my i7 970. The warmest core is around 41C (105F) With most of the others running between 26C(80F) and 30C (86C)."</post>
   <post id="76c43b8d-2726-421c-941b-e387aa219696" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Chas said: ↑ Basically there are 80, 120, 140, 240 (2x120), 280 (2x140) and 360 (3x120) AIO units out there. I have a 280 on my i7 970. The warmest core is around 41C (105F) With most of the others running between 26C(80F) and 30C (86C). Click to expand... So no AIO Closed Loops with 360 (2x180) Rad that you know of? The closest thing I have found is taking a H50 and modding it use a larger rad like a 360 (2x180). No interested in voiding warranty modding a unit. Looks like I might have to settle for 280 (2x140) rad in a AIO Closed Loop. Thanks"</post>
   <post id="0dcfc085-1e6b-4c7a-8255-a2c8aebdd4da" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Honestly, there s very little a 2x180 AIO is going to deliver for you that a 2x140 won t."</post>
   <post id="a4c6d483-17ab-4d43-bdfb-a585a1dc1a88" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Chas said: ↑ Honestly, there s very little a 2x180 AIO is going to deliver for you that a 2x140 won t. Click to expand... Yeah, you are right. I was only wanting to match the 180mm fans in my Silverstone FT02 case. 2x140 raad will probably fit better anyway with cable management. Any issues with cooling a 2x140 rad with couple 180mm fans?"</post>
   <post id="c3e1dc78-773c-429a-b66a-0c8b5130ee00" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"Depends on if you can attach the 180 s to the rad properly."</post>
   <post id="7826c015-d370-45ad-939e-4646fd5df19d" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"It s not just the surface area of the dual rads that significantly improve cooling over single rads. It s the amount of fluid available to absorb that heat. That s why custom loops are more effective in general, especially if they have a reservoir. I ve used 5 single rad AIO s of different sizes back when Corsair came out with them. I honestly think they are trash compared to a midrange air cooler, and any 120mm Noctua tower will beat the pants off them. In addition, rad fins are impossible to clean (not saying it s easy to clean air coolers) especially the thicker ones."</post>
   <post id="2585cb14-dbd4-4c18-8202-dc615f07c6e5" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"rastaban said: ↑ rad fins are impossible to clean (not saying it s easy to clean air coolers) especially the thicker ones. Click to expand... toothbrush and or a makeup brush and compressed air. easy."</post>
   <post id="3c4f804a-6983-4755-85fd-dd679eb6393a" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"pendragon1 said: ↑ toothbrush and or a makeup brush and compressed air. easy. Click to expand... I was worried about scrubbing the fins with anything, but I should give that a try in the one AIO system I still maintain. I remember the fat rad in the H70 and H80 were very difficult to clean without uninstalling them first. And those units used sticky pads behind the backplate that would get ripped whenever you unmounted. Do these units still use those pads?"</post>
   <post id="597829c7-ccf4-401e-b6a2-dfc3bcb026d1" section="Overclocking and Cooling" discussion="How much radiator is REALLY needed? Single 120mm vs. Dual 140mm!">"not that I know of. my h60 doesnt have anything like that. the only thing I wish I did have was a rubber gasket to stop the air leaks around the fan edges."</post>
   <post id="a0752f8a-dcf0-41d2-87d8-1c8f8b8a6bea" section="Overclocking and Cooling" discussion="Silentium PC Fortis 3 HE1425 CPU Cooler">"The crew at techPowerUP had a lot of good things to say about the Silentium PC Fortis 3 HE1425 CPU cooler. Price and performance were big pluses. Unfortunately, one of the bad things they listed was lack of availability. Today s review will cover the SilentiumPC Fortis 3 HE1425 and Fortis 3 Malik Customs Edition CPU coolers. These units make use of an offset single-tower design to offer increased memory clearance without sacrificing any surface area for heat dissipation. With an attractive price and a 140mm fan, each, it will be interesting to see how these stack up to the competition."</post>
   <post id="921c9150-fcba-4bda-93df-bfb4e6ce4d80" section="Overclocking and Cooling" discussion="Silentium PC Fortis 3 HE1425 CPU Cooler">"The new $35 cooler king? It just barely edges out the Cryorig H7. Due to the shape, I wonder how much of an impact a 2nd fan would actually have on performance."</post>
   <post id="aa13f8eb-8a1e-4007-9ded-1c43aceae490" section="Overclocking and Cooling" discussion="Silentium PC Fortis 3 HE1425 CPU Cooler">"Can t find it anywhere in the US though, which is kind of a big problem..."</post>
   <post id="ed7b5a42-d04f-49a9-911d-52849a205761" section="Overclocking and Cooling" discussion="Silentium PC Fortis 3 HE1425 CPU Cooler">"Reminds me a lot of the Deepcool Lucifer V2, just got one of those for $30 after MIR for an e5-2670 build, great value for the money."</post>
   <post id="0956ce3f-0f84-486a-940d-c12f23dca29a" section="Overclocking and Cooling" discussion="Silentium PC Fortis 3 HE1425 CPU Cooler">"looks euro only. cant find it anywhere in NA."</post>
   <post id="aa7fe353-a7bf-4820-b1cd-2cb4e10be12b" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"Ok, so I finally got one of these after lusting for one for many years, a Dell Precision M6700 (16GB RAM, Intel Core i7-3740QM quad, Nvidia Quadro K4000M based on the GTX 670m iirc coupled with the Premier Color IPS panel display too) and I m looking to cool this puppy down. Now, having said that and stating that I ve had it for about 10 hours now doing all sorts of testing and benchmarks and generally goofing around it s time to get serious. Even in spite of it being in immaculate condition - whoever the previous owner was (got this at a pawn shop for about $350) that person took care of it and babied it  cause there ain t a mark on it anywhere and after removing the bottom panel to look around I can t find a speck of dust anywhere or lint either. So, what I plan to do is a full disassembly and then put it all back together again and I d like to repaste the heat sinks and fans (there s two of  em in this monster beast machine laptop). I m looking for recommendations to provide good/great cooling from the thermal paste perspective - I don t need the absolute best most bad-ass compound ever created in the history of such things, but I would like to get something that s a) going to actually make a difference at this point and b) ain t going to cost me an arm, a leg, half a kneecap, and perhaps a thumb if you get my meaning. I just spent the past hour looking over other sites like overclocking.com and techreview and whatnot and none of them give me the same kind of info and opinions that the [H] folk do so I m asking the question: If you were rebuilding a laptop and wanted to ensure you did the best you could in terms of keeping it cool from the thermal paste perspective, what would you end up choosing either for the CPU and the GPU discretely (different compound or paste for each) or would you just do a "What the fuck..." thing and use the same compound/paste for both aspects. Just looking for advice and suggestions if anyone is willing to offer some. Thanks in advance..."</post>
   <post id="14558af7-d0d4-4b65-8091-14b1570fad43" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"Main thing for laptops is using a paste that will not move when it s hot, e.g. you have laptop on a weird angle on your knees or whatever... Other than that with the thermal system you have, just get something decent, i d recommend a ceramic based paste, that sets a little firmer (not dry obviously) but just stay away from the typical old grey/silver cancer cancer shit, which does get liquidy sometimes and move (we used to be able to tell if people left their system on in the carry case..) Arctic, Noctua, etc all have some decent stuff. If you want to go crazy, diamond is the best thermal conductor known by nearly an order of magnitude..."</post>
   <post id="436bb795-97d1-4a56-9cd0-248633cbf64b" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"Diamond what, however,  cause if you mean actual diamonds then I can t see that happening (on top of the other body parts I d probably have to fork over my somewhat useless soul too). For me the best thermal conductor I ve ever witnessed is still the super-secret ceramic composite materials they created for the Space Shuttle heat tiles. I ve seen - personally witnessed - a demo of a cube of that stuff about 1" square being placed into a furnace at several thousand Kelvin and when it was removed it was glowing white like a florescent bulb might, I mean a pure white brightness and the guy holding the tongs had some super thick heat-proof gloves on. He placed the cube on a surface made from the same composite material and then removed his gloves, smiled, and reached out with his right hand and picked up that glowing white cube with a thumb and forefinger not 30 seconds after it came outta that oven and it was still bright white. The dissipation potential of that material has always amazed me to this day and I still wonder why that type of composite hasn t been manufactured in most anything where high heat buildup needs to be wicked away as efficiently as possible. Imagine CPU cores constructed from such material, or heatsinks - you d be able to cool the hottest processors known today with a sliver of that stuff about the thickness of a playing card, seriously. Anyway, thanks for the info and hoping other people chime in. I realize I didn t post any actual temps yet, going to do some [H] style testing here in a bit with some stress testing and see just how hot this beast gets. I know the quad CPU has a Tjmax of 105C and I hit 98C earlier doing a 1 gig wPrime run (that was just one of the cores, mind you, the others were 87/92/89 so not too hot at all considering). Fun times ahead..."</post>
   <post id="157f1076-ca9e-4ffc-82f7-eb8c349601c6" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"It s always about the cost. That s why we never get the really nice stuff. As for the diamond stuff he referenced, it is IC Diamond. It is literally made up of microscopic diamond particles, which when applied between two surfaces, will literally cut into both surfaces, which maximizes your heat transfer area. As for everything else, they re all basically within 3-4 C of each other."</post>
   <post id="7e96fafd-cf12-4af6-83c1-082aaf66c47f" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"Whoaly crap! You are a lucky guy to see that... was it very light? That does sound like an absolutely fascinating material. I m going to look for a video, would be awesome to see! That shows extreme insulation properties (ceramic) and extreme conduction (likely diamond). Best of both worlds. I would hazard a bet they made some diamond-ceramic based material, as really nothing else comes close. I ve been doing lots of R&amp;D into this, as I have something to cool which is roughly ~2x5mm and dissipating ~200-300W or more. You think a heavily OC d CPU/GPU is difficult to cool..? Try that for size! You might be surprised (I wouldn t recommend for your application however) that diamond heatspreaders are &gt;200 bucks for 10x10mm.. they have around 1200-1500W/mK. Not as good as pure high grade industrial diamond (~2000-2200W/mk at room temp - and ~5000W/mK at far below sub zero temperatures). But you can get the full on stuff it just costs a little more. Industrial diamond is surprisingly cheap. Real diamonds are an over-inflated commodity that appears as little stones and grains of sand in streams and on beaches in certain parts of Africa. PM me if you are interested in obtaining some industrial diamond, I ll point you in the right direction. Current temps are nothing to worry about but getting them lower with some new paste would be an excellent idea. That said, if it s so tidy and clean, likely the paste is in good condition and you ll have very little gains replacing it, but only one way to find out."</post>
   <post id="e7ee951c-1896-4f85-a878-a3836cbb567e" section="Overclocking and Cooling" discussion="Finally got a Dell Precision workstation laptop with Quadro - thermal paste recommendations, please?">"Well hot diggity, we have a reseller here just down the road in Henderson, OutletPC, with IC Diamond 7 carat for $7.65, coolness (no pun intended). Might have to drop in later today and grab a tube. Since the current setup appears to be the original and untouched, and the laptop was manufactured in March 2013 that s 3 years so, it s time for a new thermal paste job as part of the teardown/rebuild. Thanks for the info. And as for a video of the Space Shuttle composite material, here ya go:"</post>
   <post id="87569a29-1bc7-4e55-a512-faf972b86a04" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"So i m going to try to do a favor for a friend, here we go. His box has an H55 aio kit that the pump is starting to hum on and off like this : https://www.youtube.com/watch?v=tHrdCxtCSPk Are there any pump parts that I can order to repair it before it dies? Specs: AMD FX8120 Corsair H55 ASUS Sabertooth 990FX Supertalent 8GB ASUS 270X OCZ vertex2 SSD Corsair AX850 PSU"</post>
   <post id="b6b09c0e-eed7-48c3-ace7-c56a0fc73f67" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"Nope, sealed loop coolers aren t really repairable. Once you cut the tubes to drain it, that s basically it as there s no mechanism to let the air out if you somehow manage to get it refilled."</post>
   <post id="dfaafb2d-ecae-4e4d-8ff8-33deba46e933" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"If you were to cut the lines and replace the pump unit with an aftermarket one you could always tap a hole at the top and put in a bleeder. That being said, its likely more than a replacement upgrade."</post>
   <post id="47a14d8d-0f88-4892-92ce-f6e06a662dbe" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"wow no bleed screw or anything?"</post>
   <post id="fb6c2a71-4498-4977-ad0d-f83946e18e66" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"i didn t know if the pump used is a common commodity pump"</post>
   <post id="19e62020-f1fd-4deb-8dc4-435bd1bb5a96" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"Not really. These are generally just a use and throw away type because of their cost. The repair parts are likely to cost the same as a new AIO. Also, no, they do not have a bleeder because they are closed units. They arent designed to lose fluid due to evaporation like a custom build would."</post>
   <post id="bdb2e110-36fe-4ca5-bfc8-5995b8454612" section="Overclocking and Cooling" discussion="Corsair H55 pump head replacement">"See if its still under warranty with Corsair... If not he s probably going to have to get a new one.."</post>
<post id="ed8f42a2-5fd0-414e-ba4f-c299bfbc85a7" section="Physics Processing" discussion="Physics Card, in addition to...">"I have a spare GT 610 POS. GTX 750 Ti SC is the main card. Would there be any reason to use the GT 610 for Physics? Or, can "Folding" make use of the cards?"</post>
   <post id="d751174f-68dd-4067-89b6-15ffbceb7745" section="Physics Processing" discussion="Physics Card, in addition to...">"The GT610 is completely useless, you d be better off just using the 750 Ti."</post>
   <post id="437cb7b0-b16c-400c-82e6-c8154c3a221d" section="Physics Processing" discussion="Physics Card, in addition to...">"Yep, that s what I thought. If I can I ll trade it or give it to somebody who would benefit from it. Also have a Quadro 295, or something or other. Just want more DDR3, I have 8, but my chipset is tripple channel. The math doesn t work out. No worries, Take care! W"</post>
   <post id="1b37596c-1649-41b1-95ad-5a143c81dcb8" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"I just bought Overlord ffor the PC . I bought it through amazon I did not relize it was going to be from steam , I added and activated game. What I don t want is for the Nvidia legacy or what ever geforce Physx drivers to install. I have an actual Ageia PPU installed and the Nvidia drivers woul totally screwup the Physx card drivers I have installed. The game was originally released in 2007 yes I know its an old game. The game does not need the legacy drivers if an Ageia card is present. How do I stop this from happening?"</post>
   <post id="eb09395c-d136-4b78-be03-b68062b02113" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"When installing nvidia drivers select the custom option and then deselect nvidia physx drivers from installing. I had a ppu also, to be honest though if you have a semi decent video card then it will perform better than the aegia ppu, though if I remember it depends on if the nvidia physx drivers support said game. But if you dont want the nvidia physx drivers then do the custom install and also you can uninstall them and only them via the installed programs menu in windows control panel."</post>
   <post id="8d908690-06c0-47ba-84a8-2f76fad783b7" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"What I meant is when steam installs a game it automatically installs physx drivers that is what I don t want"</post>
   <post id="eb82579f-8a13-4aa0-bc37-592cfcd666d4" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"According to the Wiki list, Overlord doesn t support PPU or GPU accelerated Physx. Therefore, I am pretty sure that the software (CPU) Physx software is going to need to be installed for it to work. List of games with hardware-accelerated PhysX support - Wikipedia, the free encyclopedia"</post>
   <post id="97ce6015-d27a-41bf-9c02-829c2aa3045c" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"my mistake it is overlord 2 that supports ppu, Got it and ppu physx does work."</post>
   <post id="5ff98f1d-0046-45b0-90ce-720353aedfa2" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"Can t you just uninstall it from programs and features after the game installs and then put back the version you need?"</post>
   <post id="731e0a8d-1454-4d6b-850a-443b5ca6fd3c" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"Oh No not that easy. new Nvidia drivers erase support for Ageia PPU. You have too do all this..."</post>
   <post id="e56aa5ce-d74b-48e8-a02f-50f48e94a452" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"I thought that newer GeForce cards were superior to Ageia cards at PhysX now, anyway? Most people started just using their old graphics cards for PhysX a long time ago. Or am I wrong? Surely NVidia wouldn t have disabled support if they were still worth using."</post>
   <post id="74d46871-acff-4677-83e3-aa86d11d5b56" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"Sure they would. Nvidia didn t want competition so they bought out Ageia then used Physx as a marketing gimmick. As far as Geforce being superior. BS. on games that support the PPU. I find the Ageia PPU superior and smoother. If Geforce is more powerful why can t t they run the PPU levels of Cellfactor? A dedicated device is superior to an added function in a video card."</post>
   <post id="79ffe5c0-cfc5-488c-8df9-ec82e246a84f" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"zalazin said: ↑ Sure they would. Nvidia didn t want competition so they bought out Ageia then used Physx as a marketing gimmick. As far as Geforce being superior. BS. on games that support the PPU. I find the Ageia PPU superior and smoother. If Geforce is more powerful why can t t they run the PPU levels of Cellfactor? A dedicated device is superior to an added function in a video card. Click to expand... I do see your point, but bear in mind that we re talking about at least an 8-year old product here. Some newer Intel IGPs are superior to old GeForce cards now. If Ageia were still around making these cards, you would be correct about the dedicated device being superior... but I find it hard to believe that an 8-year old piece of hardware is that much better just because it s dedicated. Is an 8-year old GeForce card better than Intel HD Graphics on Skylake? Not really. My answer for that question is that Cellfactor was probably designed around the Ageia unit. I have an old Linux game, SimCity 3000, that won t run on anything but Red Hat 6 without patching, and that version of Red Hat only works with ancient Pentium II era graphics cards. You can t even run it in a VM, I ve tried. That doesn t make those graphics cards superior, but those particular pieces of software will perform better with those old graphics cards that have drivers available than they will with any newer ones that are forced to fall back to a VGA compatibility mode. So while I would concede that the Ageia unit might be superior for playing Cellfactor, that doesn t mean it s a superior piece of hardware in absolute terms. I mean, it might be, but it seems unlikely after this much time has passed. It s probably better than some older or lower-end GeForce cards, but I doubt it s better than what modern cards can do. The game you re talking about was released in 2007... so of course it s smoother with the hardware it was designed to run on. It was likely taking advantage of that specific architecture as there was no other product on the market at the time that could do the same thing, and less smooth on newer hardware because the newer hardware is having to use a fallback mode."</post>
   <post id="9404706a-4f25-4073-b9c5-4244cae1f72b" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"I concede your point on newer games, But I wonder what might have been. After all Nvidia lacked respect for their own customers by disabling both PPU and Geforce phsyx for use with AMD cards. Mostly now Physx is just a few particle effects etc in games, I don t see any real immersive physx. Before you say I am an AMD fanboy my System is A A10-7870K with a Geforce GTX660TI and Ageia PCi physx card. Thanks for you opinion and input ....."</post>
   <post id="00267644-272c-4a20-adfa-dbca87e9114b" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"zalazin said: ↑ Oh No not that easy. new Nvidia drivers erase support for Ageia PPU. You have too do all this... Click to expand... Soooo... the first part where you have the needed files copied to a different location. If you just keep those files for later use, it should take only a couple minutes max to restore Ageia support. And if you wanted to automate the process, it would only take a very simple batch file to do so. From the "you have to do all this", I was kinda expecting some registry editing, etc., but the steps needed are very simple and quick."</post>
   <post id="518b21e9-ae6f-44d6-8b20-38bed3d5ba1e" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"But don t driver installs make changes to the registry? In that case recopy just the files would not work. Currently what I do is image my C drive to a second SSD using Macrium reflect thus I can restore if newer drivers screw up the Ageia ones. I might just do an experiment to see if just copying the folders back would work."</post>
   <post id="24e34ee7-6171-41f1-ad69-758122f85bc3" section="Physics Processing" discussion="keeping steam from installing legacy physx driver on older game?">"zalazin said: ↑ But don t driver installs make changes to the registry? In that case recopy just the files would not work. Currently what I do is image my C drive to a second SSD using Macrium reflect thus I can restore if newer drivers screw up the Ageia ones. I might just do an experiment to see if just copying the folders back would work. Click to expand... For the PhysX stuff it should just work."</post>
   <post id="72e4d023-26d6-4f10-ae94-9a05a54f7d5a" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I have A10 7870k with external R7 250 card Hybrid crossfire. win 8.1. I also have yes a Asus pci x1 genuine ageia physx card. Can I use only the 8.09..04 driver? Will it work with the hybrid crossfire. I think these drivers are before nvidia blocked the use of amd hard ware. Is the Radeon R7s in crossfire better than the Ageia card for physics? Yes I know a dedicated Geforce would probably be better but I experimenting here. Physics card is just wasting away I thoght I woul give it a try."</post>
   <post id="9e0fd6a2-8350-4ad5-a7ac-cd68f2e7be9c" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I don t know if those Aegia cards are even valid hardware anymore. I m even less sure if the nVidia drivers will run the Aegia card."</post>
   <post id="881a18e1-b9d4-4ad0-94d7-7f81be78ce5e" section="Physics Processing" discussion="A10-7870k Phsyx performance">"no the newer nvidia drivers won t work but some older games will use the card. mirrors edge, infernal and arkham asylum will. Only problem is how do I still get the current games to still have phsyx without using new drivers that would diable the ppu?"</post>
   <post id="72cd248e-d26e-45d0-8aaa-54723ffccde2" section="Physics Processing" discussion="A10-7870k Phsyx performance">"here is some info: Ageia PhysX PPU - PhysX Wiki bottom line: you may as well get a low end nVidia card to run concurrently with your AMD setup and delegate it to process the physx. this is what i did with borderlands 2, i had a crossfire 6950 setup with an nvidia GT430 as physx card."</post>
   <post id="4136bbee-3448-4022-a96e-235e81c6c3ca" section="Physics Processing" discussion="A10-7870k Phsyx performance">"What you say is interesting bu not useful info. If I wanted Nvidia I could drop in a GTX660TI that I have lying around, plus the older phsyx titles don t work with GPU physx IE cell factor. The video to update to the latest physx drivers does not help Amd owners....... PS also only have a 1x pci express slot available"</post>
   <post id="0df52216-3a7d-42cf-807e-d35824cd90c4" section="Physics Processing" discussion="A10-7870k Phsyx performance">"zalazin said: ↑ What you say is interesting bu not useful info. If I wanted Nvidia I could drop in a GTX660TI that I have lying around, plus the older phsyx titles don t work with GPU physx IE cell factor. The video to update to the latest physx drivers does not help Amd owners....... PS also only have a 1x pci express slot available Click to expand... you didn t read the whole wiki page then, directly under the video is this line: However, if you re still interested in installing Ageia PhysX card (to play old PPU PhysX games, for example) into your system, you can refer to this guide, that will allow you to use Ageia PPU with latest PhysX Drivers. so it would help you if you click on the "refer to this guide" link. I can only show you the way, you must open your eyes and do the leg work."</post>
   <post id="df480da5-88f3-4ee3-9988-5d585009a792" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I watched this before and it is referring to using the ageia card with a geforce gpu It does not bring up amd cards being used at all. In fact do not the newer nvidia phsyx driver disable any ppu or geforce card being used with an Amd card? I am NOT using a Geforce GPU but 2 R7 Radeons in Hybrid crossfire. You need to read what I wrote......"</post>
   <post id="a37b000d-ecf2-4e92-ad8d-6e20ccfcb4ab" section="Physics Processing" discussion="A10-7870k Phsyx performance">"sorry when i said "latest PhysX Drivers" i meant that the guide shows you how to enable the PPU with the right drivers that support it. here is the direct link to the instructions since it is apparently hard to click on or something: How to restore PPU support with latest Nvidia Drivers and yes i know you are trying to do ageia ppu with hybrid crossfire amd cards. the guide above is using nvidia gpu. guess what? you are probably the only person that has ever wanted to do this, that is why there is no guide laying out how to. you might have to take the initiative and try things out if you really want to do this. so follow the guide to get the ppu enabled, then follow the other guide to get physx enabled with amd cards. it might work or it might not."</post>
   <post id="b05db96f-a231-447c-a7ea-5c902b2260ad" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I wouldn t bother, the Ageia PPU isn t powerful enough to run modern Physx games (it can actually slow them down). You d be better off just running it on you CPU."</post>
   <post id="9a9f1454-bd84-4084-9141-120118a0557a" section="Physics Processing" discussion="A10-7870k Phsyx performance">"Quix said: ↑ I wouldn t bother, the Ageia PPU isn t powerful enough to run modern Physx games (it can actually slow them down). You d be better off just running it on you CPU. Click to expand... op said they wanted to play the old PPU games like mirrors edge. so modern games are not a factor."</post>
   <post id="0c76733a-e294-47a9-bf38-ae51ec72479e" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I broke down and bought a Geforce card to use for physx and games However thanks to the link I was able to also get my Ageia PPu working and it auto witches for games. Now does any one know where I can get the Ageia Reality Mark software? Links refer me to Nvidia and we know how helpful their NOT...."</post>
   <post id="414b3d22-db13-487b-bf77-5ee43168d2c5" section="Physics Processing" discussion="A10-7870k Phsyx performance">"AGEIA RealityMark"</post>
   <post id="d7e551b7-12ea-430e-9d39-23d1b18ea816" section="Physics Processing" discussion="A10-7870k Phsyx performance">"Yeah link takes me where I been before.. Nvidias site where there virtually no Ageia related demos I could find...."</post>
   <post id="c79abb13-d2d8-451e-8f72-f388010796a5" section="Physics Processing" discussion="A10-7870k Phsyx performance">"I see that now..."</post>
   <post id="40327618-5f7f-4b9a-b7e5-7e05f61ee739" section="Physics Processing" discussion="A10-7870k Phsyx performance">"i found it on Chip.de but it was hidden behind a wrapped up installer, so i extracted it out from that for you. hope this is the right software: Meet Google Drive – One place for all your files"</post>
   <post id="307cc736-3e11-4c14-8485-13f2f39b2d82" section="Physics Processing" discussion="A10-7870k Phsyx performance">"it says i need permission...."</post>
   <post id="ac57f1da-63d0-404c-a426-60765f5e1d9a" section="Physics Processing" discussion="A10-7870k Phsyx performance">"got it but it wants me to uninstall 89.04 and after the goat fuck i went through to get physx running I won t risk screwing up my physx install. earlier today I tried the legacy driver from nvidia and ended up restoring from a Macrium reflect image. What a PIA....."</post>
   <post id="3fa7a022-a997-49ea-aec1-1bfbf3a9cd6e" section="Physics Processing" discussion="A10-7870k Phsyx performance">"That sucks, I have an ageia pci card and plan on building an xp box, hopefully that will make it easy"</post>
   <post id="97692ca2-15d9-4602-b9cb-c785f592e087" section="Physics Processing" discussion="A10-7870k Phsyx performance">"Follow the guide posted by big ted, however watch the video it changed few things. I have a a10-7870k with Evga 740gt and Asus 1xPCI express ppu . Working good so far mostly ppu is used for cellfactor revolution, cyrostatis, and Warmonger 2.5. IT usually auto switches for newer games. Now if I could only find a Single slot GTX750 TI. Elsa seems the only true single slot but in Japan only!!!"</post>
   <post id="6e8c6da7-c656-4b74-827e-db3fa954e5e0" section="Physics Processing" discussion="A10-7870k Phsyx performance">"sorry didn t realize it was you thank you for the guide link ......."</post>
   <post id="22cd7d2e-9891-4c16-9a79-b5604cf914bd" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"Hi Guys, I am planning to build a Hybrid Physx setup, I have the following rig: 1. AMD fx-4100 2. MSI 890GXM-g65 3. XFX HD 7870 2 GB Dual Dissipation 4. 600 W cooler master elite power 5. 4 Gigs of Corsair RAM 1333 Mhz 6. I need an nVidia card and cant decide on what .. My queries: 1. My mobo runs the pci-e lanes at x8 / x8 if 2 cards are inserted. I cannot change my mobo, will there be any performance issues? 2. I cannot have the new card with external power from PSU. dont have more power room left, Either i will have to buy a molex to pcie power converter [if they are good and actually work] Please advice on how to proceed with this .."</post>
   <post id="89fcba11-8810-4c8a-a457-214c0808c507" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"No issues at 8X used to run it like that on x58 I use the gt640 currently no plug required and it is quiet and cool"</post>
   <post id="bd5ed336-1d4e-4891-bc27-e7a9987ea2bc" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"ok great ! But is my system Ok to have hybrid Physx .. I mean is the hybrid physx setup dependent on specific hardware or we just need a motherboard with 2 PCIe slots"</post>
   <post id="7f810714-7109-447f-85c2-1e3515002719" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"you just need a motherboard with 2 x16 physical slots. the software will run with any config as long as you have an AMD and NV gpu. good luck"</post>
   <post id="ef6cffc5-a615-47f1-b5fb-ae930e45f014" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"Great! I will buy a GT 640 [a bit costly though].. and see how it performs in Metro 2033 and Mirror s Edge.."</post>
   <post id="83037f62-f16b-432a-91bd-877fc28f5897" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"HI, before buying I wanted to know a few more things: 1. Will the games that dont use Physx benefit from the 2nd Nvidia card? Or will their FPS drop?? 2. Is there any other side effect to this setup?? I am thinking of going for this: http://www.pcper.com/reviews/Graphics-Cards/Galaxy-GeForce-GT-640-GC-1GB-DDR3-Review-GK107-no-GK104 -RK"</post>
   <post id="c10203fc-a96c-42a7-a55e-35cd35b8d85e" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"1) there will be no detriment or benefit, if you re playing a game with no physx, it won t be in use and won t take away from the main card 2) very general question, but the main side effect is using more power, you will be powering the card, and it will add to your watt total."</post>
   <post id="0a9b48e8-5543-42ff-9022-64ae756cc696" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"beware that is a dual slot card if you have a power supply below it make sure you have room"</post>
   <post id="64a91244-7829-4064-9817-81aaf6c4b55e" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"d50man said: ↑ beware that is a dual slot card if you have a power supply below it make sure you have room Click to expand... shouldn t be a problem with the board he has http://us.msi.com/product/mb/890GXM-G65.html"</post>
   <post id="5f19a24c-0175-4e9f-b72f-18c69161cab5" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"Will 600 Watts supply be enough for both the cards?? 1. XFX HD 7870 2 GB ghost edition 2. Nvidia GT 640"</post>
   <post id="e6b1bf16-5afb-4b24-b1cd-977f28102035" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"More important read the 12v rail amp rating 30A total should be safe on overrated supply"</post>
   <post id="9ef98187-aace-4a4b-b7bc-db41aadfa706" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"aarkay14 said: ↑ Will 600 Watts supply be enough for both the cards?? 1. XFX HD 7870 2 GB ghost edition 2. Nvidia GT 640 Click to expand... which power supply exactly?"</post>
   <post id="95aa87bc-3240-42ff-891b-a78301c92266" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"I have a cooler master extreme power 600 Watts PSU, is it OK? Or should I get a new one??"</post>
   <post id="d2467e92-a4bc-438b-bc27-9133157b98d2" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"aarkay14 said: ↑ I have a cooler master extreme power 600 Watts PSU, is it OK? Or should I get a new one?? Click to expand... if it were me, i d be putting money into a new PSU before getting a PhysX card. i did see one review of a later version of that model that went out of 12v spec at 450w (which is really bad, could damage components bad). get one with at least an 80+ bronze rating and a single 12v rail, probably around 500 watts or so. You ll be much better off. I am by no means an expert, and would recommend you post in the Power Supplies section HERE."</post>
   <post id="468dc868-c84b-45fc-a6b3-c3a79cb0a144" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"OK, but the zotac GT 340 takes power from the motherboard.. will it still pose a threat ?"</post>
   <post id="6b69be7e-2b3f-442a-a5e1-6347fbd6fd16" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"i think the max a video card can take from the board is like 75w, so it would be safer than buying a card that has an external connection. i have a gt430 with a 6950 and use High physx on BL2 just fine"</post>
   <post id="cdc42c14-de75-460f-a456-4b74362fd276" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"aarkay14 you are good"</post>
   <post id="7688c04f-0365-4e0f-aebb-7755e91b7470" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"I DID IT! .. Yes, got the GT640 with 384 cores, and there is no more slowdown in Mirror s Edge when the glass start to shatter !! .. However there is a minor pause in the game when some physx loads, maybe due the fact of slower memory of GT640, is there any way of overclocking the nVidia card?"</post>
   <post id="06afbcd7-f66d-4ab1-b710-124ff0e746eb" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"i think it was ngo s forums that have the tweak settings to fix that"</post>
   <post id="82cd76ee-5361-4258-b76e-fe13c3edf4e6" section="Physics Processing" discussion="Hybris physx Q- HD7870 + ?">"Its OK, Hybrid Physx is too finicky and I should mess with it once it is working fine.."</post>
   <post id="3c85ad7d-09cc-456e-8a57-80739bbab074" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"I tried asking this on the Nvidia forums but surprisingly cannot get a straight answer. I m wondering if anyone else out there is using three video cards - two in SLI and one for PhysX - without any issues with the PhysX card being recognized. I can dedicate the third card (a GeForce GTX 750) to PhysX in the Nvidia control panel and it seems to work fine. However, if I reboot - this card is no longer recognized as a dedicated PhysX card nor is it even selectable anymore in the Nvidia control panel. So what I have to do is one of two things. I can either disable then reenable SLI - at which point the GTX 750 magically reappears in the control panel as a dedicated PhysX card. Or I can disable/reenable the GTX 750 in Device Manager to get the same effect. I m puzzled why I would need to do this as the GTX 750 appears to be just fine in Device Manager when I boot. It seems like it could be a driver issue (I m currently using 353.30), but the problem occurs with older drivers as well. So now I m starting to wonder if it could even be related to my motherboard somehow (a Gigabyte GA-X99-UD3P). In order to help diagnose the problem, I would really like to know if anyone with a similar arrangement using three video cards is not having this problem. That would tell me it s likely not driver-related. Of course, if anyone has a solution to this problem that would be just Jim Dandy but I can t find anything anywhere on the internet on how to fix this."</post>
   <post id="b7566445-f34f-4878-8371-efe73be1916f" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"So I m the only one running SLI with a third GPU for PhysX?"</post>
   <post id="85dc03f9-923d-4fd3-911f-ab5e4e18e4e8" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"I missed your previous post. I happen to have 2x Titan X and a GTX 970. So just for playing with stuff I allocated the GTX as PhysX in addition to the Titan X SLI. It seems to work perfectly, the problem is I can not see any difference anywhere with the PhysX enabled. I am using latest drivers now but I think it would work fine with the previous drivers too. Do you have 3 identical cards? Maybe this is the problem?"</post>
   <post id="99facfce-81b7-4d50-8fca-a23c3060410a" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Thanks for checking Wirk. So as long as your configuration continues to show your GTX 970 as a dedicated PhysX card after you reboot then yeah - sounds like your setup works just fine. I m also using two Titan X s as well. Was planning on switching out my third card for a GTX 950 Ti whenever they become available but not sure if that will make a difference. If the issue was my motherboard I would think my third card would not show up correctly in Device Manager so I m completely baffled. For now, I just have to always remember to do that toggle off/on trick to get it to show up right as the PhysX card."</post>
   <post id="ab10cf9e-332c-4ee5-bba4-e6135eacdb49" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"I have had the same problem in the past, I had to keep re-enabling the PhysX card. Honestly though, I didn t see much overall benefit to having the SLI + PhysX card. I just up my SLI cards and let them run PhysX if I want it."</post>
   <post id="99d98534-9e6e-46d7-a258-3e2b1f9b8c8b" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"rennervision said: ↑ Thanks for checking Wirk. So as long as your configuration continues to show your GTX 970 as a dedicated PhysX card after you reboot then yeah - sounds like your setup works just fine. I m also using two Titan X s as well. Was planning on switching out my third card for a GTX 950 Ti whenever they become available but not sure if that will make a difference. If the issue was my motherboard I would think my third card would not show up correctly in Device Manager so I m completely baffled. For now, I just have to always remember to do that toggle off/on trick to get it to show up right as the PhysX card. Click to expand... My configuration is stable, keeps after rebooting. More of interest is where are you expecting to see the impact of PhysX?"</post>
   <post id="96fe0c12-945a-4430-89fc-48740691af17" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Haven t run a PhysX card alongside my SLI TItan X yet, but with my old SLI 780 + 750Ti setup, I never had a problem with the PhysX card not being detected, even with my sub-optimal 4-way z97 board with PLX chip (as opposed to your native x99 PCI-E lanes)."</post>
   <post id="7ee8d562-eb36-430f-b7c5-bf5eca499be5" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Just want to throw out there, you do realize that unless you are on X99 or higher, or have PLX chips on board, when you add that third card, you are dropping the link speed to your primary GPU s..? you are likely dropping from 8 x 8 to something like 8 x 4 x 4 Not sure how much PhysX rendering you are doing to make it worth a dedicated GPU, but if you are running anything recent, PhysX can surely be rendered on a Primary GPU, saving you some bandwidth."</post>
   <post id="ce8cbd4a-fb50-4d4b-aa35-41664ec6457b" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"cybrnook said: ↑ Just want to throw out there, you do realize that unless you are on X99 or higher, or have PLX chips on board, when you add that third card, you are dropping the link speed to your primary GPU s..? you are likely dropping from 8 x 8 to something like 8 x 4 x 4. Not sure how much PhysX rendering you are doing to make it worth a dedicated GPU, but if you are running anything recent, PhysX can surely be rendered on a Primary GPU, saving you some bandwidth. Click to expand... There is zero impact of PCIe x8 or x4 on gaming performance, not even for PCIe 3.0 but also PCIe 2.0 which is half speed of 3.0."</post>
   <post id="2373e202-490b-48b5-ab89-95c30e56badb" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"wirk said: ↑ There is zero impact of PCIe x8 or x4 on gaming performance, not even for PCIe 3.0 but also PCIe 2.0 which is half speed of 3.0. Click to expand... Makes sense... I guess I don t even understand why motherboard manf s bother putting PCIe lane divider info in the documentation. Or why Chip manf bother to tell us how many lanes our chips have, or hell, why we even have PCIe Gen 3.0, guess none of it matters, let s go back to AGP."</post>
   <post id="31daeeb0-6903-4402-b06c-73d8a2ea15a9" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"cybrnook said: ↑ Just want to throw out there, you do realize that unless you are on X99.....blurb Click to expand... Just want to throw this out there, you do realize that OP IS on X99? "my motherboard somehow (a Gigabyte GA-X99-UD3P)" l o l"</post>
   <post id="1bee0ad5-cc9d-41c5-abb7-df31eeb1f202" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Might be a setting in your BIOS I don t have that motherboard so I can t be specific but look for settings related to PCIe especially ones that scan for or are related to legacy hardware try changing them."</post>
   <post id="5046ef41-6355-480d-aefc-2f28d407e681" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"cybrnook said: ↑ Makes sense... I guess I don t even understand why motherboard manf s bother putting PCIe lane divider info in the documentation. Or why Chip manf bother to tell us how many lanes our chips have, or hell, why we even have PCIe Gen 3.0, guess none of it matters, let s go back to AGP. Click to expand... Increasing the bus speed is relatively simple so it s being done, remember the PCIe 4.0 is coming soon. But is also is very good for development since it makes possible for others component manufacturers to improve their performance, otherwise there is chicken and egg problem. In graphics cards we will have to see if DirectX 12 has higher demands on bus speed. It is known that Intel professional card for numerical computations aka Intel Phi can utilize fully the PCIe 3.0x16 bus capacity."</post>
   <post id="3ab8a02d-56f8-4d47-ad78-2a4b13eecf3e" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"cybrnook said: ↑ Makes sense... I guess I don t even understand why motherboard manf s bother putting PCIe lane divider info in the documentation. Or why Chip manf bother to tell us how many lanes our chips have, or hell, why we even have PCIe Gen 3.0, guess none of it matters, let s go back to AGP. Click to expand... Faugh! AGP? Try ISA! That s all we need For the OP: I ran (3) GTX 580 Classifieds a couple years ago, and I could easily set 2-way SLI and then dedicate the unused 3rd card to PhysX. I would hazard a guess that Nvidia s drivers haven t regressed that much and so will still let you do that."</post>
   <post id="538f7f8d-da0d-42b9-a7a6-9f42fb1c8147" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"I was doing SLI + Physx last month, no issues."</post>
   <post id="639d196b-b74f-450a-9e49-59e3ac7cd3e5" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"doubletake said: ↑ Just want to throw this out there, you do realize that OP IS on X99? "my motherboard somehow (a Gigabyte GA-X99-UD3P)" l o l Click to expand... Right. The lanes run at 16x/16x/8x. It is interesting to hear others aren t having this problem. I guess I will double check the BIOS. (I tried a few options in there before starting this thread, but nothing changed.)"</post>
   <post id="14a17aba-5ef3-4f63-8b37-dce68d7a01db" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"It occurs to me that the problem might be in the types of cards used. If all cards are identical the system is confused at bootup since it is not expecting that one card should be PhysX, it is rather SLI or separate cards. If the cards are different, the distinction is clear since they can not be all in SLI. That would explain why I have no problems with 2xTiX+970."</post>
   <post id="2f4c8089-fd63-4d38-be09-872e108f06f5" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"ehhhhh, I don t see how that relates in any way to OP s problem. He s obviously not using 3x 750 s as that s not even possible."</post>
   <post id="9ab1a7d4-ea44-4c9b-aca7-d56890b8edd4" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Well I scrutinized the BIOS again and can t find anything that would have any effect like this on the PCIe lanes. For now I ve created a shortcut where if I double click it, it will instantly disable then enable the GTX 750 card in Device Manager. This will fix the issue until my next boot, as long as I remember to click on it of course. (Adding the shortcut to my Startup folder doesn t work because my computer doesn t seem to like having a GPU shut off/shut on right at boot - my desktop switches to a dark screen until I restart!)"</post>
   <post id="bf2f07c0-bc89-4a13-923e-088252d83651" section="Physics Processing" discussion="Question for Those Running SLI &amp; a Third Card for PhysX">"Also - I should elaborate that the two GPUs I m using for SLI are EVGA Titan X s. It might be an important detail that it s EVGA since it doesn t seem like anyone else posting is having this issue - but I found a few people on the EVGA forums and elsewhere reporting this problem and so far they ve all been using EVGA cards for SLI."</post>
   <post id="23d289ca-69f3-4040-8a2a-a7d7517b9287" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"I bought a Xeon Phi 7120p and need to upgrade the mobo from ASUS P9X79 PRO which does not support Xeon Phi (precisely, it does not feature "memory mapped I/O address ranges above 4GB" (there is a writeup about that here). I am a bit torn between two possibilities. Easier one is to just replace the mobo with ASUS P9X79-E WS, another one is to upgrade the whole gear and pass my current machine to someone else. That results in the questions: 1. The ASUS P9X79-E WS officially supports the Xeon Phi 3100 series, but people (e.g. here) use 5100 series as well. Is the 7120 somehow different, or it just more expensive and hence not explicitly mentioned? Will it work with that board? 2. If I am to buy new gear, I am thinking about AMD (dual 16-core Opterons or something similar). I understand Intel claiming compatibility with Xeon CPU s only (though I don t like this kind of monopolization through unclear compatibility). Is this risky? Someone had that one working? (I know AMD may not be a good idea for HPC, but I have code which scales pretty well and 2x16-core Opteron costs the same as 1x10-core Xeon...?) What should I look at? Or are Opterons just a no-go for computing? 3. If I go with Xeon CPU (single or dual), will all mobos work? How to check that? Intel is pretty reluctant at claiming compaitiblity and recommends to buy from complete computers OEMs. I don t want that. I want to pick my mobo and CPU and everything around. (I looked at ASUS ESC2000_G2 barebone, looks nice, that s what the people at openwall.info use, or perhaps just single CPU with ASUS ESC1000_G2). Some recommendations? I don t want rack, just server box, silent if possible (sits in my kitchen, behind the door when working). 4. I bought the passive-cooled variant, thinking that I will cool it just with some fan in the chassis... not so sure about that now... :/ These guys put dual 12kRPM fans but that will be noisy as hell. If I just buy e.g. 80mmx80mm fan with a bit more than required throughput (30cuft/min), and make a funnel to push the air through the cooler, will that work? Thanks for all information and input."</post>
   <post id="ba20f11e-b0b4-4c03-b4a5-f7799f31e918" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"I guess an appropriate question would be why do you want a phi ... they are not that great for HPC."</post>
   <post id="f1b69d9c-d428-4d50-8bd0-654e943cfc10" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"The thing really does need a ton of airflow and a single 80mm fan might not be adequate. Keep in mind that it produces almost 3 times the amount of heat that your CPU might. The passively cooled variants were designed for servers with precisely those kinds of 40mm fans that you d rather not use."</post>
   <post id="607b8a75-c069-4582-9e0f-8e16f966164d" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Particule sims, that s why I need it. Those suck at GPU (unpredictable memory accesses) but parallelize very well on CPUs."</post>
   <post id="53115291-a290-48af-b476-2076d345ec8f" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Keep in mind that it produces almost 3 times the amount of heat that your CPU might. Click to expand... Good point for comparison, it is true I have 2x80mm fans on the CPU. and it has a massive cooler. The card has 3-pin fan socket, when I connect it there, will it regulate the fan depending on temperature itself? Or do I need to do that from software?"</post>
   <post id="9a7fa27a-c45d-4842-89f5-ae39bc51cb59" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Why not buying the X99-E WS board? It is the newest with the X99 chipset instead of the old X79, has 7 PCIe 3.0x16 slots and power supply for heavy loads. Most importantly it supports new Xeon v3 processors and registered DIMM memory. Apart of what is written on the Asus page that it supports all Xeon v3 processors, I can fully confirm it too since this message is written on a just assembled system with the X99-E WS, Xeon E5-1680v3, and 4x16=64 GB Crucial RDIMM set Second issue is if the simulations could be done using high-end graphics cards like Titan Black. Their floating point performance is not far or better from Xeon Phi, but obviously architecture must fit."</post>
   <post id="4c8e8d94-b757-420a-a4fe-e5fad06af911" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Why not buying the X99-E WS board? Click to expand... If I buy the older P9X79-E WS, I don t have to upgrade the CPU (i7-3930K, a 32nm model) and RAM (DDR3 1600MHz). I assume those would not work with the X99? Replacing just the mobo is the cheapest solution. If I decide to upgrade the whole thing, then, yes, X99-E WS is hot candidate (unless I go for dual CPU). Congrats to your new machine"</post>
   <post id="61277be7-e374-4fa2-a0d6-36a25059262b" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"eudoxos said: ↑ If I buy the older P9X79-E WS, I don t have to upgrade the CPU (i7-3930K, a 32nm model) and RAM (DDR3 1600MHz). I assume those would not work with the X99? Replacing just the mobo is the cheapest solution.If I decide to upgrade the whole thing, then, yes, X99-E WS is hot candidate (unless I go for dual CPU). Congrats to your new machine Click to expand... No, X99-E WS requires Haswell architecture, LG2011v3 socket, and DDR4. Meaning complete overhaul of the system. But me thinks heavy caliber card like Xeon Phi requires workstation class meaning Xeon processor and ECC memory. X99-E WS support Xeon and up to 128 GB RAM."</post>
   <post id="be72b601-fb45-407d-840c-6db5efc7c7d7" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"I confirm that the 7120p works with the ASUS P9X79-E WS (which officially supports only Xeon Phi 3120 and friends). Now the cooling, that will be a bit of a hassle. Someone owning the 7120A would care to photograph how it is arranged internally? Where is the fan connected? I could perhaps use the same pin to drive the external fan. But me thinks heavy caliber card like Xeon Phi requires workstation class meaning Xeon processor and ECC memory. Click to expand... For me that would be waste of money. Xeon Phi for the hard work, CPU only dispatches jobs there, no big performance needed."</post>
   <post id="4879b25f-ef23-4e35-bae0-b633f1f57580" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"eudoxos said: ↑ I confirm that the 7120p works with the ASUS P9X79-E WS (which officially supports only Xeon Phi 3120 and friends).Now the cooling, that will be a bit of a hassle. Someone owning the 7120A would care to photograph how it is arranged internally? Where is the fan connected? I could perhaps use the same pin to drive the external fan. For me that would be waste of money. Xeon Phi for the hard work, CPU only dispatches jobs there, no big performance needed. Click to expand... Your jobs could not be done with graphics cards, CUDA/OpenCL?"</post>
   <post id="0b1e74ba-6039-47f1-ba2a-e1c2083fe252" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Your jobs could not be done with graphics cards, CUDA/OpenCL? Click to expand... No. And believe me, I am good programmer, spent 5 months full-time on trying that plus consulted expensive GPGPU pros. GPGPU is hype, it is usefl only for very specific tasks (with predictable memory access patterns) -- most discretized continuum simulations (finite elements, finite volumes), like fluid flow or solid mechanics, lead to solving matrixes, that is where GPGPUs excel. For particle simulations, that s not the case, and there is just one code (which is very limited) simulating particle behavior on the GPU. nVidia published some "particle simulation" tutorials with CUDA/OpenCL, but those are just jokes on the real thing (500k particles, each of them different parameters, complex contact equations, collision detection etc)."</post>
   <post id="fce2cb0b-6899-4d85-aa41-15fab469b3bd" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"^What you say is true, GPU is good for specific stuff only. However, detailed analysis of performance could take into account possibility of having 4 GPUs (like Titan Black) vs. single Xeon Phi in one system. On paper single Titan Black dual floating point performance vs. Xeon Phi is similar."</post>
   <post id="4d4dc674-5636-4658-89bd-b117f0d97901" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"@wirk raw FPS are meaningless as most the time is spent (and that is true also for CPUs) waiting for data from RAM for usual tasks; and that is not a design problem of the code, it is how it is. The GPUs we had were FirePro and some high-end from nVidia and we could not even match the performance of a very normal i7 processor (with different implementation in c++, not in OpenCL). GPGPU was a big marketing, and it still is; but its usefulness is really only limited to tasks with high data locality, and those are just some. Xeon Phi is more similar to CPU in architecture, comparing Xeon Phi to GPU is mixing elephants and apples."</post>
   <post id="3509c456-9bb8-48c5-8851-7451cd54d924" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"I agree with you that Xeon Phi is more like multicore architecture which means it is more flexible. GPUs have fine grain computing units but they are rigid for specific tasks but then performance gain can be impressive as shown for the just released K80 e.g. even for linpack. There is also another fact: every big supercomputer is now a combination of CPU and GPU nodes."</post>
   <post id="bc25912b-fa17-47d5-8f66-6549c90daad0" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"here is also another fact: every big supercomputer is now a combination of CPU and GPU nodes. Click to expand... That s because most SC solve matrices (linpack) for huge PDEs discretized over an insane amount of elements. But I need to solve my problems, not those I don t have...."</post>
   <post id="bcad3972-00ec-4b28-93b8-72af215eddfa" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"wirk said: ↑ I agree with you that Xeon Phi is more like multicore architecture which means it is more flexible. GPUs have fine grain computing units but they are rigid for specific tasks but then performance gain can be impressive as shown for the just released K80 e.g. even for linpack. There is also another fact: every big supercomputer is now a combination of CPU and GPU nodes. Click to expand... That s not exactly true when the #1 supercomputer for example uses Xeon Phis, not GPUs."</post>
   <post id="f01aec32-837a-45ba-90e5-1219c273a9ca" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Blue Fox said: ↑ That s not exactly true when the #1 supercomputer for example uses Xeon Phis, not GPUs. Click to expand... It will be dethorned by the ones which use GPUs"</post>
   <post id="a69bf74e-e861-4f92-8556-072ae957897c" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Years away and there s always something better around the corner. New Xeon Phis are increasing performance by considerable amounts."</post>
   <post id="340771c5-2e86-4158-91cb-c0090c1ffce0" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"Blue Fox said: ↑ Years away and there s always something better around the corner. New Xeon Phis are increasing performance by considerable amounts. Click to expand... ...in their specific areas, there is not insignifcant pool of cases where GPUs are better ."</post>
   <post id="e3e094ac-43f9-4b0d-a895-6fce08c93ddf" section="Physics Processing" discussion="Xeon Phi 7120p: compatible mobo s">"The Phi sucks up PCIe bandwidth. To me, it makes the most sense to use it as intended- with a dual E5 board. I ve successfully tested the Phi on the Supermicro X9DAi and Intel S2600COE, but wasn t able to get it working on a single-proc Asus Z9PA-U8. Also, the Windows toolchain is not mature (or wasn t the last time I played with it a few months ago), so I wouldn t really bother unless you re using Linux."</post>
   <post id="11bdf226-9910-4da6-a9de-43a73042e998" section="Physics Processing" discussion="windows 10 hybrid physx">"Going to try to get hybrid physx on windows 10 tomorrow any bet on how bad this is going to fail? 270x + 7870 crossfire 640gt dedicated physx card"</post>
   <post id="b663fd79-5661-4db9-b14c-2c81a81637d6" section="Physics Processing" discussion="windows 10 hybrid physx">"Wow, That is a real Frankenstein build. a 270, and 7870, AND a 640... What could go wrong!?"</post>
   <post id="d58dc5c5-bd2e-4971-9fd2-9060e995c567" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"I have 1920 x 1080 144Hz screen ,hence the 1920 x 1080 Physx benchmarks. Just to clarify it is extremely hard to get every kill/blowing up stuff ETC with 5 minute frap runs in game exactly the same each time for Titan X and Titan X + 970 GTX .YMMV. Neither setup was able to run AC4Blackflag/Metro 2033 Redux/Metro Last Light Redux without 100% stutter free. May be of interest to some. Data table for easier reading For anyone interested Frametimes for all benches with fraps viewer. http://www.mediafire.com/download/g9xhyq7x9ladt24/Titan+X+Frametimes+With+Viewer.7z"</post>
   <post id="4cc7bc0d-5f3c-4766-aeb8-04eb1ef764eb" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Some of those games look like they REALLY benefited from the 970, pretty impressive on the minimums. How s it compare to like, a 460 for physx, or something of a lower class? Any plans on those comparisons?"</post>
   <post id="ef6e37f4-a742-4bce-ba61-92a7ce0ef85c" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Thanks for sharing. I think you d want at least a 750ti for Physx... there are reviews on the older cards and a 460 is too old IIRC."</post>
   <post id="d81de256-034e-48e2-9edd-7a7fbc636981" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"I think the 460 should still be fine (though not super ideal). I was just curious on a full on comparison from high to low (970 being a VERY high physx card)."</post>
   <post id="21214c2f-d3f9-4a06-91ae-faffb3fe592d" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"So I guess my wanting to have a constant 144 FPS is still a pipe dream ?"</post>
   <post id="85efd27a-5d38-41b3-ab22-cfd28ca0d886" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Simmonz said: ↑ So I guess my wanting to have a constant 144 FPS is still a pipe dream ? Click to expand... I tested a lot of games on Titan X at 1920x1080.Still lots of games can not be maxed out due to lots of reasons.Hell I been chasing 60 FPS in games Maxed out,still not there yet.Come on AMD and Windows 10 to help out some."</post>
   <post id="ac2e485a-1b56-4fd0-9d66-658788ddc9c0" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Those scores look a bit low."</post>
   <post id="b4001968-cbc7-49bb-99ab-412fc8ee8c94" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"You might be CPU bottlenecked in some of those cases."</post>
   <post id="e99e791f-c198-4f0f-88f5-857ed2214301" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Removed"</post>
   <post id="49da7178-4984-4471-bef2-b9b0a02a27df" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Nicholars said: ↑ Those scores look a bit low. Click to expand... Well lets put it this way there not low there,they are where they should be from testing 780TISLI/970SLI/980SLI/R9 290/X Crossfire.Same machine. There is a combination of things that affect scores and it is what it is. You might be CPU bottlenecked in some of those cases Click to expand... Yes this can be true and even with a 5960 not going to make much difference in some games.The Titan X is a fast card .Maybe Windows 10 can help somewhat in the CPU department in future games."</post>
   <post id="765729c1-b61a-4d47-9785-e25f1c3fbeea" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Well when you re doing 8x MSAA it s going to impact your performance a bit. Might be better off doing 1.5x DSR and 2x MSAA or something like that. In my testing doing a little bit of DSR and a little bit of MSAA looked better and was less of a performance hit."</post>
   <post id="b0e78da5-c584-4170-84a7-01be4cfd0e62" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Dayaks said: ↑ Well when you re doing 8x MSAA it s going to impact your performance a bit. Might be better off doing 1.5x DSR and 2x MSAA or something like that. In my testing doing a little bit of DSR and a little bit of MSAA looked better and was less of a performance hit. Click to expand... Well of course you can turn down AA use DSR. EG:Metro 2033 Redux 144Hz v-sync https://www.youtube.com/watch?v=HpyyMBd6kr4"</post>
   <post id="b77824e6-0bfc-4a20-81da-8a8248c81102" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"This is good stuff. I always wanted a reason to get a dedicated physx card. Planetside 2 would have been a good excuse but they never put the physx back in"</post>
   <post id="2e953b25-f40b-4d32-937f-e1400f0cc7f9" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Sk3tch did this review a long time ago. http://1pcent.com/?p=135 I ve read people with SLI comment it adds to microstutter a lot with SLI. You have to wonder if it just bogs down one card or if Physx is split across the cards. I d guess it s just one."</post>
   <post id="d893702a-fd62-40b9-8cdf-7c4d26cdb7de" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"gerardfraser said: ↑ Well lets put it this way there not low there,they are where they should be from testing 780TISLI/970SLI/980SLI/R9 290/X Crossfire.Same machine. There is a combination of things that affect scores and it is what it is. Yes this can be true and even with a 5960 not going to make much difference in some games.The Titan X is a fast card .Maybe Windows 10 can help somewhat in the CPU department in future games. Click to expand... Don t know but I don t remember arkham city going under 60fps at all at 1080p with everything including physx on high with a single 970 at 1425mhz. Maybe my memory is not very good"</post>
   <post id="73be56a1-21f2-4589-b5d3-ef6090063d52" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"I will have a 770 classified to use as a dedicated physx card in the next couple weeks. I ll add those results to this thread when I get the card (if I can pull myself away from GTA5 long enough to test.. ). Your Metro results are disappointing... those are the games I m getting the dedicated physx card for, and it looks like it won t help much at all."</post>
   <post id="ab55ddda-0c4b-49a0-8f8b-9d952bdc1a78" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Yes it does not help much in the Metro games,but I can tell you it really does not matter with the metro games if you turn off 4xSSAA and use 2xSSAA or less. Also the Metro redux games can be run in 4k really good without SSAA and no slowdowns."</post>
   <post id="ad72d01e-0bc0-4642-979c-09276660c814" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"That s interesting that Metro wasn t affected much. Did you make sure Physx effects were present in the run through? Grenades/smoke/ect? I remember a benchmark where a 290x was decimated by metro ll with Physx on (50% hit) so I thought there would if been some kind if hit. I like having dedicated Physx to reduce stutter (increase minimums). Physx effects generally happen in short bursts and have less an effect on averages."</post>
   <post id="488e1246-e433-4db0-b216-2428e6bc01d8" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"Dayaks said: ↑ That s interesting that Metro wasn t affected much. Did you make sure Physx effects were present in the run through? Grenades/smoke/ect? I remember a benchmark where a 290x was decimated by metro ll with Physx on (50% hit) so I thought there would if been some kind if hit. I like having dedicated Physx to reduce stutter (increase minimums). Physx effects generally happen in short bursts and have less an effect on averages. Click to expand... . Just did another quick test with 970 SLI. CPU Physx was faster.HMMMMM interesting.All I can say this is what I get when benching. Well i would like to say I had it setup correctly but anything is possible. Heavy Squad with all Physx stuff going on. 2015-05-08 18:48:11 - Metro Last Light-970 SLI CPU Physx Frames: 2630 - Time: 60000ms - Avg: 43.833 - Min: 36 - Max: 49 2015-05-08 18:55:09 - Metro Last Light-970 SLI Auto Physx(970 card 2) Frames: 2354 - Time: 60000ms - Avg: 39.233 - Min: 29 - Max: 48 2015-05-08 19:02:47 - Metro Last Light-970 + 970 Physx Frames: 1334 - Time: 60000ms - Avg: 22.233 - Min: 16 - Max: 51"</post>
   <post id="a223bf1a-0b12-4e66-83d1-fa368aeba051" section="Physics Processing" discussion="Titan X + 970 GTX Physx Benchmarks">"gerardfraser said: ↑ . Just did another quick test with 970 SLI. CPU Physx was faster.HMMMMM interesting.All I can say this is what I get when benching. Well i would like to say I had it setup correctly but anything is possible. Heavy Squad with all Physx stuff going on. 2015-05-08 18:48:11 - Metro Last Light-970 SLI CPU Physx Frames: 2630 - Time: 60000ms - Avg: 43.833 - Min: 36 - Max: 49 2015-05-08 18:55:09 - Metro Last Light-970 SLI Auto Physx(970 card 2) Frames: 2354 - Time: 60000ms - Avg: 39.233 - Min: 29 - Max: 48 2015-05-08 19:02:47 - Metro Last Light-970 + 970 Physx Frames: 1334 - Time: 60000ms - Avg: 22.233 - Min: 16 - Max: 51 Click to expand... Your first and second test are most probably the same settings. GPU Physx can t be run on a CPU so it defaulted to the SLI setup."</post>
   <post id="698739de-cd42-4396-97a6-c3f25d9ce5a5" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"This came up in another thread, and I hadn t seen it before, so I figured it deserved its own post. https://developer.nvidia.com/content/latest-physx-source-code-now-available-free-github By Rev Lebaredian, posted Mar 04 2015 at 09:27AM NVIDIA today put more than a decade of research, development and investment in gaming physics into the hands of game developers – by offering free source code for NVIDIA PhysX on GitHub. This will accelerate the adoption of PhysX, the premier physics engine in gaming. And it will help game developers by lowering the barrier of entry to putting world-class physics effects in their games. Used in more than 500 games on multiple platforms, NVIDIA PhysX is one of the most popular physics engines for game development. The PhysX software development kit (SDK) is already free on Windows platforms. We’re now extending this to include PhysX Clothing and PhysX Destruction, enabling game developers to easily create a more interactive gaming environment. And starting this month, the PhysX SDK is available free with full source code for Windows, Linux, OSx and Android on https://github.com/NVIDIAGameWorks/PhysX. The PhysX SDK is a proven solution for gameplay physics and simulation-driven effects. It is integrated into major game engines such as Unreal Engine 3 and 4, Unity, AnvilNext Engine, Bitsquid Engine, Dunia 2 Engine and REDengine. NVIDIA PhysX Clothing and Destruction are integrated into the Unreal Engine 4. PhysX Clothing and Destruction effects can be seen in games such as: Batman: Arkham Asylum, Batman: Arkham City, Bioshock Infinite, Borderlands 2, Lords of the Fallen, Monster Hunter Online, Daylight, as well as upcoming titles such as The Witcher 3. A major component of the NVIDIA GameWorks library, the latest PhysX version (3.3.3) is our best ever, with improved stability and performance. Features include constrained rigid body dynamics, collision detection, scene queries, character controller, particles, vehicles and much more. The NVIDIA GameWorks library is supported by developer resources including authoring tools for 3dsMax and Maya and the PhysX Visual Debugger (PVD). Simple to use authoring tools are also available on the NVIDIA GameWorks webpage, along with tutorials that provide step-by-step instructions on how to create destructibles and clothing assets. To access the GitHub repository, simply join the NVIDIA GameWorks Developer Program and accept the click-through EULA for PhysX source code. Full details can be found here. For console support, please contact physxlicensing@nvidia.com Click to expand... I m not a registered developer, so I don t know all the legal details, but this could lead to open implementations of PhysX. I think that would make adoption a lot easier for a number of people, both at the consumer and developer ends."</post>
   <post id="724e7252-6845-48c7-acb9-702a5c68687b" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"And still after over a week since this was announced, it still just goes to a 404 not found page."</post>
   <post id="8052445b-903e-4116-881c-2a0a22422445" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"https://developer.nvidia.com/physx-source-github said: Starting this month, PhysX SDK is now available free with full source code for Windows, Linux, OSx and Android on https://github.com/NVIDIAGameWorks/PhysX (link will only work for registered users). Click to expand... Are you registered with their dev program? I m not, so I can t say whether or not it s working properly."</post>
   <post id="9edce894-0874-48f0-8238-d627dec93f4d" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"InvisiBill said: ↑ Are you registered with their dev program? I m not, so I can t say whether or not it s working properly. Click to expand... Yep, I am registered with their dev program. I even signed up for more parts of their dev program shortly after the release and it still wouldn t work."</post>
   <post id="8a40bfd6-8792-42a0-93f3-406072894144" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"Ok, so the link that is posted everywhere does not work. You have to go to this page, log in with your Nvidia dev account, and register for access for the source code. https://developer.nvidia.com/physx-source-github"</post>
   <post id="1a5fd903-5bce-4d37-afc3-c50124c3c26c" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"InvisiBill said: ↑ I m not a registered developer, so I don t know all the legal details, but this could lead to open implementations of PhysX. I think that would make adoption a lot easier for a number of people, both at the consumer and developer ends. Click to expand... The licensing agreement requires that you only use the source code in conjunction with your own game code so anything like that would contravene the license. You could probably use the code to get a full listing of all API functions and then create your own implementation of PhysX from scratch (because just copying the API is apparently ok), but that would be a monumental undertaking and could have been done from the documentation."</post>
   <post id="75c927b2-ee94-43c6-97ff-51e4f0597d42" section="Physics Processing" discussion="Latest PhysX Source Code Now Available Free on GitHub">"Starting this month, PhysX SDK is now available free with full source code for Windows, Linux, OSx and Android on https://github.com/NVIDIAGameWorks/PhysX (link will only work for registered users). Click to expand... So does that answer your question? Obviously they re doing their best to make sure that only authenticated game developers are the ones who get access to the source code. You know what an easier way is? Since PhysX is part of Unreal Engine 4 and UE4 is now completely  free  with full source code (with a modest royalty agreement if your game makes over X money) then you can just get into that UE4 thing and use PhysX without issues. I hope we get a lot more cross-platform gaming now. I d love to game on Linux rather than Windows if possible. Never again deal with the damn Windows registry and a thousand+ other crap things that M$ put into Windows to gimp it from being a truly efficient gaming-centric platform."</post>
   <post id="59740f97-4b82-4f2a-aeb2-bb1765549609" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"Will running a dedicated PhysX card with PhysX enabled result in any performance increase from running no PhysX? Or would it just add new effects without any performance gains? I am curious if it offloads/stops any alternative physics engine (like Havok) that the GPU or CPU would be running otherwise, and if so if that helps wih performance gains. The only benchmarking I have seen is with dedicated card vs no dedicated card with PhysX on in all tests. I would like to see results of  PhysX off  vs  PhysX on with a dedicated card ."</post>
   <post id="24990018-7ab4-4471-9309-638ba54c570e" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"Hardware PhysX can only make the game run slower not faster, no matter how you run it. ** unless you are badly cpu limited already You can break even if you already have plenty of headroom. If the game uses PhysX then it uses PhysX, not Havok. And vise versa. PhysX has CPU and GPU libraries, the level of PhysX determines whether GPU code is used. The higher the level, the more complex the PhysX effects and thus they are offloaded to the GPU. Running the GPU PhysX code on CPU is possible in some games but you will wish you hadnt"</post>
   <post id="3016e29a-672b-4104-933c-8fbc747e85ed" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"Nenu said: ↑ Hardware PhysX can only make the game run slower not faster, no matter how you run it. ** unless you are badly cpu limited already You can break even if you already have plenty of headroom. If the game uses PhysX then it uses PhysX, not Havok. And vise versa. PhysX has CPU and GPU libraries, the level of PhysX determines whether GPU code is used. The higher the level, the more complex the PhysX effects and thus they are offloaded to the GPU. Running the GPU PhysX code on CPU is possible in some games but you will wish you hadnt Click to expand... Does PhysX take over things like  gravity , ragdoll effects, collision detection? Or does it just add new effects?"</post>
   <post id="96068a5e-f77a-417f-b2c9-756fce7e8e35" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"jamesgalb said: ↑ Does PhysX take over things like  gravity , ragdoll effects, collision detection? Or does it just add new effects? Click to expand... Both. Depends on what the developer does with it. Harkening back to the original PPU hardware, it s just a very fast hardware vector math calculator. this lines up well with GPU architecture as well. So, anything that falls into that kind of math can be accelerated."</post>
   <post id="c8f1ff16-c887-466e-bf0a-479fab1e5469" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"A few years ago I would have recommended a dedicated nvidia physx card in any PC, maybe even including an ATI rig with hacked physx drivers. But I personally see that physx in its current form is falling out of favor, because multi-cored CPU s are able to multitask in a way which mimics large mainframe servers of the past. I ve heard of rumors of a new much more advanced physx hitting the market. If that ever happens I would take a look at physx again at that point and reevaluate what I think about it. Knowing Nvidia they will milk the new tech for what it s worth. Currently though I run crossfired ATI cards along with a hexacore CPU and noticed the difference between having a dedicated physx card , and not having one doesn t really matter with a powerful CPU with enough cores to be able to handle the game and physx at the same time without being a bottleneck. Edit: Someone correct me if i m wrong , but IIRC Nvidia driver software is bundled with support for more advanced versions of physx which are newer than what CPU physx is able to run. So, in some games you will see physx effects which are specialized for nvidia cards only (i.e Batman Arkham series)."</post>
   <post id="0f1b8bc4-eeb7-4940-8e66-a482d5306863" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"jamesgalb said: ↑ Will running a dedicated PhysX card with PhysX enabled result in any performance increase from running no PhysX? Or would it just add new effects without any performance gains? I am curious if it offloads/stops any alternative physics engine (like Havok) that the GPU or CPU would be running otherwise, and if so if that helps wih performance gains. The only benchmarking I have seen is with dedicated card vs no dedicated card with PhysX on in all tests. I would like to see results of  PhysX off  vs  PhysX on with a dedicated card . Click to expand... As Nenu already said, a game generally uses a single physics engine, like PhysX or Havok. I suppose you could theoretically write a game to use both, and choose PhysX if the user has hardware for it but switch to Havok if they didn t. That s not a very likely scenario though, as it would basically be coding the physics-related portion of the game twice. If you wrote it for PhysX with GPU acceleration, there d have to be a pretty big reason to switch and have it use Havok instead of just using the non-GPU PhysX that you already have in there. Generally, the dev would pick either Havok or PhysX, and if they use PhysX, they can code it to take advantage of the faster GPU processing. If the game doesn t use the PhysX engine, or the dev wrote the game s PhysX code to not take advantage of the GPU, a PhysX card will have absolutely no effect on anything. Check out my post from a few years ago, HD5770 bottlenecked by 9800GT for PhysX. I did some comparisons with a number of AMD and Nvidia cards doing hybrid PhysX with Batman:AA. I recently did some more tests with my new GTX970 to compare old and new. Batman:AA makes good use of PhysX to boost the atmosphere of the game. There s a split-screen video with it on and off to give you a good comparison of what you re missing without PhysX. The framerate was generally cut in half by turning on PhysX. Even a GTX285 dedicated to PhysX wasn t enough to keep up with the graphics power of only a HD5770. My HD5870 with a 9800GT dedicated to PhysX was enough to give me 100fps average and 60fps minimum at 1080p. The GTX970 doing both graphics and PhysX is 30% faster than the HD5870+GTX285. LaCuNa said: ↑ A few years ago I would have recommended a dedicated nvidia physx card in any PC, maybe even including an ATI rig with hacked physx drivers. But I personally see that physx in its current form is falling out of favor, because multi-cored CPU s are able to multitask in a way which mimics large mainframe servers of the past. I ve heard of rumors of a new much more advanced physx hitting the market. If that ever happens I would take a look at physx again at that point and reevaluate what I think about it. Knowing Nvidia they will milk the new tech for what it s worth. Currently though I run crossfired ATI cards along with a hexacore CPU and noticed the difference between having a dedicated physx card , and not having one doesn t really matter with a powerful CPU with enough cores to be able to handle the game and physx at the same time without being a bottleneck. Click to expand... I agree with your general sentiment that PhysX isn t that big a deal right now (only slightly less than it was several years ago). However, CPUs still trail way behind the massive parallelism of GPUs, which is where physics calculations excel. Check out the CompuBench OpenCL benchmark results. Depending on the specifc test, an i7-5960X is comparable to a mid-level GPU from a few generations ago. On dnetc, the HD4350 I picked up for a few bucks as a basic PCIe card for system diagnostics is as fast as my overclocked i7-920. GPUs are simply better than CPUs for some types of work (which is why we all have video cards instead of just faster CPUs and software rendering). I m not saying we can t get to a point where CPUs provide acceptable performance, but without a major change in the way things are done, I don t think they ll ever catch up to equivalent (in age and tier) GPUs as far as physics performance, just because of the type of calculations being done. If my choices are using an affordable GPU as a physics processor for modern effects, or having my CPU do processing for equivalent physics from 5 years ago, I ll gladly buy an accelerator to get the high-end effects. We all know that CPU PhysX doesn t work all that well, and there were rumors that there were artificial limits on CPU PhysX in B:AA, but we re talking a difference of 18fps with my overclocked 920 vs. 98fps from the 9800GT I had leftover from upgrading. I think Nvidia really screwed up with the exclusivity on PhysX. In games that make good use of PhysX, the effects can be pretty awesome. However, no dev wants to make a game that relies on PhysX as they re instantly cutting out AMD users as potential customers. They only use it for fluff to make the game look better, without hurting it too much for users without PhysX cards. Since it s only used for extra fluff, only a portion of enthusiasts even bother with a PhysX card. It s a chicken &amp; egg situation where nobody buys it because nobody uses it because nobody buys it. If they hadn t blocked hybrid PhysX, I think a lot more people would ve bought a secondary Nvidia card (even if their primary was AMD), which would ve led to more devs doing more with PhysX, which would ve led to more Nvidia sales (either as primary cards at upgrade time, or continuing purchases of secondary cards). I m sure there are a few people out there who wanted an AMD card but bought an Nvidia card instead simply because it was the only way to get PhysX. However, I m sure the vast majority simply bought that AMD card they wanted, and forgot PhysX even existed."</post>
   <post id="6c231877-f108-44c1-aec8-3f1438e72745" section="Physics Processing" discussion="Dedicated PhysX Card vs No PhysX question?">"Depending on the criteria of your gaming system such as: CPU GPU Preferred display resolution Preferred in-game graphics settings ...then you may be much better off getting a single strong GPU or a pair of mid-range to high-end GPUs to handle graphics + PhysX. I game at 1080p and use higher in-game graphics quality settings and Adaptive Vsync for my 144 Hz monitor. Even though it s "only" 1080p, I decided on a higher-end SLI setup to drive graphics + PhysX (when available) and keep the FPS above 90 as much as possible. Now, I could move to SLI 970, but I wouldn t be gaining enough of a performance increase over my 780s to justify the cost of doing so. Yeah, I d get an extra 0.5 GB of VRAM, but I m still not pushing a resolution over 1080p or going completely crazy with the in-game settings such as AA. If I were using a single 780, I d likely be buying a pair of 970s tomorrow instead of buying a second 780. The comparatively lower power draw and heat output with that much GPU horsepower would be pretty awesome, though. Especially for the price ($660-700)."</post>
   <post id="2e4673d1-3c8e-461a-ae7a-68d93435742d" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I have a few different cards around here, so I thought I d test this out. My system had a GTX285 for graphics and a 9800GT for PhysX. I found a good deal so I decided to buy an HD5870. While that was in shipment, I decided to pick up an HD5770 locally to make sure that I didn t have issues with a hybrid ATI/Nvidia system. This is all running on my Classified E759/i7-920 system. Overclocked to 3.3GHz by turning the BCLK up to 166. Turbo and HT enabled. Here are the video cards I ll be using for the main graphics. The HD5770 that I m using temporarily. My new HD5870. You can see that it s almost exactly two times the 5770 in every spec. Here are the PhysX cards that I ll be using. My 9800GT PhysX card. I put an Accelero on it and overclocked it a bit via the BIOS (600/900 -&gt; 650/1000). My friend s GTX275 that I borrowed for benchmarking. Bone stock. My GTX285, my previous graphics GPU. Bone stock. I m testing with Batman: Arkham Asylum. These are the settings I used to play through the game (minus VSync). No tweaking done in the ATI control panel. Note that they do recommend a 9800GTX+ for the High PhysX setting. [SIZE=+3]Results[/SIZE] I ran each test three times to ensure that I got consistent results. Numbers listed are minimum, average, and maximum FPS. Code:           [color=#00FF00]9800GT     GTX275      GTX285[/color]"</post>
   <post id="31-76-126  29-79-130   30-81-134" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[color=#FF0000]HD5770[/color]  31-77-126  30-70-129   31-83-135" section="##2##" discussion="##3##">"##4##"</post>
   <post id="31-76-127  30-79-130   28-82-136" section="##2##" discussion="##3##">"##4##"</post>
   <post id="59-98-130  63-106-156  65-107-157" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[color=#FF0000]HD5870[/color]  62-97-130  63-105-156  63-108-165" section="##2##" discussion="##3##">"##4##"</post>
   <post id="62-98-132  60-104-156  61-107-163 You can see that even with just the HD5770 for graphics, upgrading from the 9800GT for PhysX does increase the average and maximum framerates. Especially with VSync locking you to 60fps, you probably wouldn t notice the difference, but the game does perform better with a beefier PhysX card. Even without an uber top of the line card, a weak PhysX card can hold you back. In reality, there s not a huge difference in performance between a budget 9800GT and a rather-expensive GTX285 though. The GTX285 is definitely better in all of the tested scenarios, but probably not enough to justify the extra ~$200 for most people. You d definitely be better off upgrading your graphics card from a 5770 to a 5870 rather than upgrading your PhysX card from a 9800GT to a GTX285. [SIZE=+3]Without PhysX[/SIZE] For comparison, here are the results without PhysX. I tested both disabling PhysX in the Nvidia Control Panel while leaving the game set to High, as well as turning off the PhysX effects in-game. Note that turning off PhysX effects dramatically changes the game s appearance. Example 1 Example 2 Code:         [color=#00FF00]Disabled     Off[/color]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="11-17-38  74-125-162" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[color=#FF0000]HD5770[/color]  12-18-39  76-128-167" section="##2##" discussion="##3##">"##4##"</post>
   <post id="11-18-40  78-128-166" section="##2##" discussion="##3##">"##4##"</post>
   <post id="11-18-42  102-216-296" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[color=#FF0000]HD5870[/color]  12-18-37  103-217-301" section="##2##" discussion="##3##">"##4##"</post>
   <post id="9-16-42  106-218-310 [SIZE=+3]Single-card Graphics/PhysX (Newer GPU - Feb. 2015)[/SIZE] I noticed my HD5870 was almost 5 years old and decided to upgrade. I got a GTX970 (specifically the EVGA GeForce GTX 970 SSC ACX 2.0+), and figured I d do some testing with the new card. Honestly, nothing else relevant to this comparison has really changed in my system. I installed the latest Nvidia drivers and replaced my Radeons (I had also been using a secondary HD5830 for BitCoin mining and second monitor duty) with the GTX970. I used all the same in-game settings. My Nvidia Control Panel settings are fairly high, as I don t really have any new games, so the quality is more beneficial than extra (wasted) performance. Code:          [color=#FF0000]PhysX Off[/color]     [color=#00FF00]GPU PhysX[/color]" section="##2##" discussion="##3##">"##4##"</post>
   <post id="122-280-400   78-141-197" section="##2##" discussion="##3##">"##4##"</post>
   <post id="[color=#00FF00]GTX970[/color]  115-276-412   74-140-189" section="##2##" discussion="##3##">"##4##"</post>
   <post id="115-277-388   78-142-205 Just to explicitly state the results, the GTX970 by itself is approximately 30% faster than the HD5870/GTX285 combo, averaging 140+ rather than ~107 (similar percentage compared to just the HD5870 too, without PhysX). Newer hardware is faster than older hardware, in case you didn t get the memo. What surprised me is just how much of the GPU the PhysX processing takes, even on a beefy new card (since I didn t previously test a single card with and without PhysX). Enabling PhysX cuts the average and max framerates in half (min is only about a 1/3 drop)." section="##2##" discussion="##3##">"##4##"</post>
   <post id="2f7b6e50-56b9-4e2d-b865-5299c7f1787d" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Do you have results of just the HD5770 alone?"</post>
   <post id="f3035ba0-2289-4252-9ce9-ce57e606f0ee" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I ll run the tests without PhysX too, just for comparison. I don t want to mess with all the hacks to get CPU PhysX (i.e. the other way to get PhysX on an ATI system). Keep in mind that the game is very different without PhysX. http://www.youtube.com/watch?v=luSAnouAFJs&amp;hd=1 http://www.youtube.com/watch?v=iWlmIjNiqWM&amp;hd=1 Ok, test results have been added to the original post."</post>
   <post id="eac63c66-29e6-4f3e-a19b-eaed9afdfe52" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I have a 5870 in my rig and a spare 9800GTX+ laying around. How did you get the physx to work with ATi card?"</post>
   <post id="67cc2b97-6ae8-478e-be97-aa096bf3d825" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"ChucklesC6 said: ↑ I have a 5870 in my rig and a spare 9800GTX+ laying around. How did you get the physx to work with ATi card? Click to expand... http://www.google.com/search?q=GenL+PhysX+mod. I ve also got some details of my own personal issues with it at http://hardforum.com/showthread.php?p=1035542384#post1035542384."</post>
   <post id="e7f1dbb8-a5a7-4be0-98ae-f93491e6b54b" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Any updates on this with the HD5870??"</post>
   <post id="9fb9ec74-da95-4f15-af60-b6675b7118c5" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"My original 5870 deal was, as I suspected, too good to be true. I ordered one elsewhere, and it will be delivered tomorrow. I should have the numbers up in the next few days."</post>
   <post id="1164800a-2e65-4f94-9d22-c6828d67dcbe" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I m interested in seeing how the 5870 would do. I m thinking of maybe buying one and a 9800gt. Would a 9600gt be at all adequate for a physx card?"</post>
   <post id="2682486c-db42-409c-b1a9-a14cf5b74514" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Aaron11 said: ↑ I m interested in seeing how the 5870 would do. I m thinking of maybe buying one and a 9800gt. Would a 9600gt be at all adequate for a physx card? Click to expand... This thread shows that a 5770 is bottlenecked by a 9800GT for PhysX. The bottlenecking will only be worse with the 5870, since the graphics card is faster while the PhysX card is the same. Stepping down to a 9600GT would make it even worse, since the 9800GT has almost twice the shaders (112 vs. 64). I m using a 9800GT because I had the card from before. If you re specifically going out and buying one, you d probably be better off spending a little more and finding deal on a GTX260, if you want better PhysX performance. I guess it depends on the deals you can find."</post>
   <post id="8379fb02-b171-4aaa-a564-aa8e7320afe2" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"would you be interested in doing a review for my website, http://www.gamephys.com ? let me know."</post>
   <post id="aa1864cf-6ea4-44a9-af3f-ff1f48a0ddb1" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I have a HD5870 + 9800GT. When I run the in game bench mark the Max. for normal PhysX is 25 so I would say that a 9800GT may be to slow for a HD5870. I have run this twice and get the same score. Would a 9800GTX+ be any faster for PhysX?"</post>
   <post id="8aeeefde-28e0-4b34-aa2c-220a247e6f8f" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Is it just me or are people asking the same question over and over again just worded differently..."</post>
   <post id="1799afa4-2fd8-46ae-b182-24819e0caf1d" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"DeanEH said: ↑ I have a HD5870 + 9800GT. When I run the in game bench mark the Max. for normal PhysX is 25 so I would say that a 9800GT may be to slow for a HD5870. I have run this twice and get the same score. Would a 9800GTX+ be any faster for PhysX? Click to expand... Look up a few posts. The 9800GT is too slow for a 5770, so it s only logical that it s going to be too slow for a 5870, which is even faster. The 9800GT has 112 shaders at 1500MHz. The GTX+ has 128 shaders at 1836MHz. Yes, it will be faster. For comparison, the GTX285 has 240 shaders at 1476MHz (over twice as many as the 9800GT and running only a hair slower). You ll have to determine if that s good enough for your own needs though. You stated that you got 25 max with Normal PhysX. What exactly do you mean by that? As you can see from the numbers in the original post, the 5770 got 31-127fps (76 average) with the 9800GT on High PhysX. With the PhysX card disabled but the game still trying to use High PhysX, it got 11-40fps (18 average). If you got a maximum of 25fps on any test, I don t think your PhysX is working properly."</post>
   <post id="e08fd7b5-72e3-405a-be9e-cd8074b21e30" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"How important/big of a hit is PhysX performance in Batman:AA? Let s consider the most ridiculous scenario possible. 2x GTX 480 + 1x GTX 480 dedicated physx processor. That s probably the best you can get... But would having the dedicated physx processor beat using 3x GTx480 in SLI without using a dedicated PhysX processor? Where is the point where, the dedicated physX processor reaches a point of diminishing importance vs how much power is dedicated to the rendering cards? Lastly, should we care enough to spend $200+ for a dedicated PhysX processor? After all, a GTX 260 is $200, a GTX 275 is $250, and a GTX 285 is $320-400. Meanwhile a GTX 470 is $350 and a GTX is $500 (if you can find them without a jacked up price). At this point I don t think there s any reason to buy a 285 for physx processing, when a 470 is the same price or less but faster."</post>
   <post id="df3a3238-f600-48d3-b2d3-15393668c703" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Ok, got the numbers from the 5870 with the GTX285 up. Haven t had time to swap the 9800GT back in for those tests yet. With PhysX set to High in-game but the Nvidia card disabled, the 5870 posts almost the exact same numbers as the 5770. The PhysX chugging along seems to be the bottleneck here. Using the 285 for PhysX, the 5870 is basically 30fps higher across the board. With PhysX effects turned off in-game, the 5870 is 30fps higher on minimums, 90fps higher on averages, and 130fps higher on maximums. This basically has nothing to do with PhysX, but gives you an idea of how the 5770 and 5870 compare to each other in general."</post>
   <post id="3995e66e-2954-4237-b1e3-75efc72d86fc" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"I m looking forward to seeing the numbers for 5870+285 vs 5870+9800GT. Obviously I think that the 9800GT is going to be MUCH slower. What might be interesting is using a value card like a 250GTS for PhysX instead. That seems to perform rather well as a dedicated processor, nearly as well as a GTX 260, and of course the price point is lot more attractive than any of the GTX series for dedicated PhysX use. Though perhaps GTX 480 GTX SLI + GTX 470 dedicated PPU might be the way to go for high end physX. [Although your ears might bleed! ]"</post>
   <post id="3b1b9198-7182-4a39-b529-962cf625ad0c" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"InvisiBill said: ↑ Ok, got the numbers from the 5870 with the GTX285 up. Haven t had time to swap the 9800GT back in for those tests yet. With PhysX set to High in-game but the Nvidia card disabled, the 5870 posts almost the exact same numbers as the 5770. The PhysX chugging along seems to be the bottleneck here. Using the 285 for PhysX, the 5870 is basically 30fps higher across the board. With PhysX effects turned off in-game, the 5870 is 30fps higher on minimums, 90fps higher on averages, and 130fps higher on maximums. This basically has nothing to do with PhysX, but gives you an idea of how the 5770 and 5870 compare to each other in general. Click to expand... I find this to be a bit strange... As a general rule of thumb would be be wise to say if you want to use PhysX get a PhysX card on the same level as the main card?"</post>
   <post id="b92958db-7479-4f08-ad74-7ab50da28fd7" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"MuZI said: ↑ InvisiBill said: ↑ With PhysX set to High in-game but the Nvidia card disabled, the 5870 posts almost the exact same numbers as the 5770. The PhysX chugging along seems to be the bottleneck here. Click to expand... I find this to be a bit strange... Click to expand... Yeah, the game even gives a popup warning when you select that if it doesn t find an Nvidia card. I m not sure exactly what it does without a PhysX card - the crippled CPU PhysX I guess? Trying to run High PhysX without a PhysX card is painful to watch (16-18fps average), so I wasn t surprised when the two ATI cards put up essentially identical numbers. The 5870 is a bit higher on maximums, which is probably from an area with almost no PhysX stuff going on, so the extra power of the 5870 allows it to pull ahead a bit. MuZI said: ↑ As a general rule of thumb would be be wise to say if you want to use PhysX get a PhysX card on the same level as the main card? Click to expand... I ve seen it recommended (on the Nvidia forums I believe) that you should use a PhysX card with half the shaders of your main card. I know that the number of shaders doesn t translate directly between ATI and Nvidia, but it gives you an idea of what to aim for. However, the 5770 test shows that there s noticeable improvement going from a 9800GT to a GTX285. I ve seen the 5770 compared to the GTX260, and Tom s chart this month put it in the same level as the 8800GTS/GTX, one step above the 9800GT. I would therefore say that the 9800GT is more than half of a 5770, and this test shows that you get improvements going even higher than that. If I had more PhysX cards to test, I might be able to find a sweet spot for performance/cost. If you want to add on a good PhysX card for maximum performance, I d say get the best card you can afford. Even if PhysX is replaced by an OpenCL competitor, you should still be able to run it on the dedicated card just as you do with PhysX (so it s not like it would be a complete waste). As far as standalone goes, bigger == better. A more important question might be whether it s better to use one new card for graphics and PhysX, or use the new card for graphics and keep the old card for PhysX. This question has already come up, and there don t seem to be a lot of hard numbers out there. What level of dedicated PhysX card does it take to outperform running it all on a single GTX480 - GTS250, GTX260, GTX285? Offloading the PhysX to any card will reduce the load on the main GPU and allow it to focus on just the graphics, but if the PhysX card is limiting the system to 70fps, then it s pointless for your main card to jump up from 300fps to 400fps. As long as your PhysX card isn t bottlenecking it below your desired minimum, then I guess you could say that any card that meets that minimum is "good enough". If you re VSynced at 60fps, then it doesn t really matter if the GTS250 gives you 70fps while the GTX285 gives you 90fps, other than planning for heavier workloads in future PhysX games. Also, I just realized that my friend has a GTX275. I might be able to swap him my 285 for a couple days to get some more numbers. I m sure they ll be just a bit slower than the 285 s numbers, but it may help pinpoint that perfect value spot. I wish I knew someone who had a GTS250 that I could test for a bit, as that seems to be a popular choice and a lot closer to the middle of the 9800GT-GTX285 gap than the GTX275 would be."</post>
   <post id="7c60907a-7f7a-4fb6-bbbb-944adc799d44" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"Isnt the physx card supposed to help the main gpu. I would think that if you put an 8600gt it would help with the processing unless the main card is just way better at working by its self than with help?"</post>
   <post id="05c884a3-35a9-4dc4-bb6c-af0da68aff87" section="Physics Processing" discussion="HD5770 bottlenecked by 9800GT for PhysX">"drnilly007 said: ↑ Isnt the physx card supposed to help the main gpu. I would think that if you put an 8600gt it would help with the processing unless the main card is just way better at working by its self than with help? Click to expand... http://hardforum.com/showthread.php?t=1492813 Read the posts made by Unknown-One. It should help explain what s going on."</post>
   <post id="e4b97576-d3a2-4830-8aa7-e0bf93c4c6be" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"Hey folks...just received a 750 Ti that I bought for cheap. Plan on refreshing my "dedicated PhysX PPU" research (link) that I last did with Borderlands 2, a GTX 690, 680, 640, 650, and 650 Ti. My goal is to test the most relevant games/tests - and in my research, I have discovered that much has not changed since 2012 when I wrote that last article. Is PhysX nearly irrelevant? Possibly. Am I bored and looking for something "fun" and "different" to do? Definitely. If you have any thoughts/opinions on what tests/games I should benchmark - let me know. Here is my current roster: Borderlands: The Pre-Sequel Passion Leads Army (PLA) Benchmark Fluidmark 1.5.2 Metro Last Light Redux Batman: Arkham City GOTY Lords of the Fallen For hardware, I have 3x GTX 980 SC (although 2-way SLI will be the max, if I even do that - may stick to a single 980 as primary) and 1x GTX 750 Ti to play with (I have a 290X Lightning - but I m not sure I want to delve into the realm of hacked PhysX drivers - has that been maintained? Back in 2012 it was pretty half-assed). Anyway - appreciate any insight or thoughts. Thanks!"</post>
   <post id="6b819fb8-9fc8-4650-842b-81173b508daa" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"I love PhysX, but I agree it s not getting much love these days. Since I m also running 3x 980, I would be interested if there is any benefit to 2-way SLI + dedicated PhysX w/ all 980 s over 3-way 980 s and PhysX auto (but I guess I could test this myself if I cared a lot)."</post>
   <post id="a164214f-33bf-4cbc-be9d-e307408b0b2a" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"test out Arkham City...while it may not be  new , it was one of the few titles that made somewhat good use of PhysX"</post>
   <post id="24dd2afd-650e-464e-a60e-22a520853cb5" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"cybereality said: ↑ I love PhysX, but I agree it s not getting much love these days. Since I m also running 3x 980, I would be interested if there is any benefit to 2-way SLI + dedicated PhysX w/ all 980 s over 3-way 980 s and PhysX auto (but I guess I could test this myself if I cared a lot). Click to expand... You will find this interesting - http://hardforum.com/showthread.php?t=1843871. I plan on doing more tests. But a lot of the info is already there. Just recalled that thread this morning. polonyc2 said: ↑ test out Arkham City...while it may not be  new , it was one of the few titles that made somewhat good use of PhysX Click to expand... Good point. I was going to skip it due to the 2011 release date (the new Batman game isn t due until Summer, I believe). I was thinking maybe Shadows of Mordor but I saw that PhysX wasn t even implemented. Pretty crazy, especially because it reminded me so much of the recent Batman games. Thanks for the replies! EDIT: adding in Lords of the Fallen to the list - has PhysX support and it looks to be pretty extensive: http://www.geforce.com/whats-new/articles/lords-of-the-fallen-physx"</post>
   <post id="1682eb3c-9e01-4559-ae27-9b36ce40395d" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"cybereality said: ↑ I love PhysX, but I agree it s not getting much love these days. Since I m also running 3x 980, I would be interested if there is any benefit to 2-way SLI + dedicated PhysX w/ all 980 s over 3-way 980 s and PhysX auto (but I guess I could test this myself if I cared a lot). Click to expand... You d probably loose more performance than you gain."</post>
   <post id="2b261b68-4d3b-456c-9fe6-4a873b7f7b8f" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"Something to keep in mind is that PhysX is currently in a transitional stage. Current and past titles are still using PhysX 2.x which largely has not been rewritten or received optimization at all since Nvidia s acquisition. PhysX 3.0 has supposedly had massive rewrites for optimization. As such the newer games about to come out which use it may have a very different performance representation than past and existing titles."</post>
   <post id="6a68f684-aef7-4079-b6a9-3d7ba86f6f72" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"I may play the Witcher 3 which said it ll use at least cloth/destruction. Debating it. Looks like it s going to be brutal on systems."</post>
   <post id="5b2d89bc-cf92-4a92-8638-baec5b118ff5" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"X-com Bureau with physX particles is killing performance so this might be worth testing."</post>
   <post id="2e8f3936-663d-4fa5-820e-440a0c2f2a6e" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"Awesome! Thanks for researching this. I ve thought a lot about adding a 750 Ti for dedicated PhysX (I had a 750 Ti before my 970 and loved it, but sold it to a friend). Hawken, Mirrors Edge, Warframe all utilize PhysX. I just started playing "Two Worlds" (which is an older game, but it does use it as well) Thing is, I already max out these games pretty well, so a dedicated card is super overkill. I really wish PhysX was utilized more."</post>
   <post id="4fe2fa84-c1ff-45a9-bfff-afb35d3abc48" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"Mafia II have great implementation of PhysX. specially in vehicle collision.. a good game to test.. =)"</post>
   <post id="5fba6911-3eb6-4d8c-9088-402a10f0c474" section="Physics Processing" discussion="Most Relevant PhysX Performance Tests for 2015?">"Sadly, it s true that at the moment, hardware-accelerated PhysX is practically irrelevant. The only recent AAA titles to use it well were Metro/Redux and the Batman Arkham games. My dedicated 750Ti sits largely unused next to my 780s."</post>
   <post id="d9566779-fbb2-4163-9e90-f142319e6934" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"I m going to be getting a GTX 980 soon and was wondering if it would be worth it to add an old 8800GTS 512MB in for dedicated PhysX ? I figure it can t hurt but I know I ve seen the opposite in the past."</post>
   <post id="8c478917-d1e9-4a0a-b913-c9413f923a5a" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"definitely not. the 8800GTS is a bottleneck when used for physx with high end cards. this was shown back in the 680 era."</post>
   <post id="abbddc3a-567f-4023-82e4-c87f6e279b06" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"worthless, sad but true and this is from a guy that is setting up a dual 8800 SLI retro system next week"</post>
   <post id="c8289876-b122-4de9-9954-7b5a7df509ce" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"Thanks for the input gents. I ll keep the 8800GTS in my spare PC."</post>
   <post id="a505672d-d2f0-4337-9765-895a9e2430d4" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"gtx 460 minimum, then 550, 640 for the lowest of those series"</post>
   <post id="b16ddce4-68c1-4c5b-99a8-a714c3da5bf3" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"just pick up a 750"</post>
   <post id="a97c8b1c-f33e-4ab6-bc76-b97c85ac23e7" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"I wouldn t bother, Physx on vs off doesn t make a big difference in frame rate if you have a high-end Nvidia card so the second card would just be taking up space. Physx could comfortably run on the CPU too if Nvidia s software implementation wasn t purposefully crippled."</post>
   <post id="32515239-015b-4503-a4f0-1ee7e1bcf707" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"Quix said: ↑ Physx could comfortably run on the CPU too if Nvidia s software implementation wasn t purposefully crippled. Click to expand... PhysX can be set to CPU in the NCP."</post>
   <post id="feaadf08-5e15-48d1-8847-f591fc512d9d" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"jojo69 said: ↑ and this is from a guy that is setting up a dual 8800 SLI retro system next week Click to expand... This makes me feel old... 8800 is considered retro.... Hell SLI is too new to be retro to me..."</post>
   <post id="f288f38c-fb02-4939-9dbd-6514f0bf8a37" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"DejaWiz said: ↑ PhysX can be set to CPU in the NCP. Click to expand... But only uses X87 code, no SIMD or multicore. And the last time I checked, we got off using Pentium II and early Athlon CPUs a long time ago. That s why Quix said it was crippled"</post>
   <post id="5dbed013-cef1-4948-8091-3b5ab773a554" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"Mr. Bluntman said: ↑ But only uses X87 code, no SIMD or multicore. And the last time I checked, we got off using Pentium II and early Athlon CPUs a long time ago. That s why Quix said it was crippled Click to expand... I reread that and understand what he meant. I initially though he meant software (as in the NCP) was crippled and prevents PhysX from running on the CPU. My bad and thanks for clarifying!"</post>
   <post id="83136169-93e6-4cca-81d4-0ffb09485921" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"KarsusTG said: ↑ This makes me feel old... 8800 is considered retro.... Hell SLI is too new to be retro to me... Click to expand... If it makes you feel an ybetter, the basement computer still uses an 8800 GTX, not dubbed a retro machine either . Still runs the new games well, although obviously not on the highest settings, I re purposed old parts for my younger brother. Also heats up the basement nicely during the winter."</post>
   <post id="0cb1a8f3-7653-40fe-9ee9-697d05d75157" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"KarsusTG said: ↑ This makes me feel old... 8800 is considered retro.... Hell SLI is too new to be retro to me... Click to expand... LOL Voodoo2 in SLI I think would qualify as retro. Hell to me anything PCI express is too new to call retro."</post>
   <post id="3d097a4d-cb53-43c2-a06d-0c63a11b51a2" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"qtfsniper said: ↑ Still runs the new games well, although obviously not on the highest settings Click to expand... Understatement of the year? Runs some newer games playably at Medium settings at 720p...maybe."</post>
   <post id="9d34c839-d5bf-49d7-83b0-59a9bc3b3150" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"try it and benchmark most likely gtx 980 faster on its own depending on application"</post>
   <post id="d2d57421-f73c-42ff-bbe4-9e2adbe9bef0" section="Physics Processing" discussion="8800GTS 512MB for PhysX">"DejaWiz said: ↑ PhysX can be set to CPU in the NCP. Click to expand... Yes, as I mentioned in my first post. The implementation is intentionally poor and is single-threaded to make non-Nvidia cards look bad."</post>
   <post id="61e313e2-5f70-42ae-b280-b0c0deaf40b5" section="Physics Processing" discussion="Open CL">"Is there any list of games that use Open CL ? I know AMD has put money into it but no idea whether any games use it."</post>
   <post id="eb3fa2ab-5ad5-4e45-87c9-466b6941769f" section="Physics Processing" discussion="Open CL">"Anything using the bullet 3.0+ physics library (not many) https://en.wikipedia.org/wiki/Bullet_(software) Not sure about other uses. Edit: Of interest; someone on reddit did an implementation of conway s game of life in opencl (via pyopencl) as a learning exercise. https://github.com/InfiniteSearchSpace/PyCl-Convergence/tree/master/ConwayCL-Final If anyone wants to get into CL this is a great jumping off point as the CL code is ~50 lines and quite easy to read."</post>
   <post id="2a0be59b-b99b-4173-9a2c-a3dde2ca83e2" section="Physics Processing" discussion="Why the Physx Hate?">"I just snagged a 750ti to go along with my 980. People are so strange to me... All the reviews I ve read (which are hard to come by) having a dedicated Physx processor seemed to help. I liked this one the most, it had good presentation. Only shows average FPS, where having a dedicated Physx card seems especially helpful for minimums... but a 780ti + 750ti was 39% faster than a 780ti doing it all for Batman, which is a game I d like to play. I also play AC4 which definitely could use a dedicated card. BL2 is another one I d love to try. http://i0.wp.com/alienbabeltech.com/main/wp-content/uploads/2014/03/mainchart-fnl.jpg Overall I can t see why anyone would hate on Physx. I definitely haven t read about any negatives, unless you use a card that s too slow, which the 750ti certainly isn t. I can only relate it to someone s jealousy on quad titans, ect. From a value perspective, I spent 40% ($200) more (970 vs. 980) for a 15-20% increase in performance. A 750ti I m spending $150 for a 6-40% increase in performance. Actually a better value for the games I care about (towards the 40% side). Am I missing something?"</post>
   <post id="e97ab6b0-d393-4275-8e18-887a085058d3" section="Physics Processing" discussion="Why the Physx Hate?">"I m a fan of PhysX, because I actually like to have that feature usable in the games I play with it. I m not a fan of having a dedicated card just for PhysX, as I d recommend getting two identical cards for SLI so that all games, PhysX or not, can benefit from having an extra GPU installed. For example, you spent the same money for a single 980 plus a 750ti for dedicated PhysX that two 970 s would have cost. I would always recommend to get the faster SLI setup, but there are drawbacks. You can t go anywhere else with a 970 SLI setup unless your system can support tri or quad SLI. You have a 980 with an upgrade path to SLI which would be faster than a 970 SLI setup. Catch 22, in a sense."</post>
   <post id="0af52a74-2344-4c52-bf2e-6a26e1de590c" section="Physics Processing" discussion="Why the Physx Hate?">"people tend to forget that all Unreal Engine games Use physX but run with CPU.. its funny when people get confused when discover that Mass effect games install physX in their machines.. anyway I like PhysX.. and love in it Batman Series... im playing arkham Origin right now and im missing my 780 just to fully enable it.."</post>
   <post id="1cb62061-70ab-4ec4-92c8-995e4d25ed2e" section="Physics Processing" discussion="Why the Physx Hate?">"I wouldn t call it hate. I used to run a dedicated PhysX card (GeForce 9600) on a former Core2Quad rig for Arkham Asylum. It just wasn t worth the extra trouble (and power) to run the extra card."</post>
   <post id="1d760db7-1338-48b2-b595-151513b1371f" section="Physics Processing" discussion="Why the Physx Hate?">"Most people don t even know what PhysX is or has evolved into. Most critics blindly think PhysX requires an NV GPU and completely forget there is a CPU accelerated version of the engine. I will say the GPU accelerated version adds a ton to a game when implemented properly. To answer simply why all the hate: "We mock what we don t understand." - Austin Millbarge"</post>
   <post id="5d603ed8-0f21-4862-898b-4873747b2218" section="Physics Processing" discussion="Why the Physx Hate?">"Cr4ckm0nk3y said: ↑ Most people don t even know what PhysX is or has evolved into. Most critics blindly think PhysX requires an NV GPU and completely forget there is a CPU accelerated version of the engine. I will say the GPU accelerated version adds a ton to a game when implemented properly. To answer simply why all the hate: "We mock what we don t understand." - Austin Millbarge Click to expand... Agreed. "What s a dickfer?" - Emmett Fitz-Hume"</post>
   <post id="49e6f664-1ac0-4c3e-9e29-c74ea2bd0057" section="Physics Processing" discussion="Why the Physx Hate?">"Cr4ckm0nk3y said: ↑ Most people don t even know what PhysX is or has evolved into. Most critics blindly think PhysX requires an NV GPU and completely forget there is a CPU accelerated version of the engine. I will say the GPU accelerated version adds a ton to a game when implemented properly. To answer simply why all the hate: "We mock what we don t understand." - Austin Millbarge Click to expand... agreed...!!"</post>
   <post id="f2e8453d-418d-4f5a-aaf8-55021b12a701" section="Physics Processing" discussion="Why the Physx Hate?">"The hate for PhysX typically revolves around 2 areas. The first being that its proprietary and not open to everyone. The second is that many games are locked to only being able to use it with Nvidia hardware which basically is looped in with the first complaint. While it can and will run some PhysX on CPUs, most of the fancy features are only run on Nvidia hardware. Apart from that, there isn t much hate on how PhysX actually works. There are those that think it doesn t really add enough for the hype and its used in a low percentage of games."</post>
   <post id="11d3cf61-62de-4478-bd95-90aa957ac934" section="Physics Processing" discussion="Why the Physx Hate?">"DejaWiz said: ↑ I m a fan of PhysX, because I actually like to have that feature usable in the games I play with it. I m not a fan of having a dedicated card just for PhysX, as I d recommend getting two identical cards for SLI so that all games, PhysX or not, can benefit from having an extra GPU installed. For example, you spent the same money for a single 980 plus a 750ti for dedicated PhysX that two 970 s would have cost. I would always recommend to get the faster SLI setup, but there are drawbacks. You can t go anywhere else with a 970 SLI setup unless your system can support tri or quad SLI. You have a 980 with an upgrade path to SLI which would be faster than a 970 SLI setup. Catch 22, in a sense. Click to expand... The SLI suggestion is a good one, except I am staying away from the crossfire/sli setup for now. Frame pacing had gotten better but not good enough for me to bother with."</post>
   <post id="53991f6f-d54c-4842-8d7c-834152d006a7" section="Physics Processing" discussion="Why the Physx Hate?">"I very much enjoy having a dedicated Physx card. I use a 750Ti to handle Physx to keep my minimum fps up in games like Batman when in 3D surround."</post>
   <post id="cfdc7328-8a09-4158-88c4-f6ff9e15d3e3" section="Physics Processing" discussion="Why the Physx Hate?">"Dayaks said: ↑ Overall I can t see why anyone would hate on Physx. Click to expand... Because AMD sour grapes. That s it. Because its a blast in the games that support it -- Borderlands 2 for example makes great use of it. Nvidia spent a ton of money acquiring and then continuing to improve it, and team red bros feel NV s intellectual property should just be given away free. Believe me if PhysX became supported on AMD GPU s tomorrow it would suddenly be the best thing since sliced bread, excepting a minority that would insist "No it sux I m still mad"."</post>
   <post id="162b88f3-9306-4662-87ca-6168215245d7" section="Physics Processing" discussion="Why the Physx Hate?">"DPI said: ↑ Because AMD sour grapes. That s it. Because its a blast in the games that support it -- Borderlands 2 for example makes great use of it. Nvidia spent a ton of money acquiring and then continuing to improve it, and team red bros feel NV s intellectual property should just be given away free. Believe me if PhysX became supported on AMD GPU s tomorrow it would suddenly be the best thing since sliced bread, excepting a minority that would insist "No it sux I m still mad". Click to expand... That s the gist I get. I bet it s the same people that have no issues with Mantle and think Mantle is god s gift to Earth. Anyways my main goal was to make sure there were no technical reasons not to do it. Looks like there aren t!"</post>
   <post id="a5460907-98b2-4baf-bb28-e2a99e458582" section="Physics Processing" discussion="Why the Physx Hate?">"I don t like PhysX due to the proprietary design, if your dedicated card is too old it actually hurts FPS not help, and that Nvidia has been proved that they purposefully slow down physics computations by using an outdated compiling method but won t change so that you buy additional hardware that better handles the old code."</post>
   <post id="673b3599-6f67-4902-b110-1ef75a31b1b2" section="Physics Processing" discussion="Why the Physx Hate?">"bigdogchris said: ↑ I don t like PhysX due to the proprietary design, if your dedicated card is too old it actually hurts FPS not help, and that Nvidia has been proved that they purposefully slow down physics computations by using an outdated compiling method but won t change so that you buy additional hardware that better handles the old code. Click to expand... of course if you are trying to use a 9500GT (just for example) with a GTX 980 then of course you will hurt the performance of the card badly... probably you are the kind of people that don t know how widely spread are physX tittles in the market since very very long time ago.. and guess what Unreal Engine 4 still use PhysX.. but not the kind of dedicated advanced PhysX found in games like borderlands, batman and few others who need to run physX from a card.. the rest of the games as posted above run it with the CPU.."</post>
   <post id="739e1772-fe76-4591-a910-dfded46ce8ea" section="Physics Processing" discussion="Why the Physx Hate?">"AMD card owner here - it s not hate. It s jealousy. I love Physx, and I want to run it. Just waiting for my next build, which I will probably go green."</post>
   <post id="95c9294c-f14b-467c-956e-7282c70ae507" section="Physics Processing" discussion="Why the Physx Hate?">"Current AMD card owner, former nvidia card owner here. Having run PhysX, I ll say I don t "hate on it" and its not just "sour grapes", but I don t see PhysX as anything other than a gimmick at this time. If its being done on the CPU then it doesn t offer much that any other physics engine/middleware can t do, maybe one or two features, but never anything revolutionary. If its being accelerated on the GPU, then the fact that it is proprietary relegates it to meaningless eye candy. Is the eye candy nice? yes, I loved playing BL2 and seeing the flags waving in the breeze and the destructible cloth (the water effects were stupid mostly).... but at the end of the day, its proprietary nature means that making PhysX an element of core gameplay would lock out half of the intended market for the game. I think this is seriously holding physics based gameplay back, which certainly doesn t make me feel warm and fuzzy about nvidia. As for the comparison with Mantle, I don t think the two are comparable. Mantle does not impact core gameplay the way GPU accelerated physics potentially could."</post>
   <post id="eedeb3c2-3a3d-4237-a547-21c7e1f3b068" section="Physics Processing" discussion="Why the Physx Hate?">"Some of the hate comes from the fact that if you have an AMD card primary and an nVidia card secondary, you can t use the nVidia card for PhysX acceleration. Even though everyone knows it s possible to do so due to the hacked (and occasional beta) drivers that allow it. nVidia forces you to have an nVidia primary card to use GPU-accelerated PhysX."</post>
   <post id="a5f14d33-4d04-473f-8171-6e774c2014eb" section="Physics Processing" discussion="Why the Physx Hate?">"Had a 570 and a 670. Wasn t impressed with PhysX. I liked my improved OpenCL performance at the time on the HD7950. Old CPU PhysX like in Borderlands 2 ran like shit on the higher settings as it wasn t multithreaded. New CPU PhysX 3.2+ runs great on the CPU in games like Project Cars as it is now multithreaded. I ve been playing that game for over 2 years and never once complained about the PhysX implementation."</post>
   <post id="bf344758-f7ec-4f09-a145-aac21c17c37e" section="Physics Processing" discussion="Why the Physx Hate?">"I think PhysX is great. A few years ago I added a second 470 to my rig so I could turn on PhysX effects in Alice Madness Returns. It really turned into a much richer experience, even though it was nothing that affected gameplay. I can t wait to try Batman and Borderlands cranked up on PhysX. I do wish Nvidia allowed AMD users to buy a secondary Nvidia card just for PhysX. Seems like a win for them (they sell more GPUs) and more developers would be willing to add advanced physics effects in the game if mostly everyone could see them."</post>
   <post id="2e30d3fe-45ec-4263-8ac4-5566493efb43" section="Physics Processing" discussion="Why the Physx Hate?">"Havok... thats why"</post>
   <post id="90b98f54-6fbc-4d5a-9bc7-a89a74c849fe" section="Physics Processing" discussion="AMD + PhysX?">"OK. SO I know a few people who dual weild. I have tried it myself. That was 2009. Does anyone know if it is improved since then? Also worth doing still? Thanks for your repspoince"</post>
   <post id="79108b45-8dea-41cf-9cbd-485326bc9f33" section="Physics Processing" discussion="AMD + PhysX?">"I tried it for Borderlands 2 with no real luck. Was going to go back and try again, but ended up selling the physx card."</post>
   <post id="4431e009-67b7-4b40-9e2b-1ca38fc63692" section="Physics Processing" discussion="AMD + PhysX?">"It s a pain in the rear."</post>
   <post id="26d37fa4-1c59-47e6-b77e-d2f777c300da" section="Physics Processing" discussion="AMD + PhysX?">"Physx isn t really worth it anyway. I do not miss it at all because most games don t use it."</post>
   <post id="04aaff89-7e30-4b76-abe7-51a39bff5b1b" section="Physics Processing" discussion="AMD + PhysX?">"zerodamage said: ↑ Physx isn t really worth it anyway. I do not miss it at all because most games don t use it. Click to expand... Personally I think it falls in the category of "cool if implemented" Is it a game changer? No, not hardly. Does it improve gameplay? Nope. But you can take PhysX away from Batman and Borderlands when you pry it from my cold dead hands."</post>
   <post id="42055b8e-3207-4b71-bcb4-1ff12055a123" section="Physics Processing" discussion="AMD + PhysX?">"I ve done it before kicks, but it s pretty pointless IMO."</post>
   <post id="fa974f0b-dbd7-4cbd-9766-e52427600697" section="Physics Processing" discussion="AMD + PhysX?">"Yakk said: ↑ I ve done it before kicks, but it s pretty pointless IMO. Click to expand... If Nvidia made it possible with a separate app that allowed the use of the Nvidia cards for physx along with AMD cards for video, then I would do it."</post>
   <post id="d9ae87ef-6414-4757-9bbf-d4a6b950c49e" section="Physics Processing" discussion="AMD + PhysX?">"zerodamage said: ↑ If Nvidia made it possible with a separate app that allowed the use of the Nvidia cards for physx along with AMD cards for video, then I would do it. Click to expand... I honestly can t think of a business reason for NVidia not to do this... unless they fear scavenging sales of higher-end cards? Based on the current trend, those aren t likely to be NVidia users anyway... so they could possibly tie in some add-on sales for older cards for the folks who want to try PhysX."</post>
   <post id="81f073a2-1667-43bb-8cb7-67d1cb1a243d" section="Physics Processing" discussion="AMD + PhysX?">"http://wccftech.com/nvidia-disables-physx-support-vendor-mixed-setup-340-52/"</post>
   <post id="2f1094e5-0b4e-40ca-92e4-1815b5a1d0e3" section="Physics Processing" discussion="AMD + PhysX?">"I had a setup way back when with a 5870 and an 8600GT just so I could try Batman: AA. You aren t missing much, go watch some youtube videos if you want to see what it does, or enable it in whatever game, it still works in "software mode" which is a complete farce, it s threaded but only uses 10% of the available CPU speed and kills your framerate. There are better physics engines out there I have no idea why game makers insist on using it. The physics engine in Ghost Busters was awesome, too bad the game sucked."</post>
   <post id="38aeb2c2-bb7f-496a-ac2f-3f815135a8dd" section="Physics Processing" discussion="AMD + PhysX?">"Deimos said: ↑ I have no idea why game makers insist on using it. Click to expand... Pretty sure the devs who use physx are sponsored/payed to do so. Curious if there are any titles that use physx which are not sponsored. Still it s academic at this point I guess."</post>
   <post id="bae3ea38-5d8e-42f1-a410-1225296ebaa9" section="Physics Processing" discussion="AMD + PhysX?">"I think something like OpenCL should be used so that all the different card makers can take advantage of it."</post>
   <post id="9bab17c7-eba9-48d3-8d5b-38ecb0aff327" section="Physics Processing" discussion="AMD + PhysX?">"physx boo, it did make me get nvidia cards for the first time. Made me realize these are some powerful cards but, i guess you can call me a amd fanboy because within a year i went right back to amd, because you can get a more powerful 2 card setup for cheaper. but i do have to say 6800 card was no joke in that generation. Best card ever made. Cant wait to get back to those days again."</post>
   <post id="be2a37f0-0d59-423b-b2a7-4929bef16bfa" section="Physics Processing" discussion="AMD + PhysX?">"Kotaku mentioned a hack for BL2 that allowed AMD cards to use physx. It s always been my understanding that it s actually a CPU action only enabled using Nvidia gpu s."</post>
   <post id="3c3d14f5-d548-4cb7-9f5a-e66c0169c016" section="Physics Processing" discussion="AMD + PhysX?">"zerodamage said: ↑ I think something like OpenCL should be used so that all the different card makers can take advantage of it. Click to expand... Hopefully the open-source Bullet 3.X physics engine (uses GPU via OpenCL) has improved significantly compared to earlier releases."</post>
   <post id="1794c976-1672-4475-a320-f1cb51363384" section="Physics Processing" discussion="AMD + PhysX?">"Hi, I got it going on my 290X using a GTS 450 as a physx processor. Running Metro Last Light at 1920X1080 with High settings and tessellation and 2X SSAO and Physx. Getting 50-70 fps on my old aging 920 D0 processor at 3.8 Ghz overclock. Theres a guide on NGHQ somewhere. Also few years back I had Borderlands 2 Hybridized. Its very worth it if you know what your doing and follow the instructions to the letter."</post>
   <post id="6aa2a86a-088c-4ab1-99d0-227d40812b86" section="Physics Processing" discussion="AMD + PhysX?">"AMD cards aren t built for that feature specifically, but for most PhysX processing you can enable it on your CPU. If you re playing a game that doesn t fully utilize all of your CPU s cores or if you have a Hyper-Threaded enabled CPU, you can usually get pretty good framerates. I think you have to enable different settings on a case-by-case basis though, although I might be mistaken."</post>
   <post id="d857d46d-7c37-4e2b-9a5a-f0be5e25edcf" section="Physics Processing" discussion="AMD + PhysX?">"is that one guy still writing cake over the lies?"</post>
   <post id="e64484dd-87ad-4edd-9deb-0644c37d71f2" section="Physics Processing" discussion="AMD + PhysX?">"What would probably be the minimum NVidia card to use as PhysX processor? I got an old 8800gts 320mb laying around, would use it conjunction with incoming r9 290 if it would do some good."</post>
   <post id="fb4f5876-98ea-49bb-b13d-9212e99428fb" section="Physics Processing" discussion="AMD + PhysX?">"jwright33 said: ↑ What would probably be the minimum NVidia card to use as PhysX processor? I got an old 8800gts 320mb laying around, would use it conjunction with incoming r9 290 if it would do some good. Click to expand... I would recommend at least a 640 gt or gts. You should go with a card that has 50% of the performance of your Gfx card. On my 450 gts and 290x combo playing Metro LL my 450gts loaded up to almost 70 % utilization in the fire scene of metro. Usually averages about 30 %. So you need a decent card. The 8800 is ancient."</post>
   <post id="1b5bacd8-d28c-4478-a8f0-bdd4cefca2fd" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"Is a GT 440 powerful enough to be a dedicated PhysX card? I have one that I will be installing while I wait for my GTX770 to come back from RMA but if it will work for PhysX I d like to keep it in my computer."</post>
   <post id="cea169e6-c232-4b9f-bd6b-3aeb7d9fd4e8" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"I was using an 8600gt in my system for borderlands 2 and it did just fine (1680*1050 with everything turned up). So I would say yes, it will work out just fine."</post>
   <post id="94d700af-b163-4e0c-9f20-5a671b7975dc" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"I don t think it requires much setup to have a PhysX card either, so you might as well use I."</post>
   <post id="9af39179-d3bf-4ce4-a00a-ccba431e67a9" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"Since I m gaming on the GT 440 while I wait for my GTX 770 Advanced RMA email to come, it won t be any extra work to leave it in."</post>
   <post id="2adf2ed2-b57a-4d39-ab9b-1177a93a31a0" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"ythe1300 said: ↑ I was using an 8600gt in my system for borderlands 2 and it did just fine (1680*1050 with everything turned up). So I would say yes, it will work out just fine. Click to expand... Sorry but there is NO way an 8600gt helped with physx as opposed to doing both on your gtx570. An 8600gt would be slower than having the 570 do both graphics and physx that is a fact. Even in games with no where near the effects as in BL 2, an 8600gt would only slow down a 570. Borderlands 2 has a few spots that all the gpu power in the world is not going to keep framerates up with physx on high due to poor optimization. If you have a higher end gpu then I would not even bother getting a dedicated gpu for physx."</post>
   <post id="201846e1-001d-47d8-b261-a20a69d9bbcc" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"misterbobby said: ↑ Sorry but there is NO way an 8600gt helped with physx as opposed to doing both on your gtx570. An 8600gt would be slower than having the 570 do both graphics and physx that is a fact. Even in games with no where near the effects as in BL 2, an 8600gt would only slow down a 570. Borderlands 2 has a few spots that all the gpu power in the world is not going to keep framerates up with physx on high due to poor optimization. If you have a higher end gpu then I would not even bother getting a dedicated gpu for physx. Click to expand... My framerate increased by about 10fps in most places when I put the 8600 in, I m not saying that it wasn t running at 80-90% most of the time, but it did help, also for some reason borderlands would not do physx on my 570 even after I changed the settings in the nvidia control panel (werid software glitch?)."</post>
   <post id="c2602f5e-4740-4534-a1ea-892bb9c5a924" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"ythe1300 said: ↑ My framerate increased by about 10fps in most places when I put the 8600 in, I m not saying that it wasn t running at 80-90% most of the time, but it did help, also for some reason borderlands would not do physx on my 570 even after I changed the settings in the nvidia control panel (werid software glitch?). Click to expand... This is good stuff to note. even when it would seem theoretically impossible for it to work, ive seen stranger things. like the original halo playing at 30fps on a 300mhz pentium3."</post>
   <post id="24a67ee4-5ec0-4591-97e8-634dfab2533d" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"CharlesLam said: ↑ This is good stuff to note. even when it would seem theoretically impossible for it to work, ive seen stranger things. like the original halo playing at 30fps on a 300mhz pentium3. Click to expand... I dont believe what he is claiming. The 8600gt has been way too slow for physx for many years now. It would barely help the gtx275 and gtx280 and in many cases barely broke even with what those cards could do by themselves. I used the 8600gt for physx with my gtx260 and it helped a little but in some cases actually gave a lower minimum framerate. With a gtx570 there is zero chance it would help especially since physx has gotten more demanding and the 8600gt is not even sufficient any longer anyway. Here you can see in Mafia 2 that the 8600gt is worse than the gtx480 doing both graphics and physx. The disparity would be even greater in newer games with more demanding physx effects. An 8600gt has not even come close to meeting minimum requirements for handling physx for several years now. uploading pictures"</post>
   <post id="4fd53a5a-3d85-455d-9e4c-5436ad8ee1e6" section="Physics Processing" discussion="GT 440 dedicated to PhysX?">"I would love to redo this experiment but unfortunatly when I recently upgraded to a 7970 I gave the 570 to a friend, I may be able to get it back though I will see. Also just adding to this, as I was saying before, it may have been a software issue as the physix effects wouldn t even show up with the 570 selected as the physix card."</post>
   <post id="966a6667-64a2-482a-964a-2214a60ca847" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"With stronger CPU, GPUs and the advance of programming, is PhysX even really a selling point? I ve owned and played games with PhyX and with the new cards and cpu, there is really no difference with it turned on or off. I do not count PhysX specific benchmarks and demos, just retail games."</post>
   <post id="2d3f84aa-4209-4b60-9ef6-0810aff920d7" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"The current game with the best PhysX is Borderlands 2. Try using your CPU vs GPU on that game and you will clearly see a difference in performance and visual quality."</post>
   <post id="3daa476a-618e-426f-9bfe-8fae5192b6bc" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"no..."</post>
   <post id="a7b8bd5c-86fa-4801-b296-3dab0a48472c" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"it was never relevant because most games don t use it...the few games that did make good use of it you can count on 1 hand- the Batman Arkham games and Borderlands 2"</post>
   <post id="db0b248f-2744-4001-b618-700cee3763c9" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"polonyc2 said: ↑ it was never relevant because most games don t use it...the few games that did make good use of it you can count on 1 hand- the Batman Arkham games and Borderlands 2 Click to expand... lol true"</post>
   <post id="d95bc0f6-1a5e-4d6e-953d-e0bcb21227ee" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"I played both batman and borderlands series and I did not pay extra for PhysX so it was and is relevant to me. all eye candy is good eye candy in my opinion"</post>
   <post id="64a01916-ca01-40bd-b890-cee3f39e34b2" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"The Batman games are very different with physx. So I would say yes it s still relevant. You have to check out Batman with and without to say for yourself. Plenty of other games have extensive PhysX effects. List of physx games and features. PhysX wiki"</post>
   <post id="6a14f1b8-506b-407d-bf4a-e1300b32b2d3" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"I don t think it s dead. I enjoy games more with PhysX enabled. It s icing on the cake."</post>
   <post id="92e53401-8abb-459f-bb9e-4ed46183f807" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"agreed with never was relevant but i really enjoy games with PhysX metro LastLight its great and way more immersive with physX enabled.."</post>
   <post id="c7bffb25-e2c9-4be9-aedf-3fe2c6fcd115" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"PhysX is cool, but it s never been a game changer on the few games where it s used."</post>
   <post id="119b3b1b-d0bc-46ad-ba80-dc85e79e549f" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Sure, it makes porn viewing 27% faster."</post>
   <post id="ee7bfcc2-f5f2-4cdc-a5f9-b37b4f190b11" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"PhysX has the innate problem that the faster your primary GPU is, the faster your dedicated PhysX GPU needs to be. Games often times run faster running PhysX on your primary card because your PhysX card can t keep up. Nvidia has created a reason to get you to buy 2 cards rather than just one. When PhysX was first announced, it sounded cool and a lot of people jumped on board. Now that everyone sees that Nvidia does nothing with it besides particle effects, it s boring and no one cares anymore. Since the PhysX integrated on many games is paid for by Nvidia (giving you a reason to use hardware PhysX), you can blame Nvdia for the lack of innovation, not developers. Properly threaded physics that run on your CPU like Havok, or open source GPU accelerated physics like Bullet, are going to remain superior method for games. I think Microsoft can also push DX11 directcompute as well to enhance GPU accelerated physics. Lets also see what they reveal with DX12."</post>
   <post id="1e641854-ebb0-4258-b249-6a3f3198edba" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"People seem to have forgotten or missed the fact there are two types of PhysX. GPU/PPU accelerated PhysX and CPU PhysX. The PhysX engine has been used in 500+ games just like Havok. I will agree that the GPU accelerated side of PhysX has been less than stellar with only 30+ games being released but Bullet isn t doing much better. Saying PhysX is only particle physics is completely false and a pretty silly claim as well. PhysX supports rigid body dynamics, soft body dynamics, ragdolls/character controllers, vehicle dynamics, volumetric fluid simulation, cloth simulation including tearing, and pressurized cloth. GPU PhysX will always be a niche market but to say PhysX as a whole is not relevant anymore is foolish. Especially considering PhysX was used in Metro, Bioshock Infinite, ARMA 3, ACIV, and is going to be used in Star Citizen, Batman:AK, Wasteland 2, Daylight, EverQuest, and Goat Simulator."</post>
   <post id="eac2ca3d-bb67-4314-bbd7-6b9105d52f71" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Cr4ckm0nk3y said: ↑ ...EverQuest, and Goat Simulator. Click to expand... Wait, what?!"</post>
   <post id="b48edb9d-e9f6-4050-b7f5-ed7aa13391eb" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Corvette said: ↑ Wait, what?! Click to expand... Sorry EverQuest Next and Goat Simulator!"</post>
   <post id="9ed92975-1ef5-4d29-affc-aaad5b734c8a" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"It s a nice feature in high end gaming, when supported. Whether that makes it important or relevant is up to the gamer. Personally, I don t really care. It doesn t have the install base to cause developers to use it in meaningful game play ways, although it can improve performance and/or effects in some games. I m still holding out hope that Havok will finally release a GPU accelerated version its physics engine for Windows. While that s been available on the new generation of consoles since last year, it s not clear when it s going to be available for PC. This week may bring some updates: http://www.havok.com/gdc2014"</post>
   <post id="e1d6551b-8f0f-4c97-ac28-2ffb186cd8e9" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Always felt it was a gimmick"</post>
   <post id="38a6bfa1-b27e-44b2-bdeb-b1a385d834ae" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"I always thought it had a lot of promise. But, if you have to ask if it s still relevant, it s obviously not being marketed very well. I think the IDEA of PhysX is still very relevant. The other competitors are great, too. Batman and others that use it have more atmosphere and are easier to get into than the more static and  flat  worlds that don t use it. It adds something to the game, even if it s not noticed that much."</post>
   <post id="3d943ef4-1c88-45e7-b5f7-244785b93977" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Cr4ckm0nk3y said: ↑ People seem to have forgotten or missed the fact there are two types of PhysX. GPU/PPU accelerated PhysX and CPU PhysX. Click to expand... No one is/was talking about the non-GPU accelerated version because it s not proprietary hardware dependent, and you really don t even know it s included in a game unless you see the logo on the box. Saying PhysX is only particle physics is completely false and a pretty silly claim as well. PhysX supports rigid body dynamics, soft body dynamics, ragdolls/character controllers, vehicle dynamics, volumetric fluid simulation, cloth simulation including tearing, and pressurized cloth. Click to expand... What it can do, and what s being done, are two different things. GPU PhysX will always be a niche market Click to expand... I disagree. If it s done in a way that all GPU s can support it, and it actually adds something to the game more than particle effects, I think developers would be more game to jump on board. Look at all the neat things you listed it can do. but to say PhysX as a whole is not relevant anymore is foolish. Especially considering PhysX was used in Metro, Bioshock Infinite, ARMA 3, ACIV, and is going to be used in Star Citizen, Batman:AK, Wasteland 2, Daylight, EverQuest, and Goat Simulator. Click to expand... Again, to what level and why (Nvidia paying for it)? More particle effects and maybe Batmans cape?"</post>
   <post id="e3a87ab3-e244-45f8-9ea5-69dc8c75b793" section="Physics Processing" discussion="Is PhysX even relevant anymore?">"Warframe shows you the power of PhysX in this video with PhysX on /off transitions. http://www.youtube.com/watch?v=IhBZeZ5uQBQ My buddies with Nvidia cards cut it off 100% of the time because they couldn t see the enemies to kill them. I would end up with 80% damage done in Warframe if they run Physx lol."</post>
   <post id="49b6403b-5761-44e7-b426-cca6f80f2b18" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Would a GTX 570 be worth using just for Physx? Or would it slow down the 680?"</post>
   <post id="8fd8dc7f-66f7-4c47-afca-e7e19052308c" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I don t see why you d need anything faster..."</post>
   <post id="5ccf1d64-2202-4594-b9aa-7bde399e3fe2" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Well today I m picking up a used 680 to replace my SLI 570s. I was wondering if i should keep one, or sell them both off. I know for todays games it may not make a difference, but a year from now? i suppose the question is very general in nature, but id be keen to know what you all think about it."</post>
   <post id="845d8d96-ad07-496c-83b9-68cdd0d6f84c" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"A 570 would be big time overkill for PhysX. I d sell both, buy something like a GTX 650 (about $100) and pocket the rest of the $$."</post>
   <post id="46577e83-b1de-4ecc-84a0-367feada5f12" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Tyler-Durden said: ↑ A 570 would be big time overkill for PhysX. I d sell both, buy something like a GTX 650 (about $100) and pocket the rest of the $$. Click to expand... Agreed!"</post>
   <post id="b334ab54-a4e9-4d7f-926d-88c1b23a8058" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"That s probably the best idea, but I m doubtful I ll get more than $100 for the 570 these days. I guess we will see."</post>
   <post id="5201d16a-053e-40cf-ab80-c8a4e048523e" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I d sell both the 570 s and not run a dedicated PhysX card. The price of used 680 s is dropping fast (I sold mine for $310 shipped), so I would just start saving for a second one. That s what I should have probably done."</post>
   <post id="01151417-329f-4341-9aa6-7c5c495cafc0" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Why do you say that? Do you think a dedicated card isnt worth it at all?"</post>
   <post id="8849cbb4-0d0e-4305-8506-c03f09ed4bdf" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"It definitely helps in games that use PhysX, but there really aren t that many. If you could be $100 to $120 dollars closer to a second card, I think you would see a much more appreciable benefit in all the games you play. Of course, I didn t really consider that the 570 will have some resale value no matter when you sell it, so maybe using it as a dedicated card until (if ever) you find a second 680 isn t such a bad idea."</post>
   <post id="7abd5b2d-ed18-4d58-8aa0-0ebe40bf092d" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I see what you re saying, well lets see what the two 570 bring in dollar wise."</post>
   <post id="71bc7111-9ded-45e6-ac82-264cd1985b60" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I ended up getting a 780, I think that should be more than enough!!"</post>
   <post id="423157a0-0243-4f70-a11a-985048eda2b6" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Magnus042 said: ↑ I ended up getting a 780, I think that should be more than enough!! Click to expand... Nice! I ended up selling two GTX 660 SC s and my GTX 680 to get the GTX 780. Still had to chip in some cash at the end! You ll definitely get better performance with just the GTX 780 than with a GTX 680 + 570, at least I did than with a GTX 680 + 650 Ti. Of course, I did keep the 650 Ti, as selling it wasn t worth the small amount I d get back after fees + shipping."</post>
   <post id="9a495ff0-b0bb-4831-9928-f885ed9c2791" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Well im selling both 570s, Im hoping to get a little cash back, that 780 wasnt cheap! lol"</post>
   <post id="0b8a6e3c-9610-4dfe-87f6-ccd8abfd0ed8" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Hurry and sell those 570s! Like you said yourself, their prices are dropping."</post>
   <post id="6ea62c8e-ab55-4e06-80b2-171d9acd25dc" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Sold them locally yesterday. I was starting to get worried haha!! My new 780 is epic, an hour of Borderlands2 last night was AMAZING!"</post>
   <post id="3cf3ad6c-0eb7-4657-8b02-bf2da98386fd" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Interesting thread. I just upgraded to a 770 myself and have this 570 left over. Resale value is not worth the effort to me so I thought about using it as a stand-alone Physx card. As it happens, I do have a lot of games that use it. In particular the Batman series and a few others. Looking at the number of cuda that each card has (770/1536 vs 570/480), I m wondering if its even worth the trouble now. Are opinions that a 570 would actually slow down a 770? I temporarily have the 570 installed in a second box, but that machine is primarily used for work and maybe watching the occasional movie. I was planning on putting an old Radeon HD 4890 in that machine and recyling the 570 as a Physx card in my  gaming  rig."</post>
   <post id="d6214e93-123b-45fa-9fc9-8ccb0899b98d" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I used a 480 for PhysX. There is no way it will slow down your primary GPU. It can handle the PhysX well uh, handily. So offloading work from your primary GPU can only help, when talking about these caliber of cards."</post>
   <post id="02521fa4-dd04-4340-8083-fb2f770c0ecd" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I use my 560ti for physx and a have average 10 fps more in game."</post>
   <post id="b502bb20-2bec-4b06-be8d-dde7a4777572" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"I have an EVGA 680 w/ 2GB of RAM. Newegg today has 660s for $150. Would a 660 2GB be overkill? Looking to improve my BF4 experiance"</post>
   <post id="0a715e4b-7f33-4969-8646-c7c423bc5afb" section="Physics Processing" discussion="680 4GB with 570 FOR PhysX">"Accursed said: ↑ I have an EVGA 680 w/ 2GB of RAM. Newegg today has 660s for $150. Would a 660 2GB be overkill? Looking to improve my BF4 experiance Click to expand... I don t think bf4 supports gpu physx. GPU phsyx is only supported in a handful of games (like the batman arkham games). That second card won t do anything in bf4."</post>
   <post id="f3d645bb-b05d-43a2-a98c-4554d3750845" section="Physics Processing" discussion="What card to get when running 780s?">"Guys what card should be run as a dedicated card sitting next to 780gtxs in Sli? My friend is asking and I have no idea, does he need another 7 series or go much cheaper?"</post>
   <post id="998a160e-a7c4-4ffe-9ef2-5b6af9da08f3" section="Physics Processing" discussion="What card to get when running 780s?">"if he absolutely has to have another card for PhysX (he doesn t, IMO), no need for a 780. Something like a 650Ti Boost would be great."</post>
   <post id="33cc7734-a01e-4fd9-b9f7-0a7c50cf655a" section="Physics Processing" discussion="What card to get when running 780s?">"I m running 3 780s in Tri Sli and I don t use a dedicated card lol. Don t know if it would even matter for me."</post>
   <post id="c6bdd37f-fa0f-45c3-b796-a002c9a049a6" section="Physics Processing" discussion="What card to get when running 780s?">"Marcdaddy said: ↑ I m running 3 780s in Tri Sli and I don t use a dedicated card lol. Don t know if it would even matter for me. Click to expand... Do games even use PhysX anymore? I always thought it was a gimmick API that died a long time ago."</post>
   <post id="201a8557-bba4-4aab-9f73-30489b1c5e7b" section="Physics Processing" discussion="What card to get when running 780s?">"Dedicated PhysX cards were a thing back in the gtx 260 days when PhysX work might have taken up a significant percentage of the video card s processing power, so you would offload that to the 8800GT you upgraded from. Now, with GTX 780 in SLI, you have ten times the power and dedicated PhysX cards are more likely to slow your system down than to help."</post>
   <post id="f27c0a91-3d4b-415a-af9e-f3daefd61895" section="Physics Processing" discussion="What card to get when running 780s?">"PornoSatan said: ↑ Do games even use PhysX anymore? I always thought it was a gimmick API that died a long time ago. Click to expand... ins t died at all, and yes, games uses PhysX, couple of recent games with PhysX?. Batman Arkham Origins(and all the batman series), Metro Last light(and 2033), Lost Planet Series, Borderlands (1 and 2), Assassins Creed IV, Mirrors edge and couple of more Etc games if you think it was a gimmick then you never has played any of those games with any Nvcard.. even upcoming games like The Witcher 3 or Mirrors Edge 2 will use PhysX confirmed and others like The division and WatchDogs are rumored that may use it.. About the OP.. what card to get?. None.. actually ins t necessary any dedicated PhysX card, specially if are a powerful system like that.. adding a third card to a 780SLI its just add power consumption and heat to the case, those card have more than plenty power to handle enough PhysX alone.. a dedicated PhysX will do nothing to improve performance in actual games with PhysX even in the 2 hardest to handle like Metro LastLight and Assassins creed IV.."</post>
   <post id="e8879b6e-36c0-45e8-9532-782c39de857a" section="Physics Processing" discussion="What card to get when running 780s?">"GTS450, essentially a 9800GTX rebadge. Plenty for physx without using too much power since your 780 s are powerful as it is."</post>
   <post id="6977635f-9454-4f6b-bb35-a7e041be607e" section="Physics Processing" discussion="What card to get when running 780s?">"For 780 SLI, I say forget a PhysX card. Just no need for it. I run a single 780 and plugged in a GT 640 I kept from a previous build. I noticed smoother game play in Borderlands 2 with the 640 as a PhysX card. Can t tell if it makes a difference in other games."</post>
   <post id="275e0067-04a3-45bb-9861-cd206090a2cc" section="Physics Processing" discussion="What card to get when running 780s?">"FWIW... Metro LL Benchmarck 2560x1600, DX11, Ultra High Quality, AF 16x, Adv. PhysX, Very High tesselation, Motion Blur normal, SSAA ON See rig in sig 780 SLI with 650Ti dedicated to physx Min: 10 Max: 118 Avg: 36.85 780 SLI without 650Ti Min: 10 Max: 108 Avg: 32.81 Not sure if Metro LL is best platform for this comparison...Any better games to use?"</post>
   <post id="b2243356-1c9e-4335-9b13-b64d93efa283" section="Physics Processing" discussion="What card to get when running 780s?">"Borderlands 2. Benchmarks? lol"</post>
   <post id="e9268eec-b9ae-4c28-965b-f1db9abbbbe5" section="Physics Processing" discussion="What card to get when running 780s?">"Does BL2 have a built in benchmarking utility? Way to difficult to do it the old fashion way...(As my 2 year old is screaming for her toy)"</post>
   <post id="ad3fc83d-d3a7-43fb-a1e8-95af6df1b2c7" section="Physics Processing" discussion="What card to get when running 780s?">"Not to my knowledge you can toggle the draw fps display via console, I use Dxtory or Fraps to gauge my FPS."</post>
   <post id="16121e27-8e4b-4de6-9173-dd0f43f37af0" section="Physics Processing" discussion="What card to get when running 780s?">"Matthew, in what way is a GTS 450 a 9800 GTX rebadge? It s video card history time! They re actually completely different. 9800 GTX was G92 based and a rebadged 8800 GTS. The 9800 GTX+ was G92b and the same core config but higher clocks, and then rebranded as a GTS 250. The GTS 450 is a GF106 Fermi based card having no relation to either Tesla architecture or the first CUDA (G80/G9x) cards. It has 192/32/16 shaders/TMUs/ROPs vs the 128/64/16 of the G92/G92b. The GTS 450 actually has less raw single precision GFLOPS throughput than the GTS 250. End history lesson."</post>
   <post id="7574ea69-6f4c-4712-9719-b59922b566ea" section="Physics Processing" discussion="What card to get when running 780s?">"He has absolutely no need for a dedicated PhysX card with 780 SLI. It will just add more heat and power consumption to his system and will make negligible difference in the small # of games that support GPU PhysX. Tell him to save his money."</post>
   <post id="633d108e-7b04-44e5-8c36-cb487315106e" section="Physics Processing" discussion="What card to get when running 780s?">"FrankD400 said: ↑ Matthew, in what way is a GTS 450 a 9800 GTX rebadge? It s video card history time! They re actually completely different. 9800 GTX was G92 based and a rebadged 8800 GTS. The 9800 GTX+ was G92b and the same core config but higher clocks, and then rebranded as a GTS 250. The GTS 450 is a GF106 Fermi based card having no relation to either Tesla architecture or the first CUDA (G80/G9x) cards. It has 192/32/16 shaders/TMUs/ROPs vs the 128/64/16 of the G92/G92b. The GTS 450 actually has less raw single precision GFLOPS throughput than the GTS 250. End history lesson. Click to expand... Actually you re right made a mistake there and meant the GTS250 and the GTS450 was not much different to the 250 in terms of performance."</post>
   <post id="df0b5f4e-37e7-481c-88a5-16216ce40932" section="Physics Processing" discussion="What card to get when running 780s?">"Guys question regarding different card for Physix, after installation boot back into windows then just install driver then change settings in Nvidia control panel to the dedicated card correct? Running 2 sets of video drivers at the same time is ok?"</post>
   <post id="04317d66-65ae-444b-8d73-d4c3c7605888" section="Physics Processing" discussion="What card to get when running 780s?">"you will not be using 2 sets of video drivers, Nvidia use a unified driver for all their series... so the most recent 334.89 are the same drivers used in the for example geforce 9XXX series.. so the drivers will be the same not matter the amount of cards taking the case in the OP 2 gtx 780 will work in SLI and a third card will work as dedicated physX its just a matter of configuration but the drivers will work the same in a game instace, the game will not recognize where its processed the PhysX."</post>
   <post id="9b62dc42-a26c-47bf-b9dc-75cc085ef0fb" section="Physics Processing" discussion="What card to get when running 780s?">"I d just tell him to get a Titan Black for Physx, no point in bullshitting around with it I ve not ran into any games that cause a significant enough hit in performance to warrant a dedicated card for physx with my SLI 780s"</post>
   <post id="39358aaf-7bea-4355-8fb2-d0c4c326a0d5" section="Physics Processing" discussion="What card to get when running 780s?">"Physx it rocks in old Physx games,new games like AC4 still sucks LOL. 780TI with 680GTX"</post>
   <post id="f119da6f-e815-49bc-90a2-455e88e88185" section="Physics Processing" discussion="What card to get when running 780s?">"Serious question. But what about a dual 770 with a 460 for physx? pointless or worth it? (my new build is 2x 770 sli and have my old 460 for physx if need be)"</post>
<post id="467ae0ea-3544-4f89-800a-8ef2bdba4a8b" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"Rosewill VALENS-700 700W Power Supply Review - While Rosewill is likely not a go-to computer power supply brand to most people, we have been surprised with Rosewill s quality on two of its PSUs over the last couple of years. Today we review an $80 700 watt Rosewill unit that is rated for Gold efficiency, and well ... that is about all that marketing has to say about its Valens-700."</post>
   <post id="371c9d7e-a142-47b2-9fec-c290b9405a20" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"This is just another example of how that 80 plus logo on the box just isn t important. The certification being based only on efficiency just doesn t provide a meaningful measure of quality."</post>
   <post id="8f696686-3191-4a3b-9434-6c625e974d9a" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"Despite great prices and specs, I ve always viewed Rosewill PSU s with suspicion. Thanks for confirming my opinion."</post>
   <post id="5f9c04ee-a942-42c4-88de-70a955e18a47" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"Loved the historical references in the review (I m an ancient/medieval history enthusiast). Guess the guys at Rosewill were pretty accurate (too accurate?) for choosing the name "Valens", since Adrianople was a huge disaster that never needed to happen in the first place."</post>
   <post id="dfac9f78-521f-44f0-aa16-899a90c8801b" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"When I was shopping for PSUs a few months ago, I kept seeing the Valens series for excellent prices. They were very tempting, but because of the lack of reviews, I passed it up and paid $30 or so more for a Seasonic. It looks like I made the right choice. Thank you for the review!"</post>
   <post id="8cf5edea-0ce0-4237-a9e8-daa2009c233a" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"Singularity_Survivor said: ↑ Despite great prices and specs, I ve always viewed Rosewill PSU s with suspicion. Thanks for confirming my opinion. Click to expand... Just like Corsair, Rosewill uses different manufactures for each product line. My Rosewill Hercules was made by High Power and is amazing, the reviewed power supply was made by ATNG which have a lot of trash floating around. I would not write off all their lines for 1 bad one."</post>
   <post id="011783ee-51df-4f62-b0e7-e9fde59f2645" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"striker444 said: ↑ Just like Corsair, Rosewill uses different manufactures for each product line. My Rosewill Hercules was made by High Power and is amazing, the reviewed power supply was made by ATNG which have a lot of trash floating around. I would not write off all their lines for 1 bad one. Click to expand... Agreed, I have the Rosewill Capstone in a rig that s pushing its limits with a +1.2gHZ overclock and multiple drives/SLI, a Rosewill Hive pushing a 2500K and 980 both overclocked, and recently used a Rosewill Arc in a build that s going strong, I was shocked to skip to the last page and see the [H] X FAIL, don t know if I ve ever seen one!"</post>
   <post id="8d5e7d0a-7180-47de-9e1b-a1abaf596019" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"I just love me that big red FAIL........"</post>
   <post id="8d4e2a24-4c15-4104-bd1a-cd71f6581152" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"A Rosewill product is crap? Say it ain t so, Jo. Say it ain t so..."</post>
   <post id="65a892f7-357b-4cbb-88e5-edb0c493cab0" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"Kogan said: ↑ I passed it up and paid $30 or so more for a Seasonic. It looks like I made the right choice. Click to expand... The last four Rosewill reviews at JonnyGuru.com had scores of 8.1, 7.8, 9.2 &amp; 7.5; the last four Seasonic reviews received scores of 9.1, 9.5, 9.2 &amp; 9.6. I think you also made "the right choice"!!"</post>
   <post id="c91c4600-6f73-47a0-8399-2b2bbd04e111" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"What surprised me with this PSU, is that it passed the Transient Load Testing, but failed at the ripple measurements. I can t recall something similar in the past. Statistically speaking (*if i m not mistaken), if a unit fails at ripple, it is very likely to fail at Transient as well"</post>
   <post id="6f867031-b8e1-48cd-ae3f-fefa6b9bafa9" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"I m not surprised at all. I ve always assumed these psu s were turds."</post>
   <post id="c206d140-c556-4c85-a462-f0fe29aa74bf" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"From the soldering on backside of the primary PCB and use of Teapo capacitors, I thought this unit was going to end-up as DNF. Surprised me how the PSU was holding-up through the tests. Then whack! the PSU dropped like condemned building when the explosions went off. Thanks for taking the time put this review together. I m sending the front page link off to a few people I know who thought their Rosewell PSU purchase was a smart investment."</post>
   <post id="c5579674-a106-470d-a41c-8e8fd5a104f1" section="Power Supplies" discussion="Rosewill VALENS-700 700W Power Supply Review @ [H]">"another disappointing series from Rosewill. they are on a steep down trend lately."</post>
   <post id="68f582b8-0036-4c77-a508-977d8c4f937c" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"EVGA 600B 600W Power Supply Review - EVGA is somewhat hit and miss when it comes to computer power supplies, and generally a lot more miss than hit. But today we give EVGA another go with its 600 watt "Bronze" rated unit that EVGA tells us is very much for a the value and budget market. Nothing we like better than a good deal, so let s see how the 600B performs!"</post>
   <post id="dec12358-c23e-4989-a250-41bb1da1e09a" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Good Filtering, Good max temp, and everything else within spec? For 30 bucks? Sounds like a great basic box PSU to me."</post>
   <post id="8d1bff49-4e6b-4c33-a29f-93f374aae44a" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Maybe my concept of value is different but this thing did what it was intended to do for nearly 1/2 the price of a similarly spec product and 600Watt is plenty for most gaming systems. At that price it s almost pointless to go with a lower power but better build PSU. Thanks for baking it for us though. XD"</post>
   <post id="556bb71b-57c7-4d25-8b87-ec8941528d31" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"ecktt said: ↑ Maybe my concept of value is different but this thing did what it was intended to do for nearly 1/2 the price of a similarly spec product and 600Watt is plenty for most gaming systems. At that price it s almost pointless to go with a lower power but better build PSU. Thanks for baking it for us though. XD Click to expand... Do you think we said otherwise?"</post>
   <post id="197e3e2f-980b-4405-b003-243ecf2e784d" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Yeah... you kind of did. I think the concept of "high end" has been skewed a bit lately. A 600W power supply is BIG for a PC in general. It s enough to run a 980Ti and a 4 or 6 core CPU, with moderate overclock. That s a long way from useless mainstream parts. I ve used a bunch of 500 and 600 EVGA power supplies over the last year and they ve all done well in the real world. Sure, I d rather put Corsairs or better in everything but people want gaming systems at RaidMax generic pricing. EVGA is getting it done big time with these power supplies. I wouldn t be able to build competitively without this series right now TBH. And I can at least sort-of trust the brand name to not make supplies where they ALL burn up after 6 months."</post>
   <post id="dc533fda-5717-41ab-9f44-3f2affb35484" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Advil said: ↑ Yeah... you kind of did. I think the concept of "high end" has been skewed a bit lately. A 600W power supply is BIG for a PC in general. It s enough to run a 980Ti and a 4 or 6 core CPU, with moderate overclock. That s a long way from useless mainstream parts. I ve used a bunch of 500 and 600 EVGA power supplies over the last year and they ve all done well in the real world. Sure, I d rather put Corsairs or better in everything but people want gaming systems at RaidMax generic pricing. EVGA is getting it done big time with these power supplies. I wouldn t be able to build competitively without this series right now TBH. And I can at least sort-of trust the brand name to not make supplies where they ALL burn up after 6 months. Click to expand... Yeah, and EVGA Support is like a breath of fresh air compared to most companies. Also, on the corsair remark. Currently there isn t a single PSU from corsair that I feel competes with the EVGA equivalent. EVGA is just rocking the marketplace currently with great prices on solid products. Are they the best of the best? Not always, but they are always up there and better priced."</post>
   <post id="946291dd-4857-4989-9151-613f5e633494" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Yeah, I was mostly basing that remark on the previous gen Corsair TX and HX supplies that were legendary and the AX are just positioned in the wrong price segment. The current CX series aren t really anything special compared to the EVGAs and cost a lot more."</post>
   <post id="40503a23-0ecc-4fd4-8511-8b77c59b3593" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"I really like HardOCP s reviews of power supplies. If I want to build a budget system, I ll probably get this one. I hear a lot of good things about EVGA support."</post>
   <post id="53b3ed56-561c-4f69-aa76-d307c2141535" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Advil said: ↑ Yeah... you kind of did. I think the concept of "high end" has been skewed a bit lately. A 600W power supply is BIG for a PC in general. It s enough to run a 980Ti and a 4 or 6 core CPU, with moderate overclock. That s a long way from useless mainstream parts. I ve used a bunch of 500 and 600 EVGA power supplies over the last year and they ve all done well in the real world. Sure, I d rather put Corsairs or better in everything but people want gaming systems at RaidMax generic pricing. EVGA is getting it done big time with these power supplies. I wouldn t be able to build competitively without this series right now TBH. And I can at least sort-of trust the brand name to not make supplies where they ALL burn up after 6 months. Click to expand... You are confusing "high end" (features, performance, quality, etc) with capacity."</post>
   <post id="2c9c8cb8-4d0d-457e-b110-8a02aa09d001" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Thanks for the review. I feel a little better about the EVGA 600W 80+ I got from Bestbuy for $32 shipped to my door. PSU calculator says I only needed 400ish watts and didn t think my Corsair CX430w would make it. This is for a 2ndary computer anyways. A question though, It s better to go multi-rail vs. single for ocp/ovp on PSU s? Corsair marketing makes me believe it is."</post>
   <post id="8af0d2ac-399a-4f6d-8e36-115bef69a2f6" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"RogueTrip said: ↑ .................................. A question though, It s better to go multi-rail vs. single for ocp/ovp on PSU s? Corsair marketing makes me believe it is. Click to expand... -There isn t any difference, as long as your PSU is a quality one (*personally i prefer single rail PSUs) -P.S. Like @Jorona already said, this seems as a great entry-level PSU, ideal for Home/office use, but i m wondering about its longevity in a Gaming-PC. (*its main CapXon 85C cap , doesn t inspire me with confidence that it will survive in a Gaming-PC more than its 3 year warranty)"</post>
   <post id="25673dcc-500d-4150-934f-f9fed707e460" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"A properly done multi-rail PSU is safer than a single rail PSU, given everything else being identical. An improperly done multi-rail PSU is inferior to a single rail PSU. 99% of modern PSUs are all single rail PSUs. Multi-rail PSUs are created from single rail PSUs by adding OCP circuits to sets of connectors."</post>
   <post id="14f7b815-dec7-4628-9945-2629cf109637" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Just a suggestion but you might want to differentiate more clearly between electrical noise and audio noise, probably by using a different term for one or the other. It was disconcerting to read about electrical noise in one paragraph and then have  Noise  as a whole new header. I really appreciated you covering the audio noise issue, though."</post>
   <post id="38ba0560-6255-41fc-bd14-8e0f421ab562" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"600B as in, booB?"</post>
   <post id="16a9a746-112c-4890-a2fa-a23878f0e383" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"I can vouch for EVGA s good customer service and their SuperNOVA series PSU s. I might build a budget rig for a friend and the 600B seems like a great pick albeit overkill in the wattage department - but at that price who cares, right. Also, EVGA makes the best looking PSU s imho, especially the beautiful SuperNOVA models. Lastly, kudos to [H] for another very solid PSU review. Any power supply you guys pass, or especially award a medal, is guaranteed to be a great investment."</post>
   <post id="817e5f84-44df-4fe2-9b19-6e4492760348" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Used a couple of these (500B and 600B) PSUs in client builds and never had one die. These are much better than the Corsair CX series in my opinion."</post>
   <post id="269c1ea8-1be0-4e2a-9267-1a832676a96a" section="Power Supplies" discussion="EVGA 600B 600W Power Supply Review @ [H]">"Good to see it passed testing. I recently purchased one of these to put in my parents HTPC as I was doubtful of how much longer the CX430 (original, non 80 plus) until would last. Tough to beat for 35 bucks after rebate (and the rebate came quickly)."</post>
   <post id="1e118a22-17e5-4ec2-9402-9c954d1494eb" section="Power Supplies" discussion="FSP HYDRO G 650W Power Supply Review @ [H]">"FSP HYDRO G 650W Power Supply Review - While FSP may not be a PSU brand that is on the tip of your tongue, we have been reviewing FSP computer power supplies now for 8 years, and the fact of the matter is that these units have been getting better and better over time. Where does the new Hydro G 650W fit into that progression?"</post>
   <post id="2fdd9ad2-c269-4f5e-947f-2a6e43b1b3c8" section="Power Supplies" discussion="FSP HYDRO G 650W Power Supply Review @ [H]">"Hydro... I thought it was something else to unnecessarily add to my water loop. Damn."</post>
   <post id="51214be9-f7b1-47bf-86e5-ca2decc0c4de" section="Power Supplies" discussion="FSP HYDRO G 650W Power Supply Review @ [H]">"Whoa! That good and affordable."</post>
   <post id="82907940-8e01-44a8-99fd-fa778b6f5cdb" section="Power Supplies" discussion="FSP HYDRO G 650W Power Supply Review @ [H]">"Shoot, because of this review, I ended up buying the 750W version with the $20 MIR off Newegg over the weekend. Thanks HardOCP!"</post>
   <post id="9fe1cba7-fb3b-493e-a391-38c32aeb8a66" section="Power Supplies" discussion="Fractal Design Tesla R2 500W Power Supply Review @ [H]">"Fractal Design Tesla R2 500W Power Supply Review - This is our first review of a Fractal Design computer power supply. This is not a new model and we just happened to get a really good deal on this one as it was on sale, so we figured we would give it a go. Fractal states it also has a contemporary Scandinavian design; black, check, square, check....alrighty."</post>
   <post id="ecbd545a-58ad-471c-a8f8-159140c17c91" section="Power Supplies" discussion="Fractal Design Tesla R2 500W Power Supply Review @ [H]">"HardOCP is the first site I go to for PSU reviews but I really miss an important component - load vs noise measurements. Besides quality it is the most important feature for many. The noise section is generally lacking in all HardOCP s reviews but I miss it the most in the PSU ones as others are easier to find elsewhere while there are only a few sites that do quality PSU reviews. Reviewer s subjective impression is not very useful and I ve been burned before by a review on this site. If you would provide the load/noise graph it would be easy to compare the relative performance between PSUs and derive from that what one can expect from a specific model."</post>
   <post id="6fb003d4-9f6d-4ed5-bf02-9b7024e8b745" section="Power Supplies" discussion="Fractal Design Tesla R2 500W Power Supply Review @ [H]">"Meeho said: ↑ HardOCP is the first site I go to for PSU reviews but I really miss an important component - load vs noise measurements. Besides quality it is the most important feature for many. The noise section is generally lacking in all HardOCP s reviews but I miss it the most in the PSU ones as others are easier to find elsewhere while there are only a few sites that do quality PSU reviews. Reviewer s subjective impression is not very useful and I ve been burned before by a review on this site. If you would provide the load/noise graph it would be easy to compare the relative performance between PSUs and derive from that what one can expect from a specific model. Click to expand... Your thoughts are noted."</post>
   <post id="ba0c95eb-51d9-4943-a9e2-09d391894ac1" section="Power Supplies" discussion="Fractal Design Tesla R2 500W Power Supply Review @ [H]">"Good review. PSU s are a crucial component. I just won a Fractal Design Integra M 550W PSU and Fractal Design Core 1100 micro-ATX from Toms Hardware contest, and this review has given me some good insight on FD. I never win anything, but these will definitely go to good use for my new build. Waiting for zen and polaris before i start buying internals."</post>
   <post id="04fad4c2-f0f4-4832-9c76-19d8faeda48f" section="Power Supplies" discussion="Fractal Design Tesla R2 500W Power Supply Review @ [H]">"I ve had a Tesla 650W R1 for several years, it had no problem driving my 2600K@4.8GHz for a couple of years. Now it resides in my HTPC, it is quiet. I also have a Integra R2 750W which runs my home server, it is quiet and stable and it is a 4790K at 4.8GHz(too), but the quality of some of the parts are subpar. I managed to break one of the SATA power connectors without any particular effort. Good thing I have splitters. Main rig(6700K) is driven by a Cooler Master V550S, which feels a notch above in quality, and is also very silent. Anyway, my feel for Fractal Design psu:s is bang-for-the-buck without any extras. Their best game is cases, of which they ve marketed a few hits. I ve had the Define R3 for some years and was happy with it, now I use a Corsair Carbide 200R for the main rig which is a minimalist case but excellent for the task. The home server is in a Fractal case though, the Core 2300, sort of a competitor to Carbide 200R. I like the Corsair better, but the Core 2300 is fine for the money, it houses a NH-D14 and temps are great."</post>
   <post id="6a150d63-803a-414f-a033-2e3a9d8704b1" section="Power Supplies" discussion="In need of a PSU replacement *Urgent*">"Iv e had my psu for just over 5 years now. As far as my memory serves me it s a Corsair TX 650 watt v2. Currently powering a P8P67 mobo, 2500K @4.4ghz, GTX 970 MSi gaming 1500 core and 100 mhz over stock memory, 16 gigs of ram ( 4 dimms). 3 X ssd s and 2 hdd s. The only reason for replacement is age, I want to make this purchase quickly. Should i go for the Corsair Rm series or something else? I don t plan on upgrading the CPU, mobo or GPU any time soon. Wouldn t mind stretching to a 700 watt but 650 would be fine for what I have. I used to have an account here but I lost the email account linked with it . : ( Any help would be great."</post>
   <post id="d64e6e88-9c70-4a9a-9bfc-6fe3a9e2475d" section="Power Supplies" discussion="In need of a PSU replacement *Urgent*">"Just pm kyle regarding your older account. He will ask several questions to verify you are the owner of the account and get a new password for you. I think you have the right idea regarding getting a newer supply...in your position i would see what the prices are compared to how they have been.....Its not entirely urgent just yet but if the prices are good why not?"</post>
   <post id="b3a5417d-99e8-4995-91fd-65d1679b407c" section="Power Supplies" discussion="In need of a PSU replacement *Urgent*">"Doesn t seem like you re in an urgent position to me. If you don t plan to do SLI and/or enthusiast Intel, there s no reason to get something larger than 550 watts. Your current system would be fine with 350 watts. If you re looking for a quality PSU where bang/buck is important, I would recommend waiting on an EVGA GS or G2, Corsair RMx, or other 550 watt PSU from Seasonic or Super Flower sale. You aren t in a position where you need to rush your purchase."</post>
   <post id="f417912b-7796-478a-9675-5f3cec86e193" section="Power Supplies" discussion="In need of a PSU replacement *Urgent*">"I concur on the EVGA G2 or the Corsair RMx series. Just purchased a 750W for my main system, and I kept going back and forth between the two (ended up picking the EVGA)."</post>
   <post id="917ab643-f775-4169-878d-1f320b31a771" section="Power Supplies" discussion="In need of a PSU replacement *Urgent*">"or Seasonic . ure not under pressure so start hunting. From 550-600W (that will fully fulfill u needs) to 750W and up is a bit of jump in prices"</post>
   <post id="d8b30633-9240-48a6-9c9f-50de4a9e0a78" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"I posted a couple months ago in the general tech forum about a power cycle issue and the consensus was that the most likely culprit is my almost 6 year old HX850. That said, I m looking for a replacement PSU that can power an OCed 2500K and 295x2. Modular is an absolute must, other than that I have no real preferences."</post>
   <post id="ef80f307-00b8-4934-95ba-61b34c09b717" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"EVGA 750 or 850 G2."</post>
   <post id="54a90153-3512-4ab4-b388-63792732ef17" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"budget? As the previous person said, the EVGA 750 or 850 G2 are solid choices for a PSU."</post>
   <post id="b1746ba0-9a2a-48c0-a6d1-5a72a9f6b016" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"If you were happy with the Corsair model, they have a really good one out now called the RM850i. The RM850x is a little cheaper, but is also supposed to be pretty good. The original RM850 isn t great, though. CORSAIR RM850i 850W ATX12V / EPS12V 80 PLUS GOLD Certified Full Modular Power Supply Nvidia Sli ready and crossfire support with C-link - Newegg.com You wouldn t be going wrong with the 850 G2 either, though. They re all around the same ballpark in terms of price and quality. Just read a PSU review from a site like this one before buying anything just because it looks like a good deal."</post>
   <post id="45347115-8575-44e1-8d9b-52c72852565f" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"athenian200 said: ↑ If you were happy with the Corsair model, they have a really good one out now called the RM850i. The RM850x is a little cheaper, but is also supposed to be pretty good. The original RM850 isn t great, though. CORSAIR RM850i 850W ATX12V / EPS12V 80 PLUS GOLD Certified Full Modular Power Supply Nvidia Sli ready and crossfire support with C-link - Newegg.com You wouldn t be going wrong with the 850 G2 either, though. They re all around the same ballpark in terms of price and quality. Just read a PSU review from a site like this one before buying anything just because it looks like a good deal. Click to expand... This. I just swapped out to a 750W RM750i, love this PSU unit. Only thing not 100% in love with is that in my case the GPU cables are rather short....but I have a MountainMods bizarro case."</post>
   <post id="75fa5c03-18ac-4157-bd03-cf17b5f0a37c" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"Just got a RM750i that replaced a 7ish year old TX850. It s been a good upgrade. I especially like how quiet it is."</post>
   <post id="77833153-6df9-4ee0-a012-fac7f4282988" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"King Icewind said: ↑ Just got a RM750i that replaced a 7ish year old TX850. It s been a good upgrade. I especially like how quiet it is. Click to expand... LOL...I have yet to get it out of fanless mode. According to the Corsair Link software I m not even 50% load when gaming. Of course, I got the 750W flavor as margin because my cheapo EVGA 600B watt-er $30USD Special took to hard clicking off under gaming load, and insta-rebooting..."</post>
   <post id="84cd5d82-4ef7-4a8e-a97d-0ac83117e80b" section="Power Supplies" discussion="In the market for a replacement PSU, any recommendations?">"My XFX XTR series unit is great, Seasonic built I believe."</post>
   <post id="071beda7-3d1e-43d3-984f-fbe08112f97a" section="Power Supplies" discussion="Anyone know max power draw for OCZ 1250w 8-pin rail?">"Hi. I ve spent about 20 minutes searching and reading, but not found my answer, and I m sure somebody might say  ___ , took 15 seconds to find , but I m just gonna ask: Does anyone know what the max power draw for an OCZ 1250w PSu, 8-pin rail is? I m interested because of what is said in this article: Pascal Secrets: What Makes Nvidia GeForce GTX 1080 Fast? The main limiting factor for the overclocking beyond 2.2 GHz is 225 Watts, which is how much the board can officially pull from the power circuitry: 75 Watts from the motherboard and 150 W through 8-pin PEG connector. However, there are power supply manufacturers which provide more juice per rail, and we’ve seen single 8-pin connector delivering 225 W on its own. Still, partners such as ASUS, Colorful, EVGA, Galax, GigaByte, MSI are preparing custom boards with 2-3 8-pin connectors. According to our sources, reaching 2.5 GHz using a liquid cooling setup such as Corsair H115i or EK Waterblocks should not be too much of a hassle. Click to expand... The OCZ 1250w PSu is a high performance device, so I kind of have a feeling that it might be able to handle higher wattage deliery."</post>
   <post id="0b1bc9b7-6720-4533-8efa-4cdd17caab64" section="Power Supplies" discussion="Anyone know max power draw for OCZ 1250w 8-pin rail?">"If the cards will draw more than 225w power, they will put more connectors in the card. They won t try to overdraw from a single 8 pin, that would be just plain stupid."</post>
   <post id="3b86a6eb-162a-4ac0-9753-3707303dc66f" section="Power Supplies" discussion="Anyone know max power draw for OCZ 1250w 8-pin rail?">"Makes sense. Though, I m sure the cards won t draw more than 225w for stock and mild OC speeds, but maybe some cards won t have multiple 8-pins with further OC ing in mind. But it sounds like enough aftermarket manufacturers are preparing additional sockets."</post>
   <post id="f5828f55-7753-4e80-888d-3a9b3bfcef55" section="Power Supplies" discussion="Anyone know max power draw for OCZ 1250w 8-pin rail?">"The OCZ is single rail, so it will allow the 8-pin to pull as much power as it wants until it melts."</post>
   <post id="fb47a7d5-98ba-45c0-9c3a-bdb24614274a" section="Power Supplies" discussion="FSP Announces 80PLUS Gold Certified Hydro X Power Supply Series">"FSP, the performance power specialist, announces the release of its Hydro X Series 80PLUS Gold certified power supplies. These ATX PSUs use premium components and Japanese-made electrolytic capacitors made to exacting standards in order to provide users excellent cooling performance at high efficiency with minimum noise. Both +3.3V and +5V modules use a custom DC-DC design with solid capacitors for efficiency, voltage stability, and high system compatibility. This design is also optimized for the latest power-saving 6th Generation Intel Skylake processors. A bespoke variable resistor (VR) design better controls the balance point of the +12V rail for tight regulation. Hydro X series PSUs ensure the output voltage is regulated within 1% under any load change. A thermometer monitors the internal temperature and automatically adjusts the speed of the 120mm double ball bearing fan to provide optimal cooling. Computers spend most of their time sleeping. When a PC is in sleep or idle modes, most of its functions are powered by the +5Vsb rail. The Hydro X series includes an Eco-Minion Controller that enhances the overall performance of this rail. Generally, PSUs achieve 75% efficiency at a low-power standby load of about 1A – the Hydro X series can achieve around 82.5% efficiency for low standby power consumption. The sudden rush of electrical current can hurt PSUs immediately after powering on. The Hydro X uses a custom power guard to curb the power surge when switching on, keeping the power supply safe and reliable."</post>
   <post id="cfee7dda-ba4d-4507-bb8f-228c5e0f833a" section="Power Supplies" discussion="FSP Announces 80PLUS Gold Certified Hydro X Power Supply Series">"Hydro, as with the unit y all reviewed recently, is so misleading! I keep expecting that PSU that was shown at CES to pop up. I want mpre things to put in my water loop"</post>
   <post id="0054676a-c9c9-44a5-a1dd-69371a906cb5" section="Power Supplies" discussion="FSP Announces 80PLUS Gold Certified Hydro X Power Supply Series">"I wonder if this could give the Supernova P2 a run for its money; I was a big supporter of Fortron back in the day. I remember a 440W PSU that screamed and had the first 120mm fan I d seen in a power supply. EVGA products have been so solid recently, and their warranty is killer."</post>
   <post id="def0ae32-6b54-440e-907d-5c953afcad58" section="Power Supplies" discussion="FSP Announces 80PLUS Gold Certified Hydro X Power Supply Series">"Napoleon said: ↑ I wonder if this could give the Supernova P2 a run for its money; I was a big supporter of Fortron back in the day. I remember a 440W PSU that screamed and had the first 120mm fan I d seen in a power supply. EVGA products have been so solid recently, and their warranty is killer. Click to expand... They are not comparable products."</post>
   <post id="597892cb-107b-42a3-8c34-db467f26c992" section="Power Supplies" discussion="FSP Announces 80PLUS Gold Certified Hydro X Power Supply Series">"Ohh well, haha. Bubble bursted, it ll probably still be solid on its own slightly lower tier i guess"</post>
   <post id="37280eb8-4cff-4892-8359-ea9117add49b" section="Power Supplies" discussion="PSU Failing? Big voltage variance in HWMonitor">"I just finished 8 hours prime blend at 175x24 (turbo enabled, multi set to 24 in bios) on OC ing my  new  X5670 One thing that is concerning is the large variance of my voltage lines; does HWmonitor typically read badly or can I realiably blame this on my PSU? 3.3V - 3.136-3.248 5V - 4.758-4.919 12v - 12.288-12.416 HWmonitor: hwmonitor_x5670_42_8hrprime.jpg What do you guys think?"</post>
   <post id="e5efd91d-35aa-4974-b5c7-2870b85f8311" section="Power Supplies" discussion="PSU Failing? Big voltage variance in HWMonitor">"Is that no load to full load variance? I can t see the pic because google drive is blocked for me. I do like my voltages to be more stable than that, but I haven t actually ever checked what they are in benchmarking situations."</post>
   <post id="b18b17b6-403a-49f9-8a79-d3719a6e0107" section="Power Supplies" discussion="PSU Failing? Big voltage variance in HWMonitor">"It was min/max per HW monitor after 8 hours of prime; the current values during when I took the picture were: 3.3v - 3.216 5v - 4.865 12v - 12.352"</post>
   <post id="157f1e02-bcfd-41aa-ab18-cc40027ea3db" section="Power Supplies" discussion="PSU Failing? Big voltage variance in HWMonitor">"Software monitoring is notoriously inaccurate."</post>
   <post id="d68d3321-f508-407f-aa8c-8c81aa235ed7" section="Power Supplies" discussion="PSU Failing? Big voltage variance in HWMonitor">"Use software readings as a guide whether you need to check with a multimeter, even then they can mislead you greatly. No multimeter, no clue."</post>
   <post id="e65e96e8-cb4c-491c-861f-46b3e4b7e94a" section="Power Supplies" discussion="Additional GPU - need a new psu?">"I currently have a hdplex 250W plus a voodoo 350w power adapter and thought about adding another gtx 970 (mini). Would my current PSU setup be able to handle it? system specs x99e-itx mono 5820k 16gb dominator ram nvme sad 4 120mm fans aquaero evga 970 gtx mini d5 pump"</post>
   <post id="25a0d720-d3fb-4759-af72-c60e74910afa" section="Power Supplies" discussion="Additional GPU - need a new psu?">"I don t know much about that external power adapter, but running two 970s on a 350W supply, even if 100% of that 350W is dedicated to the GPU, sounds like a dicey proposition. NVIDIA guidelines recommend a minimum 28A capacity on the 12 rail for a single 970, and even at 90% efficiency that s over 350W already. What sort of enclosure is this in? How do you have space for an SLI board and two cards but not an ATX/SFX power supply?"</post>
   <post id="57682167-a65b-4ed3-b131-3b717c57f908" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"hi guys. actually in my ncase m1 i have a gtx 980ti and a Silverstone sfx600w. in sept i will change video card with the new gtx 1080. Do you think that a corsair sf450 can be pilot video card or not? i have a i74790k and PSU is a 37.5A on 12v. what do you think? thanks"</post>
   <post id="59b08399-bef2-4db9-a86e-136516d22460" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"antmest said: ↑ hi guys. actually in my ncase m1 i have a gtx 980ti and a Silverstone sfx600w. in sept i will change video card with the new gtx 1080. Do you think that a corsair sf450 can be pilot video card or not? i have a i74790k and PSU is a 37.5A on 12v. what do you think? thanks Click to expand... You ll be fine. 980ti uses more power than the 1080, supposedly."</post>
   <post id="83313261-a0b7-4b6b-adcb-f0e8df902f88" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"nice. if i switch to i7 6700 that has a 65w tdp i will secure at 100% that corsair will fit. actually i have a ncase m1 i7 4790k and 980ti. i want to switch to i7 6700 h170, gtx 1080 and corsair sf450"</post>
   <post id="29f6f6d6-9c8c-4f1a-8b13-f9a75dda5a47" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"If you start OCing heavily you ll probably push the PSU too far, though."</post>
   <post id="c64cd2e6-ce84-427c-8100-27da50d39a5c" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"i74790k at stock speed: &lt;= 100watt power consumption ( Intel Core i7-5930K and Core i7-5820K Review ) 980Ti at stock : &lt;=280watt power consumption , so, theoretically the 1080GTX will have even lower consumption ( NVIDIA GeForce GTX 980 Ti 6 GB Review ) HDD : 10watts RAM: 10watts Optical Drives: 10watt So the absolutely worst case scenario for your pc will be somewhere around 410-420 watt. But this is the absolute worst, and it is very unlikely to happen. P.S. Also, as i said, the 1080GTX will have even lower power consumption than the 980Ti, so there is nothing to worry about. More likely, your PC s average power consumption will be around 250 watt."</post>
   <post id="bc8c40da-850b-4515-a3bf-1d674ef957b2" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"Sith ari said: ↑ i74790k at stock speed: &lt;= 100watt power consumption ( Intel Core i7-5930K and Core i7-5820K Review ) 980Ti at stock : &lt;=280watt power consumption , so, theoretically the 1080GTX will have even lower consumption ( NVIDIA GeForce GTX 980 Ti 6 GB Review ) HDD : 10watts RAM: 10watts Optical Drives: 10watt So the absolutely worst case scenario for your pc will be somewhere around 410-420 watt. But this is the absolute worst, and it is very unlikely to happen. P.S. Also, as i said, the 1080GTX will have even lower power consumption than the 980Ti, so there is nothing to worry about. More likely, your PC s average power consumption will be around 250 watt. Click to expand... finally. this is i wanted to hear. i m planning to switch on september to these components: from ncase m1 to dan a4 sfx case i7 6700 or i7 7700 (kabylake) 65w gtx 1080 180w 1 nvme ssd 240gb 2 ssd sata 480gb i calculated that TDP will be around 250-260w right?"</post>
   <post id="e6d5ebf0-7cd8-47b7-ab29-c812c776e302" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"antmest said: ↑ finally. this is i wanted to hear. i m planning to switch on september to these components: from ncase m1 to dan a4 sfx case i7 6700 or i7 7700 (kabylake) 65w gtx 1080 180w 1 nvme ssd 240gb 2 ssd sata 480gb i calculated that TDP will be around 250-260w right? Click to expand... According to this : Core i7 6700K processor review: Desktop Skylake the i7 6700, will have similar power consumption with the i7 4790k so the results will be very similar to the results i wrote at my previous post. Again , with your new setup, the average power consumption is estimated no more than 250 watt."</post>
   <post id="96989c44-2a49-49fe-8a73-8d40322465af" section="Power Supplies" discussion="gtx 1080 and corsair sf450. It is possible or not?">"thanks man"</post>
   <post id="a781e072-799d-41c4-925a-202047ff80b8" section="Power Supplies" discussion="HX1000 or HX1050?">"Looking to get an affordable used power supply and was looking at either of these. If the HX1000 was priced cheaper than the HX1050 is it worth it to get it or just go with the HX1050? I did look at the AX1200 as a possible alternative but it s more expensive than either of those and i don t want the Corsair link-i versions. I know that the HX1000 is based on a 2008 CWT PUC platform and it seems the HX1050 is based on a different CWT platform updated in 2011? Besides that is there any huge differences that set them aside?"</post>
   <post id="fa7b32fa-9542-400f-bfce-bfa319a18cfa" section="Power Supplies" discussion="HX1000 or HX1050?">"All the reviews, either from [H] ( Corsair HX1050 Power Supply - Corsair HX1050 1050 Watt Power Supply Review ) , or from Techpowerup ( Corsair Professional Series HX1050 Review ), or from Jonnyguru ( Corsair HX1050 1050W Review ), they mention that the HX1050 is an upgraded version of the older HX1000, so the answer to your question is quite obvious i believe ( P.S, You haven t mentioned what is the price difference between the 2 of them)"</post>
   <post id="cf9f9533-f98e-4cec-82d4-77590d98e2ba" section="Power Supplies" discussion="HX1000 or HX1050?">"I would got with the 1050 even just from a longevity standpoint. The HX1000 has probably seen a couple more years of usage, and technically the caps degrade over the time of usage."</post>
   <post id="8f13a763-33a6-48d7-9204-4cdf172bb930" section="Power Supplies" discussion="HX1000 or HX1050?">"Sith ari said: ↑ ( P.S, You haven t mentioned what is the price difference between the 2 of them) Click to expand... Well in some cases from looking at further it s now quite substantial. In Canadian pricing it s a bit more than $100 apart with the HX1000 coming in much cheaper than what an equivalent HX1050 would be. I don t have too many HX1050 to compare to as I see a number of HX1000 for sale. HeavensCloud said: ↑ I would got with the 1050 even just from a longevity standpoint. The HX1000 has probably seen a couple more years of usage, and technically the caps degrade over the time of usage. Click to expand... What would that degradation affect on the power supply? Would it become more inefficient under load and idle or would it affect the performance/stability ?"</post>
   <post id="b37e215f-0e21-448f-9f51-79f8797503af" section="Power Supplies" discussion="HX1000 or HX1050?">"FWIW I m currently running a Thermaltake Toughpower 1000w in my system. That is relevant because it uses the exact same internal OEM design (CWT PUC) as the Corsair HX1000. It has been been flawless for me. I got mine about ~6 years ago, where it then spent the next ~4 years in my secondary computer. To be fair, it only saw sporadic usage during that time, so it had a pretty easy life. I ran an Antec TruePower Quattro 1000w in my main PC during that time. When I built my current 5820K computer, I decided to put my Thermaltake Toughpower 1000w in my main computer since it overall had a lot less hours on it. My 5820K (6 core processor) overclocked to 4.5Ghz with 3 overclocked GTX680s in SLI should represent a significant load for the PSU, and it does great. One thing that is important to mention is that the CWT PUC design is essentially two smaller PSUs in one. That isn t necessarily a bad thing, but it is very important to balance the power draw of various components across the different rails intelligently."</post>
   <post id="0eade1de-7e5b-4743-a0a9-083219936baf" section="Power Supplies" discussion="HX1000 or HX1050?">"The HX1000 has dual 12V rails, the HX1050 has a single 12V rail so you don t have to worry about which 12V leads are plugged in where. What are you plugging into the PSU? If you re going Crossfire/nVSurround with high-end GPUs then that could be a consideration as you have to be very careful not to overload 1 rail on the HX1000. I have a HX1000 powering tri-Fire so I know what happens when you don t check the cables."</post>
   <post id="92d5d8a9-717e-4302-8cb9-a733490a503b" section="Power Supplies" discussion="HX1000 or HX1050?">"What are you powering that requires 1000 watts?"</post>
   <post id="ada272fa-4947-48d0-ad2e-a5b45abe2e43" section="Power Supplies" discussion="HX1000 or HX1050?">"GotNoRice said: ↑ One thing that is important to mention is that the CWT PUC design is essentially two smaller PSUs in one. That isn t necessarily a bad thing, but it is very important to balance the power draw of various components across the different rails intelligently. Click to expand... Yes I recall reading it s two 500W power supplies together which is why rail-management is essential and why it has multi-rails. rtangwai said: ↑ The HX1000 has dual 12V rails, the HX1050 has a single 12V rail so you don t have to worry about which 12V leads are plugged in where. What are you plugging into the PSU? If you re going Crossfire/nVSurround with high-end GPUs then that could be a consideration as you have to be very careful not to overload 1 rail on the HX1000. I have a HX1000 powering tri-Fire so I know what happens when you don t check the cables. Click to expand... It s going to be used for a system I am working on with multiple graphics cards, hard-drives, maybe even possibly a dual-socket E5-2670 system or if I can get my hands on it an EVGA SR-2. I would have thought the HX1050 would be a multi-rail design. What s the danger in a single-rail design versus a multi-rail design like the HX1000? I don t like the idea of having a sudden surge or current if it does happen that would overload and possibly fry critical components before the protection is activated unlike multi-rail protection. Tsumi said: ↑ What are you powering that requires 1000 watts? Click to expand... As above. Besides the HX1000 is affordable even used so why not as it s a proven power supply (although a bit-dated). If you have seen Canadian prices for power supplies brand-new even sub-1000 you would be shocked at just how much we are gouged."</post>
   <post id="832333ea-a462-40c6-8ca6-d649b2c9bde4" section="Power Supplies" discussion="HX1000 or HX1050?">"Have also been looking at the Thermaltake Toughpower 1200W [2007] (used) and noticed it s based off the same CWT PUC design. Is it is still a valid and modern design for the price point you can get it used for compared to similar 1200W counterparts?"</post>
   <post id="f5dc4fb3-eb28-4356-81b7-cff197452411" section="Power Supplies" discussion="HX1000 or HX1050?">"GothamsReckoning said: ↑ Is it is still a valid and modern design for the price point you can get it used for compared to similar 1200W counterparts? Click to expand... Kind of impossible to answer your question unless you elaborate on exactly what you mean by "valid and modern design", as well as what price the PSU is being sold for, and how much usage the "used" PSU has seen. There is really nothing "bad" about this PSU design. They were fantastic PSUs when new and that doesn t change simply because time has passed. There have not been any significant changes to any standards since then, so there should not be any concerns about compatibility. The biggest potential downside is likely going to be lower efficiency compared to newer units."</post>
   <post id="43a7900f-6aae-4d3c-9020-50d39b17941c" section="Power Supplies" discussion="HX1000 or HX1050?">"GothamsReckoning said: ↑ Looking to get an affordable used power supply and was looking at either of these. If the HX1000 was priced cheaper than the HX1050 is it worth it to get it or just go with the HX1050? I did look at the AX1200 as a possible alternative but it s more expensive than either of those and i don t want the Corsair link-i versions. I know that the HX1000 is based on a 2008 CWT PUC platform and it seems the HX1050 is based on a different CWT platform updated in 2011? Besides that is there any huge differences that set them aside? Click to expand... The Corsair Professional Series HX 1050 is 79 bucks on amazon of all places....lol how cheap are you trying to go? You had me thinking it was super expensive or something. Im not so sure about buying used power supplies anyway? I just have never gone that route (ive had ps burn up right after the warranty expired)"</post>
   <post id="2c3e9753-198e-4e40-9e47-a19de41e5234" section="Power Supplies" discussion="HX1000 or HX1050?">"Buy a good name brand power supply with a good warranty..."</post>
   <post id="af1bd560-7bda-435c-a7d5-f5048a961c42" section="Power Supplies" discussion="Corsair RMi Series 650W Power Supply">"The Corsair RMi Series 650W power supply scored high marks in this review at techPowerUP today. While there were a few things the reviewer wasn t too thrilled with, the positives far outweighed the negatives, resulting in the PSU getting a "highly recommended" award. Corsair hit the competition really hard with the new RMi and RMx units. The RM650i, which I evaluated today, performed amazingly in almost all the tests I conducted. Its overall performance is among the highest in its category, well over its main competitor, EVGA s SuperNOVA 650 G2. So far, EVGA was the only company brave enough to provide a ten-year warranty with its high-end offerings, a clear advantage to anyone looking for some peace of mind, but Corsair decided to match EVGA s offer, and from now on, all all AXi, HXi, RMi, and RMx units will also feature a ten-year warranty."</post>
   <post id="ef0f045f-468a-42ba-9a99-5a16c7ab3130" section="Power Supplies" discussion="Corsair RMi Series 650W Power Supply">"Corsair s updated "software link" at the RMi 650 seems much more user friendly &amp; useful. Great PSU overall !!"</post>
   <post id="0d2dbc92-5c22-4b8d-a2ca-9d941a2350c8" section="Power Supplies" discussion="Corsair RMi Series 650W Power Supply">"I really like the 10 year warranty with high end power supplies..."</post>
   <post id="4d04b6d8-31c2-482c-b946-12dc6dff9102" section="Power Supplies" discussion="Need a replacement PS - cable/power in back">"Need to replace an old AT power supply in a 2U chassis with something a bit more current. The power supply is mounted in the front of the chassis, with the cables and power to the rear. There is actually an extension cable that connects the power to the 110v wall. A couple pictures. Anyone know what type of power supply I m looking for? (or this was some sort of goofy one off, and it is time to pull out the soldering iron/dremel)"</post>
   <post id="56b39189-f33f-4636-98ce-a7d2eb093d42" section="Power Supplies" discussion="Need a replacement PS - cable/power in back">"Talk about a horrible design. "Engineer 1(Jeb)" : Hey Cletus, how s this design look? "Engineer 2 (Cletus)": Looks good to me. As long as everything fits it is a winner. Years later - 8 year old who opens up the machine - What the?!?!?!?! Who designs these things? I want to punch them in the face. Basically, that looks like a very proprietary design. I would get a regular AT power supply and mount it 90 degrees different then the current one. Of course the power plug will be coming out the side of the case, but it doesn t look like there is really any room to mount it somewhere else. Pics of the whole inside of the system may help give me a different idea though."</post>
   <post id="95c62d6d-8fac-4ce6-a775-e24e11a67b46" section="Power Supplies" discussion="Need a replacement PS - cable/power in back">"WTF were the designers thinking?!"</post>
   <post id="85072911-b0eb-414b-a5dc-359513c90c18" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"I am looking to upgrade system in signature to X99. I would like to reuse the 7970 in crossfire and SeaSonic SS-750KM3 power supply. Will the SeaSonic SS-750KM3 still work well for a X99 setup that includes the 7970s in crossfire? What about if I decide to upgrade graphics cards to more current SLI/X-Fire cards? I assume a single card would be fine. Just checking whether I need to upgrade PSU as well. thanks"</post>
   <post id="90204329-6d5b-43ce-8baf-58c451d24369" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"Highly depends on your overclocking goals. If you keep everything stock, you ll be fine with SLI/crossfire two top end cards. Overclocking at stock voltages would highly depend on the CPU choice and GPU choice. I wouldn t push it beyond that. With 7970s and a 6-core X99 CPU, I would keep it at no voltage increase overclocks."</post>
   <post id="5499e80b-35fc-4b05-9fc3-99c23c775640" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"Tsumi said: ↑ Highly depends on your overclocking goals. If you keep everything stock, you ll be fine with SLI/crossfire two top end cards. Overclocking at stock voltages would highly depend on the CPU choice and GPU choice. I wouldn t push it beyond that. With 7970s and a 6-core X99 CPU, I would keep it at no voltage increase overclocks. Click to expand... Ok - I understand. thanks Can anyone recommend a PSU then? What watt would I need minimum? 850W?"</post>
   <post id="ce6ea268-ba8f-41a9-87cb-bbf226c161d3" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"Depends on your overclock ambitions and GPU choice. The 6 and 8 core Intels can suck down more than 300 watts when overclocked with voltage increases, and the Fury X can suck more than 300 watts as well. If you re aiming for aggressive overclocks on top end Intel and GPUs, I would say 1k watts minimum."</post>
   <post id="b449ce3d-a1d5-456f-914c-5b930ae81c6f" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"Tsumi said: ↑ Depends on your overclock ambitions and GPU choice. The 6 and 8 core Intels can suck down more than 300 watts when overclocked with voltage increases, and the Fury X can suck more than 300 watts as well. If you re aiming for aggressive overclocks on top end Intel and GPUs, I would say 1k watts minimum. Click to expand... OK - So are Seasonic, Corsair (rebadged Seasonics), and EVG still the best PSU vendors? Any recommendation for 1K watt psu?"</post>
   <post id="fa013b62-a8e8-4324-b261-4c383c091288" section="Power Supplies" discussion="SeaSonic SS-750KM3 work for X99?">"Corsair RM1000x, EVGA 1050 GS, EVGA 1000 G2, Seasonic X-1050, Cooler Master V1000, XFX P1 1000, EVGA 1000 T2 to name a few."</post>
   <post id="db4245cc-0402-4c03-bc69-7e92f68118c8" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"Building a small cheap computer, Skylake G4400 Pentium, 4 or 8gb RAM, 1 SSD, couple of optical drives, mainly small office work. (no gaming, no dedicated video card) I find it difficult to find a cheap yet reliable and not overkill PSU. All the ones that are recommended from calculators are like 650W+ and I don t think I need more than 450-500W..? Any quality not too expensive PSU out there that fits the bill? thanks"</post>
   <post id="6132b0d2-5a00-4cbf-85ae-af6e9e1f9ef0" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"Hah, You dont even need more then 150w. 15 bucks after rebate: EVGA 100-N1-0400-L1 400W continuous power supply 2 yr Warranty - Newegg.com And if you want something abit better built, Seasonic for 35 bucks: SeaSonic SSP-300SE 300W ATX12V CrossFire Ready 80 PLUS BRONZE Certified Haswell Ready Active PFC Power Supply –OEM - Newegg.com"</post>
   <post id="553498b9-e142-4a14-b8c1-28548ec05b14" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"He seems to be posting more than building atm, in reality. And won t listen to anyone."</post>
   <post id="1a4cd144-32af-4af2-ac76-3141f0fe46b0" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"I rounded up my options 2 days ago, I intend to buy it all at once yes. And before buying I m asking around. Whats wrong with that? And thanks Jorona"</post>
   <post id="29fc35a4-655b-49e8-b4da-adf3222f2e11" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"Knock yourself out man."</post>
   <post id="2f7d7370-2bd2-466e-8a6d-4d744a7a51f6" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"Lebowsky said: ↑ Building a small cheap computer, Skylake G4400 Pentium, 4 or 8gb RAM, 1 SSD, couple of optical drives, mainly small office work. (no gaming, no dedicated video card) I find it difficult to find a cheap yet reliable and not overkill PSU. All the ones that are recommended from calculators are like 650W+ and I don t think I need more than 450-500W..? Any quality not too expensive PSU out there that fits the bill? thanks Click to expand... The Seasonic for $35 at the time of the original post that was suggested by Jorona is a good starting point. Other than that, is the case going to be a micro ATX or a mini ITX? You see, in general mini ITX components (case and motherboard) are going to cost you more money than micro ATX components for the same level of quality."</post>
   <post id="623ae1b1-b905-44eb-ba9a-36bb01d8002c" section="Power Supplies" discussion="PSU recommendation for Skylake Pentium G4400">"The EVGA 430w 80+ units are great for budget. Black sleeved cables, quiet fan, certified."</post>
   <post id="2cff0ebc-0890-4e57-abb3-4e2cc88f3aaa" section="Power Supplies" discussion="Power supply unit work or not">"My pc configuration is Processor - Intel Core i-5 2320k 3.0 ghz Motherboard - Gigagabyte H61M - S2PV Ram - 8 gb HDD - 2 TB sata Western Digital PSU - Gigabyte E570 Watt I want to buy a new graphics card Sapphire Nitro R9 390 8gb . Will this PSU mentioned above support this graphics card ? plz reply me asap."</post>
   <post id="72c318f8-1a96-433c-ac35-f1b0146b0413" section="Power Supplies" discussion="Power supply unit work or not">"Nominally a 460 watt PSU with 400 watts on the 12v rail made by FSP... I would get a new higher quality PSU. A good 550 watt PSU would suffice."</post>
   <post id="c280f065-898e-412c-a65b-33cd9890ed13" section="Power Supplies" discussion="Power supply unit work or not">"I wouldn t risk it. As said, the  570  is some peak value the PSU will graciously output for a while and it s not the kind of extra power you d want in your system. More like a suicide run mode. You appear to have the right set of cables but considering the amount of system and GPU memory (Sapphire claims a 375 Watt maximum pull!), the presence of a spinner and beefy TDP on the i5 all scream  don t do this!  to me."</post>
   <post id="b03d9bb0-25b9-499d-a47f-b97f95247f8f" section="Power Supplies" discussion="Power supply unit work or not">"In theory should work, in practice... eXtreme Power Supply Calculator"</post>
   <post id="e5c0477a-039e-437c-9e33-52d2cc3b9a50" section="Power Supplies" discussion="Power supply unit work or not">"flatty said: ↑ In theory should work, in practice... eXtreme Power Supply Calculator Click to expand... Don t trust the calculators... 1: that one isn t super up to date (missing socket 1151) 2: that one says load wattage of 312 for my system and I never see it at more than 250, even with the cpu and gpu running flat out. (number measured at the wall according to the UPS)"</post>
   <post id="198ed724-a75f-4324-be70-37f034eeb0c6" section="Power Supplies" discussion="Power supply unit work or not">"I feel flatty is also on the fence when it comes to believing the calculator. Yup, it s just speculation. My result with this particular calculator is similar to the one obtained by FnordMan - calculated 324, actual around 250. And we re talking a serious load. Intel Burn Test running alongside Furmark, overclocked GPU, overclocked everything, overvolted DDR, MCH, CPU... Watts are almost meaningless. You got a glorified typewriter with integrated graphics, few fans and one module of RAM? You might get away with 300. PCIe graphics? Go for 400-450. SLI/CFX? 550-600. I ve seen 600 or so Watt OCZ PSUs failing to keep up with two 460GTX in SLI with an I5, while my old Corsair HX520 would power that rig just fine full throttle. It s all about the quality of the delivered power. Sheer power is not enough when the PSU is struggling and overshooting/undershooting during transients or pretending to be quiet and cooking the electrolytic capacitors on the secondary after a few months of use."</post>
   <post id="ad5fa229-8cc3-4a1b-a1c6-76c49ae76df7" section="Power Supplies" discussion="Power supply unit work or not">"FnordMan said: ↑ Don t trust the calculators... 1: that one isn t super up to date (missing socket 1151) 2: that one says load wattage of 312 for my system and I never see it at more than 250, even with the cpu and gpu running flat out. (number measured at the wall according to the UPS) Click to expand... The point was that according with calculator the PSU should be fine. IF the calculator say "320" and you drawn from wall 250, is because the calculator DONT take in consideration to keep altime the PSU in full load. Because most of the PSUs having best efficiency and current quality when are loaded around 75-80%, the calculator PROBABLY consider this."</post>
   <post id="f9c56a49-e242-453e-94e8-c4fa88048080" section="Power Supplies" discussion="Power supply unit work or not">"michalrz said: ↑ I feel flatty is also on the fence when it comes to believing the calculator. Yup, it s just speculation. My result with this particular calculator is similar to the one obtained by FnordMan - calculated 324, actual around 250. And we re talking a serious load. Intel Burn Test running alongside Furmark, overclocked GPU, overclocked everything, overvolted DDR, MCH, CPU... Watts are almost meaningless. You got a glorified typewriter with integrated graphics, few fans and one module of RAM? You might get away with 300. PCIe graphics? Go for 400-450. SLI/CFX? 550-600. I ve seen 600 or so Watt OCZ PSUs failing to keep up with two 460GTX in SLI with an I5, while my old Corsair HX520 would power that rig just fine full throttle. It s all about the quality of the delivered power. Sheer power is not enough when the PSU is struggling and overshooting/undershooting during transients or pretending to be quiet and cooking the electrolytic capacitors on the secondary after a few months of use. Click to expand... That s why a Seasonic, an Corsair or an Antec worth the money, in time that other (OCZ, Mushking etc, and to not mention obscure other brands) cant handle the wattage they are rated."</post>
   <post id="837bae88-31b9-4d6d-9ee9-725f361dff38" section="Power Supplies" discussion="Power supply unit work or not">"Get an XFX, EVGA, Corsair, or Seasonic unit- Anything else is subpar."</post>
   <post id="199e21ba-159f-4681-8ab2-5da0b6fce556" section="Power Supplies" discussion="Power supply unit work or not">"flatty said: ↑ The point was that according with calculator the PSU should be fine. IF the calculator say "320" and you drawn from wall 250, is because the calculator DONT take in consideration to keep altime the PSU in full load. Because most of the PSUs having best efficiency and current quality when are loaded around 75-80%, the calculator PROBABLY consider this. Click to expand... If he is drawing from the wall 250 watts, he is drawing less than 225 watts from the PSU. The calculators calculate PSU load, NOT wall load. Do some research before you spread more misinformation. nxmbness said: ↑ Get an XFX, EVGA, Corsair, or Seasonic unit- Anything else is subpar. Click to expand... EVGA and Corsair have many mediocre PSUs, and Corsair is especially guilty of selling mediocre PSUs at near premium prices. Antec, FSP, Cooler Master, and others have their share of excellent PSUs (among mediocre and sometimes subpar ones), so blanket statements like yours does not work."</post>
   <post id="0f70f39e-ef9b-4ed7-af4e-32ca82197dd5" section="Power Supplies" discussion="Power supply unit work or not">"EVGA units are generally great, as are Corsair units. Look at JGURU reviews. The B series EVGA units are great for budgets as are the CX units. They get so much hate, but the company i work for has over 200 of them in daily use and there s been ONE die. That s 0.5% failure rate over 3 years."</post>
   <post id="2edecbb4-7793-4899-8393-aa13d7ecd4ff" section="Power Supplies" discussion="Power supply unit work or not">"Tsumi said: ↑ If he is drawing from the wall 250 watts, he is drawing less than 225 watts from the PSU. The calculators calculate PSU load, NOT wall load. Do some research before you spread more misinformation. Did I misinformed some? I briefly mentioned "wall story", I tried to point that a PSU is recommended to be loaded (on long term) around 75-80% (not keep it 100% loaded all time. Also I mentioned "PROBABLY" (in caps like now) that the calculator take this aspect in consideration. I didn t "projected" none of this calculators, by coincidence did you, to be so sure/vehement about "misinforming"? EVGA and Corsair have many mediocre PSUs, and Corsair is especially guilty of selling mediocre PSUs at near premium prices. Antec, FSP, Cooler Master, and others have their share of excellent PSUs (among mediocre and sometimes subpar ones), so blanket statements like yours does not work. Click to expand..."</post>
   <post id="69039dd1-4faa-4a81-abe5-5ea0c5a9cd0b" section="Power Supplies" discussion="Power supply unit work or not">"The calculator didn t take anything into consideration. It s just a tool by retailers to try to convince people they need a larger PSU than they actually do, and isn t even maintained properly and doesn t get accurate numbers. Besides, for a typical gaming computer, sizing a PSU to target the computer s maximum theoretical load to be at 100% PSU load capacity would have the PSU working in the 50-80% range in the vast majority of gaming scenarios. "Great for budget" = mediocre. They re mediocre PSUs, and EVGA has had a history of putting out less than good PSUs in the past. EVGA has only been getting love in the PSU department lately because they have been extremely aggressive on their pricing, but otherwise their top PSUs are in line with other top PSUs. As for Corsair, the hate comes from PSU lines like the CS, where build quality is in the mediocre range but prices are in the good to very good range of PSUs, sometimes being more expensive than Corsair s own better offerings. The best I can say about Corsair is that they haven t gone with an OEM that has put out something that was outright bad, but the CS line is something that Corsair should have never released."</post>
   <post id="6ed3fa86-fa04-40e1-9782-f9cf81fd341f" section="Power Supplies" discussion="Power supply unit work or not">"so gigabyte 570 watt psu not enough for sapphire nitro r9 390 ?"</post>
   <post id="592f25d9-8e02-44aa-b88b-96166b8c0443" section="Power Supplies" discussion="Power supply unit work or not">"No."</post>
   <post id="15f46634-ebf0-4e5b-8c1a-503a35b56cc8" section="Power Supplies" discussion="Power supply unit work or not">"FnordMan said: ↑ Don t trust the calculators... 1: that one isn t super up to date (missing socket 1151) 2: that one says load wattage of 312 for my system and I never see it at more than 250, even with the cpu and gpu running flat out. (number measured at the wall according to the UPS) Click to expand... 1. You may have missed it, but LGA 1151 is in there. 2. Of all the PSU calculators, that one is the closest to being accurate. IE, when it recommends 450W, most of the PSU OEM and retailer calculators recommend 600W plus. It s on the conservative side of reality, but nowhere near as conservative as other calculators. Basically, if a person doesn t have the ability to measure/calculate their own power draw, I m comfortable settling for THAT specific calculator, and virtually no other. Nurul Huda said: ↑ so gigabyte 570 watt psu not enough for sapphire nitro r9 390 ? Click to expand... The Gigabyte Superb E570 (I m guessing this is your PSU) is an adequate 570W PSU but not as good as the EVGA G2-550 or Corsair RM550x. So, if you were in the market for a PSU, I d steer you towards one of those. Since you already have it... That particular PSU has 2x 12V rails with a combined output of 34A (408W). That s not as good as the others above, but is more than adequate for all but the most demanding single-GPU systems. Also, the way the 12V rails are listed leads me to suspect that it may actually be a single-rail design (Seasonic S12-II did this as well). Also, whereas most quality 550W PSUs (like the two above) can sustain a load of 550W or even slightly higher, the Gigabyte claims to only sustain a load of 460W, not the advertised 570W. Here s two reputable websites ([H] and Anandtech) who tested power draw. Note: This is total system power draw, and it s measured at the wall (meaning actual power draw is lower). Power, Temperature and Fan Noise - XFX R9 390 Double Dissipation 8GB Video Card Review - 419W overclocked The AMD Radeon R9 380X Review, Feat. ASUS STRIX - 380W was their highest reading (for the 390 used in the comparison, I know this was a 380x review) If you assume an 85% efficient PSU in both cases, that means actual power draw for the entire system was 356W and 323W, respectively. If you plan to keep your system on 24/7, you want to aim for up to 40% over this, so 452W - 498W (450-500W as an estimate). These test systems also had CPUs that would draw as much as or more power than yours, so your total system draw is likely slightly lower. So, I feel comfortable saying that your Gigabyte E570 is adequate for your system."</post>
   <post id="a5a6287a-96d3-4053-b898-ce5c45c1c2b5" section="Power Supplies" discussion="Power supply unit work or not">"Im curious what if any Tsumi says in response, because ive never seen him oversize recommended power supplies before. Honestly hes usually the one arguing the one picked out is overkill. When he says its not enough, im inclined to agree lol."</post>
   <post id="c3f99cf1-953e-4155-8954-e1bfe21b1993" section="Power Supplies" discussion="Power supply unit work or not">"FSP can be hit or miss, and without any good reviews on that particular unit (cannot even find out what the platform is), I wouldn t trust it. That is the primary reason behind my recommending a different PSU, not so much the wattage concerns. And when there is the EVGA 500 B1 for $30 after rebates ($40 without), there isn t much of a reason to recommend something smaller. HEC built though, but quality is decent."</post>
   <post id="62dec53c-3117-40f9-bb28-eb480582883a" section="Power Supplies" discussion="Power supply unit work or not">"Tsumi said: ↑ FSP can be hit or miss, and without any good reviews on that particular unit (cannot even find out what the platform is), I wouldn t trust it. That is the primary reason behind my recommending a different PSU, not so much the wattage concerns. Click to expand... Valid concerns, though I haven t been able to find anywhere where it says FSP made it. I found one review of the prior Superb E550, but based on specs, the 570 seems to be a different platform possibly (actual 80+ certification this time). Still, if the 550 is anything to go off of, the 570 should be an above average 460W PSU, getting above average and within spec findings except for efficiency, where it struggled. As I said before, if he were in the market for a PSU and looking at this one, I d tell him to go elsewhere. But since he has it already, does he really need to replace it? Doing so would get him better efficiency, but aside from that I see no tangible benefit to a PSU swap at this time. Like I said, it should be adequate for his needs. No one here is going to be blown away."</post>
   <post id="4a7ba4ae-f737-49db-9e01-77a2d923fbe3" section="Power Supplies" discussion="Power supply unit work or not">"Daniel_Chang said: ↑ Valid concerns, though I haven t been able to find anywhere where it says FSP made it. I found one review of the prior Superb E550, but based on specs, the 570 seems to be a different platform possibly (actual 80+ certification this time). Still, if the 550 is anything to go off of, the 570 should be an above average 460W PSU, getting above average and within spec findings except for efficiency, where it struggled. As I said before, if he were in the market for a PSU and looking at this one, I d tell him to go elsewhere. But since he has it already, does he really need to replace it? Doing so would get him better efficiency, but aside from that I see no tangible benefit to a PSU swap at this time. Like I said, it should be adequate for his needs. No one here is going to be blown away. Click to expand... According to Realhardtechx, the Superb 550s were Acbel Polytech, while the E570 is FSP."</post>
   <post id="9a835973-2b34-4bf5-b4c2-fef7dfb21400" section="Power Supplies" discussion="APC, overpriced cheap products.">"I have two BR1500GI from APC both rated as 1500VA/865W. I tested this units with similar rigs, one with a 5930K and another one with a 5820K, both with GTX980 Ti SLI, one with Corsair AX860i and another with an Enermax Platimax 850W. Both configurations runs at 800W when running Far Cry Primal Benchmark. I see 800W from the UPS LCD and from a Watt Meter that I have between the peripherals and the UPS. So the measurement is quite good. With blender rendering the load is at about 750W and the UPS handle the load without problem, if I stop the AC the ups switch on battery and I have the time to poweroff the PC. With Far Cry Primal benchmark at 800W both BR1500GI shutdown with F02 error with long beep. I need to power off and power on the UPS to stop the beep. This on both Enermax Platimax 850W and Corsair AX860i. APC home unit are cheap overpriced crappy products."</post>
   <post id="74a24019-e2d7-4793-88fa-00a39ec65f0b" section="Power Supplies" discussion="APC, overpriced cheap products.">"nope. they do have pretty good stuff, and next to CyberPower (ups) one of the only brands i would consider getting. the problem is, most UPS are not producing a "real" sinus signal, which is needed for (pc) psu s. try the CyberPower 1500PFC or GX1325 and you will see."</post>
   <post id="94bfc65d-3a87-4515-9b48-f1c5b0337c36" section="Power Supplies" discussion="APC, overpriced cheap products.">"So you main issue is that your 865w rated UPS can t handle a continuous 800w load? Looks like you cut the overhead really close and got burned. I ll keep using APC but thanks for the laugh."</post>
   <post id="a20ffd8c-8f25-4e7d-bdf3-0754cf226a9a" section="Power Supplies" discussion="APC, overpriced cheap products.">"still, 800 isnt 850/865 and thats what the ups is rated for, so it needs to do that without trouble. independent from that, i still would swap them out for cyberpower (real) sinus wave ups, or you will throw out the PSU s pretty soon."</post>
   <post id="7bf36b82-f747-43ca-9ad2-610e13724808" section="Power Supplies" discussion="APC, overpriced cheap products.">"Ocellaris said: ↑ So you main issue is that your 865w rated UPS can t handle a continuous 800w load? Looks like you cut the overhead really close and got burned. I ll keep using APC but thanks for the laugh. Click to expand... Continuos is not the right word. I would be happy to have 1 minute or less of time to shut down my PC if an outage occurs during load (800W). On offical specs is written that this things should handle up to 865W for four minutes. By BR1500GI can t handle 800W neither for one seconds, it simply shut down instantly if the load is near 800W."</post>
   <post id="e485c324-c999-4d72-bfe9-39a0f924b80b" section="Power Supplies" discussion="APC, overpriced cheap products.">"Fry178 said: ↑ or you will throw out the PSU s pretty soon. Click to expand... inaccuracies or popular beliefs, call it how you want. simulated sine wave is good for every decent PSU. I m using simulated sine wave on Active PFC PSU since the first years of the PFC and I never got a problem or seen a PSU dying."</post>
   <post id="587c544e-ac20-4be6-b93d-5d575512233e" section="Power Supplies" discussion="APC, overpriced cheap products.">"sblantipodi said: ↑ inaccuracies or popular beliefs, call it how you want. simulated sine wave is good for every decent PSU. I m using simulated sine wave on Active PFC PSU since the first years of the PFC and I never got a problem or seen a PSU dying. Click to expand... Yeah, same here... "stepped approximation" (APC s terms) or "Simulated Sinewave" (Cyberpower s terms) are both fine with modern PSUs. My desktop machine and fileserver box have both been through quite a few power outages and they re still fine today. (PSU in the fileserver box has to be going on 5-6 years old now)"</post>
   <post id="02d5fed2-0110-4e4f-91c4-7cdcfc40806d" section="Power Supplies" discussion="APC, overpriced cheap products.">"Last time I bought an APC 2200VA unit for the server room where I work, it took them 3 replacements to get me a fully functioning one. Original purchase: We had a power outage a couple months after receiving it, and the one outlet never came back up after we got power back. I did full tests on each replacement before putting them into service - every one of these had their QA pass sheet attached to them. 1st replacement: One whole bank would not power on unless it was done manually 2nd replacement: The cooling fan was faulty and very very loud 3rd replacement: It actually worked and is still in service. Never buying APC again. Too much hassle and not reliable enough. On the other hand, I have not had a single issue with ANY of the CyberPower units we have here. I have one 2200VA and a bunch of smaller ones that are used for various desktops/laptops that have to stay powered up in case of an outage."</post>
   <post id="b32412e6-6902-4125-af77-82d713442312" section="Power Supplies" discussion="APC, overpriced cheap products.">"very very disappointed from this units. it costs three times more than a cyberpower and they are even worse."</post>
   <post id="2dab2029-0d25-493f-bdad-266eee775873" section="Power Supplies" discussion="APC, overpriced cheap products.">"@ sblantipodi are you talking about running the psu on AC power (thru UPS), or the output signal when the battery provides the power? 2 different things. and, i was referring to the CP with "real" sinus wave, not the ones running simulated (then u can just get the APC). not saying they wont work, but i remember seeing tests that showed almost all of the psu s (aPFC) dying even before the warranty was over, when running on battery. i had a 750w TX that died after 3y connected to a APC UPS, while experiencing about 10-30 brown/black outs per month. my replacement worked for 5y without any issues connected to a UPS with real sinus signal, and the seasonic i got after that, is now running 3y without problems with about 20-40 brown/blackouts per month. not sure how that can be popular belief..."</post>
   <post id="fef6021c-9de3-46f9-94b8-e46f58ecfded" section="Power Supplies" discussion="APC, overpriced cheap products.">"Fry178 said: ↑ @ sblantipodi are you talking about running the psu on AC power (thru UPS), or the output signal when the battery provides the power? 2 different things. and, i was referring to the CP with "real" sinus wave, not the ones running simulated (then u can just get the APC). not saying they wont work, but i remember seeing tests that showed almost all of the psu s (aPFC) dying even before the warranty was over, when running on battery. i had a 750w TX that died after 3y connected to a APC UPS, while experiencing about 10-30 brown/black outs per month. my replacement worked for 5y without any issues connected to a UPS with real sinus signal, and the seasonic i got after that, is now running 3y without problems with about 20-40 brown/blackouts per month. not sure how that can be popular belief... Click to expand... popular beliefs, say that your PSU died for a simulated sine wave is like saying that christ died for cold."</post>
   <post id="217dc45f-57f3-48ee-b2b6-f31ddae3f0da" section="Power Supplies" discussion="APC, overpriced cheap products.">"sblantipodi said: ↑ popular beliefs, say that your PSU died for a simulated sine wave is like saying that christ died for cold. Click to expand... I will not comment on PSUs with Active PFC literally dying when fed a stepped wave, simply because luckily I haven t had one die yet. If power goes out more more than 5-10 seconds, I have clients set to shutdown ASAP and people trained to shutdown the UPS units as well. The failures I ve had were always 100% failed bad caps on the PSU s secondary (happened to about 10% in the course of 7 years). As far as UPS devices go, I ve had slow self-cooking of a few due to power outages in the night. The UPS units (Line Interactive AVR single 12V VRLA 500W real power) happily kept the sleeping monitor and the motherboards going for several hours during a weekend long outage. Noone killed me for the beeping. But I have seen an ability to generate rapid smooth sine waves both on AC (mains passthrough mode most likely) AND on battery power as listed as a requirement for warranty service on one device or two. Could have been a Corsair PSU FAQ or the FAQ of an UPS company, but that latter would probably wreck the point I m trying to make Either way the beef I personally have with  stepped wave  on battery is that you re messing with the assumptions the PSU s designer was working with whilst designing. It s a stretch to call it a simulated sine wave when it s far from it still. With a sudden (fast) step up of an amplitude, the charging of capacitors will in some cases also happen more rapidly. Please, why won t anyone think of the little relays. Also did the designer check the cap s specs for surges this big? My worst personal experience with a stepped wave PSU was with audio actually. Some mic/mixer/recorder/monitor combos wouldn t play nice on battery until I connected a  pure sine wave  UPS."</post>
   <post id="6f01708e-46c6-4aab-92b5-c2c34f791ab3" section="Power Supplies" discussion="APC, overpriced cheap products.">"I m not technician, so i ll just tell my experience as a customer. I use 2 of APC s SMART line of UPSs, the SMT 1000 (http://www.amazon.com/Smart-UPS-SMT...UTF8&amp;qid=1458317071&amp;sr=1-7&amp;keywords=APC+SMART) &amp; the SMT 750 ( http://www.amazon.com/APC-Smart-UPS...UTF8&amp;qid=1458317071&amp;sr=1-5&amp;keywords=APC+SMART ) for several months, and i m extremely pleased with the purchace. I used some other brands in the past, and i had several minor - but still frustrating-, issues with my PCs. After the UPS s replacement these issues never appeared again, so there is a very good chance that they were UPS related. The bottom line is that i ve learned my lesson well enough: I ll never again cheap out on such a critical component like the UPS is. APC s SMART line might be an expensive line, but all the issues that i faced in the past by using cheaper units never appeared again!!"</post>
   <post id="206aeaf2-648a-4203-b334-9c2939633a21" section="Power Supplies" discussion="APC, overpriced cheap products.">"I ve since moved to Cyberpower for home units."</post>
   <post id="3442f75f-1447-490e-9d20-f93da6a917c6" section="Power Supplies" discussion="APC, overpriced cheap products.">"APC s SMART line might be an expensive line Click to expand... Refurbished SMART units can be had for less than $200 shipped with brand new batteries so its not like they are that expensive if you want a server quality UPS for home usage. And they come with 2 times the battery capacity of the home units."</post>
   <post id="2fa0a4b4-1944-430c-9078-1f8d719b2fc1" section="Power Supplies" discussion="APC, overpriced cheap products.">"@sblantipodi didnt know my personal experience is popular belief. having all my psu s (running on stepped) die BEFORE the warranty was over (incl some at work) , but not after switching to ups with real sinus output, is enough for me NOT to buy stepped ones again. michalrz i normally dont run it for more than a min or two when there is a blackout (while surfing/streaming etc), but i wont lose a ranked game to extend psu life ;-)"</post>
   <post id="ff334fcd-8d9a-4620-afe9-cd63fd9a9ae6" section="Power Supplies" discussion="APC, overpriced cheap products.">"Sorry for the late reply but the explanation is simple. The inrush current of the psu trips the overload. The capacitors in the psu are depleted holding during the switch over(psu hold time is important here) so the current is much higher for a fraction of a second charging them. This will not show up on cheap watt meters as their sample time is too slow. At 800W it does not have the reserve to meet the inrush current. I always keep my ups load at 75% max of its rating and prefer 50%."</post>
   <post id="252094ea-bb92-4ea1-9ef2-221eed69d94e" section="Power Supplies" discussion="APC, overpriced cheap products.">"stormy1 said: ↑ Sorry for the late reply but the explanation is simple. The inrush current of the psu trips the overload. The capacitors in the psu are depleted holding during the switch over(psu hold time is important here) so the current is much higher for a fraction of a second charging them. This will not show up on cheap watt meters as their sample time is too slow. At 800W it does not have the reserve to meet the inrush current. I always keep my ups load at 75% max of its rating and prefer 50%. Click to expand... a product that cost 5 times a normal UPS should be over engineered and if it shows 865W on the specifications should handle a good quality PSU like the Corsair AX860i at 800W of load without a problem. if this is not the case I see no point in sending a premium for a product that does not meet even the advertied specification."</post>
   <post id="048b5380-71ba-4b55-b15b-2b1d7c0373bf" section="Power Supplies" discussion="APC, overpriced cheap products.">"In AC power there is this thing called Power Factor. It causes additional current without a change in real power (watts). Energy Star rating requires PSUs to have a power factor of at least 0.90, but non-Energy Star models have been tested with power factors as low as 0.55. This only applies to alternating current, since it has a leading/lagging component based on the inductance/capacitance of the load that DC does not have. Without a unity (1.0) power factor, a UPS (any brand, really, and applies to generators in general) not hit a Watts limit, but will hit a current limit, and force it into overload. The farther away from 1.0 you are, the lower the watts will be for a given current (or the higher the current will be for a given wattage). Here s a decent intro without getting too physicsy Power Factor Correction FAQ - AnandTech Forums"</post>
   <post id="eb10c569-1634-4ed2-9bd0-49d97e301fa5" section="Power Supplies" discussion="APC, overpriced cheap products.">"Brian_B said: ↑ In AC power there is this thing called Power Factor. It causes additional current without a change in real power (watts). Energy Star rating requires PSUs to have a power factor of at least 0.90, but non-Energy Star models have been tested with power factors as low as 0.55. This only applies to alternating current, since it has a leading/lagging component based on the inductance/capacitance of the load that DC does not have. Without a unity (1.0) power factor, a UPS (any brand, really, and applies to generators in general) not hit a Watts limit, but will hit a current limit, and force it into overload. The farther away from 1.0 you are, the lower the watts will be for a given current (or the higher the current will be for a given wattage). Here s a decent intro without getting too physicsy Power Factor Correction FAQ - AnandTech Forums Click to expand... a UPS of this price should simply work good and it doesn t. it is better a cheap cyberpower that this extremely expensive APC. APC products are crap."</post>
   <post id="eca14013-61f9-4c23-a5db-99ca7a64ea26" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"Need help deciding between these three PSU s for a new build. These are all priced at around $100, give or take $5. The specs are going to be 5820k oc ed to 4.0 - 4.2 on an EVGA X99 Micro2 matx mobo with 16GBs of DDR4 ram running at 2400. I plan on having one SSD and one HDD. The GPU will be a GTX 970 or better, single card, no OC ing. The AX760 is actually $125 up front with a $30 rebate, where as the other two are around $100 without rebate."</post>
   <post id="17cdfa7b-bce4-4ed6-9582-6c5ea04d5ece" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"All of them are very good units, whichever you choose is a solid choise. Personally, i own both the G2 750 and the AX760, and i m pleased with both of them, but between these 2 i m more satisfied with the AX760 since it is less noisy in my opinion. P.S. Also don t forget to look the Corsair RMx750. Very good PSU. I would prefer to buy the RMx instead of the G2 (But the AX760 would still be my 1st choise)."</post>
   <post id="619f22c1-4914-4b19-a594-23af6c012d1c" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"The 650 P2 is plenty enough for your build and OC. You could honestly get away with a 550w but it never hurts to have a little extra room."</post>
   <post id="1b48a6a5-d0f5-4cff-b15e-6bb009d7300b" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"All of them are very capable units. I d take the Platinum EVGA for the low upfront cost and high efficiency/low temps."</post>
   <post id="44a104a2-1b2d-4675-8498-6cf0b1245390" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"SUpernovas; either one; evGA P2 and G2 are literally some of the best PSUs you can get using Superflower; and well priced; efficiency will &gt; any corsair; I notice NO noise issues with 650 P2 I got; can t say about g2 but I also had a 550 g2, 2 best PSUs Ive ever had; Corsairs failed me too many times."</post>
   <post id="c1d94b57-8161-4888-881f-aef5636d04ef" section="Power Supplies" discussion="Help choose: SuperNova 650 P2 or SuperNova 750 G2 or AX760">"Plat EVGA &gt; Plat Corsair &gt; Gold EVGA"</post>
   <post id="66f7b386-8ace-45d4-9696-b42c4c197d5f" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"i may be in the market for a new PSU around the 1kw range, can anyone name a PSU that they ve never had any issues with? By issues I mean: fan noise (i.e being too loud, silent preferred) or coil whine ( a deal breaker) ?? I ve been looking at the 850W EVGA P2 platinum but may spring for the 1kw version if I were to go SLI."</post>
   <post id="bb438b8a-cef1-4ca7-82a4-6a5406060bd6" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"Seasonic SS-1250XM2 If you only need around 1KW, then the SS-1050XM2 should suite you just fine. Those are only "Gold", the platinum are a little bit more pricey. 900W - 1199W, 80 PLUS PLATINUM Certified, 1200W - 1499W, SeaSonic USA, Power Supplies, Power Supplies, Components - Newegg.com"</post>
   <post id="c457b71b-e377-4ede-8cde-d05391f06602" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"Seasonics tend to be the most common of high end PSUs to emit coil whine. If that is truly your concern, I would look for a Super Flower-based EVGA PSU (like the P2 you mentioned, or the G2). Most 2 GPU SLI platforms will be easily handled by a good 850 watt."</post>
   <post id="cd01a26e-497d-4452-840f-97295ff97e61" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"My current PSU is a seasonic 660xp and it whines under load so I appreciate that"</post>
   <post id="3e319a27-68ae-4111-8bdc-85fa38478e59" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"Never had a problem with coil whine with mine."</post>
   <post id="9671e0e2-b728-4aa4-af43-6487a0d48adf" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"gigatexal said: ↑ My current PSU is a seasonic 660xp and it whines under load so I appreciate that Click to expand... I don t think that there can be "coil-whine" only under load. Either "coil-whine" exists or not. If only under load you hear sound, then it s probably related with the fan operation and not a coil whine issue. But if you want another PSU, i would propose the EVGA P2 / T2 lines, or Corsair s RMx / RMi lines as the less likely lines to give you coil-whine. (*P.S.: Right now, i m using 3 Seasonic-made PSUs: The Corsair AX760, the SS Platinum660xp2 for myself &amp; the SS SnowSilent 750 for my brother, and i have zero coil-whine issues.)"</post>
   <post id="9f8c21e6-b841-4575-b426-fa46fee1b4ee" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"I suspect the whine could be from my PSU but it could very well come from my GPU (GTX Titan X)"</post>
   <post id="63d5e428-8dcb-48ce-8477-06c88a161627" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"gigatexal said: ↑ I suspect the whine could be from my PSU but it could very well come from my GPU (GTX Titan X) Click to expand... Yeah, unfortunately, the coil-whine is an issue that can be produced by a number of factors (*PSU itself, PSU affected by GPU s operation, PSU affected by UPS s operation, house s electrical facilities, etc), so noone can guarantee you a 100% "coil whine -free" PSU."</post>
   <post id="9484158e-adda-4a2c-a6af-6a391355cb53" section="Power Supplies" discussion="recommend a fully modular silent (no coil whine) psu">"Coil whine can come and go depending on the load, so what gigatexel said is possible."</post>
<post id="491f3f3e-5daf-4fdd-96f2-7aceea527f41" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"Member List To Date: http://www.hardforum.com/showpost.php?p=1029104803&amp;postcount=178"</post>
   <post id="07b1e960-8777-4540-9fbd-d2249e5ca2d7" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"i ll join"</post>
   <post id="555964a8-88d0-46e1-aec3-696e53a6e5ea" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"Me and My ARIA are in..."</post>
   <post id="bc97f250-f225-4b96-a12a-8be43b5b974d" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"Can I be in the club? I mean, is a SN25P considered a SFF? Many don t consider ithe XQ-Pack to be a small form factor, so where do we draw the limits?"</post>
   <post id="22a1c90e-7acc-4770-908b-070e1fda439c" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"mATX cases is the cut-off I am guessing... If so, my SG01 and I are in."</post>
   <post id="206e97be-ae01-42c7-9dd7-00e20260f3ec" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"I get to be treasury...since I am an accountant"</post>
   <post id="84746266-6aa8-4ec6-ae13-60f0e79f1c9d" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"matx and down are considered sff put it in your sig if your a member"</post>
   <post id="14d306cc-f224-484d-b027-342fe793be46" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"im rockin an aspire x-q it is most definatly SFF"</post>
   <post id="027093eb-0b6b-4203-8497-78ae789fea6f" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"sff is the bestestststst"</post>
   <post id="50f12c1f-0dd7-49d1-8bbe-34bc83d1d449" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"I ll head up the badass oced SN95G5 division!"</post>
   <post id="771d1984-4447-478b-aa5d-2b6992fdf29b" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"Can i be in it even though i sold mine, but I still tend to the mATX mobos sticky cause I love ya guys"</post>
   <post id="76030539-5ecd-4ccc-865e-96354aae70c8" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"no because you are part of the "my 775 beats your 939" club."</post>
   <post id="bde91e2e-1e69-4b0b-b5d8-eb8067bfbc96" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"I am Director of all that is [H] about SFF s"</post>
   <post id="7c3ff0ee-9459-491a-89ad-7217ff80154a" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"I am president because I started it make sure to put "sff club" in your sig"</post>
   <post id="4e6c33cc-4144-4a20-bfb3-6e29dc23b101" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"wonders if girls are allowed to join this club? wonders if case i built is small enough? hugs Jen"</post>
   <post id="216a4f96-b1f6-4200-a7c7-3fcd1ee8a7ce" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"of course girls can join"</post>
   <post id="9aff5890-a1b2-43f1-9ed5-6ac69f1b65df" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"sorry for double post but this is now a sticky woot woot"</post>
   <post id="df9cb582-a3de-4a11-9867-02f8af4dd0b1" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"Steeeeve said: no because you are part of the "my 775 beats your 939" club. Click to expand... lol, you can double-club."</post>
   <post id="ff59d443-b7d8-4dbd-8b10-cca5e230052c" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"you can...but you know in your heart that this is your favorite"</post>
   <post id="dcf99c6c-4252-4519-a047-e539c10d2c00" section="Small Form Factor Systems" discussion="[H]ard Sff Club">"I have the board, but I have to build my case. Until then I will mark myself as a SFF Pledgie."</post>
   <post id="2ec1bd03-b382-4638-b1a2-fd348409edc8" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"Since we re getting a lot of questions recently about building SFF systems, I figured I d adapt the General Hardware sticky thread for the SFF arena. Please cut and paste the below questions and your answers into any new thread asking for design and building advice, part lists, etc... 1. What will you be doing with this PC? Gaming, Photoshop (or other intensive programs), Web browsing, strictly HTPC/Playback, etc. (If you have multiple things you want to do with the system, make sure you rank them from most important to least important). 2. Will you be overclocking? (If so, are you looking to watercool?) 3. What s your budget? Are tax and shipping included in this budget? Is your budget flexible? Is cost a driving factor in component selection? 4. Where do you live? Do you have any big B&amp;M (brick and mortar) computer chains nearby (e.g. Microcenter, Fry s, etc)? 5. What exact parts do you need for that budget? CPU, RAM, case, etc. The word "Everything" is not a valid answer. Please list out all the parts you ll need (especially if you will need 3.5" hard drives or expansion cards as these may restrict case options). 6. If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. For reused parts, list brands, model #s, and, if applicable, firmware revisions. 7. What specific features do you need in a motherboard? RAID? Thunderbolt? Crossfire or SLI support? How many USB 3.0 and SATA 6Gb/s? etc. Which is more important, size of the system or having the particular feature? Make sure you indicate *required* vs. *wanted* for each feature you list. 8. What resolution output do you need? 4k playback, 1080p playback, etc for HTPC or give a vertical/horizontal resolution for gaming SFF rigs. Do you need multiple monitor output? 9. Does this system need to fit into a particular space and do you need an optical drive? Think entertainment center shelves, closet space, rackmount, etc. Many modern SFF cases have either removed the optical drive or have been constructed so that removing the ODD increases the configuration possibilities immensely. 10. How comfortable are you with custom case design/modification and electrical wiring? What tools do you have (Screwdrivers/Leatherman, Drill, Dremel, Metal snips, Soldering Iron, Bending Brake, CNC/Welding machines/Plasma cutter, etc...)? 11. How important is the noise/silence of this sytem? HTPCs typically want to be quiet while all-out SFF gaming rigs don t care 12. How mobile does this system need to be? Need a carrying handle or carrying straps? Is weight important (carry-on bag, etc)? Water cooling quick disconnects, etc? 13. Do you already have a legit and reusable/transferable OS key/license? If yes, what OS? Is it 32bit or 64bit? Remember that OEM copies of Win7 have issues with new motherboards 14. When do you plan on building/buying the PC? Immediately, in a couple weeks, 3-5 years? By answering these questions you help us help you build a PC that s of better quality, better performing, cheaper or all of the above. The more details the better responses you will get."</post>
   <post id="1eb27dfb-5cc2-437e-a508-425acb2457f2" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"fuu, didn t realize i was in this thread still"</post>
   <post id="3cb9dd21-39bd-4f14-8764-0364b2b9c766" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"I would like to "officially" add one item to this list. 15. Do you need an internal optical drive. The reason is that SFF cases are just about the only ones that have done away with ODD bays in some models, and it can be one way to make a system even smaller."</post>
   <post id="7ccd6eec-1842-48af-a261-bee55d911ce7" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"Zap said: ↑ I would like to "officially" add one item to this list. 15. Do you need an internal optical drive. The reason is that SFF cases are just about the only ones that have done away with ODD bays in some models, and it can be one way to make a system even smaller. Click to expand... Very good point! I will definitely be glad to see spinners go the way of the Dodo I added your question to #9 as it really ties into the size/configuration of the cases available (also trying to keep the # of questions from expanding, lol) Thanks!"</post>
   <post id="b815959f-62eb-43b1-9b0c-69c1ecabfa35" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"Two other important questions I always ask since some SFF cases have room for these and some do not. - Do you need to use a 3.5" hard drive - Do you need an expansion slot (like say for a wireless card or video card) This is probably implied in #5 but these two things make a huge difference in which case whereas some other parts might not."</post>
   <post id="69913a3a-6fd8-4af0-bcca-91a400510e36" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"1. What will you be doing with this PC? Gaming, Photoshop (or other intensive programs), Web browsing, strictly HTPC/Playback, etc. (If you have multiple things you want to do with the system, make sure you rank them from most important to least important). 90% of the time is Web Browsing/Email the other 10% Quickens / MS Office / Burning DVD s. I don t play games on the PC anymore. That is what the Xbox if for. 2. Will you be overclocking? (If so, are you looking to watercool?)NO 3. What s your budget? Are tax and shipping included in this budget? Is your budget flexible? Is cost a driving factor in component selection?Budget is flexible. Want to spend wisely but not a deal breaker 4. Where do you live? Do you have any big B&amp;M (brick and mortar) computer chains nearby (e.g. Microcenter, Fry s, etc)?Fry s about 20 miles away along with Best Buy s 5. What exact parts do you need for that budget? CPU, RAM, case, etc. The word "Everything" is not a valid answer. Please list out all the parts you ll need (especially if you will need 3.5" hard drives or expansion cards as these may restrict case options).Starting from the beginning again I do have a pair of WD Black 640GB drives and a external Seagate 2 TB USB2 connection I can hook up. I thought about buyig a 2 bay to house the 2 WD Black drives. So I need Case CPU RAM MOBO cables Power Supply. OH and I have a external DVD/CD drive that is a USB2 connection for burning disks and loading software 6. If reusing any parts, what parts will you be reusing? Please be especially specific about the power supply. For reused parts, list brands, model #s, and, if applicable, firmware revisions.Listed under #5 7. What specific features do you need in a motherboard? RAID? Thunderbolt? Crossfire or SLI support? How many USB 3.0 and SATA 6Gb/s? etc. Which is more important, size of the system or having the particular feature? Make sure you indicate *required* vs. *wanted* for each feature you list.RAID for my data drives (WD Black 640 GB drives) at least 1 USB 3.0. I thought I could hook a USB 3.0 hub to that and run multiple external drives from the hub. HONESTLY NOTHING IS REQUIRED. i M TRYING TO UPDATE TECH FROM A 6 YEAR OLD MACHINE THAT IS STARTING TO HAVE ISSUES. I WOULD LIKE SMALLER THEN MY MID TOWER I HAVE NOW. MAYBE LESS NOISE. OH REQUIRED I WANT MY OS TO SET ON A SSD AND EVERYTHING IN DATA DRIVESRequired **WIFI** In case I move this PC away from the cable modem/router 8. What resolution output do you need? 4k playback, 1080p playback, etc for HTPC or give a vertical/horizontal resolution for gaming SFF rigs. Do you need multiple monitor output? I have a 24" monitor that is 1920x1200 9. Does this system need to fit into a particular space and do you need an optical drive? Think entertainment center shelves, closet space, rackmount, etc. Many modern SFF cases have either removed the optical drive or have been constructed so that removing the ODD increases the configuration possibilities immensely.I have beed reading a little about NUC systems and that would be nice to mount VESA to the back of my monitor. But really want to get away from the Mid Tower I have now. So NUC is not a requirement 10. How comfortable are you with custom case design/modification and electrical wiring? What tools do you have (Screwdrivers/Leatherman, Drill, Dremel, Metal snips, Soldering Iron, Bending Brake, CNC/Welding machines/Plasma cutter, etc...)?I have put together my last 2 computers but I m not a handyman so building from a kit is doable. But from scratch I m not into. 11. How important is the noise/silence of this sytem? HTPCs typically want to be quiet while all-out SFF gaming rigs don t care Quieter is better. I will not be gaming 12. How mobile does this system need to be? Need a carrying handle or carrying straps? Is weight important (carry-on bag, etc)? Water cooling quick disconnects, etc?System will not be moved around. I have a desk. I just want to reduce footprint. 13. Do you already have a legit and reusable/transferable OS key/license? If yes, what OS? Is it 32bit or 64bit? Remember that OEM copies of Win7 have issues with new motherboards WIN7 Enterprise 64bit 14. When do you plan on building/buying the PC? Immediately, in a couple weeks, 3-5 years? I would like to do this around the Black Friday time frame when computer parts are at their lowest Thank you to anyone that takes time out of their day to help me. About every 6-8 years I try to "catch up" with tech knowledge to make a educated buy/build BUT then I forget it all next time I have to buy another PC. Thanks for your help!"</post>
   <post id="f1db3f48-d24f-4af3-8a50-f5d875132583" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"Machupo said: ↑ Please cut and paste the below questions and your answers into any new thread asking for design and building advice, part lists, etc... Click to expand... This sticky is itself not for asking, only advice on how to ask."</post>
   <post id="bac683f8-1504-40a6-a181-559640b860f6" section="Small Form Factor Systems" discussion="So you want help designing/building a SFF system?">"OOPS. Starting a new thread."</post>
   <post id="044970e1-8e28-4c1b-ab85-ebfa37e27399" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Apparently pigs can fly and hell has frozen over. Copy-paste of the article, credit goes to Ian Cutress from Anandtech: 1ST REVIEW: http://www.techspot.com/review/992-asrock-x99e-itx-ac/ ASRock to Debut mini-ITX Haswell-E at CeBIT: X99E-ITX/ac with USB 3.1 I always love to see interesting deviations to the norm when it comes to motherboards, and something such as a mini-ITX based extreme system has been at the top of my list for many years. We never saw a mini-ITX X79 system (the nearest was an extended mini-ITX from Shuttle) but now ASRock has gone head first into the X99 plus mini-ITX arena, showing their first model at CeBIT later this month. The reason for mini-ITX on the extreme platform is usually for density, though there are a couple of compromises that have to be made. The socket is large, and supporting quad channel memory can be a challenge with SATA ports and 40 PCIe lanes in tow. As a result, ASRock&amp;#8217;s X99E-ITX/ac only uses dual channel memory, and we get a single PCIe 3.0 x16 slot for add-in cards. There is bundled dual-stream 802.11ac wifi, along with dual Intel network controllers and SATA Express. USB 3.1 is also supported through two Type-A ports, presumably using the ASMedia controller we previously tested on other motherboards. The box also mentions Ultra M.2, which means PCIe 3.0 x4 lanes for an M.2 slot and looking at the board it seems to be located between the socket and the SATA Express ports. With all those PCIe lanes to spare, it makes sense to use them in this fashion. In order to save space, ASRock has used the narrow version of the LGA2011-3 socket (many thanks to liu_d for the spot), which we saw in the our MD60-SC0 review. This narrow socket is incompatible with regular LGA2011-3 coolers, and the number of narrow-ILM CPU coolers on the market is usually limited to servers or OEMs. It would also seem that ASRock is bundling a CPU cooler with the board in order to ensure this is not an issue for the user &amp;#8211; this looks like a 2U server cooler, but should be sufficient for 140W CPUs as long as no serious overclocking takes place. These coolers can be loud, but ASRock&amp;#8217;s software package comes with fan controller tools both in the BIOS and in software. Pricing and release dates are not yet announced, but we will get one in for review as soon as we can. The dual channel memory restriction hopefully does not become too severe for performance, but we will run a full range of real world tests to confirm this. Source: ASRock"</post>
   <post id="93aaf449-24bf-4ae6-9d3f-0cc959fcc259" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Oh my god! Unless someone comes out with a Skylake-E Mini-ITX with 4 SODIMMs, this is so going into my future A4-SFX"</post>
   <post id="98e1358d-fb11-4d67-90a2-aa9c257cadc0" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"It s nice that some company did it, maybe others will follow but I already see few problems with it. Different than standard cooler mount is one, but there s also those sata connectors facing side of the board that won t be usable if the case hase a wall next to the motherboard like almost every its with PSU in front or the ones limited to short ITX cards. Second thing is - I wonder if they could fit more ram with something like using SO-DIMM modules instead or using vertical "add-in" like card for mounting the RAM modules."</post>
   <post id="57c97d87-a03c-4d1d-866b-0530c3ea8749" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Wow, never thought we would see something like this! Unfortunately it doesn t look like that cooler that ships with this would fit in the A4 SFX. Anyone know of any low profile lga2011 coolers that would fit with the narrow socket here and the a4?"</post>
   <post id="c9782b86-d974-4d25-958d-70f1923981cb" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"SaperPL said: ↑ Second thing is - I wonder if they could fit more ram with something like using SO-DIMM modules instead or using vertical "add-in" like card for mounting the RAM modules. Click to expand... I think the problem with SO-DIMMs is there aren t any DDR4 ones widely available yet, otherwise, with vertical SO-DIMM sockets they could have probably put 4 on there."</post>
   <post id="fde87ec7-5229-423c-9cc1-af96d0867cc8" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Holy crap what a beast of a board Not only that the M.2 port has 4 lanes, but they also included USB3.1 and SATAe, this thing is top-notch. I wonder if ASUS will follow up with an X99 mITX board themselves. Do we know how many PCIe lanes the SATAe port has?"</post>
   <post id="ec0f69f4-49b2-461b-843b-bf85b3d394db" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"It looks to me like this cooler is about 45-48mm tall. That might fit into my case but fitting is not the same thing as cooling properly. Even if it did fit into A4, it would have the same problem with PSU wall blocking the fan. By the way it would be nice if someone made a single PCI-E slot mATX board with X99 and 8 memory slots"</post>
   <post id="e8b994c8-f1c8-47a5-b98b-ca8a158e4253" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"The Noctua NH-U12DX i4, NH-U9DX i4, and NH-D9DX 3U will fit this board! ("</post>
   <post id="b928aeae-6d8d-44b9-8ab9-45d3eba7ce72" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Curiositie said: ↑ The Noctua NH-U12DX i4, NH-U9DX i4, and NH-D9DX 3U will fit this board! ) Click to expand... Which is nice for users of a little bit larger SFF cases, but for the A4, you d probably have to get one of these: https://www.supermicro.com/manuals/brochure/x10_HeatSink_Compatibility.pdf (search for "Narrow ILM") and mod a fan on top of it."</post>
   <post id="b34ad0db-c2dc-4c80-9885-dd55c2910a01" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Let s crowd fund an A4-X99NarrowILM CPU cooler"</post>
   <post id="f352419d-010c-4a6f-97cb-06f0929475f4" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Man, that s an awesome board! I wish it did support quad channel, though.... Kind of a major advantage to 2011 v3(and what I was seeking in former 2011/1366 board - 3+ channel memory). Would anybody consider external fans and a 1U/2U solid copper cooling solution?"</post>
   <post id="a038aded-3ca4-4928-85fc-942714863d24" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"What would go nice with this board is a compatible AIO liquid cooler. In any case, I applaud ASROCK for not sitting on their hands. They showed it was doable, unlike ASUS who kept saying impossible. Now to top this, another manufacturer would have to come up with a quad channel board. If anyone says "impossible" I ll slap them with this board"</post>
   <post id="ffd710c8-01f7-490f-8113-167a9a022cc8" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"I think quad channel is completely doable if the chipset were to go in the backpanel IO area. The cost would probably be in routing those signals from the chipset to pci-e around the ram slots and maybe additional pcb internal layer."</post>
   <post id="156fddfa-5c53-4a6c-806a-99d476a837e6" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"SaperPL said: ↑ I think quad channel is completely doable if the chipset were to go in the backpanel IO area. The cost would probably be in routing those signals from the chipset to pci-e around the ram slots and maybe additional pcb internal layer. Click to expand... Are you suggesting behind the audio ports? This board looks pretty tight!"</post>
   <post id="2eb3c187-fbc9-4739-aa3c-a54e2f6e969a" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"For liquid cooling, the ekwb supremacy with 2011 narrow ILM plate may fit. this may be an option for the Ncase M1. Then again, you have to have a cooling loop with a dedicated pump... I wonder if there are any pump/cpu-block-combos compatible with 2011-3 narrow ILM out there..."</post>
   <post id="fc0197aa-dc5d-421a-8516-c598574bc4be" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"An adapter plate for existing standard CLC blocks to narrow ILM should not be too tricky to create. AMD s mounting hole dimensions are close to narrow ILM (48x96 vs 56x94) that the zip-tie mounting method may work too."</post>
   <post id="9c81b87e-b090-4609-ad3b-2651f41f4717" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"I bought an M1 v2 last summer, and still haven t had time to decide the exact components for the build. I was nearly done with the choice though, but with the asrock x99 mitx a new competitor has stepped in... A 5820k in a mini itx build would be pretty sick though, especially in a complete water cooling loop with a gpu integrated. But even if the apogee or h220 could be made to fit the narrow 2011-3, the limitation may finally be that 240mm Radiator. Not sure if it would provide enough cooling surface to cool down 350+ W of TDP, as would be with an overclocked gtx 980 + i7-5820k..."</post>
   <post id="2ef4cd3e-cb8c-4692-9847-9ecc9779fc40" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Black5Lion said: ↑ Let s crowd fund an A4-X99NarrowILM CPU cooler Click to expand... No need because you can use a 1U Server heatsink with Narrow ILM (a socket-mounting standard) mointpoint (like many Dynatrons and supermicro Heatsinks have) and it will fit. Then you install a Noctua A9x14 on it and you can use it on the board in the DAN A4-SFX. This will results in Systems like: DAN A4-SFX Octacore Xeon or I7 Nvidia TITAN X ASRock X99E-itx/ac 16GB DDR4 ..."</post>
   <post id="a7465503-437f-44ab-990f-c72b28812069" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Asrock currently has one 16GB DDR4 module in their compatibility list for both their X99 mATX boards, and at ~$200 it s not outrageously priced compared to 8GB DDR4 modules (both RDIMM and UDIMM): http://www.newegg.com/Product/Product.aspx?Item=N82E16820147382 So this bodes well for those that want a high-end 32GB ITX system."</post>
   <post id="e21b5f4f-4696-498a-9920-60be9f7b2c8f" section="Small Form Factor Systems" discussion="X99 on mITX: ASRock X99E-itx/ac">"Does the asrock x99 itx support ECC ram?"</post>
   <post id="a1c45243-1df8-4dd2-a8a6-c35122d4c585" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"Introduction The A4-SFX case is a one-man project with the goal of creating the smallest case possible while still using high-end standardized components, such as Core i7 processors and powerful full-length GPUs such as the GeForce GTX 980 Ti. The result is a unique product that is much smaller than all competing cases. This case is perfect for SFF (Small Form Factor) enthusiasts, those who need a highly portable system, developers who require a case with a smaller footprint due to limited desk space, and gamers who want a high-end PC experience in their living room. How it works A number of creative ideas were needed to create the case. Using a PCIe extender allowed for the most prominent design feature of this case, which is the location of the GPU behind the motherboard. The A4-SFX will come with the highest quality PCIe extender on the market, made by 3M, which allows for PCIe Gen3 and Gen4 support. The case allows for easy mounting of either SFX or SFX-L power supplies. The PSU is located in the front of the chassis. Depending on the size of the PSU, up to two 2.5&amp;#8221; HDDs or SSDs can be mounted in the drive bay. This drive bay could potentially be mounted with rubber spacers to reduce vibration. A third drive can be mounted behind the front cover. Every component is able to cool itself by getting fresh air directly from the outside. Hot air in the case will move to the top and then outside without the need of an extra fan. This principle works perfect and results in an amazing cooling efficiency compare to other cases. Specification Case Dimensions (H x W x D): 200 x 112 x 317mm, 7.25L Overall Dimensions: 205 x 112 x 327mm (including feet and rear protrusions) Weight: 1,25 Kg Graphic cards support: Dual-Slot up to 295mm length Motherboard support: Mini-ITX Power Supply support: SFX, SFX-L Drives: 3 x 2.5" HDD/SSD Front ports: 1 x USB 3.0 (internal 20pin plug) Power button: Premium-grade button Material: 1.5mm aluminum, brushed exterior Sidepanels: Easily clippable with Lian Li Push Pin technology Colors: Anodized black or silver exterior, matte black painted interior Risercard: Includes the 3M Twin Axial 300mm riser cable PCIe Gen3+ support, Link: 3M product page Gallery Download (click on Image for view) News 30.08.2015 DAN Cases is online: www.dan-cases.com 08.07.2015 Professional pictures of the A4-SFX were made. Many thanks to Torsten Paris! 09.06.2015 DAN A4-SFX cooling performance: Spoiler: Cooling Introduction: Below, I want to inform you about the cooling performance of the DAN A4-SFX, because many potential buyers are sceptical that powerful hardware can be cooled in this case. Also, the test should determine which CPU coolers with a maximum installation height of 48mm is suitable for this case. Many readers are also interested in: How a Top-Blow cooler graphics card will perform in this case. This question is intended to clarify as well. Testsystem: The following hardware has been used for the results: CPU: Intel Xeon 1230v2 3,5Ghz TPD 69W (Ivy Bridge) GPU1: Nvidia Geforce GTX 780 reference design GPU2: MSI Geforce GTX 970 Gaming 4G The hardware was tested in an open build (without case) and inside the case at a room temperature of 21-22°C. The fan speed is the same in both setups. All tests inside the case were made with the sidepanel Version 1, which will be used for the final product. This Version offers the better look and allows the same cooling performance as Version 2. CPU Cooling: As already mentioned, the maximum installation height incl. fan is only 48mm. This measurement refers from the top of the CPU to the sidepanel. Therefore the selection of suitable coolers is very limited. For the tests I also used coolers, higher than 48mm, which fit while using a thinner fan. Now I would like to introduce the test candidates. Intel Boxed cooler: The Intel Boxed cooler is probably the most famous cooler at all. Every boxed Intel CPU includes this cooler. With an height of 47mm it fits perfectly in the case. However this coolers is not very popular, because of his bad cooling performance. Noctua L9i: The L9i is one of the smallest cooler in this test. With a height of just 37mm incl. fan, it is truly tiny. The cooler includes the Noctua A9x14 fan, which is also available without the heatsink. But the rotation speed is different for the standalone version. The L9i version offers 2500rpm and the standalone version 2200rpm. Therefore I use the 2200rpm version in the test. Due to the low height of the cooler, it can also be operated with a 25mm thick fan inside the case. So the L9i was also tested with the NF A9 PWM. Silverstone Argon SST-AR05: The AR05 is the smallest cooler in the test. Directly attached heatpipes to the CPU heatspreader are special for this cooler. This cooler was also tested with the NF A9 PWM. Cooltek LP53: With the default height of 53mm the LP53 wouldn t fit inside the case. But if you switch the f an with an thinner version like the A9x14 it fits. However the mounting of at thin 92mm FAN must be performed with cable ties, because the default 92mm fan has mounting points of an 80mm fan. As a special highlight I m going to test this cooler with the Thermalright TR-Y100, which is the default fan of the AXP100 Cooler. Whats special of this fan are the dimensions of 100x100x15mm and the increased air pressure towards to the A9x14. Xigmatek Janus: Even the Janus does not fit without adjustments on it, because with its 60mm it would actually be too high. If you unscrew the 120mm top fan and change the lower 80mm fan to the Noctua A9x14, Thermalright TR-Y100 or Scythe SY1012SL12M the cooler fits. The lower fan was mounting in priming position through the upper heatsink. Mounting it the other way results in 10°C higher temperatures. Phanteks PH-TC12LS: The last test sample is the PH-TC12LS. With it s 72mm this cooler is too hight as well, but after unscrewing the top fan it fits. You can mount a Scythe SY1012SL12M (12mm) between the top fins and the lower heatplate. CPU cooler test scenario: The following tables are showing the test results in idle and under full load. The fan speed is fixed to 100% with Speedfan for all tests, to show you the best possible values. Of course, under you can setup the fan speed to 30% for low usageand you will never reach 45°C. For the idle test, the temperatures of all four cores without load were noted after 20 minutes on the desktop. The average value was insert into the table. In load mode, the system is operating in Prime95 20min in 8K test. The 8K test produced the highest temperatures on the cores. ATTENTION: The temperature values in Prime95 8K are not comparable to those in games or processor-intensive applications, since Prime achieved a 15% higher CPU temperature as other applications. Overvolting and Undervolting: The next test should demonstrate what is possible by using the Cooltek LP53. Therefore, Prime has been tested both in undervolted and in overvolted state. A normal Ivybridge could reach the 4,2-4,5Ghz stable with 1,2V voltage. As you can see normal overclocking could be possible with the right cooler in this case. Or you can lower the noise level under load y undervolting the CPU. Graphics card cooling: Another important part of this test are the results of cooling graphic cards in this case. Especially the comparison between radial cooler and top blow cards is important. Info: Radial cooler cards blow the air out through the slot bracket from the housing. Whereas Top-Blow cards blow the air directly on the heatsink and and the air escapes mostly upper and lower side of the card. Only a very small part of the air escapes through the slot bracket. For the test I use a Nvidia GTX 780 in the radial cooler design and a MSI GTX 970 Gaming G4 in top-blow design. Graphics card test scenario: Such as the CPU cooler, the graphics cards were tested in idle and load mode. The fan speed was fixed to 30% under idle and 60% under load for both cards. The speeds was fixed with the tool MSI Afterburner. In the idle mode, both cards was very silent (subjective value). At a speed of 60%, the GTX970 was still silent, but you are able to hear the GTX780. For the measurement results, the cards were tested in 3D Mark Test Firestrike demo for 20min and 20min in idle on the desktop. The 3DMark test ran in continuous loop and the temperatures were recorded with the Tool MSI Afterburner. Case efficiency: The final test was to prove the housing efficiency. The efficiency is the overall avarage temperature difference between an open body usage and usage inside the case. Noise level: Finally, I want to say something about the noise level of the components inside the case. Of course, these results are subjective, so everybody will percipience it different. In idle and low usage mode (office, browsing or watching movies) each CPU can be cooled very silent. Under load you will hear the CPU cooler while testing with Prime95. But under normal load usage in games like GTA5 or high load applications like rendering tools you can set the fan speed to 60%. In this setup the cooler is far from being realy disturbing. By the time the game is starting with a normal volume, you can t hear nearly all coolers in the test. Under normal usage and with a fan speed of 30% both cards are very silent. Only while playing games or running benchmarks with a fan speed of 60% the MSI card is still quiet, but the GTX780 is definitely hearable. Final words: I hope I was able to convince even the last sceptics with this test, that it is possible to cool hardware from the impact of an NVIDIA Titanium X and an i7 4790K / 5775C in the DAN A4 SFX. However the remarkable thing about this case is the cooling efficiency. It can accumulate air at any point and every component works cool technically self-sufficient without an the need of case fans. Hot air rises and can escape directly over the top ventilation holes. All fans of the components blow into the case to provide pressure and promote a faster escape of the heated air over the top. Thank you for reading my test. I will be back soon with many professional made product pictures. [/FONT][/SIZE] 05.2015 Prototype from Lian Li arrived FAQ When will this be released? How can I buy one? In the 1st quarter 2016 on Kickstarter or Startnext. How much will it cost? 230€ + shipping + tax (depending on where you are located) It is possible to get the case with dust filters? No they are not included, but I will try to make them buyable with Demiflex. Why does it only have one USB 3.0 port on the front? After much discussion, I have decided that one port is enough for most users as having more ports on such a small case will hurt the aesthetics of the case. Where do you ship? Worldwide Does the case includes a manual? Yes, every case includes a manual paper in two languages (German &amp; English). How do you ensure that the backside of the GPU does not make contact with the metal motherboard tray and SFX PSU? The motherboard tray and PSU will have a non-conductive shield attached in order to ensure that the back of the GPU does not come into contact with bare metal."</post>
   <post id="db4ed9c4-d76b-4636-868b-6c5f681c4f69" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"p-p-put your pixels in it. (all links go to thumbs and not bacon!)"</post>
   <post id="36dfd62e-b586-4e74-ac3b-5954f3c82a0f" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"I like it."</post>
   <post id="b9cb13f1-df1f-48a0-9b25-4ed0d92a40ff" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"Remarkably similar to an idea I got some help with here http://hardforum.com/showpost.php?p=1040424470&amp;postcount=41 I knew I couldn t be the only one with this idea Can you really power a 780 or r9 on only 380w? How does the riser cable work for you? Insulation or supports between the MB and GPU? Maybe squeeze in or mount externally some 92mm rads? I am so excite!"</post>
   <post id="3248caee-95de-4799-b998-6d8edd0412d4" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"Looks pretty slick! But holy crap dude, host your pics someplace else. I don t even want to click through the pictures from all the popups and crap that come up. Lame!"</post>
   <post id="2ae4bb37-9a5c-4a72-a48f-9e9eea8d3570" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"I would love one of these! My friend and I are building a case very similar to yours, but we re using a regular SFX PSU, which makes makes it wider (positive if someone wants more space for HDD/SSD/ODD). We ve never thought about using a dc-dc powerboard. Holy smokes. That Pico-Box X7-ATX-400 is $999!"</post>
   <post id="4cd73688-f671-4d76-9d16-d1c14cbeaf0c" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"The price is only so high because pico-box-factory has no x7 in stock. The normal price is 80$"</post>
   <post id="b66b29db-f2ab-4905-af81-a6f0c49cacb1" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"DrakonSan said: ↑ Remarkably similar to an idea I got some help with here http://hardforum.com/showpost.php?p=1040424470&amp;postcount=41 I knew I couldn t be the only one with this idea Click to expand... nope, not the only one. I saw something similar in this topic here http://www.techpowerup.com/forums/threads/titan-itx-status-placeholder.156077/page-2#post-2527068 i never thought it would be possible to actually see something a reality though b/c it would be hard to  fold  the video card underneath w/o some custom parts"</post>
   <post id="be4b4837-c1be-4993-b956-3637b41ed4fb" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"CMadki4 said: ↑ Looks pretty slick! But holy crap dude, host your pics someplace else. I don t even want to click through the pictures from all the popups and crap that come up. Lame! Click to expand... At the end of the article i add a spoiler with all pictures in full size. By the way: You can use google-translate to translate the german review about the dc-dc-powerboards. Maybe i translate and puplish it in this forum. But my english istnt the best."</post>
   <post id="5c2c93b4-2bf5-458b-8501-222363e3327b" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"dondan said: ↑ At the end of the article i add a spoiler with all pictures in full size. Click to expand... Awesome! I really like the old and new layouts. Looking forward to the prototype of the new folded design!"</post>
   <post id="6f9a4931-ebf5-491f-8548-0426f01abc7b" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"I think that $999 is a misprint. The transaction history shows $80 a piece. US $80.00 x 3 pieces. And the reviews on it, also say $80 a piece. i would say $80 would be about right. The 200W one is $29-31."</post>
   <post id="b1f09c80-8fbf-4808-9cd7-c2760d86321a" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"marka211 said: ↑ I think that $999 is a misprint. The transaction history shows $80 a piece. US $80.00 x 3 pieces. And the reviews on it, also say $80 a piece. i would say $80 would be about right. The 200W one is $29-31. Click to expand... Dondan is correct about the $999 being there only as an indicator of being out of stock. I came across their page a few months ago and noticed the same price discrepancies. I messaged them and they confirmed that that is what they do."</post>
   <post id="a335fee7-1581-44fd-8422-b44f5abe163c" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"CMadki4 said: ↑ Awesome! I really like the old and new layouts. Looking forward to the prototype of the new folded design! Click to expand... I attached some more pictures of the old one in the last spoiler."</post>
   <post id="8e5bc06a-d1b0-4ef5-86fb-159c386c6999" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"pretty slick! I think it would look much better with no front usb ports tho. I mean you could have 6 on the back and if you need more you could always get a hub."</post>
   <post id="edc8704c-69df-4517-b3c0-683dd168730e" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"I thought about this too, because i also like a clean front without any ports, but most of the customers want a usb port."</post>
   <post id="9ea0e815-dd4d-460f-a40d-69453c1e27ac" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"dondan said: ↑ I thought about this too, because i also like a clean front without any ports, but most of the customers want a usb port. Click to expand... Agreed. The ports won t actually show up that much on a black case. Besides, depending on your application, a USB dongle for your keyboard/mouse will get better range in the front port than on the rear and will look better than a hub. For example if you re using this case in home theater setting. Based on experimentation, it is best to have the USB dongle in the front than in the back."</post>
   <post id="9720bd60-5857-4dd3-8090-be3e5633168f" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"dondan said: ↑ I thought about this too, because i also like a clean front without any ports, but most of the customers want a usb port. Click to expand... I can t believe you put the power button on the back! I really like everything about your case! I even had the same thinking of power/frontpanel on the back (see here: http://imgur.com/a/V91KY#10) granted that is only a modified sg05, I really believe having the power button on the back is pure genius! It looks much better, no argument there. And it makes better use of space I applaud you kind sir, for you have made THE perfect case! Now we just need more powa! &gt; ps: sorry for (what I d consider) the wall of text edit: if possible maybe you could make some kind of modular front panel, so you could could swap it around (brushed aluminum solid, brushed aluminum with ports, vented brushed aluminum, solid acrylic, vented acrylic, acrylic with ports, etc...). It should allow more customization, since one can simply buy a plain front and paint it to their liking. And the option with a solid or vented front ie: no ports, should give you a little more room for the gpu. : &lt;--- never mind that I guess I wasn t looking very well."</post>
   <post id="b3f822ad-75eb-4d14-837d-16949f131cc1" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"I like it, however I would love it if you extended the depth enough to seat an sfx 450 in front of the mb and figured the airflow out. I d buy a prototype today. I need a gaming case that can fit in a flatter style backpack for when I take the motorcycle to work. Keep up the good work"</post>
   <post id="2830dd1b-8477-4af9-b7bc-2aa937660af2" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"Poser001 said: ↑ I like it, however I would love it if you extended the depth enough to seat an sfx 450 in front of the mb and figured the airflow out. I d buy a prototype today. I need a gaming case that can fit in a flatter style backpack for when I take the motorcycle to work. Keep up the good work Click to expand... I d actually like to see the project move forward with that 400w picoPSU. Something different. And if works and is stable I could see a lot of great DIY cases and new case designs based around it and the latest short 170mm graphics cards. Ultra compact power!"</post>
   <post id="8afd9a0b-0f92-4a66-83d0-de798c5a0305" section="Small Form Factor Systems" discussion="DAN A4-SFX: The smallest gaming case in the world">"Black5Lion said: ↑ edit: if possible maybe you could make some kind of modular front panel, so you could could swap it around (brushed aluminum solid, brushed aluminum with ports, vented brushed aluminum, solid acrylic, vented acrylic, acrylic with ports, etc...). It should allow more customization, since one can simply buy a plain front and paint it to their liking. And the option with a solid or vented front ie: no ports, should give you a little more room for the gpu. : &lt;--- never mind that I guess I wasn t looking very well. Click to expand... A good idear. Maybe it would be a option for the kickstarter campaign. Poser001 said: ↑ I like it, however I would love it if you extended the depth enough to seat an sfx 450 in front of the mb and figured the airflow out. I d buy a prototype today. I need a gaming case that can fit in a flatter style backpack for when I take the motorcycle to work. Keep up the good work Click to expand... Maybe in a later edition, because i want to revolutionize the psu scene with the dc-boards. They have a higher potentional than sfx because they are much smaller, running cooler and help to reduce the noise level. I think the biggest problem is that only dell have a external psu on the market with over 300W. My dc-board review shows that all dc-board can handle a 2500k clocks to 4x4,4ghz and a overclocked GTX 670 running Prime95 and 3D Mark simultaneous (380W). A combination of a default i7 4770k and default GTX 780 ti need 340W of power. So you can put the maximum of hardware in my case. Sombody can say:" how is that possible the dell can only provide 330W". This is wrong the dell shuts down after pulling more than 420W"</post>
   <post id="99f7763b-592d-4590-b65d-417a210bf76c" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"I am designing my next build (current box needs to be put to pasture). I chose a SFF build so that I can transport the PC when I fly. A lot of my flights are on smaller craft (Bombardier Q400), so it needs to be pretty compact. This build will become my primary PC and game rig (1080p primarily, but I want to have VR as an option). I have selected most of my components except for GPU and case (since I can t post links, please see PCPartPicker unique ID: sqQTwP). The GPU will be either GTX 1070 or 1080 (unless AMD reveals something amazing in TDP efficiency at month s end). The choice of case has me conflicted. I could either go with an Ncase M1 case or the Silverstone FTZ01. The Silverstone is cheaper and more likely to be easily stow-able in the limited carry-on space a small plane has, but another concern I have with this build is thermal management. I have no desire to have the processors clamp, hard drives die, or end up running games on a jet engine. Can anyone here offer insights into which case would offer better air cooling thermal mitigation? If you see any issues with the rest of component selection feel free to voice them. The processor selection is locked as is the brand of RAM and SSD. I am not willing to give up a 3.5" HDD either. The Slim ODD can be dropped, but I d rather get a 5.5" bay. At risk of stating the obvious: flying with this means it must be air cooled."</post>
   <post id="a3390bd7-61e8-4055-8d21-6ca8fede050b" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"Depending on your size restraints; and keeping in mind this chassis JUST meets the maximum size to still be (technically) considered aSFF chassis… Check out the new CaseLabs BH2 mITX chassis, not really that compact at all, but supposed to be built like a tank &amp; has dual top-mount handles available, making it more knock proof &amp; easier to wrangle using the handles…"</post>
   <post id="9142b683-68e5-4469-8f3b-b2e629483af6" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"Elaboration: reasonable dimension requirements are set by the height of the overhead bin. An airline rep claimed entrance height is 7", but I am sceptical that it is quite that small. Still close, so 7" on the smallest side is a good limit. The M1 and slim Silverstone cases seem to be the best options to achieve 7-" wide , 3.5" support, and full size GPU support. I want to know which of those two options would handler the thermal load better and why. Also any physical support issues would be nice to know since this will travel assembled."</post>
   <post id="1dec4c1e-c36d-4d6d-b6aa-4ce7ddd90dc2" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"If you want a case that can offer very good thermal performance and be transported in a plane like luggage, you should probably go for the M1 and buy a Pelican case to put it in. Phuncz is an expert on aircooling in the M1, which you should choose over water for stabilities sake. Take a look at his posts in the M1 thread, that should give you an idea of how well a GPU can be cooled in that case. The Silverstone cases are fine, but you won t be able to use as big heatsinks in them, so noise will inevitably be higher, except you re planning to use a 45W TDP CPU or something along those lines."</post>
   <post id="d6ac4e4c-3037-465b-9585-51187bc73825" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"The Ncase m1 will net you the best cooling performance. It accepts a much larger cooler height which is key to air cooling and could fit 2 240mm rads for liquid cooling. Get a slim hard case for it and you should be fine. Pelicans are nice cases but they re typically much thicker than an aluminum hard case."</post>
   <post id="fb4c4c08-73ac-4175-bece-4433ce8f19a3" section="Small Form Factor Systems" discussion="Looking for input on case selection for first SFF build">"Btw are you going with an i5 or i7? If you re going with an i5 the tdp is low enough that you don t need any major cooling and in that case I d recommend the silverstone or the node 202. An l9i or Cryorig C7 will be fine for cooling am i5, they re surprisingly good coolers for the size."</post>
   <post id="6e58b7d5-6015-4214-aa9b-f7e0b98c8a73" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"NCASE M1: a crowdfunded Mini-ITX case (was: "Aluminum SG05 evolution by Lian Li") ---------------- This thread documents the origin and development of the NCASE M1, from the original concept of an "aluminum SG05 by Lian Li," through multiple design iterations incorporating community feedback, prototype testing and design finalization, and finally crowdfunding of the finished product. The NCASE M1 started right here in this thread, which now serves as a general discussion for new and existing owners of the M1. Please note that per forum rules, we cannot tell you how or where to acquire an M1. ----------------- M1-related resources Have a question? Check PlayfulPhoenix s FAQ for a quick answer. Check out the user build gallery for ideas, reference and inspiration. A user-contributed Google docs spreadsheet, covering parts and compatibility ( edits are public and affect everyone - be careful!) M1 carry bag, made to order (organized by another [H] member - not affiliated with NCASE) For those experience a wobbling issue, please see this video (mostly affects early M1s). For those with panel alignment issues, please see this and this video (mostly affects early M1s) M1 Specifications Dimensions (H x W x D): 240 x 160 x 328mm, 12.6L (250 x 160 x 338mm overall including feet and rear protrusions) Motherboard support: Mini-ITX, Mini-DTX Liquid cooling support: Single 120mm or 240mm slim radiator Power Supply support: SFX, ATX (limited, only with short GPUs) Drives: 3 x 3.5" Mounts: 1 on case floor 2 in removable side bracket (cannot be used with dual radiator or ATX PSU) 3 x 2.5" Mounts: 1 inside chassis front 1 behind front panel (in place of optical drive) 1 on case bottom (in place of 3.5" drive) Included double-stacking bracket allows 2 x 2.5" drives on one mount (depending on drive thickness) Optical Disc Drive: Slim slot-load optical drive bay (vertically mounted with slot on top panel), supports 12.7mm thick drives Fans: 4 120mm fan mounts 2 on side bracket 2 on case bottom (in place of 3.5" drive) 1 x 80/92mm fan mount (bottom) 1 x 80/92mm fan mount (rear) Dust filtration: 120mm plastic frame mesh filters (screwed into fans), 2 for the side intakes (V3 and earlier only), and 2 for the bottom. Magnetic dust filter for side intakes (included with V4 and later). Front ports: 2 x USB 3.0, HD Audio Power button: Blue/red (purple combined) power/drive activity LED Material: 1.5mm aluminum construction, brushed and anodized exterior, matte black painted interior. Steel fan bracket (V4 and later). Package Dimensions Estimate: 228.6x304.8x406.4mm / 9x12x16" Package Weight Estimate: 2.72kg / 6lbs Team: NCASE Designer: Necere Operations: Wahaha360 OEM manufacturer: Lian Li Thermal &amp; Noise Testing Part 1 - http://hardforum.com/showpost.php?p=1039852611&amp;postcount=2579 Part 2 - http://hardforum.com/showpost.php?p=1039866874&amp;postcount=2686 Part 3 - http://hardforum.com/showpost.php?p=1039908672&amp;postcount=2968 ----- The story: - Wahaha360 likes SilverStone SG05, but wants something 100% aluminum - couldn t find anything, left wanting - Wahaha360 finds [H]ardForum and meets Necere, the designer - Necere &amp; Wahaha360 use CAD to show design ideas on the forum, forum members contribute, critique, make fun of...etc - Necere comes up with a viable design - M1 - Lian Li and SilverStone become potential OEM manufacturers, then Streacom, Jonsbo and Realan - A big discussion about company name - NCASE, in the end, still NCASE - Necere adds ATX PSU and Slim Optical Disc Drive support to M1 - A successful Indiegogo prototype campaign - Prototype from Lian Li arrives and testing began - A big discussion about possibly making the case bigger, in the end, no need - Prototype testing complete (see links below for testing results) - A successful Indiegogo M1 production campaign - Lian Li started production and for the most part, things went smoothly - All M1s shipped to backers ------ Miscellaneous renders Prototype and test build pics (click for larger versions)"</post>
   <post id="20b6085e-383b-4c5f-87ab-df82c26c1d65" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Best of luck with that. I bet Silverstone won t be too happy."</post>
   <post id="2af76106-598e-45d4-8e8f-f29fa236e8c7" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"yeah thats just waiting for a lawsuit. what correspondence do you have with lian li about this? lian li makes numerous new cases every year, whats to stop them from just designing their own case with a similar layout but in their style?"</post>
   <post id="6826ed31-f290-4a5b-b206-53bd1de89df7" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"This doesn t even pass the smell test."</post>
   <post id="f0756fd8-50ef-415e-be3e-8dd9eaf87fc1" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Silverstone themselves will do custom builds if you order some hundreds. If you look at the quality of the FT03-mini panels, you d know that not only Lian Li can do quality builds with anodised aluminium."</post>
   <post id="c3292e04-52c6-4fc1-806c-3343ee664cc2" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"WiSK said: ↑ Silverstone themselves will do custom builds if you order some hundreds. If you look at the quality of the FT03-mini panels, you d know that not only Lian Li can do quality builds with anodised aluminium. Click to expand... What makes you think Silverstone would make a tiny lot of several hundred? Retooling costs would far exceed the profit they would make on just a few hundred cases. You ll have to go with a small manufacturer. Which gives you more flexibility. And as far as lawsuits, as far as design patents and copyrights, case layouts are pretty hard to pin down. Either way, if Lian Li or Silverstone did choose to take you to court, they are going to outlast you. Even a legit patent holder doesn t always win against the bigger players. At some point its going to come down to who has more money to keep up with the proceedings. Sucks, but it s true."</post>
   <post id="e43e4524-93d6-4eff-8a2b-c62f13291db4" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"cmadki4 said: ↑ What makes you think Silverstone would make a tiny lot of several hundred? Retooling costs would far exceed the profit they would make on just a few hundred cases. You ll have to go with a small manufacturer. Which gives you more flexibility. Click to expand... [Edit] I have read that Silverstone have in the past, and are currently building small run custom versions of various of their cases. I have no direct contact with them, so I can t quote exact numbers."</post>
   <post id="b8335242-373b-4597-aca1-da46ae8c8190" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"WiSK said: ↑ [Edit] I have read that Silverstone have in the past, and are currently building small run custom versions of various of their cases. I have no direct contact with them, so I can t quote exact numbers. Click to expand... Roger that. SIlverstone making variations of SIlverstone cases is one thing. Lian Li making a variation of a Silverstone case, that s a totally different beast. If Silverstone is willing do short runs, that d be sweet. But the OP s original wish for a CAD model of the SG05 to give to Lian Li is a big no no and should be hastily abandoned. That being said, the SG05 wouldn t be too hard to remodel with enough variation to make it original. And don t put the Silverstone logo on it, haha"</post>
   <post id="8c5fea8f-6f20-4af3-8847-9aa796ee2957" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"IMHO, Lian Li uses good material, high quality, but their internal design just horrible"</post>
   <post id="68562b3b-2ac8-408f-b357-7269768db9ec" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Why not get them to do a modified version of one of their current cases? If you made the PC-Q16 a bit wider to accommodate a pair of expansion slots and maybe opened up the front ventilation a bit more you d basically have the SG05 (sans optical drive). edit: in fact, if you re really going forward with this and can get the capital together, talk to me. I have some ideas for the design (check out my SG09 redesign, if you haven t)."</post>
   <post id="9132e5f7-4bcf-4c39-930c-9f00ac53c204" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"wahaha360 said: ↑ Lian Li is willing to manufacture a small quantity of aluminum cases INSPIRED by the SG05. Click to expand... I have no intention of making a clone, that s why I used the term "INSPIRED". The SG05 design is outdated, it s only logical to design something improved. I intend to do everything legally and have been working with a USPTO certified Patent Agent / lawyer. There should be an aluminum SG05 alternative on the market and I want one myself. Either SilverStone reads this thread and decides to save me the time and money by making such product, or I will do it myself via Kickstarter. Necere, do you have a design as compact as the SG05?"</post>
   <post id="2f9d7093-b2b9-444b-a983-85ab57b42d8d" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"wahaha360 said: ↑ Necere, do you have a design as compact as the SG05? Click to expand... I have many; SFF is kinda my thing. I ll send you a PM."</post>
   <post id="0f3645b5-1d90-445a-946b-f0012c44746f" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Necere said: ↑ I have many; SFF is kinda my thing. I ll send you a PM. Click to expand... NDA."</post>
   <post id="a5e6b8a9-c6cc-448e-9182-72f1d5ab1388" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"cmadki4 said: ↑ NDA. Click to expand... I m not worried about it. I come up with new stuff all the time, and I ve shown some of my better work on other forums already."</post>
   <post id="b02f2b63-cf6e-4cd6-a3d9-d7977e377254" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Disclaimer: I didn t set out to profit from this. Collaboration with a Patent Agent is NOT intended to profit from intellectual property, but to prevent troubles for myself and others helping me. In fact, it s very unlikely I will make any profit - it s a small order and I have to keep the unit cost low for others to commit to such order. That being said, I m happy to sign NDAs and take all the help / advice I can get."</post>
   <post id="7ae8c15e-3910-4b71-afb2-e05ee2075bab" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"This is my base model / template. Very Similar to SG05, but more compact. http://sketchup.google.com/3dwarehouse/details?mid=16308e73605713371083e57c0db02b26&amp;prevstart=0"</post>
   <post id="e86a36be-9800-485f-86e8-65fd2bcb3425" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"Necere, sounds like we could collaborate on something -- check out my n(A) thread... I m modeling v2 right now to include 2x 15mm 2.5" hdds (read 4TB) in under 7.5L."</post>
   <post id="9d84f0dc-317e-4984-8fb7-42a68611710b" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"wahaha360 said: ↑ This is my base model / template. Very Similar to SG05, but more compact. http://sketchup.google.com/3dwarehouse/details?mid=16308e73605713371083e57c0db02b26&amp;prevstart=0 Click to expand... Yeah, that s the basic SG05 layout, condensed a bit. The external GPU is, frankly, a poor idea though on something that s not supposed to be a test bench. I d be wary about some of the publicly available sketchup models - many aren t all that accurate. I m guessing you re working in inches there, because some of the parts are off by a few mm. Machupo said: ↑ Necere, sounds like we could collaborate on something -- check out my n(A) thread... I m modeling v2 right now to include 2x 15mm 2.5" hdds (read 4TB) in under 7.5L. Click to expand... Heh... well, one thing at a time. The thing about scratch builds though - you kind of need to do a lot of trial and error with different materials/techniques to come up with things that work and look good (key point; I haven t seen very many scratch builds that accomplish the latter), whereas if you re working with a manufacturer they can just tell you what they can and can t do. Like I was telling the OP, I m more of a designer vs. a engineer/builder, so I don t know how much use I d be. Besides, scratch builds are really personal projects that showcase one s own abilities."</post>
   <post id="8017f6c7-db9f-4fb3-b564-15ad7534067a" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"The pic below is what I have so far. It s a little bit of SG05 and FT03-Mini to minimize the footprint. Parts: Asus P8Z77-I, GTX 680, ST45SF, 2.5" HDD, Slot Load Slim Drive, 140mm x 25mm Fan It s my first attempt. Since the SketchUp components are probably inaccurate, most likely a flawed model. Necere, I can send you the SketchUp model if you want to take a closer look"</post>
   <post id="c88f3a58-1137-45e9-9934-58db6b2f4c5e" section="Small Form Factor Systems" discussion="NCASE M1: a crowdfunded Mini-ITX case (updates in first post)">"size comparison, from left to right: SG05, SG05 standing up, prototype, FT03-Mini, Prodigy"</post>
   <post id="b58538f7-ff08-4c6d-9f8d-7c3fa26c9fea" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Hi all, I m interested in doing a build with two GPUs in SLI using one 16x PCI-E slot on a mini ITX motherboard. My understanding is that the Z97 chipset supports PCI-E bifurcation so you can just split the signal into two 8x ports. However, my motherboard has no setting for PCI-E bifurcation. Is it necessary to enable this, or will the chipset just figure it out when it sees two devices on the same PCI-E slot?"</post>
   <post id="0e8c90b7-79a8-416f-85fd-c7a6dd0450d2" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"PCI-E Bifurcation requires bios support, I m not actually sure the Z97 supports this feature anyway. As an example ASRock s support site says only their X99 boards support it."</post>
   <post id="74abcb1b-8bfd-4831-bc83-9762f38f7a21" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Quix said: ↑ PCI-E Bifurcation requires bios support, I m not actually sure the Z97 supports this feature anyway. As an example ASRock s support site says only their X99 boards support it. Click to expand... Take a look at page 52 here: http://www.intel.com/content/www/us/en/chipsets/9-series-chipset-pch-datasheet.html It seems like this would suggest Z97 does support bifurcation."</post>
   <post id="04bae520-2e37-48c3-9c0b-3cf2966d68bd" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"jb1 said: ↑ Take a look at page 52 here: http://www.intel.com/content/www/us/en/chipsets/9-series-chipset-pch-datasheet.html It seems like this would suggest Z97 does support bifurcation. Click to expand... Chipset support and motherboard support are two different things."</post>
   <post id="5c45bbb6-3f07-4d81-bd69-8fa0604b180a" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Yup, contact your motherboard manufacturer to be sure."</post>
   <post id="4c7f781d-8458-4bc4-a9c8-fa28bbee1acd" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"The ASrock X99E/ITXac board is confirmed by a hardware rep to have bifurication: http://forum.asrock.com/forum_posts.asp?TID=355&amp;title=pcie-bifurcation-in-z97eitxac"</post>
   <post id="656622a9-a74b-4d28-a7c1-4ae4c070e23a" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Some ASRock motherboards have support but also require a specific BIOS to enable them, like the Z87E-ITX. Mind you that all Z87 and Z97 chipsets support PCIe Bifurcation, but only a select few BIOSes have this enabled."</post>
   <post id="f942749b-d5cb-46d1-a92d-cc71fa5b5922" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Okay great, thanks for the note&amp;#8211;&amp;#8211; I couldn t find bifurcation mentioned anywhere in the X99E/ITXac manual. Anyone know about gigabyte s GA-Z97N-Gaming 5?"</post>
   <post id="efb99ce9-c897-4b64-8245-7fbafe2e6f58" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Don t count on it. As far as I know, ASRock is the only brand that has consumer-oriented boards with this feature: http://www.ameri-rack.com/ARC2-PELY423-C7_m.html You could contact Ameri-Rack for a list of consumer boards and supported BIOS versions that do."</post>
   <post id="42b6b0d4-8d96-4fc3-8899-12485f6e01b1" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Just called gigabyte... whomever I spoke with hadn t heard of PCI-E bifurcation before and said that it won t work. I believe this. Somehow I feel cheated of this excellent feature of the Z97 chipset&amp;#8211;&amp;#8211; should have anticipated this desire a year ago."</post>
   <post id="6e2280e9-6aa6-4db6-9f4d-dedbf2901268" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"OK, another idea. Is it possible to get a PCI-E splitter with a PLX chip on it? This is the way it s done on the dual GPU cards, correct? For example, this says active: http://www.acmemicro.com/Product/13...E16-A-LHS-Active-PCI-E-2U-Riser-Card?c_id=356 Does that mean this has a PLX chip?"</post>
   <post id="d2a34922-82c8-4765-ac21-ef4ad9121fb4" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"dude, I m doing the exact same thing with the asrock x99e itx board, what a small world. I have actually tried it with a few diff splitters and have had no luck so far. Products I have tried are, this one failed to show anything. http://www.amazon.com/Supermicro-RS...r=8-3-fkmr0&amp;keywords=supermicro+pci+explitter I have also tried this one, also failed to show any graphics card display. http://www.ameri-rack.com/ARC2-PELY423-C7_m.html I just got into today: http://www.acmemicro.com/Product/13...E16-A-LHS-Active-PCI-E-2U-Riser-Card?c_id=356 This product is different from others in that it has an active PCI splitter but I have yet to verify if it has a PLX chip yet because it s under the heatsink. I ll do that this weekend when I have more time with the system. Unfortunately, this splitter card is too long for the case I m using so even if I get it working I ll have to find an alternative solution but at least I ll know it works. Anyone know if this is bios related or not? Do I need to turn something on/off? I m really hoping to get this all working for this special project I m working on which will be a one of a kind but getting this dual graphics card working in SLI would be amazing!"</post>
   <post id="26165c65-bab0-4922-a4c3-015d9326e89f" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Nice, glad to see you re trying this! You might want to call Asrock and see what they say&amp;#8211;&amp;#8211; maybe you need a special version of the BIOS to bifurcate? As posted above, the X99 ITX should work with bifurcation according to Asrock: http://forum.asrock.com/forum_posts.asp?TID=355&amp;title=pcie-bifurcation-in-z97eitxac Also, for the active splitter that you just got (RSC-R2UG-A2E16-A), could you post the dimensions of the card? I want to see if this will fit in my case and I can t find concrete details on its length and width. Please let us know how it goes!"</post>
   <post id="ce3dcc1d-f834-4c7a-827c-be8e000757f7" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"jb1 said: ↑ Nice, glad to see you re trying this! You might want to call Asrock and see what they say–– maybe you need a special version of the BIOS to bifurcate? As posted above, the X99 ITX should work with bifurcation according to Asrock: http://forum.asrock.com/forum_posts.asp?TID=355&amp;title=pcie-bifurcation-in-z97eitxac Also, for the active splitter that you just got (RSC-R2UG-A2E16-A), could you post the dimensions of the card? I want to see if this will fit in my case and I can t find concrete details on its length and width. Please let us know how it goes! Click to expand... Got to try out the new Supermicro PCIE Riser and unfortunately it did not work either. No boot screen at all. I sent Asrock a support ticket and we ll see what they say. Perhaps a bios update is needed to make this all work in the end. BlueFox, from another thread has it, v1.35 so we ll see. You can see progress here: http://hardforum.com/showthread.php?t=1855235&amp;page=15 As for the super micro rise, it s about 6.8 inches in length, a big longer than the actual ITX form factor of 6.7"."</post>
   <post id="027d7ce0-8569-4898-97e4-4026505fee72" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"Btw, just tried the bios 1.35 from blue fox and no luck. Looks like we ll have to wait for Asrock to officially respond."</post>
   <post id="e507edc9-e26c-4079-8b63-492a4bc8cfdc" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"In order to have PCIe Bifurcation to work for 2 PCIe devices you need the following: 1) Bios Support, the Bios needs to have th code to detect en change the PCIe lane assignments from 16x to 8x/8x if the code is not there it doesn t work 2) Each PCIe device needs a Reference Clock. Multi PCIe boards have multiple Reference clocks 1 for each PCIe slot. In order to get more then 1 PCIe reference clock into 1 PCIe slot you need either A) deviate from the PCIe specification and use some of the pins to bring in another reference clock. This is what SuperMicro does. B) Multiplex the Reference clock on the PCIe riser PCB. I ve had a look into this as well with the same idea of running X99 ITX with 2 GPUs. I ve measured all of the pins on this SuperMicro card and in my excel sheet below you can see they hacked up the PCIe slot specification to get all the signals in, that is why they only work on a select number of their own server boards. RSC-R2UG-2E4E The actual pin-out The other option I ve looked into is the PLX chip, but those will be very expensive, this is old information but these things can cost as much as $80, plus the validation that needs to be done because of the switching involved. But with a PLX chip you can get any dual GPU setup to run on a single PCIe slot, but that riser will more then likely costs $100+ http://www.anandtech.com/show/6170/four-multigpu-z77-boards-from-280350-plx-pex-8747-featuring-gigabyte-asrock-ecs-and-evga/31"</post>
   <post id="4549b31c-d934-43a6-a173-3fa105485429" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"chemist_slime said: ↑ Btw, just tried the bios 1.35 from blue fox and no luck. Looks like we ll have to wait for Asrock to officially respond. Click to expand... Unfortunate! By any chance do you have the width of the card in addition to the length? Maybe this isn t really a possible option given QinX s post though... QinX said: ↑ The other option I ve looked into is the PLX chip, but those will be very expensive, this is old information but these things can cost as much as $80, plus the validation that needs to be done because of the switching involved. But with a PLX chip you can get any dual GPU setup to run on a single PCIe slot, but that riser will more then likely costs $100+ http://www.anandtech.com/show/6170/four-multigpu-z77-boards-from-280350-plx-pex-8747-featuring-gigabyte-asrock-ecs-and-evga/31 Click to expand... I wonder, can consumers even purchase PLX chips and soldier the PCI-E connections to the chip?"</post>
   <post id="3c2d2b74-141e-4f03-962a-24709cf1ba04" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"jb1 said: ↑ Unfortunate! By any chance do you have the width of the card in addition to the length? Maybe this isn t really a possible option given QinX s post though... I wonder, can consumers even purchase PLX chips and soldier together the PCIE connections, to the chip? Click to expand... It should be possible, the problem lies only with the motherboard manufacturer, if they have the code in the BIOS to bifurcate then you can make a PCB for it. PLX chips are BGA packages, yes you can solder it, but not with your regular soldering iron. Also because the PLX chip is a rather advanced switching chip, implementing it isn t easy, there is a lot of validation required to be sure it works properly. The best route to go is to build a PCIe riser card to duplicates the Reference clock. I ve been wanting to design the PCB for it and I think I know what it needs, but because I couldn t find a ITX board that has a BIOS for PCIe bifurcation I haven t bothered to give it a try."</post>
   <post id="1c72585c-6ebe-40b0-83d3-65a22f40f4d3" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"QinX said: ↑ It should be possible, the problem lies only with the motherboard manufacturer, if they have the code in the BIOS to bifurcate then you can make a PCB for it. PLX chips are BGA packages, yes you can solder it, but not with your regular soldering iron. Also because the PLX chip is a rather advanced switching chip, implementing it isn t easy, there is a lot of validation required to be sure it works properly. The best route to go is to build a PCIe riser card to duplicates the Reference clock. I ve been wanting to design the PCB for it and I think I know what it needs, but because I couldn t find a ITX board that has a BIOS for PCIe bifurcation I haven t bothered to give it a try. Click to expand... Interesting. I ll be curious to see how the Asrock X99 ITX testing goes since they have a hardware rep confirming bifurcation support. As for building a PCIe riser to duplicate the reference clock, do you mind me asking what would be involved?"</post>
   <post id="e7bdb649-4520-43d2-989a-ccb8b945268f" section="Small Form Factor Systems" discussion="PCIE Bifurcation">"It seems that the only thing you really need to do is multiply the reference clock signal. All the other signals can be daisychained as seen in the Supermicro example. The only thing the added to the PCIe fingers was more power and 2 more RefClks. Something like the IDT 9DB233 should be able to double up the Reference Clock signals from the looks of it. You mentioned you had tried the ARC1-PELY423-C7 and the RSC-R2UT-2E8R. Could you identify what chip is on those 2 cards? It might be that they have the same type of chips."</post>
   <post id="b051bff1-0a32-4ddc-bb0a-010150986ded" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Hello guys, I m new here - just registered to ask you some questions, hope you ll help me out. I ve been looking for some time for cool and cheap steambox like case for gaming PC without luck for some time and realized there s no such thing on the market. You all know the problems - it s either big, its a cube or it doesn t support dual-slot VGA s. I think I ve got quite good conditions to make a good product and boost the crowdfunding campaign. Some info on me: - PC builder and fixer - at least 250 pc s configured or fixed over 15 years including notebooks, servers and workstations - Family company designing and creating custom machines like powerplants and lathes - cad engineers and experience with outsourcing metal works to china - Game developer - have connections to some big and hyped game devs to boost campaigning I want to build a case fitting mostly standard gaming grade pc parts like the steambox case. Click to expand... PROTOTYPE V GALLERY: SENTRY: Console-sized gaming PC case CURRENT STATUS: Pricetag TBD depending on final metalworks cost, currently aiming around 159$ Campaign date TBD, most likely on indiegogo. Minimal quantity/target goal on campaign will be probably 200 or 100, but I think we should get a lot more orders Specs -340 x 310 x 66mm main body - excluding stands, vertical stand and VGA bracket hold -340 x 320 x 74mm total outline - including stands and VGA bracket hold -mITX only motherboard, 7mm standoff s -generic flex riser, can be replaced, for example with different pci-e lane width generic flex risers -conditional 48mm or 38mm max coolers depending on cpu socket location and primary 2.5" hard drive mount use -conditional SFX-L 130mm max or SFX 130mm PSU s depending on secondary 2.5" hard drive mount use, max 64mm height -conditional use of up to 12 2.5" drives in VGA bay depending on the card size or no card installed -dual slot full size 305mm VGA cards support -vertical stand -possible to carry in some 17" laptop bags and backpacks Drive mounts: -Primary Master 2.5" drive mount, partially above motherboard, collides(unusable) with coolers taller than 38mm when cpu socket is next to PCI-E -Secondary Master 2.5" drive mount, next to PSU location, collides(unusable) with SFX-L -Primary Backup 2.5" drive mount, in the VGA bay, near the back of the case, to be used with full length, blower type cooled cards -Secondary Backup 2.5" drive mount, in the VGA bay, near the front of the case, to be used with short cards -Tertiary Backup 3.5" drive mount, in the VGA bay, obstructs both primary and secondary backup 2.5" mounts, used with no dedicated card CPU Coolers that should work: - AMD APU(65W LP) - Intel stock 1150 - Noctua NH-L9a/NH-L9i - Scythe Kodati - Silverstone AR04/AR05 - Thermolab ITX30 Spoiler: Renders Spoiler: Update history DECEMBER UPDATE: We re ready with the design and we sent inquiries to potential metal machining contractors few weeks ago, but it looks like most of them didn t want to bother responding before Christmas. Also we could ve had the prototype made already from our local metal machining shop but they are quite expensive when it gets to small custom stuff. That way we would have a semi-useless prototype because we would need to order another one from the production contractor of choice to make the final metal adjustments anyway. Some of them might be able to make better air inlets like those small hexagonal holes before laser cutting and bending which would optimize the price and tweak case looks. It has to move early January somehow and we should know the approximated price then. I m really sorry though for not taking that lazy December thing ahead. We re not releasing any media info or interior design because of two things: first is - unless we have a physical prototype there always might happen something we didn t think of and slight tweaks might occur. Also render is only a render. As for the current state of the case: I m satisfied with the utility of the case within its dimensions and looks - its totally awesome and when you see the interior its something that s totally new and game changing. There are few things that are not satisfying as much as the above, like the amount of cover s screws (8) and current air inlets - those are somehow little redneck for the industry, but that s what we had to do for the minimum order amount which could be even like 20 units if not for the additional parts retail price. FEBRUARY UPDATE: We have just built the first early prototype. Metal machining quality is a bit off and we re waiting for the metal machining shop to update their toolset for increased bending precision. This means another setback. The prototype lets us check out numerous little things we can now fix in the design. The internal layout, including graphics card and riser support looks good and there shouldn t be any big revolutions here. Prototype case just barely, but fits inside earlier mentioned laptop bag. Meanwhile Chieftec started shipping their SFX-500GD-C (SFX-L) which is oversized by 0.5mm. Because of that, case will now grow in height by this 0.5mm to support 64mm height SFX-L PSU s which might become more common if other manufacturers follow Chieftec s lead on breaking out of the SFX standard dimensions. While waiting for the prefered metal machining contractor to reach required bending precision we will try to order prototype parts at local shop. Here You have a photo showing the actual size of the prototype laying on zombi s desk. We hope You like ll it : APRIL UPDATE: We ve received the metal parts for the second prototype just before Easter. Sadly, it s not production ready yet. The reason is that even the local metal shop exaggerated the precision of bending they have. The problem looks to be the lack of experienced operators of bending machines and we have to take that into account for the production. Because of this we have to redesign some internal pieces introducing more margin for bending errors. It s not like we didn t have any before but it looks like it wouldn t be enough for the production. Some additional conclusions from this prototype and what we learned last two weeks: 1) We ve found the way to ensure top cover surface coming together nicely with the front 2) We ve tested the installation of whole system inside the case. Even with non-modular SFX the wiring hell looks still manageable, but for the SFX-L we d recommend using modular cables. 3) The P4 cpu power connector will need an extending cable. We ll most likely provide one with the case. P8 doesn t look to be common at all in ITX boards. 4) The power button looks just like the one on renders. The led ring is white/grey lightly-translucent plastic when not powered. Stay tuned, we are still trying to make it real as soon as possible. JULY UPDATE I: We just had a meeting with our supplier from the laser-cutting company. It looks like we ve achieved bending repeatability. It means, next step will be repeatability in point-welding, galvanizing and painting. We re thinking about laser-cutting our case parts from the metal sheets, which are already galvanized. The only problem is that, laser makes edges which will stay without galvanized cover. Of course whole case will be painted, but in case someone will scratch it on the edge, then rust can show up. We have to think it through. If individual galvanizing won t be very expensive, than we ll probably do it in the mass production. We have a little teaser for You. I hope You ll like it Please also note that this is still unpainted prototype without galvanized cover, so it s a little bit rusty. At this moment it s prepared for point-welding and it s only screwed by screws. JULY UPDATE II: CURRENT STATE OF WORKS: We ll be ordering the (most likely) final prototype for metal parts which will be laser cut, bent, welded together and powder coat painted. The only real difference from last prototype you ve seen on photos is added clearance for powder coating and galvanized steel. Hopefully there s no much that can go wrong with it. We re completing the supply list for required items. There s two more details left for case parts - so we re getting really close. We re also thinking about packaging already. Changes made recently in design and notes from prototype: Case cover will not be sliding from behind anymore and can be freely put from the top side of the case. We re dropping the default mounting points for 3.5" drives in the bottom of VGA bay - the reasons for that are both heat of 3.5" and total mess made by 3.5" mounting points in bottom air inlet. You can still use the stacking bracket to pack up two 3.5" drives together and lay it on the bottom of the case in horizontal position. If the demand for those drives come to our attention later we ll be thinking of solving this problem. Small single slotted cards might not be perfect for such type of case because of the distance from the outside wall and passively vented separate VGA bay. Such config will probably end up mixing the hot air inside the bay. I d recommend some additional fan to induce the airflow if someone totally needs to use a single slotted card for gaming. I think it ll be the same for all of such type cases since silverstone also noted something about passive venting in RVZ02 which has virtually the same VGA bay size: Expansion card area is also passively vented so we recommend graphics cards with open air cooler for best cooling performance. Click to expand... CPU, motherboard and PSU s are cool and quiet on stock intel cooler. AUGUS UPDATE: Prototype 4 ZombiPL said: ↑ Just like we promised, here You have a little gallery of our 4th prototype. There are several things we have to improve before ordering the 5th prototype, but before that we want to know Your opinion about actual design. Please note that our IEC C13-C14 cable, USB extension cable and long PCI-E riser are made only for this prototype and will be different in a production version. Click to expand... Temperature tests results Spoiler: full test info Another update: Results of testing weekend are here HARDWARE Test bench: Pentium G3258 Intel BOX cooler 46mm Gigabyte B85N Phoenix 8GB DDR3 1600Mhz in one stick Chieftec SFX-500GD-C 2.5" WD Caviar Blue 1TB 4mm rubber feet in desktop/horizontal position Test cards: Palit GTX 970 4GB Blower Type (150W TDP) Gigabyte R9-270X Windforce 3X OC @ 150W (-20% Power) METHODOLOGY First thing to mention is that most of you would want to see really different temps on each gpu and case and it s not really going to happen because of how thermal throttling and gpu boost work. Essentially cards will go up to 80 degrees with boost going way more than declared boost frequency and when they hit the 80 degrees they throttle down to base clock to cool down and go up a bit and do that over and over. That s how it ll work if they won t hit the fps cap like v-sync. Because of that I ve decided to observe the clocks rather than simply log the temps. I burned the card up to stable 80 degrees (or other stable) and logged the average clocks and framerates in games and benches. This can tell us how the card will throttle down rather than how hot it will be. Screen resolution 1920x1200@56Hz instead of 1080p60 - Basically I don t have 1080p screen because I still have my good old 16:10 screen that can be oversized if required. 1920x1200@56Hz is a really close workload to 1080p60 and I had to use such screen resolution to run benchmarks in 1080p All games were running max possible settings. Games were played in same locations instead of running scripted benchmarks but I picked a lot of them to average the results. I think that will do. Games were played with Vsync except for Alien: Isolation which I decided to let run freely on max fps because all other games wouldn t exceed fps cap. CS:GO was added with the cap as a different graphics quality title to check out temps on lower clocks. It was excluded from the average values in the summary. RESULTS Spoiler: Specific Test Results Results - Desktop/Horizontal position Results - Stand/Vertical position Summary in games. CS: GO excluded because of VSync cap. CONCLUSIONS Huge open air coolers will most likely work a lot better than blower coolers in vertical position. Blower Coolers doesn t look to be starved for air in horizontal position. There s not really a problem with card s temperatures since they re still running their nominal clocks when hitting the thermal barrier of 80 degrees. ADDITIONAL NOTES Chieftec SFX-500GD-C makes chirping sound initially but it goes away after some time. The grill s gold coloured plate makes it get out of the SFX standard dimensions. It had to be turned around to the inside to fit. The plate doesn t touch the fan this way so there s no worry. 45cm long modular cables can be fit inside the case but it requires proper approach. We ll tweak the design to ease that process. Palit GTX 970 Blower s fan makes chirping sound all the time even when running at 20% of speed. I wouldn t advise picking such unit for a vertical stand on the desk. 10mm tall rubber feet will most likely be added as secondary or default stands for horizontal position to not starve the open air coolers."</post>
   <post id="bd5ab21f-f9e5-4821-a416-324c9dbf451c" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Welcome! I see you too are interested in SFF PCs. I think the most important question firstly is the layout of your case. Where is the gpu in relation to your motherboard? Is it going to be parallel to the motherboard, like the steam machine? Personally size matters a lot to me, so I would want the smallest case. I don t care about mATX, especially if it makes the case bigger. ODD is not crucial to me, although it is to a lot of people. Power supply is interesting. Most people like their SFX power supplies, but I would not mind a DC-DC power board and AC adapter, especially if it makes the case smaller."</post>
   <post id="1726c2ff-a37a-40e0-879d-5585e0069e41" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ - Is size this crucial for you as for me it is? I d like to have console form factor - 7 litre max case. Click to expand... Yes, of course. Otherwise why bother? - How about silence and thermal conditions? Do you need to put high-end VGA s inside? Click to expand... 11" graphics card support is almost a must, since you never know how long the next gen will be. - Would you sacrifice some of the space(get slightly bigger case) for mATX support insead of ITX? Click to expand... In a steambox setup with risercarded graphics card a mATX board would actually be counterproductive, as it would block parts of the GPU cooler. - Would you rather want externall passive PSU instead of internal SFX one? Click to expand... Internal. The way things go 400w for the PSU is a must and it s neither easy nor cheap to find external solutions for that. - What pricetag are you interested in? Click to expand... $250 if it looks the part. - Is ODD crucial? Click to expand... Not for me. But a slimline slot-in optical should easily fit in there somewhere. Bottom line: Silverstone already has 3 iterations of their steambox, NCASES are working on theirs right now (see other thread). So find way to make things better. You will limit your target audience by restricting GPU length below 10" or requiring external PSUs which aren t readily available above 200w everywhere."</post>
   <post id="15bb1593-d23e-4fff-8078-80fa943eb2af" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Thanks for your answers timmay said: ↑ In a steambox setup with risercarded graphics card a mATX board would actually be counterproductive, as it would block parts of the GPU cooler. Click to expand... Yeah i get it, that s why I was wondering about making the riser switch the card turn card around so its cooler faces same direction as cpu cooler"</post>
   <post id="1a09fe03-c967-4d56-9e4b-4f447781c354" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"To be honest if you do all of this, you ll be making a case extremely similar to Necere s new NCASE project, dondan s new B3 project and also the valve prototype. So I suggest you make something different with this. It could be making the case smaller, using a DC-DC board, only using short graphics cards, I don t know. But make your case unique and target a particular audience; don t try to please everyone."</post>
   <post id="3d056fe0-7a4b-4220-b483-c6e21d727f60" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"What exactly would be different with your case that the Silverstone RVZ01B doesn t already cover? For me, I would like to see a case that s far lower in price than the RVZ01B."</post>
   <post id="ab93be2d-c250-4f84-a95b-d9126899483c" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"@rawrr - To be precise it s not about making something different just because there are similar projects like this - we ve got the steamcase prototype yet nothings there in reach for end user yet. @Dangman RVZ01B is quite fat - its 14litre design while steambox case as I remeber was something just below 7 litre. Also RVZ01B is seriously ugly - the new NCASE is probably the simplicity in looks I d also aim for. About the cost - yeah thats it - i believe that case shouldnt cost more than fifty bucks but cannot guarantee this until we get the initial designs ready and count the manufacturing costs."</post>
   <post id="b902b434-7077-40d5-a14c-94c47b0c8328" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ @Dangman RVZ01B is quite fat - its 14litre design while steambox case as I remeber was something just below 7 litre. Also RVZ01B is seriously ugly - the new NCASE is probably the simplicity in looks I d also aim for. About the cost - yeah thats it - i believe that case shouldnt cost more than fifty bucks but cannot guarantee this until we get the initial designs ready and count the manufacturing costs. Click to expand... $50 is going to be hard to do if you re planning on using a PCI-E riser. For regular consumers, PCI-E risers are about $20 to $25 alone."</post>
   <post id="b0091e78-ee15-46e8-8df4-3558e40d7a3c" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Yeah, I get it, I haven t researched the riser s yet but the prices for them are like that because that s a custom unpopular item not because its expensive in material."</post>
   <post id="9fce44bf-080e-4198-9cc9-dbdb70a1fff6" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ So here are my questions about what you want from the case, ofcourse more to come (ie follow-ups) - Is size this crucial for you as for me it is? I d like to have console form factor - 7 litre max case. - How about silence and thermal conditions? Do you need to put high-end VGA s inside? - Would you sacrifice some of the space(get slightly bigger case) for mATX support instead of ITX? - Would you rather want externall passive PSU instead of internal SFX one? - What pricetag are you interested in? - Is ODD crucial? Click to expand... Size should be as small as possible for me. Check the NCase steam-box - huge one. Please consider shorter video cards instead of going full size. There are now too many ITX sized (17cm long) cards, so a volume reducing can be easily achieved. ITX MB wins every time over mATX. Internal PSU is preferred to me, even if not standard one, as long as its with decent quality and provided with the case. Price ~ 150$ (up to 200$ with ~400W psu) I like the idea with reversed VGA."</post>
   <post id="89e4d7cf-c6a6-4fdf-aced-2df1b1b04122" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ About the cost - yeah thats it - i believe that case shouldnt cost more than fifty bucks but cannot guarantee this until we get the initial designs ready and count the manufacturing costs. Click to expand... And then suddenly you find out why decent cases cost what they do... FYI there s an Azza branded "steambox" style case on Newegg currently for $45 shipped after rebate."</post>
   <post id="10ada867-8aef-47ed-8c9e-e6ce7aaa7186" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"niksus said: ↑ Size should be as small as possible for me. Check the NCase steam-box - huge one. Please consider shorter video cards instead of going full size. There are now too many ITX sized (17cm long) cards, so a volume reducing can be easily achieved. ITX MB wins every time over mATX. Internal PSU is preferred to me, even if not standard one, as long as its with decent quality and provided with the case. Price ~ 150$ (up to 200$ with ~400W psu) I like the idea with reversed VGA. Click to expand... The thing is often when you implement an internal psu, there will be enough space to put in a longer graphics card."</post>
   <post id="37a12f39-1b80-482f-879c-b246743c5e4e" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Zap said: ↑ And then suddenly you find out why decent cases cost what they do... FYI there s an Azza branded "steambox" style case on Newegg currently for $45 shipped after rebate. Click to expand... The only idea in my head why it could cost this at this moment is cost of connector coating ( not the slot). printing the board itself shouldn t cost too much except for this one thing. Thanks for info on Azza - still it looks like crap and is quite big. @rawrr &amp; niksus - I ll try to figure out the 17cm long cards and internal psu combo by numbers today and maybe draw some boxes in cad to show my ideas."</post>
   <post id="5b6c0d67-2c55-4a04-8434-35601ded77e5" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ The only idea in my head why it could cost this at this moment is cost of connector coating ( not the slot). printing the board itself shouldn t cost too much except for this one thing. Click to expand... The cost is in the flex, not the in the PCBs at the ends. It s not just a row of wires with bonded insulation and foil wrapped around, they re essentially 40 subminiature coax cables, capacitance matched to within very tight tolerances (this means both precision manufacture of the cabling, and precision cutting of the resulting ribbon)."</post>
   <post id="0cfc9814-a45f-45fe-942b-c956a87ff1ae" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"SaperPL said: ↑ - Is size this crucial for you as for me it is? I d like to have console form factor - 7 litre max case. - How about silence and thermal conditions? Do you need to put high-end VGA s inside? - Would you sacrifice some of the space(get slightly bigger case) for mATX support insead of ITX? - Would you rather want externall passive PSU instead of internal SFX one? - What pricetag are you interested in? - Is ODD crucial? Click to expand... 1. sure, why bother otherwise ? 2. Good airflow, possibility to put silent (large) fans is crucial. Vga cards up to 250mm would be awesome. 3. nope. Itx is the way. 4. INTERNAL please. Higher efficiency, less cable cluttering, easier to keep clean. 5. &lt;100$ 6. OD-what ? We all have high-speed internet now, don t we ?"</post>
   <post id="b575c0f8-75b9-47a2-9212-1f2c17efd752" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"http://azzatek.com/csaz-103-techspec.html kind of looks nice, but may be a bit short for my GPU &amp; the USB/Audio ports are in a strange place (I like them on the front). http://www.silverstonetek.com/product.php?pid=524is good so you can put a real single slot GPU in a Element Q now, come on guys give us a 2 slot EQ. 6. OD-what ? We all have high-speed internet now, don t we ? Click to expand... That is still no reason to not include a option, just make it a slim ODD bay."</post>
   <post id="8513d357-a56b-4069-ab91-048445221c3f" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"ODD slots are ugly and complicates the design... There exist like a million cases for ODD lovers already"</post>
   <post id="1951d092-000c-47b0-882d-9e33498c80d2" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"qwerkus said: ↑ 2. Good airflow, possibility to put silent (large) fans is crucial. Vga cards up to 250mm would be awesome. Click to expand... 250mm would be very long for ITX cards and too short for cards like GTX 770/780. Better to make it shorter or longer."</post>
   <post id="59564122-1551-4ab8-9d5f-d3427a0ca9a2" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"With 170mm limit I think we could go for something like A4(card below motherboard) but with SFX PSU inside and make it just below 4 litre size if I didn t screw the math. Bad thing about this would be complicated riser or flexible riser"</post>
   <post id="6ce4c2d9-dde9-4ac7-8143-591496d3c973" section="Small Form Factor Systems" discussion="SENTRY: Console-sized gaming PC case project">"Here s the component spacing for the idea of limiting case to 170mm cards. Includes some 5mm spacing between components. components: motherboard graphics 2.5" drives SFX PSU Outer dimensions: 300x170x84 [mm], 4.28 Litre For comparison: Xbox One 343x263x80 [mm], 7,22 Litre Playstation 4 305x275x53 [mm], 4,45 Litre Pros: the size, 4.3 litre Cons: It s a bit cube like complex pci-e riser/extender (card reversed -air inlet from the bottom) cpu cooling and ram limited to ultra low profile ones max 30mm (standard for simm without cooling) cards limited to 170mm air inlets from both sides What do you think about this?"</post>
   <post id="124f41b2-71c9-4a87-afd8-949bd7c39875" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"This case looks intriguing, I like the looks and it seems to be slightly smaller than a fractal design node 304 while supporting excellent cooling and its light (2.4 kg). Anyone have any thoughts on this?"</post>
   <post id="d4111ca4-d0be-44ac-a000-3e5ce4813956" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"That s pretty nice. It s like Lian Li s take of a cheaper and more consumer orientated of the NCASE M1 that they built with the M1 being an enthusiast grade case."</post>
   <post id="037189ba-b0ed-437b-b73e-9b053c3208c8" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"Lian-Li advertises the Q10 as accommodating a 2x120mm radiator on the top panel, but then where is a power supply supposed to go? I downloaded the Q10 manual, but it gave no answers."</post>
   <post id="9a4dcf2e-dffa-4786-8287-ad9de9fdd80d" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"rsquared said: ↑ Lian-Li advertises the Q10 as accommodating a 2x120mm radiator on the top panel, but then where is a power supply supposed to go? I downloaded the Q10 manual, but it gave no answers. Click to expand... I don t have this case, but looking at the product page, if you use a radiator, it actually gets mounted on top of the case, not inside. It might be possible to mount a 120mm single radiator inside if you replaced that case fan. Lian-Li Global | PC-Q10 The Q17 page (basically same thing with some Asus branding) shows one installed Lian-Li Global | PC-Q17"</post>
   <post id="346a6618-ff48-472c-bbfd-4e66047d4072" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"Yeah, 2x120mm radiator gets mounted on the top. I have one coming next week for an ITX build with a 980 Ti, I can try to take some pictures if that would be of interest. I was intrigued by the good temperatures it got in the SPCR and Tom s Hardware reviews, and since people have been able to put in an MSI 980 Ti 6G in there (which is 7mm longer than what is officially supported) I thought about giving it a go. Plus it takes ATX supplies and not those noisy SFX PSUs."</post>
   <post id="bdc34911-e540-4c5c-93e7-6883299d890d" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"My build is in progress; I only started on it last night. I am happy with the progress so far. Positives are that the heatsink for the Dark Rock 3 fits as has been shown in the past, and my MSI 980 Ti Golden Edition also fits! Untitled Untitled Untitled The actual heatsink for the be quiet! does not touch the acrylic panel when I peaked through the grating; it looks like there is ~1mm of gap between the highest parts the heatsink (the round dots on the top which are probably nice caps for the ends of the pipes). However, the fan being 135mm does cause the door to bulge out by about 1mm or so. Not a lot but noticeable if you are looking at it. If you are using RAM without any heatsink on it then you should be fine with the stock 135mm fan; my Kingston HyperX Savage 2x8GB DDR4 heatsinks are too tall for it. I have a 120mm Noctua NF-F12 iPPC coming to use as an alternative. The PCB length looks to be 279mm in for the 980 Ti Golden, however the heatsink is almost 3/8" shorter. The placement means you can move the USB 3.0 and HD Audio cables so that they bend downward a bit underneath the PCB of the video card, and it looks to me like there is not enough bending going on to feel uncomfortable about it. I did get a 140mm PSU as I was kind of wary of using my existing 160mm one, but it looks like a 160mm would fit. You would have tighter cable bends though. I will probably put a 800RPM Scythe up in the top, and maybe replace the Lian Li one with the same if I find the fan noise to be annoying from it. I really wish I had a short cable kit for this though . Maybe I will try and actually use the cabling tools I bought two years ago and make some shorter ones."</post>
   <post id="da3cc41c-8304-4ca1-9229-1b785f84b0f7" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"Finished pictures are below. I have fan noise issues that need to get resolved. I m very disappointed that the Noctua fan is my biggest noise offender in the case... that is usually my go-to PWM fan brand as they tend to not have any electrical noise. The cooler master fan also makes ticking/buzzing noises at idle which is disappointing. If I put a magazine over the fan grates on the top you can t hear the noise anymore, so I might look at partially blocking some of the grating holes on top if I decide to continue on with the case. Have some different fans on order for the CPU and exhaust areas that should be here tomorrow. The Cooler Master PSU was fantastic to use space-wise though, and the cables are very flexible which helped with the funky routing I had to do. I don t think I could attempt a 160mm PSU in here though, and 150mm would definitely be the limit. I was happy that the CM PSU was 140mm. There are alignment issues with the DVD drive in that it gets caught on the lip when you eject a disk. Have to use a paperclip to straighten out the disc as it ejects to let it come out all the way. I have not played any games yet to see how temperatures are."</post>
   <post id="755bce69-38e4-4191-ac91-62a286a144c7" section="Small Form Factor Systems" discussion="Lian-Li PC-Q10 ; anyone have this?">"Hey I have this case. I bought the Asrock x99e motherboard for this and mistakenly didn t realize I can only use CPU coolers that are compatible with a  narrow ILM bracket  (I m stupid I know). Anyways this narrowed down my choices bigtime. I tried a h80i GT that I had but that didn t work. And now I m considering trying a Noctua NH-D14. Noctua doesn t officially support it, but I have the bracket and tom s hardware managed to get it on this motherboard. Dynatron R27 And R24 Versus Noctua NH-U9DX i4 - Introduction Has anyone tried putting a Noctua NH-D14 in this case? The height of it seems to be at the absolute limit for this case so I m a little hesitant. But I really want to get a decently beefy cooler in here. Would love to hear anyones experience. Thanks!"</post>
   <post id="c0757305-79ce-4b84-98a5-20563ac7277b" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Just received this unit today and thought I would take a look at it. It s the only 150mm long FlexATX PSU with full modularity, and at 300W it has enough power for an R9 Nano and a decent i7. The awesome thing about that is that you can make your own cable harness with perfect cable lengths without having to solder or losing your warranty, which is normally a huge issue with FlexATX PSUs as almost none of them even have PEG connectors for the GPU. With 80Plus Gold efficiency there s potential for quiet operation during idle and moderate load. I won t actually turn it on until I get the prototype parts for Brevis S, but I got pretty excited just looking at it. Here are my first impressions. Thanks for reading!"</post>
   <post id="b122d2cf-a026-403b-9e66-c06e96ed8b8e" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Interesting, especially when thinking about the Hutzy XS… So, could one simply remove the wires that were not needed (SATA power, IDE &amp; Floppy power). Could one also  strip down  the CPU wires if, say, one only needed a 4-pin CPU assembly…? If so, would make for a very tidy cable system; with a M.2 boot/system drive &amp; no other drives, one could have a basic three cable system; MB,CPU, &amp; GPU…! Pull the  extra  wires, shorten the ones you are keeping to the appropriate length, sleeve same; one custom sleeved Flex ATX PSU…!!!"</post>
   <post id="b56b8bfe-732f-4674-9734-c1d9cc530cba" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Damnit, just looked at this the Seasonic website, it does not have a dedicated GPU connection…"</post>
   <post id="3adb3135-50ab-4b38-94ec-338271550a7e" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Okay, so I am guessing one would use the pins/connections for the SATA/IDE/Floppy power to make a 8-pin connector for the GPU…?!? I am definitely interested in this, if it is possible to mod the harness to include a 8-pin GPU connector…!"</post>
   <post id="c270ec39-69ee-4c93-8b29-4f25bdff9a92" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Boil said: ↑ Interesting, especially when thinking about the Hutzy XS… So, could one simply remove the wires that were not needed (SATA power, IDE &amp; Floppy power). Could one also  strip down  the CPU wires if, say, one only needed a 4-pin CPU assembly…? If so, would make for a very tidy cable system; with a M.2 boot/system drive &amp; no other drives, one could have a basic three cable system; MB,CPU, &amp; GPU…! Pull the  extra  wires, shorten the ones you are keeping to the appropriate length, sleeve same; one custom sleeved Flex ATX PSU…!!! Click to expand... Yes, that s the idea. Unfortunately, because so many pins on the cable harness have two wires crimped to them, there is no way to remove all pins for SATA/IDE connectors and be done with it. The only completely separate part are the ATX12V connectors for the CPU. Everything else is connected together in some way. For a case manufacturer this would mean that they had to supply a custom harness with the PSU, but that s much more affordable than supplying a completely custom PSU. Boil said: ↑ Okay, so I am guessing one would use the pins/connections for the SATA/IDE/Floppy power to make a 8-pin connector for the GPU…?!? I am definitely interested in this, if it is possible to mod the harness to include a 8-pin GPU connector…! Click to expand... Yes it is, but you ll have to redo the whole harness. You can reuse the connector housings, but you ll have to get new pins. I guess you can leave all the cables in the ATX24pin connector and just shorten them, so it s not too complicated."</post>
   <post id="afaaa100-86b7-48b1-aa67-6723ab219da4" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"I did mean that one would reuse the wires from the SATA/IDE/Floppy, sorry if I wrote it to read that I would actually reuse the existing pins… I know those would need replaced… So, any idea of the proper procedure for creating a viable 8-pin GPU power cable from the existing SATA/IDE/Floppy cables…? Like, the proper pin-out &amp; such…?"</post>
   <post id="5a49df58-3cd1-4536-af60-9b49737f4da5" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"The stock fan is 2 pin, so wouldn t it run at full speed constantly?"</post>
   <post id="57d2621a-e046-4067-aad8-6ddf6b8567c9" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Boil said: ↑ I did mean that one would reuse the wires from the SATA/IDE/Floppy, sorry if I wrote it to read that I would actually reuse the existing pins… I know those would need replaced… So, any idea of the proper procedure for creating a viable 8-pin GPU power cable from the existing SATA/IDE/Floppy cables…? Like, the proper pin-out &amp; such…? Click to expand... So this is the pinout for the PSU side connector: The relevant pins for PEG (GPU power) are 12V (yellow) and GND (dark grey). 12V: Pin 2 is connected to ATX24pin and SATA. Pin 3 is connected to ATX24pin and IDE/Floppy. Pin 14 is connected to the first half of the ATX12V connector. Pin 15 is connected to the second half of the ATX12V connector. GND: Pin 16 is connected to the first half of the ATX12V connector. Pin 17 is connected to the second half of the ATX12V connector. Pin 18 is connected to SATA. Pin 19 is connected to IDE/Floppy. So the easiest way to add a PEG connector is to remove the ATX12V connectors and use those wires. When you want to remove IDE/Floppy or SATA, then 5V and 3.3V are relevant as well: 5V: Pin 20 is connected to ATX24pin and SATA. Pin 21 is connected to IDE/Floppy. 3.3V Pin 22 is connected to SATA. So, to get rid of those, you ll have to remove the pins 2, 3, 18, 19, 20, 21 and 22, re-crimp the 5V wire of ATX24pin to pin 20. Then you can use pin 2 and 3 to connect to the 12V contacts of the PEG connector and ATX24pin and use pin 18 and 19 to connect to the GND contacts of the PEG connector. I hope that s detailed enough. Hahutzy said: ↑ The stock fan is 2 pin, so wouldn t it run at full speed constantly? Click to expand... No. Pretty much all PSU and GPU fans are 2 pin from what I know. They re voltage controlled, not PWM controlled. The third pin on normal fans is for the RPM readout, the fourth is for RPM. The problem with non-RPM fans as case fans is that the mainboard can t know the fan curve (some can t even use voltage control), which might not be linear, so fine-tuning is very hard. With PSUs, the manufacturer is exactly aware of the fan an can thus trim the voltage response to the desired result. Or they cheap out and just use a thermistor. If this unit is decent in terms of noise, it would be a great fit for both of our cases. And pretty much all FlexATX cases in general."</post>
   <post id="4d017c39-bc6b-40e6-aeff-794a8370d060" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"TY very much for the pin-out breakdown…! I do believe I could fumble through the rest (maybe with a little bit of help from the Internet)…!"</post>
   <post id="564a7d46-c919-4c89-b619-cc10094a4245" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Did you test out the PSU at full load? How is the fan curve / noise? Would it be possible to power an R9 Nano + i7 @ 4ghz on 300watt?"</post>
   <post id="78a7e3ec-0783-4fd3-bfe7-4d921680992c" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"andgo said: ↑ Did you test out the PSU at full load? How is the fan curve / noise? Would it be possible to power an R9 Nano + i7 @ 4ghz on 300watt? Click to expand... iFreilicht said: ↑ I won t actually turn it on until I get the prototype parts for Brevis S, but I got pretty excited just looking at it.! Click to expand..."</post>
   <post id="ebd7c9ac-9513-4b0c-ba7f-5e9851c2ccd3" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Boil is correct. The prototype parts are scheduled to arrive on the 3rd of May, so until then I won t do any testing. andgo said: ↑ Would it be possible to power an R9 Nano + i7 @ 4ghz on 300watt? Click to expand... I say it is possible. The i7-6700 has a turbo clock of 4GHz and a TDP of 65W, the R9 Nano has a TDP of 175W. While TDP is not equivalent to power consumption, it s a good estimate. Give each of them 15W overhead (just to be sure) and you arrive at 270W, still way below the maximum 300W. You can easily put an SSD or two in there as well, still won t reach the 300W. Additionally, you ll never have GPU and CPU and all drives under 100% load at the same time, that s just not a realistic scenario. So yes, very much doable."</post>
   <post id="b4c4787f-ed44-4c0f-8114-4e3cda6ea543" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"iFreilicht said: ↑ Boil is correct. The prototype parts will arrive on the 3rd of May, so until then I won t do any testing. I say it is possible. The i7-6700 has a turbo clock of 4GHz and a TDP of 65W, the R9 Nano has a TDP of 175W. While TDP is not equivalent to power consumption, it s a good estimate. Give each of them 15W overhead (just to be sure) and you arrive at 270W, still way below the maximum 300W. You can easily put an SSD or two in there as well, still won t reach the 300W. Additionally, you ll never have GPU and CPU and all drives under 100% load at the same time, that s just not a realistic scenario. So yes, very much doable. Click to expand... Well, looking forward to see someone try it"</post>
   <post id="a6bb8a5e-e495-4eac-b38b-6eae58a7c4e8" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Great, looking forward to the results I am planning to set up a small NAS with a NUC board and 2x3.5" HDD-s (&lt;30W needed), and looking for a capable small PSU. (the supplied NUC PSU would most likely fail to feed the big hard drives) Do you have any chance to measure efficiency at idle? iFreilicht said: ↑ Boil is correct. The prototype parts are scheduled to arrive on the 3rd of May, so until then I won t do any testing. I say it is possible. The i7-6700 has a turbo clock of 4GHz and a TDP of 65W, the R9 Nano has a TDP of 175W. While TDP is not equivalent to power consumption, it s a good estimate. Give each of them 15W overhead (just to be sure) and you arrive at 270W, still way below the maximum 300W. You can easily put an SSD or two in there as well, still won t reach the 300W. Additionally, you ll never have GPU and CPU and all drives under 100% load at the same time, that s just not a realistic scenario. So yes, very much doable. Click to expand..."</post>
   <post id="67ba8ed7-b8f6-4b89-b14f-4e62f1e61a0f" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Unfortunately I don t have the test-gear necessary for that. The prototype parts arrived, so hopefully I ll get a chance to use this PSU until Friday or Saturday, but don t expect too much of a technical review. I can mainly run it and tell you how loud it felt to me."</post>
   <post id="e1f8293d-6ec8-49c4-b645-cc8b76b8a03d" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"I ordered one today, want to test 2 things: 1) Whether my case s C14 cutout fits 2) Noise @ load vs FSP 400W"</post>
   <post id="07bd7192-c208-400f-a446-0d04c6828286" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"For preliminary calculations, use these measurements (sorry, forgot to post them): You ll have to calculate the center point position yourself, I m in a hurry^^ Make sure to report your findings about noise, I d be very interested in that!"</post>
   <post id="893e8595-ec34-45c3-8975-8bae6397a912" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"That s worrying.. I drew up something quick and it s showing me there s 1.9mm between the top of the C14 connector, and the left-most 6-32 tap on top of it. Which means even if the cutout fits, you need to use a 6-32 screw with a screwhead diameter of &lt;3.8mm to not be obstructed by the connector. They didn t really think this through did they.. If I have to accommodate the measurements as they stand, the material between the cutout and the hole is somewhere along the lines of &lt;0.3mm. No thanks. I think the long term solution is to tell them to move the C14 connector down 1mm at time of assembly."</post>
   <post id="d3ac72b7-84b3-448f-b33d-b509d02494f3" section="Small Form Factor Systems" discussion="The Seasonic SSP-300SUG fully modular 150mm FlexATX PSU">"Yeah I think we ll just have to send them an email and ask whether that will be fixed. I can t imagine that being a knowing design decision, it just seems like a mistake that nobody has spotted yet."</post>
   <post id="e233d572-04ba-463a-b7bf-8627ed5fbda8" section="Small Form Factor Systems" discussion="Smallest 1U/Flex PSU &gt;700W">"I ve been playing with case designs recently since modding my M1 and been inspired by the GTR GT3-BH, Dan s A4-SFX and the Hutzy XS. There have been some PSUs that kick out a goodly amount of power but I wonder if anyone has found anything better. Obviously some of these aren t available but as a starting point: FSP500-50FSPT-FSP GROUP :::PC Power Supply, IPC Power Supply, Open Frame, Adapter ::: 500W in 0.495 litres (1010 W/l) (platinum rated) FSP700-80UEPB-FSP GROUP :::PC Power Supply, IPC Power Supply, Open Frame, Adapter ::: 700W in 0.972 litres (720 W/l) (platinum rated) Logic Case SC-SG1U700 | Single 1U 700W 80 plus PSU 700W in 0.88 litres (795 W/l) (gold rated) Has anyone come across something in the 900W range that could power consumer grade equipment (i.e. comes with PEG connectors for GPUs)?"</post>
   <post id="3b09ebec-c2bb-4499-8bec-c97381b88a8e" section="Small Form Factor Systems" discussion="Smallest 1U/Flex PSU &gt;700W">"1U high PSUs, no matter whether regular or FlexATX, are designed for server use, so they never have PEG connectors. If you put GPUs in your server, e.g. for GPGPU applications, you ll be talking about 3U racks in which you can use a much larger PSU anyway. The only company I know of that sells 1U PSUs with PEG connectors is AthenaPower, but their PSUs aren t even able to deliver their rated power, so I wouldn t recommend them at all. AFAIK, the FSP500-50FSPT has the highest power density of all currently available ATX compatible PSUs on the world. If you really want to go for the 900W range, use two of those in your case next to each other and use a double PSU adapter. That s the only way you can really get to this sort of power in that form factor."</post>
   <post id="9a50b186-f46c-41d9-8766-76ebbe470312" section="Small Form Factor Systems" discussion="Smallest 1U/Flex PSU &gt;700W">"Thanks for the info iFreilicht, will have to rethink plans."</post>
   <post id="7406bb45-d3f7-430b-b4e7-935639143fff" section="Small Form Factor Systems" discussion="Smallest 1U/Flex PSU &gt;700W">"Can t you use dual molex to 6 pin PCIE? Is this a horrible idea?"</post>
   <post id="6bffbbd9-4211-4e07-b1b9-a283adfdf71b" section="Small Form Factor Systems" discussion="Smallest 1U/Flex PSU &gt;700W">"Those work absolutely fine, but if you need a 700W PSU, you re probably looking to power two high-end GPUs, so you d need 4 of those, which means 8 IDE connectors on the PSU. Also, all of these PSUs have multiple 12V rails to my knowledge, so you need to make sure the load is properly balanced between them. Often that means you ve got to rework pretty much all 12V connectors, including the EPS12V one."</post>
   <post id="df48f26e-77fb-4273-8113-185d2931aa12" section="Small Form Factor Systems" discussion="Buildin  my first SFF PC!">"Hi everyone! I m extremely new here. A representative showed me this forum while I was on Reddit! I had lots of helpful members guide me- but I feel like I d get much more advice here since the subreddit is quite inactive. I sold my old gaming PC for 750 and would really like to have a PC that I can lug around no problem. I m in a dilemma. I need a PC that is quiet, cool, and can play games no problem. I have a small list here but I have tons of questions and would like to know if anyone can provide a bit of insight! Here s what I have currently on PCPP. PCPartPicker part list / Price breakdown by merchant CPU: Intel Core i5-6600K 3.5GHz Quad-Core Processor (Purchased For $0.00) CPU Cooler: CRYORIG C7 40.5 CFM CPU Cooler (Purchased For $29.99) Memory: Corsair Dominator Platinum 16GB (2 x 8GB) DDR4-2666 Memory (Purchased For $109.99) Storage: Samsung SM951 512GB M.2-2280 Solid State Drive (Purchased For $0.00) Video Card: EVGA GeForce GTX 980 Ti 6GB Superclocked Video Card (Purchased For $400.00) Power Supply: Corsair SF 600W 80+ Gold Certified Fully-Modular SFX Power Supply ($119.99 @ Amazon) Case Fan: CRYORIG QF120 Balance 49.0 CFM 120mm Fan (Purchased For $13.00) Case Fan: CRYORIG QF120 Balance 49.0 CFM 120mm Fan (Purchased For $13.00) Other: NCASE M1 (Purchased For $185.00) Total: $870.97 Prices include shipping, taxes, and discounts when available Generated by PCPartPicker 2016-05-17 00:57 EDT-0400 ______________________________________________________ I m going to be doing some light overclocking but may increase it over a certain period of time. I chose these parts from other s completed builds, but I still have a few questions. First of all, the motherboard. I need to have something really really nice that I won t have much problems with. Meaning... nice BIOS, easy overclocking, M.2 SSD compatibility (with the one I have now) and overall spectacular build quality. Next- the graphics card. I m seriously planning on getting the reference 1070, but I have the option to get a used 980 ti for 400 USD. I don t know which one to get! I will for sure be waiting to build my PC until after Pascal cards come out. One thing I d like to also receive information on is the power supply. I hear it s very good, but I don t know much other than I should be purchasing this. I m stuck on getting the 450 watt (I think it exists? Unless I mean the one by silverstone) version or the 600 watt version. I d like to save power and my electric bill is quite high. If I can save costs by any means I will do so. What option is best, and will support a card like the R9 390, 1070, 980 ti, etc? From what I ve been told they both can handle the cards easily. Another thing is the fans. I hope these are a good choice. It matches my CPU cooler and is relatively cheap. I don t want to spend too much on fans but I hear that they re good quality, good cooling, and relatively quiet. Lastly I d like to get custom cables so that I can make it look nice in case I want to add a window in the future and be spacious so I can easily remove parts here and there later on. I m pretty sure I don t need to get custom cables for everything- just the ones that are important. If anyone here has experience ordering them for SFFPCs, I d love to hear about it. I d like to know what the perfect sizes are and the only cables I need to purchase. I think someone said their quote online was about 50 dollars. The other parts I didn t mention is what I m pretty much set on. I got the SM951 M.2 512 GB SSD for free so I already have it! Other than that, thank you in advance! Thank you for reading too- I apologize for how fricken long this thread is. I really don t want to fuck up so I spent a long time considering what questions to ask. ++ If anyone has a bag or case that they use for carrying around their NCASE M1, please let me know! I d like to know how people lug around PCs to lans and stuff."</post>
   <post id="8a3d95ce-3292-4805-b71e-5da4adc6329d" section="Small Form Factor Systems" discussion="Buildin  my first SFF PC!">"Save 50 bucks &amp; get Corsair Vengeance LPX RAM, rather than the Dominator Platinum RAM… 400 bucks for a used 980Ti is pretty good, but if you are waiting until Pascal anyway, the newer card is a no brainer, 1070 or 1080… Only place I could see for a window on the M1 would be below the side fans, showing the top edge of the GPU…? As for MB, use the filters on Newegg &amp; narrow down what meets your wants (M.2 &amp; such) and go from there… 1 x M.2, 2 x M.2, 1 x Ultra M.2, Mini ITX, Intel 100 Series, LGA 1151, New, Intel Motherboards, Motherboards, Components - Newegg.com"</post>
   <post id="a1b80718-f174-4aef-82be-eb0f39efa2d0" section="Small Form Factor Systems" discussion="Buildin  my first SFF PC!">"Boil said: ↑ Save 50 bucks &amp; get Corsair Vengeance LPX RAM, rather than the Dominator Platinum RAM… 400 bucks for a used 980Ti is pretty good, but if you are waiting until Pascal anyway, the newer card is a no brainer, 1070 or 1080… Only place I could see for a window on the M1 would be below the side fans, showing the top edge of the GPU…? As for MB, use the filters on Newegg &amp; narrow down what meets your wants (M.2 &amp; such) and go from there… 1 x M.2, 2 x M.2, 1 x Ultra M.2, Mini ITX, Intel 100 Series, LGA 1151, New, Intel Motherboards, Motherboards, Components - Newegg.com Click to expand... I think the Dominator Platinum looks really good and holds its value because of it for resell purposes- plus I can fit it into my budget. More importantly, 450 watt or 600 from corsair s new SFX line?"</post>
   <post id="60bb1b88-6159-44db-87d7-fbbc7182b6fb" section="Small Form Factor Systems" discussion="Buildin  my first SFF PC!">"Gotcha on the RAM… Well, I just received a brand spanking new SF600 from a giveaway (smallformfactor.net) I entered  just because , not expecting to win AT ALL…! With a mITX build &amp; its attendant single GPU, most rigs would be pushing about 300 to 400 watts or so maxed out, and when are you really gonna see that, outside of running benchmarks &amp; stress tests…?!? So, the 600 watt model should actually be quieter, since it is hitting less than half load when actively gaming and the such… And if you ever transition that 600 watt PSU to a larger mATX rig, you have the extra power if you want to go SLI/CrossFire…"</post>
   <post id="d8e6aaeb-3dd8-4e4a-a3ae-7374f2580419" section="Small Form Factor Systems" discussion="Buildin  my first SFF PC!">"Boil said: ↑ Gotcha on the RAM… Well, I just received a brand spanking new SF600 from a giveaway (smallformfactor.net) I entered  just because , not expecting to win AT ALL…! With a mITX build &amp; its attendant single GPU, most rigs would be pushing about 300 to 400 watts or so maxed out, and when are you really gonna see that, outside of running benchmarks &amp; stress tests…?!? So, the 600 watt model should actually be quieter, since it is hitting less than half load when actively gaming and the such… And if you ever transition that 600 watt PSU to a larger mATX rig, you have the extra power if you want to go SLI/CrossFire… Click to expand... Agh, I really don t know what to do. Some are saying the 600 is louder, others saying 450 is quieter."</post>
   <post id="46aad77e-36f9-4294-93b5-32cedd9ed37c" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"http://www.tomshardware.com/news/corsair-sf600-sfx-psu,29317.html 600w. Fully modular. 92mm fan. The max power output of the SF600 is 600 W, as its model number implies, and its efficiency is 80 PLUS Gold certified. Although we usually find 80 mm fans inside such small PSUs, which in most cases are noisy, Corsair managed to squeeze a 92 mm fan into the SF600. The larger fan will be able to rotate at lower speeds, while providing enough airflow to keep the PSU at normal temperatures. The original manufacturer (OEM) of the SF600 is High Power, which lately has made a strong entry into the SFX PSU market where up until now, Enhance Electronics dominated the field. Click to expand..."</post>
   <post id="b1817697-de96-49fe-a626-828d4ff2495c" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"More photos"</post>
   <post id="fd7dce41-d4ff-4578-8422-ea262914363c" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"eager for reviews"</post>
   <post id="513f871d-ad13-4785-9c37-ea119c1321da" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"More interested in how it will compare to Silverstone s line-up."</post>
   <post id="26fef6c8-4efe-42b0-8e8d-4ba723bf4e5f" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Just sent a message to Corsair s Facebook and found out it s scheduled for a Q4 release. Guess we ll be waiting on those reviews. Hopefully it ll be ready by the time the A4 ships. Screenshot: http://1drv.ms/1MQaJEm"</post>
   <post id="90c1dbed-9281-4167-ac04-b510e4c9cacc" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Brandonandon said: ↑ Just sent a message to Corsair s Facebook and found out it s scheduled for a Q4 release. Guess we ll be waiting on those reviews. Hopefully it ll be ready by the time the A4 ships. Screenshot: http://1drv.ms/1MQaJEm Click to expand... They mentioned Q4 when it was first shown"</post>
   <post id="cb2edc4f-f096-49ab-bb11-938debb351ad" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"good to see more competition. maybe they ll also have an sfx-l sometime down the road too"</post>
   <post id="f893b89f-3870-4d75-9bbc-e4d75b780333" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Hanakuso said: ↑ They mentioned Q4 when it was first shown Click to expand... My bad. Didn t see it anywhere in the articles I scoured. Hopefully it s the start of Q4! I just want a quiet SFX PSU. It s too bad the fan in the Silverstone SFX makes that annoying noise."</post>
   <post id="8efed27c-980c-4789-956d-52cd1e4e00a1" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Hanakuso said: ↑ They mentioned Q4 when it was first shown Click to expand... That s disappointing, I was really hoping to use this in my itx build in the next couple months might have to get the silverstone, just to hold me over."</post>
   <post id="133fa5a4-713b-49f1-b6b0-b164532b6145" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"There s a number of concerning complaints about Silverstone s PSU. I really hope Corsair hits this out of the park."</post>
   <post id="9965c988-9b9b-4abb-bba0-869cd68650e4" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Prizm4 said: ↑ I really hope Corsair hits this out of the park. Click to expand... It looks really attractive, with a symmetrically placed 92mm fan. I guess they managed to re-arrange the inside to make the fan fit. It always felt strange that SilverStone only managed to squeeze in a 80mm fan in there. But... what are the odds Corsair launches the perfect SFX PSU? Close to zero, I guess. I am sure it will have some of the usual traditional problems; non-japanese caps to save $5 low quality loud fan to save $5 custom height on the fan (they like proprietary stuff), 11mm or something, making finding replacement fan impossible drowns the fan connector in glue, with an atomic bomb attached, making it hard to replace the fan messed up fan profile (too aggressive, goes from 200 rpm to 1500 rpm after temperature threshold X was reached) messed up passive mode (heard it was passive to 30% load, or threshold temperature?) coil whine (cheap components, don t want to spend $5 to "glue" the coils) suspicious not so easily replaceable fan grill, mounted form the inside (wrong grill pattern can cause more noise than others when air flows through)"</post>
   <post id="bf50d62a-4290-43f4-850c-d74cb0f982a8" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"I just want Seasonic or Superflower to come up with an OEM SFX psu design. Something tells me that is probably in the works since the SFF market has gained a bit in popularity. In regards to Corsair, the only units worth looking at are the AX series and possibly the HX series. The rest are just above average at best sacrificing quality of capacitors."</post>
   <post id="002991d3-bbd1-4f31-8f6c-779c47db2dee" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Mackan said: ↑ But... what are the odds Corsair launches the perfect SFX PSU? Close to zero, I guess. I am sure it will have some of the usual traditional problems; non-japanese caps to save $5 low quality loud fan to save $5 custom height on the fan (they like proprietary stuff), 11mm or something, making finding replacement fan impossible drowns the fan connector in glue, with an atomic bomb attached, making it hard to replace the fan messed up fan profile (too aggressive, goes from 200 rpm to 1500 rpm after temperature threshold X was reached) messed up passive mode (heard it was passive to 30% load, or threshold temperature?) coil whine (cheap components, don t want to spend $5 to "glue" the coils) suspicious not so easily replaceable fan grill, mounted form the inside (wrong grill pattern can cause more noise than others when air flows through) Click to expand... lol aint that the truth"</post>
   <post id="7fb08152-6514-4a36-af27-67128d5bfb6f" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"All I know is I m jumping ship the moment a better option than the SX600-G becomes available, the noise it makes is annoying as hell. Would be cool if Seasonic came out with an SFX PSU."</post>
   <post id="b1b90cac-52d6-42ba-9017-575882446773" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"About time Corsair.. wonder if this one will have 7 years warranty like other Corsair PSUs."</post>
   <post id="6b9f38b2-4017-48be-a650-241fe70c02db" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Is there any news about release date?"</post>
   <post id="1657f4a7-fae8-4b68-baba-d6fc86eadb5b" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Last I heard it was delayed to Q1 2016."</post>
   <post id="93506b3c-ca88-41e2-ad45-b446f2596420" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"I heard it was October... But now soon November. Tired of these paper launches and likely 6+ months of waiting."</post>
   <post id="e9a929e8-878f-431a-8e3c-363926c07067" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"I want this so bad! Cmon corsair! Talked with a rep that told me it was still on schedule for a Q4 release."</post>
   <post id="89c00b57-d6b4-4a73-831d-db32a8fafbd8" section="Small Form Factor Systems" discussion="Corsair SF600 600w SFX Powersupply">"Jonnyguru on Corsair forums said they are allocating the first batches for their Bulldog system, but that it s still on schedule for November release. Don t think their Bulldog system will sell, but the SF600 might. Best to keep expectations low, though."</post>
   <post id="04cff692-8d81-4f71-8439-358e951b5d20" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Latest update: Cable harness completed, first tests with new PSU Full update. Spoiler Because the stock harness of the SSP-300SUG didn t include PEG connectors, I had to make a custom one. This took quite a bit of work, but it was well worth it: I m also walking through the connectors and the problems that arise with the limited pin-count on the modular connectors. Short tests with the new PSU make me very confident that it will be bundled with the case in the future. It is very quiet in idle and has acceptable noise under load. The thermal divider isn t in place yet, so it could be that the GPU heated up part of the PSU and made the fan run faster than it would ve needed to. Current status: First prototype has arrived, and while it is not complete, but is already used as my main system. It is currently being used for functional testing. Overview: The Freilite Brevis S is designed to be a portable PC case with support for ITX mainboard, short GPUs and FlexATX PSUs. The goal in terms of size is staying below or at least close to 5L of volume. These renders don t represent the current state of the case. They will be updated soon. Specification: Specifications are subject to change during the development phase! Mainboard: mITX CPU Cooler: 38mm max. height GPU: Dual Slot, up to 183mm long, up to 148mm tall PSU: FlexATX, 150mm (Seasonic SSP-300SUG included) Storage: 2x 2.5", 9.5mm thick Components: Compatibility spreadsheet. Dimensions (W*H*D): 59mm*418mm*201mm Volume: 4.957L Material: Front Panel: 3mm brushed, anodised Aluminium Side Panels: 2mm brushed, anodised Aluminium Inner Frame: 1mm Steel, finish undecided Thermal Divider: 4mm Acrylic Features: Vertical and Horizontal orientation Horizontal orientation with vents on the bottom for placing underneath screens Easily modifiable Front I/O hidden behind door Footprint similar to TKL keyboard, fits in nearly every messenger bag or backpack Reversible PSU mount allows mounting PSU with cold side towards 2.5" drives Separated compartments allow components to get direct intake from the side and exhaust to the bottom, back and top without heating each other up Future Tasks: A second HDPLEX riser should be ordered to allow screwing the two main parts together. The thermal divider has to be prototyped to make accurate tests with the PSU possible. The design needs to be revised to fix issues discovered in the first prototype. The cable management solution and front mount are to be finalised, drawn and ordered. Same goes for the outer shell and front panel assemblies, but they have lower priority as they can be omitted or made by hand from wood. Updates: (Most of these updates are paraphrased, shortened versions of the originals. Links to those are included) 0. Original Post Spoiler After successfully finishing the Freilite Alpha in the PC-Q12, I of course had to notice how much space was wasted in that case because it wasn t designed for the components I built into it. So I got to the drawing board and managed to scrape off two more litres, arriving at currently just under 5L. This is the PC that I wanted to build when I built Alpha, and it is now time to make it happen! (Well sort of, I have to finish the design up, but I want to get it out there.) I proudly present: The Freilite Brevis S It s this small: Height: 420mm Width: 60mm Depth: 197mm Enclosing Volume: 4.96L It fits this stuff: Mainboard: mITX CPU Cooler: &lt;41mm PSU: FlexATX (150mm, supposed to be preinstalled) GPU: 180mm long, 115mm tall, 2 slots (Effectively all mITX GTX970 currently available) HDD/SSD: 2 * 2.5"x9.5mm It has these design ideas: Intakes on only one side: This allows the case to be placed under a monitor, be VESA mountable or placed in a HiFi-Rack without suffocating the components and allows an extremely clean look from one side. Recessed GPU: By recessing the GPU into the case, the PCIe brackets don t stick out the back and the cabling for its power connectors can run directly into the PSU cabling area. Portability: By being very thin and short, this case fits into many sidebags or backpacks while still leaving space for other gear. HDDs far from heat sources: By being placed on the cold side of the PSU and far away from the underside of the GPU, the HDDs experience the most minor heat from other components possible in such a small enclosure. Minimal waste of space: By using an angled flexible riser, having the PEG connectors intrude into the area in front of the PSU, letting the HDDs connectors intrude into the Mainboards PCIe connector space and using the space next to the GPU for a front USB3.0 cable, the height of the case is kept at a minimum while using every little bit of space available. Easy installation: To ease installation, most panels can be removed, giving easy access to most components. What s left to do before I can make it: Tasks: Thermal dividers between all three main components, maybe made out of acrylic Done Stands for vertical and horizontal mode Sample of the flex riser from LiHeat to make sure it fits Done Redo intake and exhaust holes Maybe done, maybe I ll redo them again Questions: Should the case be made a little bit taller to make sure the HDDs fit with mainboards that have their socket right next to the PCIe connector and wider GPUs? Currently you can only have two of the three at the same time or resort to one HDD instead of two. Yes, added 6mm to allow two HDDs always. How can I mount the HDDs? Adhesive tape seems like the easiest way, it decouples the drives and makes installation quite easy. But it seems like a cheap solution. HDD bracket is designed with no drawbacks from adhesive tape. Is there space for a TRRS 3.5mm audio jack? (That s what smartphones use.) I personally like that as a solution for Front Audio because you only have one jack which looks sleek but still maintain all functionality you d get from two jacks. Yes, there is. Now to designing a PCB for that. Is it possible to design the PSU mount in such a way that replacement PSUs can be mounted upside down? They should always have the hot side facing away from the HDDs and I d want to enable the use of other PSUs. Jup, done. 1. First design advances This is a multi-post update. Open the spoiler to see details. Spoiler The intake holes were reworked. Full post. The PSU mount was redesigned to be reversible. Full post. And a TRRS 3.5mm Audio Jack was added to the front. First post. While it looks much better than two separate jacks, it isn t standard for PC cases, so I also set out to develop a custom PCB to make this work. As it turns out, this is quite a complex thing to do if you want to do it right. More details in the full post about that. 2. The LiHeat Riser Full update. Spoiler To keep the height of the case down, an angled PCIe riser is required. The first company that I found to make decent quality ones was LiHeat. I ordered one of their risers and tested it a bit: It worked out fine, no stability issues or anything like that, but didn t do any benchmark comparisons. It was also determined that their A-Type riser, which is angled downwards, would work just as well while blocking less of the exhaust. More details can be found in the update about that. 3. Many new features Full update. Spoiler The thermal divider between GPU and PSU was drafted: Back vents were added for improved exhaust: The vents were redesigned once more: A concept for the Horizontal stand was designed: As well as a concept for a VESA-mounting solution: 5. New HDD mount and small changes This is a multi-post update. Open the spoiler to see details. Spoiler It was decided that I needed to switch from mounting the mainboard directly to the outer panel (like the LianLi PC-Q12) to having an internal frame that the board is mounted to, like regular PC cases do. That way, there s easy access to the back of the mainboard and side panels can be made from pretty much any material. A new HDD mount was also designed. It was decided later on that this would be made from steel rather than aluminium. 6. An add-on for more drives and an ODD Full update. Spoiler I had an idea how to make the case more attractive to users that wanted to use it as an HTPC and cared less about transportability. It uses the mounting holes for the horizontal stand. And this is what it could look like inside: Space for an ODD, up to four 2.5" drives or PCIe brackets to extend I/O. That draft doesn t allow for actual full-height PCIe cards, though: After exploring this, I decided that I should stop messing around and get on with actually working towards a first prototype. It was an interesting thought experiment though. 7. Small changes, first prototype ordered, HDPLEX riser discovered Full update. Spoiler The Kensington Lock Slot and Nameplate found a place on the cases back. Dimensions were slightly changed as well, the final height of the case is now 59mm. The main mount and GPU mount were ordered from a metal-working shop and are scheduled to arrive a month later. They are now to be made from steel instead of aluminium for higher structural integrity. I also discovered the HDPLEX Silicon riser, which is very thin and seems to be of high quality. It was tested a week later or so and I made a separate thread about that. 8. First prototype parts arrived! Full update. Spoiler The parts of the prototype arrived, and they re looking pretty good. And here they are with components mounted: I had to use the LiHeat riser, which is about 15mm too short, so the GPU mount isn t screwed onto the main mount at the moment. Everything fits pretty well, apart from the GPU, which uncovered a crucial design flaw: In a following up update, this was crudely corrected: It was also shown that the Seasonic SSP-300SUG, which is now a good candidate for being the included PSU, is not exactly adhering to the FlexATX standard, which results in a fitment issue: 9. Cable harness completed, first tests with new PSU Full update. Spoiler Because the stock harness of the SSP-300SUG didn t include PEG connectors, I had to make a custom one. This took quite a bit of work, but it was well worth it: I m also walking through the connectors and the problems that arise with the limited pin-count on the modular connectors. Short tests with the new PSU make me very confident that it will be bundled with the case in the future. It is very quiet in idle and has acceptable noise under load. The thermal divider isn t in place yet, so it could be that the GPU heated up part of the PSU and made the fan run faster than it would ve needed to."</post>
   <post id="50909380-ff46-40a8-a0e5-67fa1a27b096" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Looks great! How thick is the top panel? Maybe you could have standoffs pressed in or welded so you could attach brackets for the 2.5" drives to mount to rather than using tape."</post>
   <post id="40bbcf4d-d89c-41ae-8019-c3f28b258887" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Hey, good stuff man. Love the use of the FlexATX form factor PSU; it needs more love. I m about to get on a plane, but I ll have more comment in a few days."</post>
   <post id="f9fd2142-bdfc-4706-b3c8-a02cc09f5b06" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Aibohphobia said: ↑ Looks great! How thick is the top panel? Maybe you could have standoffs pressed in or welded so you could attach brackets for the 2.5" drives to mount to rather than using tape. Click to expand... Thanks! Both panels are 2mm thick. The Mainboard standoffs are already planned to be pressed into the bottom panel, so I thought about something like that as well, but it has drawbacks: Firstly, detaching the top panel would become a PITA and you d not be able to use short SATA cables any more. Some mainboards have SATA ports about 5-10cm away from the HDDs, it would be very nice if one could use those instead of having to use 30cm long ones. Secondly, decoupling would be a major design challenge as most rubber grommets that are normally used for that have a diameter of 1cm or more and there are only 11.5mm between the PSU and the top panel. And installing the HDDs without decoupling could prove to be a mayor annoyance, especially when the PC is in idle or just working as a music box. Maybe it would be possible to make brackets that attach to the thermal dividers I want to place between the three main components, that could be an alternative. esplin2966 said: ↑ Hey, good stuff man. Love the use of the FlexATX form factor PSU; it needs more love. I m about to get on a plane, but I ll have more comment in a few days. Click to expand... Thanks, yeah FlexATX has to be pushed! If I can get this thing to crowdfunding in time, our group buy of the 500W FlexATX PSU may be made even easier. Looking forward to it, enjoy your flight"</post>
   <post id="3f11097c-956f-4b99-a895-7ad4df97f395" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"I liked your last idea more I think you don t have enough space for bending the flex riser at the edge of the case. I m not sure if you ll be able to make a double bend like that you have at the back where you mount the card bracket especially with all side bends to attach top/bottom. Also I m not sure if the riser will survive the heat from the GPU back side. Isn t that why dondan s a4 have the riser on the side of motherboard rather than at the back of the GPU? Also if you re going for ITX only cards you have to support oversized ITX cards which are up to 130mm not 115mm. I don t like the idea of flexATX PSU use in htpc especially gaming one. People are running away from standard SFX psu s to SFX-L because of the noise and you re trying to sell them even louder stuff. The other thing about psu s is how the power is usually drawn from them might not fit the needs of GTX 970. Intakes all on one side makes the case cover not rigid at all, especially with your long openings like that. Also those are prone to let coins fall inside. Hard drives are just in the middle of all incoming heat - If the card isn t a blower type which is obvious for the ITX size, it will push the hot air in all directions. How are you going to mount the USB without screws sticking outside? It will be screwed to that internal panel with top and bottom fins for screwing covers? You ll need some kind of a stand for tall and thin case like this for vertical configuration. and finally 414mm is a big dimension. regardless of the volume you re coming close to a rack width. When you add the space for oversized itx gpu s and enough space to bend the riser you ll end up with 450mm which is even more than a rack width."</post>
   <post id="b05ec9da-dc3f-41b5-8060-d978fc1adb5f" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Hey Saper, you ve always the critical kind, but I actually have answers for close to everything. Thanks for your feedback! SaperPL said: ↑ I liked your last idea more Click to expand... I ll hopefully make that one some day, but I wanted to start with something more easy first. I think you don t have enough space for bending the flex riser at the edge of the case. I m not sure if you ll be able to make a double bend like that you have at the back where you mount the card bracket especially with all side bends to attach top/bottom. Also I m not sure if the riser will survive the heat from the GPU back side. Isn t that why dondan s a4 have the riser on the side of motherboard rather than at the back of the GPU? Click to expand... I got pictures from LiHeat with their older silver riser bent like that and even that one would fit. They have newer black ones which are thinner and have a lower bend radius and I think are even non-conductive on the outside. IIRC, dondan just said when he can choose between going for the mainboard side and the GPU side, he d rather take the former one because of heat. I don t think he said that there was actual danger of the riser malfunctioning. I ll ask the LiHeat rep about it, though. Also if you re going for ITX only cards you have to support oversized ITX cards which are up to 130mm not 115mm. Click to expand... I knew that would arise. They are 130mm from the farthest point of the PCIe bracket, but I did the measurement from the far end of the PCIe edge connector, which is about 15mm closer. There seems to be no standard for how to measure this, GALAX even measured the length of their ITX card from the far edge of the PCIe bracket which added about 12mm to the length which is why a lot of people thought it was even longer than the short Zotac 970. About the bends I don t know, I doubt that it could be made exactly like that, but there are ways to give the bending tools more room. I don t like the idea of flexATX PSU use in htpc especially gaming one. People are running away from standard SFX psu s to SFX-L because of the noise and you re trying to sell them even louder stuff. Click to expand... Well that s mainly personal prefernce, right? When you compare this to last- and next-gen consoles, my concept is whisper quiet The thing is, I do indeed want to sell something louder, but I also want to sell something way smaller. The other thing about psu s is how the power is usually drawn from them might not fit the needs of GTX 970. Click to expand... Not sure what you mean by that. The PSU bundled with this will probably be the FSP500-50FSPT, which can supply 288W on each of its 12V rails. There s no way even an overclocked GTX 970 can exhaust this. I m also thinking about the FSP270-60LE, which would be enough too, but I d rather have the headroom and efficiency of the 500W counterpart. Intakes all on one side makes the case cover not rigid at all, especially with your long openings like that. Also those are prone to let coins fall inside. Click to expand... Redoing the openings is on my todo-list, they are a bit too large right now. Why exactly would that cover have to be very rigid? It doesn t carry any weight of any components and the main rigidity of the case is already provided by the bent front panel and the completely closed bottom panel. Also what the hell, coins falling inside the intake holes? What should I expect people do with this case? Even the slots of your case are large enough to fit small coins, that seems like made up criticism. Hard drives are just in the middle of all incoming heat - If the card isn t a blower type which is obvious for the ITX size, it will push the hot air in all directions. Click to expand... Not sure whether you read the todo list I wrote, but there will be thermal dividers that force the hot air from the GPU to go out the other side. I think I ll even make them adjustable so they can be placed directly at the GPU cooler, giving the hot air no way to get to the HDD area. There will also be one of those dividers between the PSU and mainboard area so the PSU fan doesn t intake hot air from the CPU. How are you going to mount the USB without screws sticking outside? It will be screwed to that internal panel with top and bottom fins for screwing covers? Click to expand... Will be screwed to the internal panel with countersunk screws. You ll need some kind of a stand for tall and thin case like this for vertical configuration. Click to expand... You really didn t read the todo-list. That s already on there. I ll also make a stand for the horizontal configuration that will allow the case to sit inside a HiFi-Rack or under a monitor. and finally 414mm is a big dimension. regardless of the volume you re coming close to a rack width. When you add the space for oversized itx gpu s and enough space to bend the riser you ll end up with 450mm which is even more than a rack width. Click to expand... As I said, no space needs to be added. I ll maybe have a few mm more to make the HDD position compatible with boards that have their CPU socket directly at the PCIe connector. And yes, 414mm is a big dimension, but It s actually very well suited for the use cases I m going for: Placing it under a 22" screen is no problem as the screen itself is about 420mm wide, mounting it behind the screen works for the same reason. Putting it in a rack works nicely and it fits with the other HiFi equipment because of the width. Putting it inside a backpack works nicely even though it s so tall. Keyboards that have a keypad are about as wide, so if your bag can fit your keyboard, it can probably fit the Brevis."</post>
   <post id="049db965-091b-4f79-bae1-3366c74e1c3a" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"It looks like an interesting case, but three things immediately spring out: 1. Why run the USB cable all the way to the other end of the case when you can have it right next to the motherboard? 2. Turning the GPU over would make maintainability much easier and shorten the PCI Express ribbon cable. How is the GPU currently secured, anyway? 3. Is there actually enough room for two SSDs once cabling is considered?"</post>
   <post id="ad6c947f-8968-4338-b7b2-1ae14b1357af" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Quoting on this forum really sucks I d rather simply select the text I want to quite and click quote. Btw sorry for not noticing the TODO list earlier. Anyway: Here s the photo of asus 970 itx: Here s my model made from all data I could get(note that I have a different bracket model but that doesn t really matter) And I think you re still up to 10mm short on this problem. The noise of FlexATX psu is a personal preference. As for the other stuff - I didn t follow the thread on those flex psu s so that depends on whether they have PEG connectors and were tested properly in some HPC configurations (Nvidia tesla for example) or simply you will need to test it out. About the coins - we re addressing the same problem on our end and we re talking about possibility of shrinking those holes so stuff like coins won t fit. I wouldn t care about this as it s supposed to be a cheap case but it happens that people tend to ask about that a lot. About the thermal dividers - I m not sure if this is such a good idea - that means you ll block the path for designed exhaust. It might end up working as a blower type cooling but might as well block the air circulation. This needs to be tested, I think. As for the drive mount - you could make a simple bracket with two bends that would catch the PSU from the sides and have opening for drives. like this |__| but inverted. mount drives to this and put it over the PSU. Top cover would keep it in place."</post>
   <post id="d629b904-c2c9-47f3-a3f1-2a281b6dda62" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Quartz-1 said: ↑ It looks like an interesting case, but three things immediately spring out: 1. Why run the USB cable all the way to the other end of the case when you can have it right next to the motherboard? 2. Turning the GPU over would make maintainability much easier and shorten the PCI Express ribbon cable. How is the GPU currently secured, anyway? 3. Is there actually enough room for two SSDs once cabling is considered? Click to expand... 1. Because I actually can t have it right next to the motherboard. There isn t enough space there, it would interfere with RAM modules and other components on the board. But I may have to add room there anyway for the case screw that comes from the bottom panel. 2. Well it would make the design easier, but I think my solution does a good job at easing maintainability. 3. Yes, if you don t have an extended with GPU or if you don t have a mainboard where the CPU Cooler is right next to the PCIe slot. As I said in the OP, I should probably change that. SaperPL said: ↑ Quoting on this forum really sucks I d rather simply select the text I want to quite and click quote. Btw sorry for not noticing the TODO list earlier. Anyway: Here s the photo of asus 970 itx:[...] And I think you re still up to 10mm short on this problem. Click to expand... I ll check once I m at home, but I m pretty sure I got this right. The noise of FlexATX psu is a personal preference. As for the other stuff - I didn t follow the thread on those flex psu s so that depends on whether they have PEG connectors and were tested properly in some HPC configurations (Nvidia tesla for example) or simply you will need to test it out. Click to expand... Yes they will have the required connectors and well I tested one in my current build already, it worked out just as expected. They adhere to all standards that I know are required. About the coins - we re addressing the same problem on our end and we re talking about possibility of shrinking those holes so stuff like coins won t fit. I wouldn t care about this as it s supposed to be a cheap case but it happens that people tend to ask about that a lot. Click to expand... Wouldn t have guessed that anyone really thought of that as an issue. Maybe hex holes are better anyway. About the thermal dividers - I m not sure if this is such a good idea - that means you ll block the path for designed exhaust. [...] It might end up working as a blower type cooling but might as well block the air circulation. This needs to be tested, I think. Click to expand... There is the same kind of exhaust on the other side and the exhaust on that side will be blocked by the PSU either way. This way I ll just make the impact of the GPUs heat on the PSU lower. I will try to test this to the best of my abilities. As for the drive mount - you could make a simple bracket with two bends that would catch the PSU from the sides and have opening for drives. like this |__| but inverted. mount drives to this and put it over the PSU. Top cover would keep it in place. Click to expand... That s a pretty nice idea, I ll see what I can make of it."</post>
   <post id="be6f0a97-6f3f-434f-80e5-2476ffa1b3ab" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"So, about the GPU width: I got it wrong by ~1.5mm. My model is now a little bit larger than yours, but at least the distance from the edge connector to the side of the card is now 121.9mm as Asus is specifying on their website, that s the most accurate I can get without buying one of these."</post>
   <post id="3b5cdf55-1689-4687-850d-789b22367382" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Gigabyte states 129mm btw. Here s how I used that 121.9mm dimmension (rounded to 122): Anyway from what I get now, you were around 2mm short depending on how did you measure that. I ve got ~117.5mm from the connector to the other end including that PCB corner used to attach connector to. I know it s a mess with those dimensions at manufacturers but also that 115mm dimensions is really misleading. Btw did you think about switching sides of the front? I mean the power button and rounded corner at the card side and USB next to the motherboard?"</post>
   <post id="d8cabbde-24ca-49d5-b050-0f815c0acf0d" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"SaperPL said: ↑ [..] Anyway from what I get now, you were around 2mm short depending on how did you measure that. I ve got ~117.5mm from the connector to the other end including that PCB corner used to attach connector to. I know it s a mess with those dimensions at manufacturers but also that 115mm dimensions is really misleading. Btw did you think about switching sides of the front? I mean the power button and rounded corner at the card side and USB next to the motherboard? Click to expand... Jup that s what happened. I think I ll just ask support whether there is a drawing of the dimensions available. My guess would be no. Yes I did and boy, and there are a few things to consider there: The USB3.0 front cable (and possibly front audio cable) would be a lot shorter, which is great, but may require the case to be even taller because the only singular front USB3.0 I could find is &gt;3cm deep, and that s without the cable, see the picture below. The power button position may need to be redone. It can t be as high on the front as it used to be because that space is occupied by the GPU. When moving it as high as possible, it could easily interfere with the GPU power connectors and the PSU cabling. Having the Power button sit lower on the front also looks pretty bad in my opinion. It may both positively or negatively affect cooling performance. The GPU generates more heat, so maybe it may be beneficial to have it sit at the top. On the other hand, this may force the CPU fan to recycle more hot air than before. As you can see, there is a lot of room below the GPU that is used for the front USB. That s not available at the mainboards location. If there were USB3.0 front mounts that were only about 2cm deep, then it would work easily, but the other considerations remain."</post>
   <post id="2da00414-087c-4bec-a7db-ff04db108031" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"You could always use a different type of power button and usb port like those complete sets on pcb. This would let you loose that distance from the front of the case you re leaving for a power button and rounded corner."</post>
   <post id="3fbf3b86-35b3-42ed-8b7c-2b27b69ff9da" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"SaperPL said: ↑ You could always use a different type of power button and usb port like those complete sets on pcb. This would let you loose that distance from the front of the case you re leaving for a power button and rounded corner. Click to expand... That space isn t actually left specifically for those, it s there because the case has to accommodate cards up to 180mm length. I really, really want an LED ring on this, it just looks too good to switch to something else. As easy as that sounds, I have specific requirements for my front panel connectivity, so that PCB would have to be all custom, which can get quite expensive. I think I ll make a few mock-ups of the front and see what people like."</post>
   <post id="f26d3e0a-af9f-466a-a074-3ff2ea9579d4" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"With the GPU that way around, how do you actually get it in?"</post>
   <post id="68eb4d72-08d7-4fb3-ae93-ba3e6c111f9e" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"I think the idea here is to install the GPU before mounting the PSU and drives. I see no other options unless the outer front + sides wall is detachable from the bottom which would be weird."</post>
   <post id="a1796eca-9219-47fd-b718-85d19986b034" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Quartz-1 said: ↑ With the GPU that way around, how do you actually get it in? Click to expand... SaperPL said: ↑ I think the idea here is to install the GPU before mounting the PSU and drives. I see no other options unless the outer front + sides wall is detachable from the bottom which would be weird. Click to expand... Nope, I wanted to specifically avoid the need to install any component before another one, which was one of the main problems I had with the Freilite Alpha build. And yes, front and sides are removable which is a bit weird, but it is the only way to make installation in such a small enclosure easy. As you can see in the following picture, the back of the case is made of two pieces. The first one holds the Motherboard I/O and the PSU and should be screwed to the bottom panel at all times, there s no need to detach those two pieces from one another. The second panel holds the GPU and it has to be detached from the rest of the case to install or change the GPU. The basic idea for installation is that you remove all panels that aren t needed which allows to access all components as easy as possible. as can be seen in the OP:"</post>
   <post id="b068421e-017f-43e2-949a-0489cb8714f8" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Hey iFreilicht, I love the idea! The only strong suggestion I have now is that you drop the front USB and use that space for a good audio jack like you described. Definitely don t make the case larger just to accommodate a front USB."</post>
   <post id="48d1585b-b146-4351-9412-d750e1addc21" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"theGryphon said: ↑ Hey iFreilicht, I love the idea! The only strong suggestion I have now is that you drop the front USB and use that space for a good audio jack like you described. Definitely don t make the case larger just to accommodate a front USB. Click to expand... Thank you so much, that really made me smile It s amazing when someone is just half as enthusiastic about something as yourself! EDIT: I m not very keen on the idea of making the case any larger, either. Well ideally it would fit both. Would you prefer the audio jack for optical reasons or do you need its functionality more? Also, I m working on new ideas for the hole patterns, this is the first one. Shamelessly copied from the PC-Q12 and maybe some other LianLi cases, but I think it looks pretty clean without being overly boring."</post>
   <post id="c64d96b0-842b-4884-8192-f26f39ab8c47" section="Small Form Factor Systems" discussion="The Freilite Brevis S - A &lt;5L case with internal PSU">"Do people tend to use front audio jacks? I d have thought that rear jacks would be better (interference on the front jacks?), or you might use a dedicated amp/DAC."</post>
   <post id="246dc752-22a8-43d4-a34b-750293cc36f1" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Hi All Interesting? http://www.pcper.com/news/Motherboa...kylake-Based-Z170-Gaming-Mini-ITX-Motherboard"</post>
   <post id="cf153266-409a-4b0c-b856-c021e55b7401" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"In before "another black/red themed motherboard" But yes, very interesting. Hoping to see 80 mm M.2 and true PWM headers."</post>
   <post id="e16bb19d-f2ae-4be9-9261-31dab29b6e4d" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"this caught my eye when I saw photos of it yesterday"</post>
   <post id="11f06c4d-4a2a-4be2-a5d9-717f534e1438" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Oh my, what a board! ASrock is really pushing their reputation with the SFF community, I ve gotta say. Let s see if the details are right too, full length M.2 and PWM fan headers would be nice, they apparently have two case fan headers already, which is nice. If the quality of the audio circuit is right as well, they might make a fortune on this board, it seems to have it all. Would ve been nice if they could ve utilised the I/O space a bit better, though. There are quadruple stacked USB3 ports, I would ve liked to see that. Then again, they have three display outputs which I suspect can all be used at once, so that s rather useful as well."</post>
   <post id="e89341a3-2b5b-4ae7-80b3-04bdb83a1475" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"How long till we get multiple M.2 ports? No more excess power and sata cables."</post>
   <post id="01ab1dc4-9784-4384-8b80-5cc75aca04d4" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"you will be able to get multiple M.2 ports in the higher end ATX boards."</post>
   <post id="8bbf6d55-df60-4ccd-bf9f-6591eb935984" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"I m waiting for the board and Skylake to lauch... I haven t upgraded my desktop system in forever it seems."</post>
   <post id="d52e6df7-5335-4e0c-a45d-f7672ad0b936" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"silk186 said: ↑ you will be able to get multiple M.2 ports in the higher end ATX boards. Click to expand... I feel like in the days of surface mount components, we should have two M.2 slots on the back of at least one high end mITX board with Skylake. Then again maybe something like this will happen once M.2 WLAN chips become widely available, so manufacturers will just go with two M.2 slots instead of using an mPCIe one."</post>
   <post id="0ec6907a-5e4a-48c2-a544-3ee4754a3a46" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"I d actually rather have vertical M.2 mounts on the front side. Either like the Impact s M.2 or the WiFi card on the X99E-ITX."</post>
   <post id="359881de-ca70-40d9-a8b7-c6c438784422" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"I d very much appreciate raised M.2 slots - Right over the board s heatsink. Rear and vertical m.2 / mPCIe mounts don t play well with all SFF offerings."</post>
   <post id="a7947774-2010-4259-9118-78cd19f5324f" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Nice thread. We should keep it open and start post all new itx skylake mobos we find. Not only z170 but all above h110 atleast. I would like to see a board with double M.2 slots, one under and one on top. Other then that it s only a board with the best wi-fi on the market built in."</post>
   <post id="2d82fb60-6e43-45b6-97fe-743a5c9686be" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"I m waiting for a Z170 ITX with U.2"</post>
   <post id="17e08772-f1bc-42a6-917f-4953ffd245dc" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"jamesgalb said: ↑ I m waiting for a Z170 ITX with U.2 Click to expand... What s U.2?"</post>
   <post id="751fa9da-4be4-45a9-b47b-017a54948017" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Black5Lion said: ↑ What s U.2? Click to expand... The port that has basically made sata express still born. It was previously known as SFF8639. It s the port that the Intel 750 2.5" ssd requires. There are a few m.2 to u.2 adapters. Pretty much all motherboard manufactures are making them. The question is when will we see them on mainstream motherboards. I d like to see options for two u.2 instead of 2 m.2. Why? In sff systems rear mounted systems with no airflow wil end up with high end m.2 drives overheating and throttling themselves. The other benefit is u.2 ssd will always have much larger storage options."</post>
   <post id="33f45d87-a3e0-4b61-82cc-71f9f221af17" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Black5Lion said: ↑ What s U.2? Click to expand... the new M.2 Includes power from PCIe lanes, likely so the Full-Slot-PCIe and M.2-Like-SFF cards use the same standards. Also allows for a smaller wired connector so it doesn t need to be attached to the motherboard... and for some reason I am thinking it allows for quicker bandwidth because of that extra power, but I may be wrong there. Anyways, "Its the future" for SFF SSDs."</post>
   <post id="4cf6c3b8-6969-4ec2-9645-093a28d1f039" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"jamesgalb said: ↑ the new M.2 Includes power from PCIe lanes, likely so the Full-Slot-PCIe and M.2-Like-SFF cards use the same standards. Also allows for a smaller wired connector so it doesn t need to be attached to the motherboard... and for some reason I am thinking it allows for quicker bandwidth because of that extra power, but I may be wrong there. Anyways, "Its the future" for SFF SSDs. Click to expand... M.2 is for blade type ssds now and in the future. U.2 is for highend 2.5" ssds now and in the future. Right now the only real consumer option for u.2 is m.2 to u.2 adapters."</post>
   <post id="1fecd555-41be-44c0-91a6-d2a82bc3d2ae" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"wreckem said: ↑ M.2 is for blade type ssds now and in the future. U.2 is for highend 2.5" ssds now and in the future. Right now the only real consumer option for u.2 is m.2 to u.2 adapters. Click to expand... Yeah this needs to be clarified. M.2 is the new mPCIe/mSATA. U.2 is the new SAS/SATA/SATAe/ePCIe connector system. What it basically specifies is a connector that is compatible to current SATA drives, but can also carry PCIex4 signals so it acts as a replacement for the current SATA express connector. It is the same size a regular SATA Data + SATA Power connector have on the back of an HDD/SSD today, just in one connector that has a multitude of additional pins. Maybe, just maybe, we will see a standard for eGPUs with this type of connector?"</post>
   <post id="b27db840-9333-469b-bc93-42f3f74c28f4" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"As far as I can tell from the SFF-8639 specsheet, U.2 is the connector standard for the SSD end, and for the SSD end ONLY. What happens at the other end of the cable (i.e. the motherboard end) is undecided. It might be the HD Mini-SAS connector that has shown up on M.2 converter cards, or it might be something else entirely."</post>
   <post id="55a4833d-7321-485e-8454-ee1daaf5ef7d" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"EdZ said: ↑ As far as I can tell from the SFF-8639 specsheet, U.2 is the connector standard for the SSD end, and for the SSD end ONLY. What happens at the other end of the cable (i.e. the motherboard end) is undecided. It might be the HD Mini-SAS connector that has shown up on M.2 converter cards, or it might be something else entirely. Click to expand... Ah right, I found the naming of those different ends a bit confusing. Does the SATAe port on mainboards actually carry enough power for a 3.5" HDD? I guess it must because U.2 is compatible with those."</post>
   <post id="b6ab81df-ca76-4659-a554-9a396f3b6321" section="Small Form Factor Systems" discussion="Skylake-Based Z170 Gaming Mini ITX Motherboard">"Not too sure why everyone is against a rear-mounted m.2 slot as you can easily apply thermal pads to the drive and dissipate heat directly to the case; because the drives themselves are the size of a stick of gum the case should easily be able to handle the amount of heat."</post>
   <post id="dd06ed93-d4e1-4cbc-ad63-e27c895aec77" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"The original thread is so huge and I m really only interested in the delivery of v2 in August sometime. Thought I d start a thread specific to this version to share ideas and builds on it. Not sure if there is one. What do you guys plan for yours when you get it? I plan on moving from a sugo05 to: Black M1 v2 Gigabyte WiFi Board 16GB RAM i7 4770 EVGA FTW GTX 780 500GB Samsung EVO 1TB Hybrid 2.5 Windows 7/Hackintosh Not sure what to do about cooling. Thinking I ll go/try water all the way around as I plan on this being my permanent rig for quite awhile. Don t have a lot of experience except for AIO units like H60/H75/H80 Edit: Adding Necere s M1 Image Gallery http://imgur.com/a/zOoA2"</post>
   <post id="c19adb6d-ba81-44d1-9426-b140ee3d58f4" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"silver v2 4770k asrock z87e-itx 780ti or titan 16GB 256GB samsung msata drive sfx-l psu and a h220 + gpu waterblock setup. may or may not try a blu ray drive, and stuffing a pair of 4tb drives somewhere"</post>
   <post id="28248790-aeac-4ce5-9e68-fdfed0bddaa0" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Black v2 4770k Asus maximus impact Corsair 16gb Samsung evo 1tb ssd 780 ti Sfx psu Maybe a corsair h100i if it fits properly."</post>
   <post id="6abdcecb-381f-414f-b404-e5be4df6812e" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"I did have a pretty good idea of what I was going to put in mine 4770k 780 Ti Impact VI Slim optical drive 500GB solid state And custom water-cooling with the EK PE rad however this plan is going to fail because i don t think I have the funds, so I am either going to build a less supreme computer or save up my money until maxwell and broadwell come out as well as the silver stone 600W PSU and impact VII"</post>
   <post id="a63efa82-7bb3-46a3-8b26-ba8c00cfdcb1" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"What if we re not sure about it? I mean, I want to get this case but  the budget!  I would get the silver one with no slim ODD i5-4590 gtx 750 Samsung evo 250GB Crucial Ballistix Sport VLP 16gb Asus Z97i-plus sfx psu (not sure which one) Corsair H80i - does that fit? How loud is it? I only own the video card so far. Is the case overkill for my needs? I really like the versatility of it, though. Heck, I might turn into a gamer...no, better not.  Windows 7/Hackintosh  - how difficult is it to do that? I d go with DC if I was overclocking but cpu + M1 Case is probably out of my ballpark. Originally, I was looking at the Sugo SG05."</post>
   <post id="249cc4c5-1db2-413e-8c90-8f24431bb992" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Carbon_Le said: ↑ Black v2 4770k Asus maximus impact Corsair 16gb Samsung evo 1tb ssd 780 ti Sfx psu Maybe a corsair h100i if it fits properly. Click to expand... H100i from Corsair or the H220 (or CM Glacier 240L which is the same model) have been tested to fit. Some other 240mm might work but those are the two everyone else pretty much used for AIO H2O on the v1. I am in fact using a rare quad fan H100i setup."</post>
   <post id="4bd7800b-c33c-427d-9ea9-f78f02f0ced0" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Topweasel said: ↑ H100i from Corsair or the H220 (or CM Glacier 240L which is the same model) have been tested to fit. Some other 240mm might work but those are the two everyone else pretty much used for AIO H2O on the v1. I am in fact using a rare quad fan H100i setup. Click to expand... push/pull with slim fans? My build will be moved over from the original Ncase. My original Ncase will probably be built on a very tight budget for web browsing and light gaming."</post>
   <post id="f71a8de1-c6b2-484e-8ac4-0ee150da33b5" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Hanakuso said: ↑ push/pull with slim fans? My build will be moved over from the original Ncase. My original Ncase will probably be built on a very tight budget for web browsing and light gaming. Click to expand... Yes push pull with Scythe Slipstreams. Probably not an optimal solution but seems to work well enough (34c at 75F room temp for Idle, high fifties low 60 s at load). I wanted to try 4 lower RPM fans rather then two large fast fans that came with it."</post>
   <post id="594c45c8-d430-493f-a237-63f657beded6" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Thanks topweasel for the info. Cant wait until the case arrives."</post>
   <post id="92d41484-b017-48fc-b844-f130eb1c0511" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"When I eventually get my NCASE M1 v2, I m going to need some inspiration (and pictures) from you guys as regards to the best configuration for me. I m going to need this as quiet as possible with the best cooling fan combinations bearing in mind I will be having the Samsung 840 EVO 250GB SSD as a boot drive and also have 3 x 4TB 3.5" hard drives. I ll also be doing some light overclocking! Do I water cool my CPU and what s the maximum number of case fans that I can put in and also in what type of push/pull air combination?"</post>
   <post id="470b371b-85fd-4f7a-aeaa-455177718481" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"phillai said: ↑ When I eventually get my NCASE M1 v2, I m going to need some inspiration (and pictures) from you guys as regards to the best configuration for me. I m going to need this as quiet as possible with the best cooling fan combinations bearing in mind I will be having the Samsung 840 EVO 250GB SSD as a boot drive and also have 3 x 4TB 3.5" hard drives. I ll also be doing some light overclocking! Do I water cool my CPU and what s the maximum number of case fans that I can put in and also in what type of push/pull air combination? Click to expand... What did you have in mind for the GPU? That s the biggest source of heat, and will affect the rest of your build choices the most. I have to tell you, cramming 3x3.5" HDDs in the case with a GPU, while possible, isn t something I d recommend."</post>
   <post id="9f70f799-c7cc-4f94-8991-750ca6c8ad88" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"phillai said: ↑ I m going to need this as quiet as possible with the best cooling fan combinations bearing in mind I will be having the Samsung 840 EVO 250GB SSD as a boot drive and also have 3 x 4TB 3.5" hard drives. Click to expand... For those drives, I recommend you look at something like this: http://www.synology.com/en-global/products/overview/DS414j"</post>
   <post id="e7aa3c51-8da2-40dc-925f-4138b61d0dfe" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Crossposting to this thread, since you guys will probably find it useful: M1 user build gallery"</post>
   <post id="d140cd81-c4e0-4dd5-bcf8-34ce71d6f374" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"Right, I think I get it! So if I use the NCASE M1 v2 as my primary PC, could I get away with using just my Samsung 840 EVO 250GB SSD and 1 x 4TB drive? All the other storage that I would have put in my 3 x 4TB drives, I could put to my other HP MicroServer. Necere, I m definitelty thinking a very quiet mid range NVIDIA card this time in my new build."</post>
   <post id="dbc826ec-334c-4422-af6d-f08bac8d7abc" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"phillai said: ↑ Right, I think I get it! So if I use the NCASE M1 v2 as my primary PC, could I get away with using just my Samsung 840 EVO 250GB SSD and 1 x 4TB drive? All the other storage that I would have put in my 3 x 4TB drives, I could put to my other HP MicroServer. Necere, I m definitelty thinking a very quiet mid range NVIDIA card this time in my new build. Click to expand... Those microservers are pretty cool. They can run this."</post>
   <post id="9bdf07bc-ddc1-402e-84a0-a727597d1ce7" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"phillai said: ↑ Right, I think I get it! So if I use the NCASE M1 v2 as my primary PC, could I get away with using just my Samsung 840 EVO 250GB SSD and 1 x 4TB drive? All the other storage that I would have put in my 3 x 4TB drives, I could put to my other HP MicroServer. Necere, I m definitelty thinking a very quiet mid range NVIDIA card this time in my new build. Click to expand... I want to achieve the same with this goal of yours: "I m going to need this as quiet as possible with the best cooling fan combinations" Without all the HDDs. I will have some HDDs, but I plan on having them in enclosures. When I need them, I ll plug them in (USB 3.0, mostly). I also want low-noise and will wonder what fans to use and which cooling. Plan on using the same SSD. I bought a used Nvidia GTX 750. It s not dead quiet but it s not noisy. It s also short (EVGA). Not much for gaming but the other components I want to invest in, not the video card for now. Btw, Necere, thanks for the gallery link!"</post>
   <post id="215f84ae-0ead-499a-8cb7-e4a467ae2982" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"for those of you with the experience of water cooling your GPU in the US, where do you get the parts? i don t see many preassembled card like those from EVGA if any."</post>
   <post id="0264aeda-a7e6-423e-8123-baba4c577e7c" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"CHANG3D said: ↑ for those of you with the experience of water cooling your GPU in the US, where do you get the parts? i don t see many preassembled card like those from EVGA if any. Click to expand... im wondering the same thing."</post>
   <post id="ed0e5b82-02bf-498c-b3d1-dbd0d29079b7" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"FrozenCPU and PerformancePCs are the go-to online vendors for watercooling in the US. The reason to buy EVGA for watercooling is because they are the only GPU vendor that doesn t mind you removing the stock heatsink, and will accept RMA even if you have water cooled your card. At least, they were the only watercooling friendly manufacturer. Anyone correct me if I m out of date about that. Maybe others have relaxed RMA rules recently."</post>
   <post id="55b2ef1c-fd20-4919-94a3-b6043b69d181" section="Small Form Factor Systems" discussion="NCASE M1 v2 Build Thread">"There is a couple of planned EVGA HydroCopper in the plans on the Google spreadsheet, but no one has confirmed to have assembled one. I m wondering if it fits, cause getting a reference EVGA card and a EKWP cooler seems to be the more expensive way to do this; so why isn t just getting the HydroCopper more popular?"</post>
   <post id="a327c38d-ad2d-40d7-a089-e03e39b1457d" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Reserved."</post>
   <post id="bd33f28e-6db4-4e9d-84a6-12e20a59e557" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"----RESERVED FOR THE LATEST DESIGN STATUS INFORMATION ---- 5/5/2016: PSU shown to show general fit. Showing how to fit 2 hdd/ssd and bottom case fan and sfx psu. Design and Features blurb -- General Features: Simple, clean styling. Small form factor keeps desk uncluttered. Dimensions 5.3”w x 7.8”d x 9.6”t ( 135 x 198 x 244mm). Footprint 41 sq in (267mm^2). Volume 6.5 l. Substantial, corrosion-resistant aluminum and stainless steel construction. 2mm thick aluminum chassis. Stainless steel fasteners. Open physical architecture simplifies working in the case. 1-pc cover allows access to both sides and top of case. Only 4 fasteners needed to attach the cover. Accepts mini-ITX size motherboards (e.g. 1150, 1151, 2011-v3), including those with angled SATA-Express jacks. Cutout behind MB for access to backplane and cpu cooler bracket without removing MB. Easy access top-mounted USB 3.0 jacks and audio. Customizable, removable front cover plate. Rear mounted power switch to minimize clutter. Performance and Flexibility: Fresh air intakes for the CPU, GPU or other PCIE card, and PSU fans to maximize efficiency. Cover vent patterns sized to match up to all current MB cpu cooler locations and sizes up to 120x120mm, and all current gpu fan locations. Fits CPU coolers up to 2.48” (63mm) tall. Accepts full-height, 1 or 2-slot (1.7”, 43mm), ITX-sized GPUs or other PCIE card up to 7.4” (188mm) long, with clearance for PEG connectors. Flexibility to use any SFX or SFX-L PSU. Quick-disconnect 2.5” SSD/HDD mounts made of 301 stainless spring steel. Standard screw mount locations for 2.5” SSD/HDD to tie to chassis heat sinking, or use of vibration isolators. Flexibility to mix and match up to 3 SSD/HDDs (up to 15 mm), 80mm case fan, clearance for MB SATA-E angled connection. PCI-E 16x shielded riser cable supports Gen 3. High end GPUs that will fit: All R9 Nano GPUs GeForce GTX 970 GPUs: Asus GTX970-DCMOC-4GD5 Gigabyte GV-N970IXOC-4GD​ GeForce GTX 960 GPUs: Asus GTX960-MOC-2GD5 EVGA 02G-P4-2962-KR EVGA 04G-P4-1962-KR EVGA 04G-P4-3962-KR Gigabyte GV-N960IXOC-2GD Gigabyte GV-N960IXOC-4GD Gigabyte GV-N960OC-2GD (rev. 1.0) Gigabyte GV-N960OC-4GD​ Sapphire R9 380 100384ITXOCL Sapphire R9 285 2G D5 GeForce GTX 950 GPUs: Asus GTX950-M-2GD5 EVGA 02G-P4-1950-KR EVGA 02G-P4-2951-KR Gigabyte GV-N950OC-2GD MSI GTX 950 2GD5 OC ​"</post>
   <post id="6379d692-b8b4-4953-9c70-782092e843e4" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"(Original thread starter post moved here) After reading so much about the great cases being designed by the community (A4, M1, L3, etc), I came up with a case derivative idea. It is a bit of a niche idea: a case just big enough for the recent mini-ITX-sized high-end GPUs. Since there are now 5 mfgrs (Gigabyte, XFX, ASUS, EVGA, Sapphire) offering m-ITX models covering GTX960, 970, R9-380, Nano and R9-285, it might make some sense. It uses the fantastic layout of the opposed GPU/CPU in Dondan s A4 as the starting point, with the separated GPU and the direct cooling. My thought was the new GPUs (largest about 7.2") could yield a pretty small case footprint. The rough size is about 5.2" wide x 9.5" tall x 8.2 deep, which means 2 can fit side by side on 1 sheet of paper, which sounds pretty sweet. I put the PSU on the bottom to reduce the depth. I picked the SFX PSU which drives the 5"+ wide case requirement (it s not going to win any HTPC low profile contests, lol). I started with Flex and TFX, but as we all know the fan size is so small which drives the noise level so high, I couldn t stand the idea. I want to design a case that is so small it can sit on the desk without getting in the way, have enough power for gaming, and LAN parties or whatever, be able to hold 3 HDDs (2.5") and be simple to manufacture, and not look too horrible. It s around 6 liters, thus the name MI-6. I m still kicking around the idea, and it is a bit "nichey" but would appreciate feedback. Thanks. Here is a render of one side of the case."</post>
   <post id="abc95ef6-f5d0-48df-9335-78cfaf793195" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Looks like that worked, so here is the other side.. Thanks!"</post>
   <post id="a86f6aca-3330-4c01-9b3c-16883c4053d4" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"There s an edit button, you know? Also use something like imgur for hosting images or grab direct image url from dropbox to link it. Getting back to your idea: If you put the psu this way you end up with something that s not so efficient. You could just go without the riser and put psu over the motherboard and make it a nice small cube."</post>
   <post id="2238e467-b182-46c5-b27f-63f275b7635f" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Yeah, I see the edit button now. I ll get the hang of it I m sure. I can still learn new tricks. I got the links in there, but now wondering how to show images instead of links. I m having the PSU pull the air from the bottom of the case, not the inside, if that s what you are talking about. Do you think that would still be less efficient? Gonna need to add some case feet for air flow..."</post>
   <post id="22e6867c-7f47-4c93-a25f-27f1dbc400ca" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Would this be any smaller than the Osmi case?"</post>
   <post id="79659398-be8b-4573-9393-0f477a1b1124" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"It s about 6L, so yeah, a bit smaller"</post>
   <post id="f296c7d0-ec1e-41a9-94e5-90d4e4136cc1" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Links do not work"</post>
   <post id="2bc6328a-8e83-46e6-a07e-b7a1c6924454" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Added links to Google photo server as well as the drop box linked already. Hopefully the links work. If not, I ll open an incur acct and use that."</post>
   <post id="0c925407-0e04-4cb2-89bd-79cfac22e163" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Firewolfy said: ↑ Ok, I just linked to 2 pics. Click to expand... If you change the www.dropbox to dl.dropbox when embedding the images they will display. But it d be much easier to just use imgur."</post>
   <post id="340b8878-ada6-4840-bf11-d8c10cbe5a4b" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"The basic layout is nice, but couldn t you go even shorter? The 2.5" HDDs at the front could be turned sideways to fit below the Mainboard, in front of the PSU. Internal length could be 180mm."</post>
   <post id="369a699f-36ea-4e99-8efd-819bb65b931a" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Looks like the button on the front is about ready to hit the ram, I d guess that s why it s not shorter. I d also vote for a button in the back instead, clean front ftw."</post>
   <post id="c912fd34-dcdd-4942-a6c8-d58160c656d5" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"There are loads of different buttons, you don t have to use the vandal switches. It could also be placed on the top panel, on the front at the bottom or at the front at the left side where the GPU resides. There s space for the PEG connectors there anyway, maybe the switch would fit next to them."</post>
   <post id="9b15be83-8dc0-4bae-bb4e-80dcca96f8a8" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"I am working on some tweaks, such as putting the power button down with the USB and audio to simplify cable routing. I had wanted to keep the button isolated to prevent accidental pressing when messing with USB or headphones, but it would be nice to minimize cable clutter. I found a corsair combo front panel board that has all three. I ll see if I can put it in there. Nice idea on the HDD location. I am a bit afraid of the PSU cable spaghetti, so I was keeping a plenum area in front of the PSU. On the GPU side, I was thinking to keep about an inch of clearance in front just for airflow, since some blowers vent out the front as well... Hmmm"</post>
   <post id="441193e7-4738-4f1a-968b-3923d13e8ef0" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"I could move the HDD bracket up and out of the way of the PSU cables. I think most itx MBs have connectors coming up from the board. I have seen a few on matx where the sata conns come out the edge though."</post>
   <post id="fbfff150-1980-4eb7-8ee6-52154557470b" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Combo panels are a nice solution if you have the space for it. Cheap and simple. I wouldn t worry too much about the cables of the PSU, you ve got yourself a nice big area down there to tuck excess in, even with HDDs installed. Good thinking, but you ve already got that vent design on the front, why not just use that for exhaust from the GPU? There are two mITX boards that have SATA connectors on the edge as well, but with angled connectors, 10mm of clearance will be enough with your design, and you need that for the ATX24pin locking tab anyway."</post>
   <post id="3241c386-db39-4ee7-bc8f-89de2bdf739f" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Aibohphobia said: ↑ If you change the www.dropbox to dl.dropbox when embedding the images they will display. But it d be much easier to just use imgur. Click to expand... Thanks, I appreciate that."</post>
   <post id="e2510468-6f94-4631-b6d9-17e9d0fae506" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"Thinking about the cable management, the 4pin cable for cpu will a little bit long if it is surround the case or just simply across the mb at the front / back of the motherboard , if the display card have a 6/8pin plug, there are no way to get in from the top of the case, how about turning the mb and display card 180 degrees or just put the power supporter at the top of it?"</post>
   <post id="7d023802-5e85-4756-bc37-45ce852e0eb9" section="Small Form Factor Systems" discussion="MI-6: Nano-Class mini-ITX Case (status on 1st page)">"LOL, looking at my renders some more, it looks like I managed to inadvertently simulate rust along the bottom of the case. Wow, gotta get some rustoleum."</post>
   <post id="f0d2f0b9-5a6c-48be-aff9-f849409464da" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"I m looking to build a mini-ITX system, I noticed that there are shorter GPUs like the GTX970 available that are not full length, allowing the use of smaller cases. I m just having trouble finding such cases, most I ve found are longer to allow a good size GPU. P.S. Osmi looks to be the best answer using a SFF PS."</post>
   <post id="5275fa3d-986c-4e71-99ba-817196305b79" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Smaller cases like the Lian Li PC-TU100 @ 11 liters Or even smaller?"</post>
   <post id="f12add60-3fdc-41f9-b13a-499d6c5a267c" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Close, that case gives 193mm for the GPU, but the card here http://www.gigabyte.com/products/product-page.aspx?pid=5252#ov only needs 170mm, same as the motherboard. I see they slipped a fan in that extra space, which is a good idea, but the fan could be overhead."</post>
   <post id="215d55bc-b753-4da7-acab-24a5987c79c8" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"The Lian Li PC-TU100 at 11L and the Ncase M1 at 12.6L are about as compact as you can get and still use the GPU (even a short PCB card). Both cases are similar in size, but the TU100 has significant heat/airflow problems. If your budget allows, the NCase M1 is having it s third production run soon and their site is currently taking preorders."</post>
   <post id="32e6a4d7-c83e-4e1a-b79b-cf7afeb1077e" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"I don t think there are viable options as of now. NCASE are currently in the development phase of the LRPC, which is about 8 Litres but that still allows very large GPUs. If you are keen on modding, The LianLi PC-Q12(http://www.lian-li.com/en/dt_portfolio/pc-q12/) has enough space for a 150mm FlexATX PSU and a GTX970. But other than that, I don t know of any cases that actually emphasise the ITX-sized GPUs. Maybe it would be time for one to start doing that."</post>
   <post id="c366796e-8e6d-4bb1-a901-ae4e6e47ffd9" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Modding can net you a ITX gpu in a PC-Q02. See Neutronium V3 by machupo."</post>
   <post id="f87b234c-0d1d-4f19-ae30-411bcae14446" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Too bad PC-Q02 wastes space for optical. Seems like there is a potential for a nice case that is built for these short graphics cards."</post>
   <post id="f211bcef-0c80-4af1-9958-9b1c7f48646b" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"There s the Cooler Master Elite 110 - but I wouldn t exactly call that a "smaller" case. It s stubbier, for sure, and has a stricter limitation on GPU length, but it s not really small, as it is taller and wider than, for instance, the Silverstone SG05."</post>
   <post id="e792329b-0a3a-49c0-9366-13931cce78f1" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"andgo said: ↑ Too bad PC-Q02 wastes space for optical. Seems like there is a potential for a nice case that is built for these short graphics cards. Click to expand... Definitely! Especially if it were shipped with a FlexATX PSU (40.5*81.5*150mm), a box-like case could have dimensions of about 150*180*200mm, which equals a volume of 5.4L with room for one or two HDDs or a decent CPU cooler. And a DVR-like flat case could have dimensions of 400*180*55mm, which comes down to a volume of 4L with no room for anything. That would be nifty!"</post>
   <post id="6b73745b-924e-45fa-a409-f2df7bf4bb68" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"i ve been waiting for a case like this forever. essentially a short SG05. SG05 is still king though, even with a third of my SG05+short asus 670 rig completely empty it s still smaller than every other case out there and I can fit a decent CPU cooler on it too (samuel17)"</post>
   <post id="4bafc320-1014-4959-a8ac-5b8a32e6cebe" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Just go the SG05 and save yourself the trouble."</post>
   <post id="63ff04e8-12c9-4780-8fa5-9d7f3f58f98e" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Or get into some trouble and make the SG05 shorter yourself"</post>
   <post id="83f12cfa-c44d-4024-a6d0-fee9adf10850" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"I d really like to see something like a stripped-down sub-7L M1-style tower that only supports ITX-style and smaller GPUs. In my head, I kinda picture it like this.. First time messing with Sketchup, so not really sure where I m sticking things Panel vents would be as close as possible to both the bottom and side of the GPU, leaving just enough room for cables and filters. PP05-E flex cables would tuck in behind the mobo and then back up from under the 6x 2.5" drive bay. Would like the front panel to look like Aiboh s Nova with hidden slots for PSU intake. Actually, if removing a few of the 2.5" drives, it should fit up to 24cm GPU I think. The Samuel17 is pictured, but would like it to fit up to a C12 or maybe an H60 CLC. Dunno. Perhaps something like this already exists?"</post>
   <post id="22bd93e8-3aeb-4457-bf3f-d8b0cc879fff" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"I suppose I could add MiniMiniNova to my list of case designs to try Good job with the model, once you get the hang of it, it s really fun playing around with the different components and trying out different potential case layouts."</post>
   <post id="2b15db06-5e4a-45c5-b023-898db36223a1" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Aibohphobia said: ↑ I suppose I could add MiniMiniNova to my list of case designs to try Good job with the model, once you get the hang of it, it s really fun playing around with the different components and trying out different potential case layouts. Click to expand... Super-mini Nova! Well, I didn t smash my mouse into pieces while playing around w/Sketchup, so I guess there s that. Actually trying to design a case around those components.. no way"</post>
   <post id="83f96f3a-1294-4978-8884-2eba15d3d5fb" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"andgo said: ↑ Too bad PC-Q02 wastes space for optical. Seems like there is a potential for a nice case that is built for these short graphics cards. Click to expand... If you had a look at neutronium v3 you would see that he got rid of the optical drive space."</post>
   <post id="5cb51464-edc9-4bb4-86b9-e3f8ee1a70c9" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"Aibohphobia said: ↑ I suppose I could add MiniMiniNova to my list of case designs to try Good job with the model, once you get the hang of it, it s really fun playing around with the different components and trying out different potential case layouts. Click to expand... Nova -&gt; MiniNova -&gt; MicroNova (the above) -&gt; NanoNova (NUC)"</post>
   <post id="e2051bce-b576-46a7-bfdc-06280de7d9dd" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"rawrr said: ↑ If you had a look at neutronium v3 you would see that he got rid of the optical drive space. Click to expand... Could you link to the thread? The only thing I found was where he planned on a scratch build and then decided to use the LL case, but no updates after that. Also, I m not sure if I understand you correctly, but the point was that the case is larger because of the optical drive space, not that the ODD is a waste of space inside the case."</post>
   <post id="79e332e8-8149-46eb-b172-7f1b3c25a7fa" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"http://hardforum.com/showthread.php?t=1730666 Actually without the space for the ODD you wouldn t be able to fit a gpu in. By not using it and shifting the motherboard upwards, you can fit one in."</post>
   <post id="ee32adb0-9e5e-4ba8-9276-bc1372e4746f" section="Small Form Factor Systems" discussion="SFF Case for mini-ITX GPU/MB">"AFD said: ↑ Super-mini Nova! Click to expand... Great, now I m thinking of a water-cooling version of MiniNova instead AFD said: ↑ Well, I didn t smash my mouse into pieces while playing around w/Sketchup, so I guess there s that. Actually trying to design a case around those components.. no way Click to expand... Ah come on, it s only several months of work But really, it s not that the difficulty level is that high as far as skill, it s mostly tedious work making sure everything lines up and fits together. Having a basic understanding of the manufacturing processes involved is required though to make sure the design isn t impossible/really expensive to make. What I did was watch Youtube videos of laser cutters and CNC press brakes in action to get an idea of how they worked. Phuncz said: ↑ Nova -&gt; MiniNova -&gt; MicroNova (the above) -&gt; NanoNova (NUC) Click to expand... That would be confusing, Nova is the microATX and MicroNova is the short Mini-ITX"</post>
   <post id="605cf8cc-0ac5-4ec6-b911-39b129cab970" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"So this happened: SilverStone is flexing its engineering muscle, to woo the compact gaming PC community that the SFX-L form-factor of power supplies have arrived, and ready for multi-GPU. SFX-L is slightly bigger than SFX but significantly smaller than ATX. The company is ready with a 700-Watt PSU in the SFX-L form-factor. Part of the company s new SFX-L G series, the lineup will be lead by the 700W SX700L-G, followed by a 600W model, the SX600L-G. The company pioneered this form-factor with the 500W SX500L-G, earlier this January. The new PSUs will likely have enough juice and straws for gaming PC builds with up to two graphics cards. The two will boast of 80 Plus Platinum efficiency ratings. The company is expected to show them off at Computex 2015, this June. Source: TechPowerUp I m hoping this either doesn t have semi-fanless or a really properly NASA-engineered version. Nicely timed with the mATX case from Kimera Industries"</post>
   <post id="b2595bde-9f33-4111-a3cf-64496b413e03" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Nice. Tony did make it kinda obvious there will be something coming after the SX500-L but I didn t expect it this soon. I didn t realize there is a market for a 700 watt SFX-L PSU."</post>
   <post id="40e103e5-bffb-4bc5-9199-c872d70ba067" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"YEEEEEEES!!!!!!!!!!!!!! Dual Titan-Xs here I come"</post>
   <post id="c7260737-56db-4968-93be-62ab1c985c9e" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Phuncz said: ↑ So this happened: *pic* SilverStone is flexing its engineering muscle, to woo the compact gaming PC community that the SFX-L form-factor of power supplies have arrived, and ready for multi-GPU. SFX-L is slightly bigger than SFX but significantly smaller than ATX. The company is ready with a 700-Watt PSU in the SFX-L form-factor. Part of the company s new SFX-L G series, the lineup will be lead by the 700W SX700L-G, followed by a 600W model, the SX600L-G. The company pioneered this form-factor with the 500W SX500L-G, earlier this January. The new PSUs will likely have enough juice and straws for gaming PC builds with up to two graphics cards. The two will boast of 80 Plus Platinum efficiency ratings. The company is expected to show them off at Computex 2015, this June. Source: TechPowerUp I m hoping this either doesn t have semi-fanless or a really properly NASA-engineered version. Nicely timed with the mATX case from Kimera Industries Click to expand... So this is the one w360 talked about.. Looks nice, let s just hope silverstone doesn t fail again.. Tony, when can we have one?"</post>
   <post id="0806bfb9-8d8f-441f-b586-f641c179826e" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Showing off at Computex is one thing, availability another. I guess some time after the summer, at best."</post>
   <post id="71ac19a2-a37a-4802-877e-510f8fa8ad51" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Blk said: ↑ So this is the one w360 talked about.. Looks nice, let s just hope silverstone doesn t fail again.. Tony, when can we have one? Click to expand... I don t know if this is the one Wahaha360 was talking about, the "talk" was about a new SFX PSU made by Dirac, this seems to be an SFX-L Sirfa unit."</post>
   <post id="35c4c74b-b1d1-40f3-bf0e-ac99d4a050cc" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Phuncz said: ↑ I don t know if this is the one Wahaha360 was talking about, the "talk" was about a new SFX PSU made by Dirac, this seems to be an SFX-L Sirfa unit. Click to expand... Dirac is a distributor not an PSU manufacturer. More than likely the Dirac unit is based on this same Sirfa design."</post>
   <post id="626b58f1-13a5-42f6-916d-ea801fabe8d9" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"My wish did come true!!! LOL!!! THIS IS AWESOME!!!! I was hoping something like this would be release before the Nova.....ahhhhh mannnn I m getting excited!! Hurry up and get those cases rolling!! @Aibohphobia"</post>
   <post id="23f939e8-bdcf-4e39-9c6c-4d533dadc4c8" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"The TechPowerUp article does seem to suffer from some copypasta - the image says SX700-LPT but the text reads SX_00L-G, which doesn t match. If they do indeed score a platinum rating, it may suggest they have used higher quality capacitors, etc., to achieve this. No mention of the "semi-fanless" mode yet, but given its inclusion in the SX600-G and SX500-LG, I would say it s likely to return in these models. While I m excited at the SFX(L) models, and higher outputs, I m cautiously optimistic that there will be improvements to the fan (noise)."</post>
   <post id="9a832bdb-d0e4-4d0b-9d23-b9d66bb83758" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Phuncz said: ↑ I don t know if this is the one Wahaha360 was talking about, the "talk" was about a new SFX PSU made by Dirac, this seems to be an SFX-L Sirfa unit. Click to expand... This looks like 130mm, and w360 said that, there s probably no need to make changes for a ncase v4 (depending on the psu). Obviously the length is a problem, either silverstone will sell angled connectors or w360 was talking about another unit. But then again none of the other manufactures seems to be interested in sfx and w360 could be talking about other changes."</post>
   <post id="01d7cc71-e3f1-43f0-821a-3cd29c1b3249" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Phuncz said: ↑ I m hoping this either doesn t have semi-fanless or a really properly NASA-engineered version. Click to expand... Semi-fanless is a huge selling point for most people so I doubt they ll remove it. Even most members of this forum wanted it if you look back a couple years; I find it funny that we ve gone from "if only the ST45SF-G was semi-fanless" to "please remove semi-fanless" Really I just hope they took the feedback from the SX500-LG thread seriously and get to the bottom of the ticking noise - then everyone can be happy."</post>
   <post id="2b74839c-a387-472f-bed3-94af34eca006" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"goodbyegalaxy said: ↑ Really I just hope they took the feedback from the SX500-LG thread seriously and get to the bottom of the ticking noise - then everyone can be happy. Click to expand... Same root cause as the noise complaints in the 450w, 600w SFX models: cheap fans"</post>
   <post id="a18ba1a9-5812-4dff-b4bf-8b368aecdb93" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"I wonder if this would be enough to power a 395x2. This might just change my build for this year."</post>
   <post id="ef7ec9ea-3be9-442a-bc9b-40c9acc60bc6" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"I will give them all my money to own one of these. I imagine that if it was running at 60% or less load the fan wouldn t even be needed. Or at least, that s what I m hoping for.."</post>
   <post id="2b1c2767-2b55-4656-a13d-021459c27755" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Curiositie said: ↑ I imagine that if it was running at 60% or less load the fan wouldn t even be needed. Or at least, that s what I m hoping for.. Click to expand... The 300W SilverStone SFX is fanless to ~40% load. My napkin math puts the waste heat at that load at ~20W. The SX700-LPT at 50% load should be generating about 30W of waste heat. It s a bigger unit but the 300W casing is pretty empty while this will certainly be packed full so I d say the 700W will probably be fanless to about 35% load. You could do quite a bit with 245W though."</post>
   <post id="49ba7b6a-3b99-4060-bb59-65ded2b5ab3d" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Aibohphobia said: ↑ The 300W SilverStone SFX is fanless to ~40% load. My napkin math puts the waste heat at that load at ~20W. The SX700-LPT at 50% load should be generating about 30W of waste heat. It s a bigger unit but the 300W casing is pretty empty while this will certainly be packed full so I d say the 700W will probably be fanless to about 35% load. You could do quite a bit with 245W though. Click to expand... I m pretty sure my current rig is under 245W full tilt, Maybe I ll have to test your math once this PSU is available. 3570K/ 750ti"</post>
   <post id="887028ae-906e-4157-a557-9e88fc4affcd" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Tom s has more details on this - and has confirmed that SilverStone released this info, so we know for certain that it s legit now: Tom s Hardware said: Today, SilverStone sent us some juicy details about a new SFX-L format PSU: the SX700-LPT. The SX in the name indicates that it is part of the SFX series, the 700 is for its wattage, the L for the longer SFX format, and PT for Platinum. Yes, you read that right; this is an SFX-L PSU that can push up to 700 W and packs an 80-Plus Platinum efficiency certificate. It comes with one 24-pin ATX connector, one 8-pin EPS connector, three or four lines for SATA or Molex connectors (the total will be decided by how many connectors are on each cable, which is typically three), and most impressive of all, the image reveals not one, but two PCI-Express power headers (see the blue connectors). To each one of these PCI-Express power headers you ll be able to attach a cable that ends in two 8-pin PCI-Express power connectors, meaning that technically, if you really wanted to, you could drive two graphics cards from this little puppy. At press time, SilverStone hasn t yet revealed info on pricing or availability. And all of the exact juicy tech specs are still to come. Click to expand... It has the exact cabling you need to power two GPUs, which is great to hear - using adapters with the 500/600W units they have is clearly a bit of a pain (let alone quite messy)."</post>
   <post id="89671661-b83a-4684-9382-ebe79f4448aa" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Curiositie said: ↑ I m pretty sure my current rig is under 245W full tilt, Maybe I ll have to test your math once this PSU is available. 3570K/ 750ti Click to expand... It definitely is, a 5820K and a GTX 960 should draw about that."</post>
   <post id="aba740d3-921f-4f0a-b5e9-e6ad242a3ea0" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"Excellent. I suspect the semi-fanless feature remains, but addressed either with an improved fan or through higher wattage/efficiencies changing the threshold for activation. We ll have to see if that ends up being the case."</post>
   <post id="a748568c-3983-42a1-9831-2908467752cf" section="Small Form Factor Systems" discussion="Silverstone SX700-LPT 700W Platinum SFX-L">"I m sure Tony is tired of hearing us whine about the 500W and 600W so hopefully this has a fancy fan controller. Also, Noctua as a slim 120mm fan in development. They re usually a year from announcement to release and they announced it at last year s Computex."</post>
   <post id="49661883-47e2-4c5a-9fa4-c5c3d4f01514" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"It s always really bothered me that computers, cases, and airflow typically don t work well together, there s a lot of 90 degree angles, perpendicular cooling, and working against hot air rising. I had the idea to use PCI-Express extenders with graphics cards that have vertically aligned coolers (Gigabtye Windforce) remove the fans and to try to cool the whole system with only 2 fans and work with airflow and hot air rising. Here s my initial mock up, you could fit 4 3.5in drives on the opposite side of the motherboard, there s plenty of space back there because of the SFX PSU. If I was actually constructing the case, I would remove the shroud and fan from the PSU, It ll probably be nesicary to construct plastic air ducts to guide as much air as possible through the heat sinks. I m still looking for the ideal CPU cooler to use for concepting. I d like to keep it as quiet as possible, the top would have sound damping material that breathes to let the air out while minimizing noise and not holding heat next to your components. Currently cable management and wiring hasn t be given too much though besides leave some space for it. The SFX PSU as a lot of room to be re-positioned. Please tell me if this idea is stupid and why. Silent, powerful, and small PCs have always interested me. Please imagine vertically aligned heatsink without fans on the GPUs and CPU. I m planning on doing some photo-realistic renders once everything is planned and modeled."</post>
   <post id="6ad4cd0f-e4e8-43e8-b69e-6c7566529b74" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"Hot air does rise (actually cooler, denser air displaces it) but its effects at the small scale of a computer case is greatly overblown. That said, the basic concept seems feasible. What s that block at the top for? I think it d be a good idea to put two exhaust fans there if it isn t being used for anything."</post>
   <post id="cb434c49-1158-49ab-89a0-cb6d0ad296d3" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"I figured the top would let out the most noise, so I was planning on putting a few layers of sound damping foam, but it could be thinned out, or I could make it foam or space for slim fans depending on your wants. Also didn t want open vents dust could fall in when the computer is off."</post>
   <post id="3fb34c4e-6901-4bf0-9797-1b0b3266212f" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"Silverstone makes an entire series of cases with the internals rotated 90 degrees (the back of the motherboard is on the top of the case.) I don t know if that would interest you. Using PCI extenders isn t a terrible idea, but I think you re still going to need a fan on your CPU cooler/radiator with this setup because there just won t be enough airflow over it. That or a positively huge passive heatsink like the ThermalRight HR-22. Raven series. http://www.silverstonetek.com/raven/products/index.php?model=RV01&amp;area=en"</post>
   <post id="b3050db1-e88f-4b6e-855d-76f908d1e83e" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"Assuming the motherboard doesn t have the chipset far down enough that airflow to it would be blocked by the  front  GPU PCB, it could work. You d need to use aftermarket heatsinks with a vertical fin orientation, and the CPU would be getting hot air from the GPUs. Reversing the airflow direction (thermal updraft is such a tiny effect in a PC case it can effectively be disregarded) would avoid that. With CPUs having a much lower TDP than a pair of GPUs, this may be preferable."</post>
   <post id="b0d73794-fa60-45ac-9a63-e291cba48178" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"127mm x 310mm x 300mm = 11.8L Those are about the smallest dimensions i could see with this layout. Might need to expand some of those a bit for fitting. But yea, 12L should be Do-Able. That would give you enough space on both sides (or top/bottom for vertical) for 25mm thick fans. Rising heat is a lot less powerful than you think. It takes less than 10CFM worth of air movement to both counter and be more effective than convection. You don t really need to worry about it unless your going for a completely passive build. I would make the fans on both top and bottom (or both sides when horizontal) be intake, for a positive air pressure case, and plenty of cool air for both CPU and GPU regions."</post>
   <post id="4a0b05f4-4925-426e-aff6-d0e3273fbee8" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"I figured since the CPU heatsink could be larger in theory, that it wouldn t be a huge issue to have it after the gpu. Although if I had fans at the top and bottom you could easily reverse the case and test yourself. Maybe it would be quieter with 4 fans."</post>
   <post id="5b4b0466-2f44-46d3-ba7f-1bdb1e70a66b" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"I love the idea, and I think it would work perfectly fine! Actually, I did some testing with a mini-ITX board and a tower CPU cooler in this vertical setup. The results were quite impressive: When the mobo was oriented as in your case idea, the CPU (i7-3770U) could be passively cooled to about 50°C under full load, while the temps just kept rising when the board was oriented horizontally, and you could easily feel the airflow above the cooler. I think when you find the largest possible coolers, it would be possible to turn off all fans and make the system passive in idle, just letting the heat drive the air through the cooler fins. Of course, that won t be enough during a gaming session, but it should be quite an effective cooling system nevertheless. Additional idea: If you want to go as small as possible, you may want to try to use two FlexATX PSUs instead of one SFX. I have absolutely no idea how you would turn on the second one, but volume- and cooling-wise you could orient them in a way that would make the 40mm coolers obsolete. Placing one on each side of the motherboard would give quite a nifty system, but it s probably overkill. One last thing: Where is the SLI-bridge going?"</post>
   <post id="f05a53b9-1959-486e-ae62-ffc540927ba8" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"There s too much of the MB being blocked by the front graphics card and it looks like the SLI bridges wouldn t work. AMD crossfire would work, I suppose, but just looks a bit too infeasable to do. Go with a dual GPU card and an ITX mobo."</post>
   <post id="5148eb4c-f8b0-4523-95b3-8c553dca1b04" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"I haven t spent too much time looking at bridges, I could move the back GPU up to make the bridge distance shorter. There s no x99 itx mobo."</post>
   <post id="6757f556-f2ec-4b2a-9958-90bea915f94e" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"Ah, I ve got an idea! What if you turn the GPUs around by 180° so the SLI connectors face downwards? That would require a longer riser for the Card behind the motherboard, but I think it s the only way you ll get SLI working here."</post>
   <post id="d59dff67-38ad-4069-8311-44e3e33a9a02" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"medeyer said: ↑ AMD crossfire would work, I suppose, but just looks a bit too infeasable to do. Go with a dual GPU card and an ITX mobo. Click to expand... That s not the spirit man! We re here for innovation!"</post>
   <post id="b79f55b7-5a36-4331-aca6-a0e132c29611" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"rawrr said: ↑ That s not the spirit man! We re here for innovation! Click to expand... Well here s a suggestion since you re asking for innovation: instead of having one GPU on each side of the motherboard, have them both parallel one on top of the other in front of the motherboard so the whole lot are vertical. Like a GPU layer over the motherboard. I m not at home, so I can t do up a diagram in sketchup, so I ll attept to do it with text on my phone. |G| [M] |P| [O] |U| [T] |1| [H] ...... [E] |G| [R] |P| |U| [R] |2| [D] Hopefully that makes sense."</post>
   <post id="7042aa1f-a3a0-48cf-a0a7-71b7c396168b" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"I like that idea, but I think it would leave much to be desired for CPU cooling, plus there is no space for the PSU left. Code:"</post>
   <post id="fb0426c9-61b3-4b65-8723-0fbbc5e6157c" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"With the extenders its not so much the length as it is interference. 3M makes a 250mm one but it s ~$100 due to the shielding and materials."</post>
   <post id="d6f3a4c1-17fc-4e33-b5f8-f753f2f0c7c5" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"We still got LiHeat, they make shielded risers that seem to be of quite good quality. Not as top-tier as the 3M ones, but they also offer different insertion types, which can be quite helpful, too."</post>
   <post id="64caf838-78fd-4f39-bca6-d85b9c57e9f6" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"iFreilicht said: ↑ Ah, I ve got an idea! What if you turn the GPUs around by 180° so the SLI connectors face downwards? That would require a longer riser for the Card behind the motherboard, but I think it s the only way you ll get SLI working here. Click to expand... I tried to wrap my head around the SLI bridge connector orientations but my brain blew up. This hardforum-hardware-custom-SFF-case-tetris-trend is producing some really original ideas though"</post>
   <post id="1fe53730-4e11-4cbb-a726-285cb75cc7c7" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"PcZac said: ↑ I haven t spent too much time looking at bridges, I could move the back GPU up to make the bridge distance shorter. There s no x99 itx mobo. Click to expand... ASRock &gt; X99E-ITX/ac"</post>
   <post id="685a4e61-a9d2-45ca-b46e-7ef4db6e8799" section="Small Form Factor Systems" discussion="Probably a really stupid idea for a 12L SLI mATX case.">"16 month necro... Back then the board wasn t announced yet."</post>
<post id="158c9200-46b2-43a7-bba8-1546a9709081" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"SilverStone Reversible Phone Charging &amp; Data Cord - While this product is not in our wheelhouse when it comes to hardware reviews, it does come from a company that you are likely very familiar with, SilverStone. If you have a Smart phone, and you have to charge it, you might want to give this a read."</post>
   <post id="a9542833-81ea-4110-8d0a-1eb886c8b616" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Thanks Kyle, excellent write up. One thing isn t mentioned on their site is the amp rating of the cable. When charging did the cable get warm at all? What other products did you try charging? Edit: an issue I can see popping up in the future is the mechanism wearing out and the cable breaking."</post>
   <post id="b5e2c0ae-d3ce-45fc-85c5-6195387d2ec1" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Trimlock said: ↑ Thanks Kyle, excellent write up. One thing isn t mentioned on their site is the amp rating of the cable. When charging did the cable get warm at all? What other products did you try charging? Edit: an issue I can see popping up in the future is the mechanism wearing out and the cable breaking. Click to expand... Dunno amp rating, I have that question into SilverStone, and they are active on this board, so I would not doubt to see them post here. The cable has been used extensively for charging, charging while running video for well over an hour, and I have not had any issues with it getting warm. I have only used this on my phones here at home. I and I did comment on the mechanism and the cable quality in the article."</post>
   <post id="4c31b988-69a9-4c26-88b3-f7384a29005a" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Interesting cable, and more interesting timing. With USB-C coming around the corner, the micro-side is not long for this world. But the USB-A side is a nice little addition. THough I use wireless chargers pretty much everywhere now, I could definitely see picking one of these up for my car, and for no more than $5-7."</post>
   <post id="cddf1b89-2806-4ac0-aeb9-aeea1af563b8" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Kyle_Bennett said: ↑ Dunno amp rating, I have that question into SilverStone, and they are active on this board, so I would not doubt to see them post here. The cable has been used extensively for charging, charging while running video for well over an hour, and I have not had any issues with it getting warm. I have only used this on my phones here at home. I and I did comment on the mechanism and the cable quality in the article. Click to expand... Good to know. As for the quality, it may be of high quality but this is a tiny clicking mechanism, just a worry of mine as I m not declaring anything. I want this but only for my kids, they break cables every few months because they jam the cords into their device and usually in the wrong way, hoping these are easy to use. Not paying $15 though"</post>
   <post id="f980a8f2-97bd-49c3-aa0c-637a25fc7093" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"I ve already got a USB-C cabled smart phone. Had to invest in all new cables. Don t think any of them were Silverstone. Got cheapies off Amazon primarily. I guess I ll find out if they last or not, only been a few months."</post>
   <post id="fab46983-e42b-480a-b896-19caf102e99d" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"EODetroit said: ↑ I ve already got a USB-C cabled smart phone. Had to invest in all new cables. Don t think any of them were Silverstone. Got cheapies off Amazon primarily. I guess I ll find out if they last or not, only been a few months. Click to expand... Congratulations. I have registered an account after over a decade of lurking just to reply to you. You need to trash those cables you bought stat and get good ones. A lot of manufacturers are taking the USB 2.0 spec and slapping a USB-C connector on it. This is bad given the increased current capacity of USB-C. There is a google engineer who is testing random Amazon cables for this. One of those cables fried his Chromebook Pixel 2. A vast majority of the rest are about as bad. I garner you want to find out the quality of those cables without burning down your house. I can t give you a link because first post, but search for Benson Leung."</post>
   <post id="05a27133-9432-486f-8413-186ff0088622" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"OracleofEpirus said: ↑ Congratulations. I have registered an account after over a decade of lurking just to reply to you. You need to trash those cables you bought stat and get good ones. A lot of manufacturers are taking the USB 2.0 spec and slapping a USB-C connector on it. This is bad given the increased current capacity of USB-C. There is a google engineer who is testing random Amazon cables for this. One of those cables fried his Chromebook Pixel 2. A vast majority of the rest are about as bad. I garner you want to find out the quality of those cables without burning down your house. I can t give you a link because first post, but search for Benson Leung. Click to expand... Said Engineer s reviews: http://www.amazon.com/gp/pdp/profile/A25GROL6KJV3QG/ref=cm_cr_rdp_pdp"</post>
   <post id="880ca315-40d0-4a20-b71d-2060462de174" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"I d buy a couple 6ft and 10ft models if they d make them and lower the price just a hair."</post>
   <post id="ee5940a6-1cec-4a9b-8cb6-41bd4cbe6aa6" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Thanks for the review. Looks like a nifty product."</post>
   <post id="3a49cbf5-ef1d-41e2-923b-687138263738" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"If the cord is as good of a quality as Silverstone says, and if it were longer (five feet) then, to me, the $15 price tag would be appropriate. Thanks for the review, Kyle."</post>
   <post id="ca00bbbe-b1c3-403c-8766-0418d03a0ef1" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"OracleofEpirus said: ↑ Congratulations. I have registered an account after over a decade of lurking just to reply to you. You need to trash those cables you bought stat and get good ones. A lot of manufacturers are taking the USB 2.0 spec and slapping a USB-C connector on it. This is bad given the increased current capacity of USB-C. There is a google engineer who is testing random Amazon cables for this. One of those cables fried his Chromebook Pixel 2. A vast majority of the rest are about as bad. I garner you want to find out the quality of those cables without burning down your house. I can t give you a link because first post, but search for Benson Leung. Click to expand... I ll consider myself congratulated. I think. Here s the ones I got: Amazon.com: USB 3.1 Type C Cable, MoKo 3ft USB 3.0 Type A Male to USB 3.1 Type C Male peripheral or mobile devices Sync Transfer data &amp; Charging Cable Reversible Design for Google Nexus 5 / 6P, Nokia N1, WHITE: Computers &amp; Accessories Amazon.com: SIENOC Black 3.3ft 1m USB 3.1 Type C Male to 3.0 Female Data Cable For Macbook 12 inch etc.: Computers &amp; Accessories Amazon.com: Type C Cable, Yoozon® 3.3ft/1m 56k ohm pull-up resistor USB Type C to Type A (USB-C to USB-A) Cable for Nexus 6P,Nexus 5X,Oneplus 2 and Other Type-C Supported Devices: Cell Phones &amp; Accessories And one of these since the new phone didn t have any kind of flash slot: Amazon.com: PixelFlash USB 3.1 Type-C Invincible Connection SD + MicroSD Modular Card Reader with Detachable Cable SDHC, SDXC, TF Memory Adapter Secure Interface Zero Interference No RFI Issues: Computers &amp; Accessories Also, got one cable in the mail from the service provider for the phone by surprise about a month after I bought it. Edit: Wow that auto-linking of amazon links is annoying as fuck. Not my doing, the forums is doing it."</post>
   <post id="c8a7c736-e5d3-4d66-83e1-706e415366f3" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"EODetroit said: ↑ Here s the ones I got: Click to expand... I don t have any USB-C devices, so I only know vague generalizations like among the first 15 or so he tested, only one passed. There appears to be a community-tracked spreadsheet of said reviews. It s like the second result on Google. You should check out his reviews on Google+ and the spreadsheet for yourself. There s also some revision by manufacturers, issues with selling old stock, and whatever else. There was an app (CheckR) that checked cables, but was apparently less accurate than the programmer liked, so he pulled it."</post>
   <post id="dcd2277c-2272-4e32-9c4c-994c83fe4a94" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"EODetroit said: ↑ I ll consider myself congratulated. I think. Here s the ones I got: Edit: Wow that auto-linking of amazon links is annoying as fuck. Not my doing, the forums is doing it. Click to expand... So, there is a spreadsheet out there summarizing his findings: USB-C Cables and Nexus Accessories Yoozon is suspect: Amazon.com: Benson Leung s review of Type C Cable, Yoozon® 3.3ft/1m 56k ohm pul... Moko is a no-go per the spreadsheet. The Seinoc hasn t been reviewed yet."</post>
   <post id="93815c6a-d834-4463-83ae-ccef4bb50739" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"I like how this thread got changed into the USB-C thread... But this is kind of what Silverstone and another company with a successful campaign on kickstarter is facing. These reversible plugs are a little too late imo. And it ll only confuse other people when they pick it up and jam it into a USB-C slot thinking it s a type-c cable. I think where Silverstone might make more of a hit on is maybe a reversible USB type A hub if not multiport charger."</post>
   <post id="6b7b1d90-3458-418f-953b-91097779f58a" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Trimlock said: ↑ One thing isn t mentioned on their site is the amp rating of the cable. Click to expand... Amp rating is 2 amps."</post>
   <post id="a73f04b2-018d-4141-a585-2dc97d08977f" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Kyle_Bennett said: ↑ Amp rating is 2 amps. Click to expand... Thank you for the follow up! That is really good news, I only have one item that needs more than 2 amps."</post>
   <post id="f45d92d9-ff2d-4f1e-a7f5-f205e1ce5490" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"I bought a *three pack* of these from another manufacturer on Amazon for less than $10 on sale back in January. Listed as $11.49 now Amazon.com: USB Cable, 3 Pack Ace Teah™ 6.6ft Long Reversible Micro USB to USB Cable Nylon Braided Quick Charge Cable and Data Sync Cable A Male to Micro B Charge for Android Samsung - Green, Blue, Purple: Cell Phones &amp; Accessories Quality seems above average. The  A  end is a bit stiff to push in but that might be normal for the reversible types EDIT: Reading fail - the ones I got are not reversible on the  B  connector"</post>
   <post id="03b3e531-30b3-4c5e-b3dc-44efbad17620" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Nice cable design. Where the !@#$% were these things before type C came out? I have seen the reversible A connectors at the computer swapmeet for a few years, but it s of limited use, really the reversible micro is a big deal though. Combining both is awesome, and if the quality of the length of the cable itself is good I can see this being worth $10, $15-20 retail."</post>
   <post id="cbef1c84-33d0-405c-b125-43d15ea62401" section="Smart Phones and Devices" discussion="SilverStone Reversible Phone Charging &amp; Data Cord @ [H]">"Tweak42 said: ↑ Nice cable design. Where the !@#$% were these things before type C came out? I have seen the reversible A connectors at the computer swapmeet for a few years, but it s of limited use, really the reversible micro is a big deal though. Combining both is awesome, and if the quality of the length of the cable itself is good I can see this being worth $10, $15-20 retail. Click to expand... Yeah, now that I have a few where they come in handy, I don t see me giving these up."</post>
   <post id="11d8d70c-2f14-4988-ad20-1b815a17c23e" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Just wondering how many of you use your smartphone as your only mobile computing device when you are away from your desktop PC (i.e. you don t have an ultrabook, laptop, etc.)."</post>
   <post id="3460ce60-0207-4db5-b482-80586c8788ec" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"No idea how this could even be done."</post>
   <post id="6ce85afc-8fd2-4da6-b9f5-00397411af35" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Should have mentioned "general computing" (i.e. things you would normally do on a light-weight ultrabook). Stuff like browsing the Internet, posting on forums, watching a movie, etc."</post>
   <post id="f86b8ace-8fe7-40d7-a816-d1c2642917de" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I guess if it s a /really/ big phone, or you use it docked to a MHL display, and you have a BT keyboard (and possibly mouse). Still, seems a very niche use case. Are you considering trying this, or do you already?"</post>
   <post id="7798fcd2-b3b4-4c14-9f9d-25e8dd9856ca" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"nope. 5" phone, 7" kindle fire for magazines at a minimum. 5" is too small for reading, and anything larger is too big to carry everywhere for me."</post>
   <post id="72d1cc87-4e94-4893-b65e-b95d0a6b70e9" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"My phone is all I use. I have a Surface Pro 3 but that is only for recording music or typing documents. I so everything else with my phone. I was talking to one of my customers about this the other day. I never intended to become this way. It just happened. A testament to how powerful and versatile smart phones are these days. I have no use for any other device. I don t even have a desktop anymore. I m kind of over PCs. Nothing I do requires one. The Surface Pro 4 keyboard I got for my SP3 is more than adequate enough for any intense typing or other CPU intensive tasks. I really only use it for my guitar to use Guitar Pro 6 lol. And I could even do that on a phone too if I really wanted. I m using a G Flex 2 that I got last year for $250. I m planning on getting the Note 6 or the new Nexus when they come out this fall. A little bigger and higher quality screen will make the phone only situation even more fantastic. I think the stylus functionality would be something nice to have that I might actually use. I m excited to see specs for the Note 6."</post>
   <post id="ada972d9-157e-4d2d-a8fc-ca60b81c39b4" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I only have my phone and my desktop computer, and TV if that counts. I can do just about anything I need for work from my phone, it s just a bit of a pain in the ass do some stuff."</post>
   <post id="c8dbc44e-1e9a-4979-bf27-342ea990ca63" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Phone and tablet for me, though the tablet is pretty much only for media consumption. Working at home has made my MBP feel kinda neglected. Last time I used it extensively was over the 2015 Christmas holidays."</post>
   <post id="e6c48ed9-be7b-497e-aca2-c0aaaf580da3" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Screw that, nothing will be better than working, or even playing on, a decent desktop with 2-3 monitors. I m a big mobile user/gamer as well, but couldn t imagine using my phone and tablets exclusively."</post>
   <post id="c8801946-a6cf-4134-b9bd-2c68919989c4" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Why don t they just sell a display and keyboard, and the user docks the phone? Plus let it access an SSD as OTG. I don t want a dual-core Intel processor for a low price."</post>
   <post id="3756e9df-c0d9-418a-aae9-cab43a86e4d5" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Still waiting for a Surface phone to do just that... it could be the world s true pro phone."</post>
   <post id="ac19be27-4e78-40d8-84a2-347f45d71a14" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I can t stand smartphones. I inevitably end up pulling out my Microsoft Surface because I m just not satisfied with what phones can offer. Sometimes I use it in tablet mode with a pen, but often with the keyboard. Basically, I end up using lighter convertible laptops rather than phones. There are maybe four things I can stand to use a phone for... GPS system, receiving texts, phone calls, and a digital camera. I do not like surfing the web, fiddling with dumbed-down, stripped-down apps, playing games, or even writing out texts on a touchscreen."</post>
   <post id="5ac6a8bf-af51-4e1d-938b-af6b92614038" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I own a laptop and its basically permanently docked so for all intensive purposes it s my desktop. I habe several tablets and all are gathering dust. The only portable device I use other then my smartphone is my paper ereader.."</post>
   <post id="344a2cc0-98b6-4b50-adaa-a3ffc79b3d3b" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Media consumption only for my smartphone. Anything that requires some input more advanced than a block of text, I d prefer on something with better input mechanics. I regularly reach for my surface pro3. For example: Form filling on phones have always been a crappy experience for me, with the popup keyboard covering the text entry fields and dumb/aggressive spellchecks... Edit: and I totally despise mobile websites and their push for me to get the app. Just show me the damn content! (Yes I do desktop mode for the majority of sites, but I haven t figured how to do it by default)."</post>
   <post id="3255733d-827d-4588-8962-ae319cab6ccf" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I use an iPad Mini this way, I guess that s close."</post>
   <post id="5c18623b-64cd-4580-81c8-c209b227005e" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Hmm I ve got 5,5" phone, ipad mini, ultrabook and playstation vita to top my collection of mobile devices"</post>
   <post id="ce4ae2b0-bcf0-4973-af54-bf529b4ae32d" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"My wife uses her iPad almost exclusively: web browsing, writing, school work for her online program, etc. The only time she uses her laptop is if there an application or submission that isn t comparable with iOS or if there is a large enough project to warrant booting the laptop."</post>
   <post id="8dc460f5-8d4d-4621-a9dc-f3c75a36f396" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"I use my Note 4 for just about everything. I pay bills, do banking, social media, email, write notes down, GPS and navigation. Hell I only use my desktop for gaming. Its gotten so bad I can barely type on the keyboard when Im on my desktop. I actually have thought about downsizing next year when I upgrade to maybe the Galaxy S8 or whatever is out next February. Not sure if I will though, I really do love these Notes even though theyre kind of a pain to deal with sometimes due to their size."</post>
   <post id="e6236f5d-3ad9-4ce0-b398-1ba9964298f3" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Gookitron said: ↑ Media consumption only for my smartphone. Anything that requires some input more advanced than a block of text, I d prefer on something with better input mechanics. I regularly reach for my surface pro3. For example: Form filling on phones have always been a crappy experience for me, with the popup keyboard covering the text entry fields and dumb/aggressive spellchecks... Edit: and I totally despise mobile websites and their push for me to get the app. Just show me the damn content! (Yes I do desktop mode for the majority of sites, but I haven t figured how to do it by default). Click to expand... Wow, my experience with forms is great on a phone. Chrome has all my info saved and filling out a form is super easy. Rarely are there forms asking for stuff beyond that. It s literally one tap to complete a whole form."</post>
   <post id="ea49e2c4-08a3-42b5-9b7e-f82dc3efa986" section="Smart Phones and Devices" discussion="How many of you use a smartphone as your only mobile computing device?">"Nexus 6 here. No need or want for a tablet, or especially a laptop ever again"</post>
   <post id="ad5ed1b1-8a0c-4831-a044-b6bb3ae5e7b7" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"So the OnePlus Three ( Nexus 6-1/2 as I call it )should be announced later this Spring, and on sale around May / June. I am really torn on OPO as a company, on one hand I can t stand their cocky crappy attitude, and the stupid invite system just blows still. But the original OnePlus One for $349 truly was an awesome deal, matching the flagship specs of the HTC One M8 and Samsung Galaxy S5 which were selling for $750 for their 64GB versions. I am not saying the OPO was a better phone than the M8 or S5, but for $349 it was a pretty sweet bargain. As is the OnePlus X for $249, a very well crafted phone, and a nice 5" size, and decent spec s for a budget phone. The OnePlus Two = major turd to me, and I had ZERO interest in that, it seemed a step back for OPO, and a pretty big letdown. Word is that OPO has learned from the failed Two, and that the upcoming Three will bring them back to glory. OnePlus Three = $399 -SD820 -4GB RAM -3400mAh Battery -5.5" QHD Display -Metal body -Dual Speakers -NFC -QuickCharge -Rear fingerprint scanner"</post>
   <post id="2cdac3b0-10e3-42b5-97f2-ec08a0de517d" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Those rendors are supposedly from OPO leaked CAD drawings of the Three, found on a Chinese site in November."</post>
   <post id="f1df5a74-237b-4fce-a9d6-ab5482855d55" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Might consider it if I move to AT&amp;T with their new unlimited data plan. Otherwise they re useless on Verizon and I would rather get the next Moto X with the same specs and stockish Android. I wish more OEMs would put IR blasters on their phones though. I ve used the one on my M8 almost daily since I ve got it. So I m really looking more toward the M10 at the point and am hoping HTC just recreates the M8/M9 with updated specs. But I m sure they re going to do something a be more radical this time after the M9 failure. I just hope they don t drop the boomsound speakers, IR blaster, and SD storage if it s not 64GB standard."</post>
   <post id="f2698d68-d58d-4b6e-9229-4d83741ed2b6" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"I m interested to see of OnePlus can keep their game going. I m inclined to say no. The One worked because they kept it simple. They focused on what was important. It was as fast as any other flagship and had oodles of storage, for half the price of Samsung and company. They were smart about what to include, and where to cut corners. The camera was only ok. The screen was *only* 1080p (which is all you need, imo). There was no fingerprint sensor, no wireless charging. No fluff. For a lot of people, this was exactly what we wanted, and it was incredibly popular. With the Two OnePlus was trying to have a long list of fancy features, the exact opposite of what made the One great. Instead of cutting out features, they cut corners on quality. The fingerprint sensor was garbage. The camera still wasn t very good. The metal body wasn t very durable. The USB-C wasn t within spec. There was a reason other phones with these features cost a few hundred dollars more. If those specs end up being what s actually there... they are going to be in the same position they were in with the two. You can t cram all the shit from a $600-$700 phone into a $400 phone and have everything work the way it should. They are going to be cutting corners again to say all that shit is in there. I d much rather see a quality 1080p screen over a shitty QHD. Or a plastic body in exchange for a fingerprint sensor that actually, you know, works. If they release another over-promised, under-baked phone, people are going to stop giving a shit. To make it very simple... I went from a LG G2 to a OPO. At that time, the OPO was a better phone in many ways, and yet the G2 was still probably selling at the same price, or more. The OPO begged the question of what are we getting by spending $200+ more on a flagship... and that was a difficult question to answer. But when I went from an OP2 to a Nexus 6p, that same question got an answer. It was painfully obvious what my extra $200 was buying. Despite the two phones having the same specs on paper, I felt like I had just upgraded a generation."</post>
   <post id="bd6089f8-1c15-4f6b-ad18-23a7aebcc5b3" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"For sure the Nexus 6P is the best stock vanilla Android available today. Is sad there s only one high end stock Android phone, too bad they stopped making GPE phones. We ll see how the OnePlus Three pans out, could be another winner like the original One, or another turd Two."</post>
   <post id="72ddaef6-9a74-406a-babb-373f87df6104" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"My last three phones were Nexus4 -&gt; OPO -&gt; OPT. I got both the OPO and OPT on their release, and am currently still on the OPT. I completely regret getting the OPT, why oh why did I spend $400 for this thing!?! I should have waited for the Nexus 5X. When the OPO came out it was great for the price and I thought this company was a blessing from the heavens so I thought they could do no wrong. Right when I got my OPT I knew something felt off, but I shrugged it off. I made excuses as to why some of the features felt horrible. "They ll fix it in the next update" I told myself. "This OS will get better with time." No, it sucks. Back to pure Android I go :/"</post>
   <post id="68eec173-44ac-42e6-b9b8-0b2bb1e84bd9" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Welcome to the forum, deltfo. I m not interested in the op3 from that render because the dual speakers looks like they are both placed in the bottom. Also, Oxygen OS seems like a let-down at this point. And Cyanogen Inc is a bunch of assholes whom I would place among the likes of Walmart. With Motorola and Nexus prices, I dunno why people would continue to support OnePlus especially after the bullshit Two. They confirmed themselves to be cutting corners and making crap. No NFC? USB TYPE-C that ruin other phones? I d go with Nexus or Motorola anyday."</post>
   <post id="08a38634-170d-41cf-b303-68bdfed4b66d" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Prepare for another idiotic invite system"</post>
   <post id="9631ccfc-b2d7-4afc-976f-eca3c1f95901" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Oneplus hardware is OK. Their homebrewed Oxygen OS is marginal at best. I was a long time OnePlus One user as I got an early invite for it and used it for about 7 months. My son is still using it running stock CM. I bought the OnePlus Two and OnePlus X, both of which I sold for one reason or the other. The Two is more of a side grade from the One and Oxygen OS is most likely what makes it a side grade as it just was not and is not ready for prime time. It was more or less a beta release. The X, to me, was an experiment to see if the loyal followers would shell out for a pretty phone with old hardware. It s nice to look at and hold but that s about it. Lack of Band 17 for me on AT&amp;T was the largest issue as I could not get LTE so it was dog slow compared to my iPhone 6s Plus or Nexus 6P. If you are willing to root the devices and run a custom kernel or ROM then they are OK devices but if you just want to buy it, turn it on and use it there is a lot to be desired. I don t see Oxygen OS going anywhere as Carl has said that is where OnePlus expects to make their money, much like the other Chinese phone manufacturer s. The luster is off OnePlus as their forums are littered with customers complaining of issues, poor customer service, etc. And their fearless leader Carl loves to make outlandish claims but never quite gets to backing them up. One of my favorites: Carl has a long way to go to meet his claim that in 5 years there would only be Apple, Samsung and OnePlus left in the smartphone market. http://www.usatoday.com/story/tech/2015/08/02/oneplus-carl-pei-interview/30947799/ (August 2, 2015) USA TODAY: Where do you see OnePlus in the future? Pei: In 5 years I think it will be Apple, OnePlus and Samsung because there s no more room in the market. Everyone else would ve died because they couldn t reach the scale they wanted fast enough or they couldn t have a margin to sustain their business. Look at the soft drink space: there are only two players, Pepsi and Coke."</post>
   <post id="d4b26a04-9120-4c1a-a1da-4ddbb169940e" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"This supposedly leaked OnePlus 3 video is most likely fake, but we sure wish it weren t"</post>
   <post id="18c5343d-9f9c-43ce-8644-d2430e308198" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Its a good idea to amplify two channels versus a single channel to get louder sound, you don t need to use as much energy and there s a lot less clipping. I think most phones next big thing is better acoustics."</post>
   <post id="d3be3291-5057-4eba-9599-02172e9961c7" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Specs seem on point; the lack of NFC on the previous was kinda  baffling. Hopefully they don t cut too many corners."</post>
   <post id="043dbe3a-debb-4917-954f-5e196d6743d0" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"A lot of what they re including has been standard for a few years now, so prices are considerably cheaper."</post>
   <post id="89cb55cf-2984-4c3a-9b5e-6f7a39d22527" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"The OnePlus 3 is expected to launch "at the end of the second quarter," said Carl Pei, co-founder of OnePlus, in an exclusive interview with CNET en Español. Exclusive: The OnePlus 3 will launch by June "The US will be very important for us this year," says Pei, I wonder if Carls statement is a reality check after Xiaomi announced the Mi5 and the price. Mi5 has killer specs and an even more impressive price. OnePlus will have a tough time competing at that price point with those specs so now he plans on turning to the US where a high end phone can still be sold for $500+/- and be considered a good price. I loved the One. Hated the Two. Liked the X bit lack of Band 17 made me sell it. Curious to see what the Three will bring but if they can t figure out how to get the software right I can t see buying another OnePlus phone when so many other great phones with working software are available."</post>
   <post id="f0642125-9d31-49fa-904e-8ea0ad36f0e0" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Call me crazy, but I am actually very interested to see what the OnePlus Three is all about. To me these OPO phones are sort of like Nexus .5 releases, meaning typically better than than the current Nexus phone, but then several months later the next gen Nexus phone comes out being better. My main phone right now is a rooted + ROM d T-Mobile Note 5, which I like a lot. But...I still have my original OnePlus One, and running the latest CM13 ROM, I put my SIM back in it for the weekend, and this phone for being two years old, still feels very fresh and modern. CM13 is super smooth and fast on this phone, zero issues, and rock solid stable. I wasn t a phone of the Two, I liked the One and the One X. So here s hoping we get a kick butt OnePlus Three in that $399 price range, with flagship spec s, it is said will get the SD820 + 4GB RAM + 3,500mAh battery + 5.5" QHDScreen."</post>
   <post id="eed240cf-2e55-470e-86f0-393faf609eed" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"I m in the same boat as everyone else - One was great, Two was thoroughly mediocre. The little X was good though, if it had LTE support I d be all over it. I suspect the Three will do better than the Two but I don t think they ll ever recapture the magic of the One."</post>
   <post id="7f1c67d8-2e7d-4832-b298-da227d9a9703" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"project86 said: ↑ I m in the same boat as everyone else - One was great, Two was thoroughly mediocre. The little X was good though, if it had LTE support I d be all over it. I suspect the Three will do better than the Two but I don t think they ll ever recapture the magic of the One. Click to expand... If they would just go stock Android and concentrate on the hardware they would be further ahead. They just don t seem to be able to figure the software end of things out. The camera is a perfect example as they have used good enough hardware but still lack in the processing of pictures."</post>
   <post id="2244d499-9227-4416-8816-d707eacc156a" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"my oneplus one would randomly reboot once a day or every time I used the camera. so hopefully this new one doesn t do that"</post>
   <post id="c5209103-1ed2-499b-b5c4-3bc62c24f485" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Would people prefer an Honor/Huawei or Oneplus with the same specs and price?"</post>
   <post id="36f1bef3-61fd-48e2-aea1-51d5fe159098" section="Smart Phones and Devices" discussion="OnePlus Three ( 2016 )">"Oneplus easy"</post>
   <post id="7e7c45b7-4c32-4b76-8b87-42cd3d9359c4" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Well, my beloved 6P after just a few months has finally lost its luster. The data connection drops all the time. Cannot use streaming music at all without resetting from airplane mode back to reattach or get a new signal. Sounds like a widespread problem that Google has no intention of fixing. will be calling them about it but I know what that means. the runaround. I don t want a new phone, as I got a perfect phone other than this. Seems like it may be related to Android updates. Oh well, back to samsung or apple I guess. Thanks google."</post>
   <post id="6478758c-fdd2-4b12-bfd5-9b6a6d8489c1" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Is your 6P on Android 6.0.1? It seems like that particular update broke a ton of shit. I realize this is rather involved, but try downgrading back to 6.0.0 and see if that doesn t fix anything."</post>
   <post id="82ecab0b-8813-4ea9-b839-59cf836ccd6a" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"King of Heroes said: ↑ Is your 6P on Android 6.0.1? It seems like that particular update broke a ton of shit. I realize this is rather involved, but try downgrading back to 6.0.0 and see if that doesn t fix anything. Click to expand... I am suspicious of that update. However, I have done at least two updates since 6.0.0 so I am not sure if the first update broke it. Called google and they are all but blaming the carrier. Bullshit I said, because I was fine for a month or two after getting it. This happened either after a third party app was installed or an update. I am going to run in SAFE mode for a while to see if that fixes it. I love the damn phone, but if I can t fix it I am going to have to ditch it."</post>
   <post id="8b31d37a-1316-49e9-af2f-fc6f8ef06b96" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"I know the modem for 6.0.1 causes a lot of problems for many people. Could be worth unlocking just so you can flash the older modem (which works fine even in 6.0.1)."</post>
   <post id="0b61970e-e4a6-4867-8986-632c1754e0d6" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Seems like every phone I get is great for one month and then the shit starts to stink. Woe is me."</post>
   <post id="c3f7f99d-c830-420d-9ead-66022dce1201" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"This is why I disable all OTA updates and auto app updates. Almost always seem to make things worse. Or they fix or add something cool, only to screw something else up that was perfect. Android just pisses me off these days it seems."</post>
   <post id="c40665ad-9e80-4226-b368-8b139b22eaf3" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"BeavermanA said: ↑ This is why I disable all OTA updates and auto app updates. Almost always seem to make things worse. Or they fix or add something cool, only to screw something else up that was perfect. Android just pisses me off these days it seems. Click to expand... I agree, I have a 6P and thankfully I haven t had any major issues. I really love the hardware, but even being pure nexus I still get little glitches every now and then. stock apps will crash every now and then. It will flake out here and there when I click things. it will act like it s hanging and not responding and then will like 5x ffwd and catch up to the couple things I clicked on. Not major, but some annoying things. Sucks because the hardware is effing fantastic. Love the camera and finger print sensor. I really wish Microsoft would get their act together and actually put in the effort to join the smartphone ecosystem."</post>
   <post id="b8f5d5ce-2357-4364-8cea-3f0ba780c511" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Hmmm I have a nexus 6 on 6.01 and this is the first phone I have not rooted right away. had it about 6 weeks and it s pretty awesome."</post>
   <post id="51179138-e917-4364-b11f-efbfb1aebc97" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"I m currently running a 6.0.1 modem on top of a 6.0.0 ro. That fixed alot of signal issues in weak areas for me but the connection issue that others have been having by taking the entire 6.0.1 has been non-existent."</post>
   <post id="e415e306-4817-40a7-9184-e3513c48dda1" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Have you tried flashing older radio s? I ve had no issues but I m always typically in solid coverage areas."</post>
   <post id="a129a868-6de0-4ba1-80d8-87882872d297" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"HardUp4HardWare said: ↑ Well, my beloved 6P after just a few months has finally lost its luster. The data connection drops all the time. Cannot use streaming music at all without resetting from airplane mode back to reattach or get a new signal. Sounds like a widespread problem that Google has no intention of fixing. will be calling them about it but I know what that means. the runaround. I don t want a new phone, as I got a perfect phone other than this. Seems like it may be related to Android updates. Oh well, back to samsung or apple I guess. Thanks google. Click to expand... Damnit I was just about to buy one...."</post>
   <post id="f9c51aec-aae3-4448-8689-60c284b8bf5f" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"HardUp4HardWare said: ↑ I am suspicious of that update. However, I have done at least two updates since 6.0.0 so I am not sure if the first update broke it. Called google and they are all but blaming the carrier. Bullshit I said, because I was fine for a month or two after getting it. This happened either after a third party app was installed or an update. I am going to run in SAFE mode for a while to see if that fixes it. I love the damn phone, but if I can t fix it I am going to have to ditch it. Click to expand... Which carrier are you running? I haven t heard to many things about Huawei but I wonder if they could be the issue?"</post>
   <post id="e611f2c9-4818-4733-ac11-42afd6de84fb" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"This is the reason I left Android, it s very sad to see the unreliable updates hit vanilla."</post>
   <post id="b1cc8b76-38d4-4d52-8896-e89fefee9e7a" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Well, looks like I may be holding on to the One m8 a little longer."</post>
   <post id="e25c0294-b1da-404f-bc5d-505272805c55" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"Zibigan said: ↑ Well, looks like I may be holding on to the One m8 a little longer. Click to expand... How is it ?"</post>
   <post id="85e30cfd-547f-45f8-88ae-ecc73cf63dd2" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"I repair phones as my job, ill be staying with Sammy. Too much hassles and weird problems with other brands, HTC M8 is at the top section of my dont buy list, despite its seemingly nice interface, Sony Ive lost interest in and LG I hope makes a sturdier phone as planned in the G5 (and maybe modular?). Apple is on its own planet as far as I can tell, for the people who arent into real tech. East enough to fix an iPhone in most cases, but the look on a customers face when i tell em how much the repair of a 6S is gonna be is priceless. The S6 was pretty ordinary IMO, the S7 looks like its gonna be a stunner, I own a Note 5 and its great, my day to day is an S5 and Ive had very few hassles (mostly attributed to running out of RAM cos only 2gb), the Edge models are niche and also very expensive to repair. On the Huawei front Ive havent really seen anything out of the ordinary, but the majority of them are very basic. The Blackberry Priv steikes my fancy but I hear battery life and the keyboard arent that great, also yet to repair one."</post>
   <post id="4ffc7a56-41af-49bc-9eb1-10496e69044d" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"ComputerBox34 said: ↑ Have you tried flashing older radio s? I ve had no issues but I m always typically in solid coverage areas. Click to expand... I have not tried flashing anything. Will try to talk to Verizon before taking any more steps."</post>
   <post id="4726a8ef-ab22-45ef-bc4a-4db570bb5954" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"ledcriss said: ↑ Damnit I was just about to buy one.... Click to expand... I wouldn t let this problem stop you quite yet. It is still THE BEST phone I have ever had. I hope this will be resolved but many are not having this problem so who knows. When I look back the only other phone I wold consider is the iPhone 6S Plus but I just cannot stomach going back to IOS"</post>
   <post id="15899a75-a490-4d1f-b89e-59477612ed32" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"HardUp4HardWare said: ↑ When I look back the only other phone I wold consider is the iPhone 6S Plus but I just cannot stomach going back to IOS Click to expand... And I bet your head and your heart feel as bad as your stomach having to fathom that. Dont jump on that space shuttle dude, its a long road back."</post>
   <post id="563a2c82-f913-4800-82eb-76eb9de42621" section="Smart Phones and Devices" discussion="Nexus 6P the honeymoon is over">"SsmB_92 said: ↑ And I bet your head and your heart feel as bad as your stomach having to fathom that. Dont jump on that space shuttle dude, its a long road back. Click to expand... I know, dude, I know. must resist....."</post>
   <post id="d3d4271c-3cff-43b0-81ae-f4652b8ebabd" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I was just wondering if anyone else had one of these and if so what the reliability is on them? I got one for my Lumia 950 and one for my Dell Venue 11Pro..."</post>
   <post id="31fe834c-668e-4ded-ae26-a4b1d451356c" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I just put one into my backup phone (S5). My main phone - S6 Edge Plus - doesn t have expansion slots, so will have to wait until I get my next phone / S7? But so far it works fine."</post>
   <post id="c71b1729-a80b-49f1-a2b4-31d3345f250c" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I have the SanDisk one in my Surface Pro 3, and in my Galaxy note 4. Seems to work great. Performance wise on the Surface it works great as a second hard drive, and on the Galaxy note 4, i think it s limited by USB 2.0. I haven t run any benches to see what the performance is, but I don t notice any difference between that and the SSD in the Surface. Even use it for Torrenting."</post>
   <post id="6863e298-0202-4c47-a7d2-3e4e900632bc" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I ve tried it in my Note 3 but couldn t get it to read over 128gb. Oh well, it s in my PC now, no issues."</post>
   <post id="15372871-3231-49cb-b6c1-57af00f33f42" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"LG sent me one for free for the V10. When I ditched that phone for the S7e, the card went right into it."</post>
   <post id="57d8fa16-6a2d-4ba8-b2ad-78dd67d219c2" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I ve got a 128GB card in the S7 Edge... and there s nothing but pictures/video from the camera on it, cause I m too lazy to mess with ADB and get adoptable storage (or whatever it s called) working. Eh, not having space issues, anyway. Maybe one day."</post>
   <post id="d7fab7ed-a548-4b21-b448-fecff80c3ca3" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"Got the free 200gb card that LG sent me with my V10. Haven t had a problem with it yet, though I haven t used it heavily yet either. Just stores photos/videos for the most part."</post>
   <post id="4699d9a4-9989-4bf3-a9b3-5f708045aced" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"YeuEmMaiMai said: ↑ I was just wondering if anyone else had one of these and if so what the reliability is on them? I got one for my Lumia 950 and one for my Dell Venue 11Pro... Click to expand... It s almost 100% to be TLC memory right? Those aren t known to be reliable."</post>
   <post id="c211dd1d-d8b4-4cc8-b82d-785fb37e79f8" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I got a 128GB Samsung U3 card- I too have the 200GB card from the LG promo, but it found a home in my surface instead."</post>
   <post id="70b6104a-e02e-480b-ac32-5c3ee45db247" section="Smart Phones and Devices" discussion="Anyone else have a 200GB card in their phone?">"I have LG G4,,,,,,,,,, It s internal memory is 32 Gb but it can be more than 32 gb after slotting a SDcard on it.,.,,. It will be up to 200 gb"</post>
   <post id="14672f25-d637-4417-94fc-20068ac5d6fa" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Why does my screen keep turning on and showing the padlock every 5 seconds and how do I make it stop? I barely breezed through the settings, but saw nothing that would make me think it controls that. Untitled by OEM +, on Flickr"</post>
   <post id="a8176972-2c84-4022-99a1-4e524d055355" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Did you look in the display settings..? Open the settings app in the app drawer (or click the settings gear at the top right after swiping the notification shade down) &gt; display settings. Odd they gave you a 1.5 year old Turbo phone. Should still be a decent phone though."</post>
   <post id="0f18de27-78b8-4969-bb35-606fd3e8e7c3" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"You have a device with Active Display meaning it will "pulse" on occasion with notifications and whatnot - it s working as it should, to be honest. The display shown in the picture just means it s telling you the time and that the device is locked. If you put your finger on the lock icon and swipe down it ll unlock the device, that s how Motorola stuff works. On the Droid Turbo it might be renamed as "Moto Display" or "Moto Actions" from what it originally was when the Moto X came out, "Active Display." If you absolutely must get rid of that, go into Settings - Active Display and disable it. Most folks, myself included, consider that one of the better aspects of Motorola devices - it ll give you information on the display without actually having to wake it up which is of course a swipe away if needed. Droid Turbo is a damned fine device, really, even being basically 2 generations behind it s still awesome hardware."</post>
   <post id="2398f9fc-4d29-4063-a38d-57b146ffc7b6" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"It s the light sensor so you don t have to press a key to wake the phone up. Also if you swing the phone down twice - like a hammer - it turns on the light for a few minutes. Sweet features that I use on the daily."</post>
   <post id="eeb9e12d-88cb-4060-8b42-92bfa7dabcba" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"It just seems like a huge battery drain for no reason what so ever. The reason they gave me this phone is because I dropped my iphone face down squarely on the glass...seriously so flat that the phone didn t even bounce, it just stopped, from about 7 feet (I was on an 18 wheeler trailer). This phone was the cell phone of someone who just retired and the phone was just sitting around. So, rather than buying me a new phone, they just gave me this one."</post>
   <post id="bfcb58c1-0e4f-4159-a3a2-c05d82a8879a" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"OEM said: ↑ It just seems like a huge battery drain for no reason what so ever. The reason they gave me this phone is because I dropped my iphone face down squarely on the glass...seriously so flat that the phone didn t even bounce, it just stopped, from about 7 feet (I was on an 18 wheeler trailer). This phone was the cell phone of someone who just retired and the phone was just sitting around. So, rather than buying me a new phone, they just gave me this one. Click to expand... Active Display hardly consumes any battery, actually -- it s taking advantage of AMOLED only lighting up the pixels that are necessary. Remember, you can unlock the phone right from Active Display when it kicks in... really handy if you d rather not hit the power button."</post>
   <post id="77f3d383-4d6b-4a5f-88db-3a506031688e" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"When I had a Moto X (2nd gen 2014 model) that feature really surprised me. At first, it was annoying, but then I came to like it after a while. Now I miss it on other phones. The only thing I d like is an adjustment to make it slightly less sensitive. The Moto X was a little too willing to light up even with minor movement from some distance away."</post>
   <post id="cd3c636c-accc-4f70-99a5-884a69e5a82d" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"The active display is my favorite feature of Motorola phones, kinda wish others would implement their similar programs like motorola."</post>
   <post id="d68623bc-d129-40fb-bc6f-cc72e783e2cc" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"So this thread will just be my go to if I have any questions about this thing. How the hell do I get rid of the google search banner? Again, I searched through settings briefly but didn t see anything that jumped out at me as being the setting for this. I don t want it up there as I ll never use it: Untitled by OEM +, on Flickr"</post>
   <post id="06448db4-6ac5-49cc-a263-a11f19e72bf3" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Can you just hold in on it and drag it to the trash can (at the top or bottom of the screen depending on the launcher)?"</post>
   <post id="62f9c8c3-59b4-4793-a43f-fffda00052ce" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Nope. That was the first thing I tried."</post>
   <post id="df101c3f-b7bc-4ffc-863a-2daf2a4f1243" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Quick search showed this: Long press on any empty space on your home screen. This should bring up two sets of menus. Click settings, and turn off "Show Google search bar on home screen Click to expand..."</post>
   <post id="95665ce9-6621-4785-ad13-a6e7f87a5ae4" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"T4rd said: ↑ Quick search showed this: Click to expand... I don t think there is a way to do this anymore."</post>
   <post id="19daf001-d95f-400e-a755-59cd42c3fbc9" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"T4rd said: ↑ Quick search showed this: Click to expand... Awww shit. Thanks dawg. Quix said: ↑ I don t think there is a way to do this anymore. Click to expand... it worked!"</post>
   <post id="1aeacc7b-61d1-4dc0-a88b-75ef7fdf9fae" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"nxmbness said: ↑ The active display is my favorite feature of Motorola phones, kinda wish others would implement their similar programs like motorola. Click to expand... Honestly, outside of me devouring headphone jacks because I don t know what I do wrong, of every cell phone I ve ever had my turbo has been my favorite by a long shot. It s snappy still, it has a good screen, the battery life is still damned good. Honestly, my only complaint, is that I don t care for a display that is &gt;1920x1080 on a phone. Then it s eating up more battery, I d rather just have a lower-res screen and a super long battery life, and super powerful internals than anything else. But alas. Now here s to hoping project ara lets me build my dream phone..assuming it ever see s the light of day."</post>
   <post id="3af093cf-e189-4ff3-91f5-93b85f7c6b85" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Sadly i think Ara is dead."</post>
   <post id="b514beb5-ee9d-4256-bdf1-56faeb1f7d9e" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"So I ve had this thing almost a week. There are only two things I like about it. Weather on the main page or whatever you want to call it, and being able to wave your hand over to see if you have messages. Neither are good enough to get me to switch. But, I m not due for an upgrade until September, so who knows...maybe I ll like it by then? Doubtful, but since this is effectively a free phone test drive I m being open minded. The battery life isn t great. I use my personal iPhone significantly more throughout the day and I m getting about the same battery life AND it charges significantly faster."</post>
   <post id="95782996-f03e-4d5f-87f8-4ae038805d6e" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Wonder if they gave you the original charger for it. It supports Quick charge 2.0 and should be able to go from 0-100% in a little over an hour, so about 1%/minute at least until it gets to 90%+ charge. But you have to have a QC 2.0 (or above) charger to do this, which the original charger is."</post>
   <post id="2231c32a-c826-4d87-8eec-5235d15aae00" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"T4rd said: ↑ Wonder if they gave you the original charger for it. It supports Quick charge 2.0 and should be able to go from 0-100% in a little over an hour, so about 1%/minute at least until it gets to 90%+ charge. But you have to have a QC 2.0 (or above) charger to do this, which the original charger is. Click to expand... This is what I got when my HQ sent me the phone: Untitled by OEM +, on Flickr Untitled by OEM +, on Flickr"</post>
   <post id="4e2bb4fb-f0c9-4ca1-bfde-94d5965f2a58" section="Smart Phones and Devices" discussion="Work just gave me a Motorola Android phone">"Yeah, that s a crappy/old charger and not its original charger. Most (Android) phones use at least a 2A+ charger and that one is 1A. But the stock charger (and all other aftermarket Quick Chargers) will show outputs at 9V and 12V as well, with different amperage s equaling about 15 Watts. If you get a quick charger for it, it will charge significantly faster; at least twice as fast."</post>
   <post id="3f0a9324-a9b8-4b50-b4e5-00c54ba2b92b" section="Smart Phones and Devices" discussion="HTC 10">"Announced this morning. I was really hoping for stereo speakers and an IR blaster since I ve gotten used to them on my M8. HTC 10 Product page Intro vid Tester teaser testimony so far. Looks pretty good otherwise though. Not sure if I ll pick this up yet or wait or just get a 6P for now since I m leaving Verizon soon. This definitely seems more appealing than the G5 or S7 for me so far though. Edit: It looks like it does actually have stereo speakers still. Awesome!"</post>
   <post id="1c8c1978-76bb-4548-b1b7-5ad06617dbf4" section="Smart Phones and Devices" discussion="HTC 10">"Hands On With The HTC 10: A Fresh Start Anandtech has a pretty good hands on write up about the speakers. Evidently it sounds great. Almost like you have a pair of front facing speakers. HTC 10 camera overview: A great all-rounder for stills and video | DxOMark Apparently, DxOMark gave HTC 10 an 88 in camera score, a first place tie with the GS7 camera. Now I wait for the Huawei P9 scores. 5 best things about the new HTC 10 Lowest touch response latency, even compared to the iPhone. And 2 day battery life. (73 hours of continuous music playing?!?)"</post>
   <post id="e6f59abf-b86e-4149-a874-e93348b56e85" section="Smart Phones and Devices" discussion="HTC 10">"BTW, T4rd, not to go off topic or anything, but I strongly suggest you get a Logitech Harmony hub, companion, ultimate, or elite (or whatever the marketing names are). I have the "ccompanion " or smart control w/ hub because I like having a regular remote that lasts instead of having no remote or a remote that needs to be recharged every two days. As you know, I went from the M8 to the iPhone. So I had an issue with that. The harmony software is also so much better than whatever IR blaster app HTC had; was it Peel? I need to control three pieces of hardware to watch anything: TV, Receiver, and cable box or Amazon Fire TV. And the Harmony software controlled that much better. I get to switch between "TV" and Fire with one press of a button despite having to change inputs and powering down or up the cable box. I got my companion from watching deal sites, and it is a great time saver. This one is exactly what I got: Logitech Harmony Smart Control w/ Hub Logitech Harmony Smart Control w/ Hub $70 + Free S/H"</post>
   <post id="fade4de6-dea4-4eed-946c-e1106f2c621d" section="Smart Phones and Devices" discussion="HTC 10">"I am eagerly awaiting real reviews of the HTC 10. As long as battery life is on par with my note 5, which has the same size 3,000mAh battery, I know processors are different, but they should be sort of similar efficiency wise. When will carrier stores have them on display to fondle ?"</post>
   <post id="d87021a8-70a6-4a2a-840c-3d36a39cf6d5" section="Smart Phones and Devices" discussion="HTC 10">"HTC is advertising this with a 2 day battery life. How much do you need? LOL"</post>
   <post id="637358a0-1d97-41c7-a240-c0e40b03fd8d" section="Smart Phones and Devices" discussion="HTC 10">"It looks like a great phone all-around, but I m still taken (slightly) aback by the inclusion of AirPlay support. Yeah, it s probably just for audio, but think about it -- that means you can use tech that was previously limited to Apple hardware and software. I m primarily a Nexus guy when I buy Android phones, but the HTC 10 seems like it d be my pick if I were going to go non-stock. HTC s certainly better than most about timely OS updates."</post>
   <post id="d63ff94b-c3e3-47d4-8ad5-1984d9133e0f" section="Smart Phones and Devices" discussion="HTC 10">"This... actually looks like a desirable and competent phone from HTC. Even if HTC is making the Nexus 5 this year based on this phone, I might consider the normal version if Sense is really as near-stock as advertised so I can get the better camera software."</post>
   <post id="c4342d16-1cb8-4ed1-9d7a-67559df100dd" section="Smart Phones and Devices" discussion="HTC 10">"Luckily I m on JoD T-Mobile, but that $699 price is crazy IMO, compared to the Nexus 6P can be had brand new for $449. I would never pay $600+ for a smartphone, that s absurd. When the Nexus phone is almost every bit as good hardware wise, and better software wise. But with the 6P being 1/3rd cheaper, I would still recommend that over any new flagship today, price being a main reason. Or the S7 Edge being what $750, that s insane, and the iPhone 6S Plus being like $800 LOL, who the F would pay those crazy price for a smartphone ? When the Nexus 6P is so much cheaper, and really near as good."</post>
   <post id="25a9fc7c-ab9e-4a45-b6ba-ce2a6036e7fd" section="Smart Phones and Devices" discussion="HTC 10">"Zorachus said: ↑ Luckily I m on JoD T-Mobile, but that $699 price is crazy IMO, compared to the Nexus 6P can be had brand new for $449. I would never pay $600+ for a smartphone, that s absurd. When the Nexus phone is almost every bit as good hardware wise, and better software wise. But with the 6P being 1/3rd cheaper, I would still recommend that over any new flagship today, price being a main reason. Or the S7 Edge being what $750, that s insane, and the iPhone 6S Plus being like $800 LOL, who the F would pay those crazy price for a smartphone ? When the Nexus 6P is so much cheaper, and really near as good. Click to expand... I would hope carriers would offer it a bit cheaper, esp. since it seems that the T-Mo units are coming without the headphones, which is ghey."</post>
   <post id="8abc37c1-702a-4ba2-8f21-f8b8ee9e5910" section="Smart Phones and Devices" discussion="HTC 10">"Zorachus said: ↑ Luckily I m on JoD T-Mobile, but that $699 price is crazy IMO, compared to the Nexus 6P can be had brand new for $449. I would never pay $600+ for a smartphone, that s absurd. When the Nexus phone is almost every bit as good hardware wise, and better software wise. But with the 6P being 1/3rd cheaper, I would still recommend that over any new flagship today, price being a main reason. Or the S7 Edge being what $750, that s insane, and the iPhone 6S Plus being like $800 LOL, who the F would pay those crazy price for a smartphone ? When the Nexus 6P is so much cheaper, and really near as good. Click to expand... Wish folks would stop saying that every phone should be priced like a Nexus. Google sells its devices as cheaply as it does because it doesn t intend to make a profit on them; they re ambassadors for Android. You can certainly say that you d rather get a Nexus 6P for the price, but I wouldn t call $699 crazy. It s roughly on par with high-end phones from companies that want to be profitable. Remember: for many people, a smartphone is more important than their computer at home. Dropping $699 on it every 2-3 years is reasonable for such a crucial communication device."</post>
   <post id="3ae7c33f-ebf1-4134-bf5c-405ec76f3063" section="Smart Phones and Devices" discussion="HTC 10">"Let s face it. The Nexus 6P is no where near the quality of a GS7, HTC 10, or even the Huawei P9. Let s use your best case scenario argument of the P9 for being the cheapest of the three, and it s $599. So a hundred dollars means HTC quality, better UI, better warranty with coverage even with bootloader unlocked so better developer support. That s worth the $100 extra bucks."</post>
   <post id="528a9caa-2269-4622-b6ae-b8a4dc462f9d" section="Smart Phones and Devices" discussion="HTC 10">"CHANG3D said: ↑ Let s face it. The Nexus 6P is no where near the quality of a GS7, HTC 10, or even the Huawei P9. Let s use your best case scenario argument of the P9 for being the cheapest of the three, and it s $599. So a hundred dollars means HTC quality, better UI, better warranty with coverage even with bootloader unlocked so better developer support. That s worth the $100 extra bucks. Click to expand... Says you and no one else? It s a great 2015 phone in every aspect."</post>
   <post id="d2473255-685c-401c-ba66-e578af32b398" section="Smart Phones and Devices" discussion="HTC 10">"AT&amp;T will not carry the HTC 10. You will need to buy the unlocked version direct from HTC. The HTC 10 Will Not Be Sold By AT&amp;T, But The Unlocked Version Will Be Compatible HTC is running $100 off on a pre-order with coupon: HTC1008 When it comes to our loyal customers we obsess over ways to say thank you for choosing HTC and giving you reasons to choose us again. Experience our latest phone with a front and back OIS camera, longer battery life, and BoomSound Hi-Fi Edition—so you can get the most out of everything you enjoy. That s why we re inviting you to an exclusive pre-order on htc.com, so you can get $100 off the new HTC and get it before anyone else. Coupon code: HTC1008"</post>
   <post id="98e26b19-fc0e-48bc-af33-f0ea5b3c7b11" section="Smart Phones and Devices" discussion="HTC 10">"I m definitely interested in this phone. Glad they finally got serious about making a camera that doesn t get housed by its competitors. Also curious as to how well optimized that software is with the "okay" sized 3000mah. I seem to recall the M8 doing very well battery wise and then the M9 taking a step backwards even though it had the same size battery. Either way, I m glad HTC didn t fuck up anything obvious to make me exclude this phone from the start. Wouldn t mind going back to HTC. I haven t used one since my OG HTC evo days. Before that I had an HTC Hero. Those were the days."</post>
   <post id="daca053b-14e2-47fb-9fbf-4968fa8e9dae" section="Smart Phones and Devices" discussion="HTC 10">"Aurelius said: ↑ Wish folks would stop saying that every phone should be priced like a Nexus. Google sells its devices as cheaply as it does because it doesn t intend to make a profit on them; they re ambassadors for Android. You can certainly say that you d rather get a Nexus 6P for the price, but I wouldn t call $699 crazy. It s roughly on par with high-end phones from companies that want to be profitable. Remember: for many people, a smartphone is more important than their computer at home. Dropping $699 on it every 2-3 years is reasonable for such a crucial communication device. Click to expand... I really doubt whoever is dropping $699 on the phone will keep it for 2 years."</post>
   <post id="9ee373e6-4a19-4503-a10e-f4dc5b625925" section="Smart Phones and Devices" discussion="HTC 10">"Those iPhone lines outside Apple stores, are not people paying $700+ cash out of pocket for a new iPhone. In the U.S 99% of them are carrier contracted or whatever the new finance options are. Nobody is actually paying the full retail price all upfront, they are just putting down $199 at the most, or on these "Jump on Demand" plans that cost just the tax of the phone to get the new model. The day the U.S. carriers require you to pay the full amount upfront all at once for a new phone, is the day smartphone sales drop dramatically. Most people will not plop down a whopping $700 for a cell phone, no way not gonna happen in large numbers here in the States. Off topic; If I had to poll everyone I know, family, friends, coworkers, and client so mine. Let s say that s 200 people or so. With the vast majority very well off, most making well over $100k a year each. Out of those 200 people, I can count on one hand the number of people that would actually pay full price for a new smartphone. Most of them, 95%, stick with the same phone for 2 or 3 years, and only upgrade on their phone contracts timeline, or even after that, and wait for their phone to practically be broken, or stop working before they upgrade. Out of all of these people, who are financially well off, I don t think any of them would ever dream of paying $700 for a cell phone. And i think that s the pulse for most Americans and their smartphones."</post>
   <post id="50286bc6-e20c-46e1-9929-6d6b2b067e0d" section="Smart Phones and Devices" discussion="HTC 10">"Continued off topic... Agreed. Everyone in my family still talks about the phones costing $100 or $200 depending on which one they get. I tried explaining that is really $600 and are paying for it one way or another... but, but but, its $200. ...aaaaaaaaaaaaand back on topic. Good to see HTC back in the action with a viable phone. I had a re branded HTC as an iMate SP-5 (two actually, lost one...) and the HTC Dual. Great phones. The question now is if they are too far gone to become relevant again. Liking the bold decision to have a great battery and not play the thin game."</post>
   <post id="5dcc3efa-b1df-4f0c-af74-e6cb00db9e89" section="Smart Phones and Devices" discussion="HTC 10">"Preorder an Unlocked HTC 10 for $599 using Code "HTC1008" or "HTC1009" ($100 off) So is $599 worth it? Hi-Fi Edition ---- is it like an amp?"</post>
   <post id="6756c672-0bfc-4105-9180-1a4f3c2a4f5f" section="Smart Phones and Devices" discussion="HTC 10">"singe_101 said: ↑ Preorder an Unlocked HTC 10 for $599 using Code "HTC1008" or "HTC1009" ($100 off) So is $599 worth it? Hi-Fi Edition ---- is it like an amp? Click to expand... I m struggling with that as well. I know I can wait a month or two and pick one up from Swappa for under $500 but I can get a gently used Nexus 6P 64gb right now from Swappa for under $450 and is the 10 worth the premium over the 6P. Not that I need another phone, but new releases always make me think about it. I think I ll just keep the 6s Plus until the fall."</post>
   <post id="ed4fca39-0b01-4207-be7e-56cbc07bae50" section="Smart Phones and Devices" discussion="HTC 10">"Wait. It s only 5.2 inches? Too small."</post>
   <post id="f2d4388e-cb57-4efe-a98a-0322dafb90de" section="Smart Phones and Devices" discussion="Nexus 5x">"Has anyone here has experience with the Nexus 5x? How is battery life? Durability? Performance? Curious to see as i m looking to pick one up."</post>
   <post id="1db8a2ea-cadf-4489-8905-658187a31903" section="Smart Phones and Devices" discussion="Nexus 5x">"nxmbness said: ↑ Has anyone here has experience with the Nexus 5x? How is battery life? Durability? Performance? Curious to see as i m looking to pick one up. Click to expand... Battery life is on the good side of "ok". I ve seen some reports for ~3-4 hours of screen on time. I ve never really had mine on that long but I do notice the battery takes a large-ish hit when I play even simple games. "Durability" is more about how one treats the phone more than anything else, i ve never had a cracked screen on a smartphone for one. Performance is fine here, don t let the "but it s only got 2Gig of RAM" whiners get to you, it s got more than enough."</post>
   <post id="60b82c69-63c1-4e87-8b01-06280197cf5a" section="Smart Phones and Devices" discussion="Nexus 5x">"The 5x is the high end of good solid phones like the moto G line. Good screen, great camera, asop nexus smoothness, decent battery offset by really fast recharge. Its a solid choice but if you can hang on a bit longer rumored new nexus devices are on the way which will push current line down in price. A good friend has the 5x. Built by LG is a solid plastic phone. Get a decent case and you should be fine."</post>
   <post id="dac370e7-c978-45fc-a457-20e3e7bd8367" section="Smart Phones and Devices" discussion="Nexus 5x">"I tried the 5X and it was a disappointment. The older Nexus 6 performed a lot better."</post>
   <post id="7cf066a9-b9f0-457d-a2e0-fec5d394479a" section="Smart Phones and Devices" discussion="Nexus 5x">"Just got the 5X. Nice phone, but rooting and a custom rom and kernel make it even better. I recommend Chroma and Elemental X. SOT of about 4.5 hours on LTE - haven t tested on wifi."</post>
   <post id="b7dd7126-707b-4e5e-b84c-3d39f6cda6a1" section="Smart Phones and Devices" discussion="Nexus 5x">"can anyone tell me that anyone here has experience with the Nexus 5x? that what s the main quality of this phone and what about battery back up..."</post>
   <post id="7a348ae3-805d-40bb-9213-ec92ca032328" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"So the only phones I m interested in right now are the Moto X Pure and Nexus 6P. I have 3 lines on Verizon, 2 of which are on unlimited data still (wife and I), and I have my mom on my account on a 2GB line. My unlimited line is out of contract (month to month now), wife s unlimited line is on contract until May 2016, mom s 2GB line was just renewed a few months ago. We ve been transferring all of our upgrades to my mom s 2GB line to keep renewing our contracts while keeping unlimited data. I was originally planning on getting an iPhone 6S to renew my contract and then sell/trade towards the 6P, since I can get a 16GB iPhone for $250ish (after the retarded $40 activation fee and taxes) and it should resell for around $600 new. and pretty much cover the cost of a 64GB 6P. There s also the LG G4 that I can get for $150ish on contract right now with a promo they have going on, along with a $200 gift/Visa card rebate, and then sell the phone for around $300. Which I ll spend about the same after adding another $100 to ($300+$200) in order to get the 64GB 6P, so comes out about the same either way, but Apple doesn t get a sale if I get the LG, lol. Or I m considering dropping my line and financing a 6P through Project Fi. I use at least 4-5 GBs/month though, so not sure that will save me much money and I really like to tether to my laptop occasionally when I m away for work or doing school work on the road. I would prefer to go to T-Mobile, but alas I can t get the 6P or Moto X Pure still through T-Mobile and would have to come $450+ out of pocket for either phone. My current phone is an HTC M8, which I m still happy with and don t mind keeping for a while if need be. I just replaced the USB port and battery in it, so it s basically good as new now. It will only get me about $150-$200 if I sell it too, so doesn t help much if I leave Verizon. So what suggestions do you all have for getting these phones? If I m going to stay on Verizon, I want to at least extend my contract. I may just ask my mom if she wants to upgrade her Moto X (2013) right now so I can at least extend my contract and I ll keep my M8 until I can upgrade again next May. I m sure once the 6P supply issues get ironed out in the next month or two, I ll be able to get it on Swappa or something for a bit cheaper too. I d rather not buy one now when Google is making it a PITA to order one and everyone else is just flipping (price gouging) them just to exploit the supply issues they have. Sorry for the wall of text, it took me just a couple mins to type all that and it didn t seem like much, lol."</post>
   <post id="14501577-b5b6-47ea-b5ce-ac6eee0f2d2a" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"If you are anywhere near solid T-Mobile signal there lte coverage has come a long way. The only other option that might work is something like cricket aka att. Solid discounts and no overages for multiple lines. I love my T-Mobile service here in socal"</post>
   <post id="12278eaa-795e-445a-a6c9-6557c136f180" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"At this point I d ditch Verizon. They re only going to keep increasing the price (I m betting yearly) until all unlimited users are gone because they re pricks. Best thing would be watch for T-Mobile to do another promotion for unlimited. My wife and I are $100 for two devices. Unlimited talk/text/LTE and 7GB tethering both lines."</post>
   <post id="e45ca67f-8891-49b9-a570-e436db8c6886" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"The area I live in has good TMo coverage, but a lot of family and friends I visit away from here does not. The whole southern half of my state has Edge only on TMo, which is where my bro and dad live. Plus since TMo doesn t offer the Nexus and Moto phones, I m going to have to buy them outright still. My Verizon bill is $190/month right now and my mom gives me $55/month for her line because my bill was only $135/month for my wife and I before we added her to my plan. I just discovered a cool method of extending the contract without buying a new phone though. Apparently there s some commentators on the Droid Life article that were able to extend their contract by 1 year just by calling and adding a "Loyalty 100 Minutes or Text promo" to their line. Worth a shot."</post>
   <post id="5303f26b-5701-47fc-8c66-b3d03057aef8" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"Seriously check out Tmobile- I get 90Mb+ on my N6, here s a speedtest from my Z3. The network has come a LONG way and coverage is nearly everywhere."</post>
   <post id="de56eae8-181c-4c51-aec2-c7bc7e9491fd" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"Meh, download speeds don t mean much to me, anything past 5-10 Mb/sec is pretty excessive for a phone and there s not much benefit past that. That said, I ve seen over 100 down on Verizon while tethered and I consistently pull 20-30 down around where I live. And like I said, TMo is nearly nonexistent where a lot of my family lives still. If I can get a hold of a Nexus phone though, I might try to get a TMo SIM and try prepaid for a month while I m down there just to see if their coverage map is accurate. But it shows nothing in the southern part of my state. I think I should have used a different thread title, because I think I m just trying to find the best/cheapest way to get a Nexus phone on Verizon rather than deciding if it s better to switch. TMo s biggest incentive for me to switch is their Jump program, but when the phones I want aren t available through TMo, then that s basically useless to me."</post>
   <post id="fb9aeaba-84e4-4756-9da8-51bd82db68ea" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"Wanted to bump this since it seems T-Mo has added a LOT of coverage since I made this thread. They seem to cover pretty much all of the areas I travel to and where my family/friends live. So since my other unlimited data line contract expires next month and I can expect Verizon to tack on another $20/month to my bill because of it, I m switching to T-Mo. Bastage told me about their current promo for 2x 6GB lines for $80/month and I can add my mom s 2GB line for another $20/month, making it $100/month total, which sounds good to me as long as I can bump up my plan to unlimited whenever we take trips and stuff. My kids used 25GBs tethering their tabs to my phone in the car on our vacation last week, lol. Some of that was tethering my laptop and Fire Stick in the hotel room too though. T-Mo will have to buy my mom s line out of contract still though because it doesn t expire until August 2017. They said it can take up to 8 weeks to reimburse you for the ETF, does anyone know if it normally takes that long or not? Not sure what phone to get her since she doesn t want to pay $600+ for a new phone and wants a smaller phone too, not much bigger than her 2013 Moto X. I guess she could get by with financing a GS7 or iPhone 6S for $25ish/month, but I would rather buy a cheaper $250ish phone on Swappa like I did for her Moto X a couple years ago. Any suggestions? I really like the Oneplus X for her, but I think I remember seeing it missing a band or two for T-Mo. I know that if T-Mo is going to buy her contract out, would they let me finance a phone for my line and let her bring her own device if I find one instead? I m hoping the HTC 10 comes through so I can get it next month and I can just do that, because none of the current phones really interest me that much. Another question about T-Mo though; is there any way to see what areas use band 12 or not? I think my wife s Verizon GS6 will work on T-Mo minus Band 12 (haven t checked yet), so I m hoping it will work in most areas still without it."</post>
   <post id="14c573c6-b3b6-441c-a952-c2ace799aa1c" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"You can keep unlimited, renew your contract, avoid the $20 hike and get the 6P on Verizon for cheap if you want. Bit of a hassle, but worth it, for me at least. Get 130mbps/35mbps at my house, and travel fairly often, so no interest in switching."</post>
   <post id="3e9f5080-fd33-4a68-9e1a-1c6ebf16090e" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"BeavermanA said: ↑ You can keep unlimited, renew your contract, avoid the $20 hike and get the 6P on Verizon for cheap if you want. Bit of a hassle, but worth it, for me at least. Get 130mbps/35mbps at my house, and travel fairly often, so no interest in switching. Click to expand... Yeah, I could do that, but honestly Verizon has given me every reason to leave them now and I m tired of jumping through hoops to keep my unlimited data and dealing with their shitty policies and pricing. I ve already been hit with the $20 hike on one line and will be again on my other line next month, so I d rather just vote with my wallet at this point, even if it means getting slightly less coverage and usable data. There s some other strong appeals to T-Mo for me too, like WiFi calling, more root-friendly phones, and the ability to use any GSM/unlocked phone I want like the Oneplus and Sony phones."</post>
   <post id="6ee84540-2a0d-4920-838d-6811abac49dd" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"T4rd said: ↑ Yeah, I could do that, but honestly Verizon has given me every reason to leave them now and I m tired of jumping through hoops to keep my unlimited data and dealing with their shitty policies and pricing. I ve already been hit with the $20 hike on one line and will be again on my other line next month, so I d rather just vote with my wallet at this point, even if it means getting slightly less coverage and usable data. There s some other strong appeals to T-Mo for me too, like WiFi calling, more root-friendly phones, and the ability to use any GSM/unlocked phone I want like the Oneplus and Sony phones. Click to expand... Like I said, you could avoid the $20 hike for 2+ years if you renew the contract before it gets hit with it. As shitty as Verizon has been with all their fees and other bs over the years, don t think my bill has changed since my original contract in 2010. Other than losing employer discount when I changed jobs, and taxes. And I ve upgraded every year subsidized, avoided the upgrade fee, am paying less than new customers with crappy share everything plans all while using 200+gb a month. If you think you re getting a better deal elsewhere and the coverage is acceptable, then by all means go for it though. Would consider switching to T-Mo myself as I could get 2 unlimited lines instead of 1 UDP/1TDP like I have on Verizon. But it s still more expensive than Verizon and I believe they throttle/cap LTE after a certain amount as well."</post>
   <post id="abe8503b-a218-4fcd-b798-ced60739ebf0" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"BeavermanA said: ↑ Like I said, you could avoid the $20 hike for 2+ years if you renew the contract before it gets hit with it. As shitty as Verizon has been with all their fees and other bs over the years, don t think my bill has changed since my original contract in 2010. Other than losing employer discount when I changed jobs, and taxes. And I ve upgraded every year subsidized, avoided the upgrade fee, am paying less than new customers with crappy share everything plans all while using 200+gb a month. If you think you re getting a better deal elsewhere and the coverage is acceptable, then by all means go for it though. Would consider switching to T-Mo myself as I could get 2 unlimited lines instead of 1 UDP/1TDP like I have on Verizon. But it s still more expensive than Verizon and I believe they throttle/cap LTE after a certain amount as well. Click to expand... I know, I ve been doing the same thing since they killed the UDP. I was paying $135/month for 2 lines on unlimited data originally, then I added my mom on my account with a 2GB line, which bumped it up to $190/month and I ve been using her line to transfer all of my upgrades to so I can keep unlimited data on my other two lines. Then I let one contract expire last October when they added the $20/month price hike to UDP lines and now it s at $210/month. On T-Mo, right now I can get 2x 6GB lines and a 2GB line for my mom for $100/month before any phone payment plans are added. So even if my mom and I get new phones, it will still only be $150-$160/month (since most new phones are $25-$30/month on their payment plans). Or I can upgrade to unlimited data for another $30/month if I need to. So it seems that any way I go, I m going to be paying a bit less on T-Mo than I am currently on Verizon. I just hope I can trust their coverage map that s showing LTE coverage pretty much everywhere I would ever go. I may see if they re still doing that 1-week trial there where they give you an iPhone to test out coverage for free just to make sure before I switch."</post>
   <post id="41bd4aef-04b4-4915-8e75-e7675b4af2c7" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"The best way to see what T-Mobile is doing or plan on doing with Band 12 is reddit and this: Map of T-Mobile s 700 MHz spectrum I unfortunately live in a major metropolitan area that TMo still has no plans to deal with channel 51; seems like one of the only 3 metro areas. The FCC details shows that Sprint has a band 12 leasing deal in place for another 8 years or something that they are not currently using... Seems like a way for Sprint to continue to fuck me."</post>
   <post id="fba6640f-2f04-4c1b-9766-dfa63a261ebb" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"If and when T-Mobile does an unlimited promo jump on it as its for life and since I have mine for 2 years they have not up the price yet. I have 2 lines unlimited everything 100$. As they tend to not keep there unlimited promos around. And once its gone you can t add it"</post>
   <post id="058e0157-13b6-4c12-9c8d-75b95795476c" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"T4rd you have to finance a phone for tmo to pay off the ETF from VZN.. You dont have to finance a high end phone though (ie the Galaxy Core Prime or the LG K7 are both 140 at retail so its like 5 &amp; change a month) and then you can get whatever afterwards &amp; use something else if you can get it for a good enough deal to be worth it. The Unlimited upg from the 6gb plan is 45 a month. You can up it any time, but to drop it back down you have wait until the end of your billing month. Vengance_01 is totally right about the unlimited promo s.. That 2 for 100 unlimited deal was sweet, but I just changed mine about a month ago when it was 4 for 150 unlimited (added my mom &amp; my little brother to drop from 50 per line to 37.50 a line). With the Tmo plan promo s like these once they are added your locked in until you opt to change it so it will not expire. If you watch SD every time Tmo has a good plan promo pop up there ends up being a front page deal posted about it. BeavermanA T-Mobile does not throttle you on unlimited no matter how much you use. What does happen is after 23gb you get deprioritized. Most of the customers this happens to do not even realize it happens. Basically all it means is that if you are on a congested tower you have a lower priority in data usage then the users who have not hit that limit. Places where most people would notice it would be at things like a major sporting event where there is 60k people hitting the same couple towers at once bogging everything down. that of course resets on the billing cycle day every month as well."</post>
   <post id="be693097-dc5a-47af-a2f3-3796beda35b7" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"I have been with T-Mobile for 10 + years and I have no reason to change"</post>
   <post id="b55459d2-8c66-40bf-abac-a320397d3971" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"5+ years with T-Mobile using their $30/month plan the whole damned time and still going, never had one single problem with this plan, the service, or anything, never had any reason to call them for support for anything, etc. Just totally satisfied and praying they don t dump this plan anytime soon and if they do that they ll "grandfather" us long time users of it for a few more years. While I don t have any use for full blown max speed LTE (HSPA+ in my area has slightly better coverage and building penetration with T-Mobile), if I do a speed test it ll typically be in the 60-90Mbps down and 20-40 Mbps up with crazy consistency. I ran 10 speed tests in a row recently and they were between 79 and 86 Mbps down and 35-40 Mbps one right after the other, was pretty amazing considering where I live and I ran the tests in the late afternoon on a weekday. Now with BingeOn and Music Freedom (yes, I do get video streaming on this $30 plan, I didn t ask for it, was told my plan didn t qualify but damned if I can t watch movies off Netflix and it doesn t ding my 5GB allotment at all which is damned awesome. And of course the fact that I can do speed tests using the Speedtest.net app as much as I damned well please that s cool too and it helps their network or so they say. I must have done 11GB of speed testing last month, no harm no foul on my plan. They have bandwidth to burn and they don t give a fuck anymore hence the great deals. I m sure a few years from now they might hurt for it but for the moment it s a win-win situation for  em. AT&amp;T is taking note of the boost in T-Mobile s subscriber base with that new Cricket "unlimited" plan for $70 a month ($65 with autopay), they are swearing up and down it s truly unlimited and you can use as much as you want but there s two negatives: 1) it has no hotspot or tethering support at all, none, and 2) it s capped at 8 Mbps all the time. Now, I m not too worried about the hotspot thing personally and I could live with a rock solid 8 Mbps connection without limits, that would be fantastic. I did the math and I think that if you could pull down 8 Mbps solid 24 hours a day for a month that s like 2.4 TB or something close to it - I wonder what Cricket would do it someone actually did that legitimately (meaning just the phone, using data 24/7 constantly at max speed of 8 Mbps, no tethering at all). But that price is crazy for that low speed cap, at least to me. I d pay about $40 a month for that kind of service myself, not $65 and certainly not $70 but Cricket is part of AT&amp;T (a few year nows) so it s expected they have that bloated pricing structure. Still to this day I ve yet to find a better deal for me and how I use my smartphone than the T-Mobile $30 plan. I use Google Voice so I don t give a damn about the piddly 100 minutes of talk time my plan comes with - the only number I even give out is my Google Voice number. My actual carrier number for T-Mobile is known to like a handful of people, works better that way. They re definitely making big waves, I just hope they don t end up getting pulled under in the process."</post>
   <post id="f08d15fd-9edd-4220-8189-b8ef524f65d8" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"T-Mobile is hit or miss here in Vegas. Most the time I get good coverage except in some of the casinos. For the most part I usually hover around the 12-15Mbps up/down speeds. The good thing about T-Mobile is that they let you stream music and video (YouTube and Netflix are the ones I use) without it using your data and I have the family 10GB plan with each line having 10GB for essentially web browsing and downloading with each line having a 10GB data stash with unlimited talk/text and I only pay $120 for just the service for four lines. But I pay far more because of the phones I m leasing and insurance on three phones. Overall, for the price you can t go wrong unless you absolutely need the best coverage non-stop or the fastest of fast speeds , even then T-Mobile might be up there. Plus, they have that unlimited data plan for a measly $30 more than what you would pay normally, so something like $80 here in Las Vegas. Their customer service has been top notch with me as well.. they literally credited me for my S6 when I traded it in although at the time they hadn t received my phone through the mail just yet. All in all, compared to Sprint and AT&amp;T, while the download speeds no where near AT&amp;T and Sprint offering to cut your bill in half (although that s just for the service, nothing else) T-Mobilr is to me the lesser of all cell phone company evils."</post>
   <post id="cfab192f-970c-4a6c-8e05-aba5f631f5a6" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"bastage said: ↑ T4rd you have to finance a phone for tmo to pay off the ETF from VZN.. You dont have to finance a high end phone though (ie the Galaxy Core Prime or the LG K7 are both 140 at retail so its like 5 &amp; change a month) and then you can get whatever afterwards &amp; use something else if you can get it for a good enough deal to be worth it. Click to expand... After May 4th, I ll only have one of my three lines on contract, which is my mom s line, so she ll have to finance a phone for her line when we switch. I m just wondering if they ll care which phone line I ll finance on so I can finance a new phone for my line instead and get her a cheaper one off of Swappa like I did last time and buy it outright. I ll prolly have to finance a new phone for my wife too now though, because while her Verizon GS6 will work on T-Mo, it looks like people have issues with SMS/MMS messaging doing that and it will be missing band 12 support as well. I wish T-Mo would just let us trade her Verizon S6 for a used/refurb T-Mo S6 outright, that would be nice since she really don t need a newer phone than that."</post>
   <post id="cc9a269f-5b0d-446a-97de-444eb60cab14" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"The dev will have to be financed on your moms line, but tmo couldnt give a shit less where you use it so your fine there.. As for swapping your wife s phone... Put an add on CL &amp; see if you can find someone switching carriers the other way."</post>
   <post id="d1f50f2e-b3c9-468d-b4aa-50e876346300" section="Smart Phones and Devices" discussion="Switching to T-Mobile">"T-Mo has been awesome- the only place I ve had spotty service has been in Montana and Maine (north of Portland)- even then though there was roaming on ATT, so I still had voice service (and 200MB of data). In SLC I can get nearly 100Mb down while my VZW work phone on  XLTE  struggles to pull down 4Mb."</post>
   <post id="66048e9a-8485-4255-b0bf-34f0878b7809" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"I have a situation I m hoping someone here may have already tackled and would be able to recommend some apps to me. I m trying to find an app or apps that will allow one Android tablet to always be plugged into a stereo system inside our cottage that allows other Android devices (phones) to control what it plays. I m not necessarily talking about casting music to it, I am more looking to store a bunch of music locally on the tablet, but casting music from a phone would be a plus if visitors wanted to play something. All devices would talk over a local WiFi setup just for this with no access to the internet. Anyone familiar with a setup like this? I noticed a Clementine app that has a Clementine Remote app, but the app isn t available on a tablet. Any guidance would be greatly appreciated!"</post>
   <post id="806d1e83-31b6-4765-b34c-009e9efc940f" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"Setan said: ↑ I have a situation I m hoping someone here may have already tackled and would be able to recommend some apps to me. I m trying to find an app or apps that will allow one Android tablet to always be plugged into a stereo system inside our cottage that allows other Android devices (phones) to control what it plays. I m not necessarily talking about casting music to it, I am more looking to store a bunch of music locally on the tablet, but casting music from a phone would be a plus if visitors wanted to play something. All devices would talk over a local WiFi setup just for this with no access to the internet. Anyone familiar with a setup like this? I noticed a Clementine app that has a Clementine Remote app, but the app isn t available on a tablet. Any guidance would be greatly appreciated! Click to expand... I don t know any software that does what you want it to do. Honestly, your best bet (and simplest) is spending the $35 on the Chromecast Audio and just throwing your music into Google Play Music. That way you can access all your music all the time and friends could connect to the Chromecast Audio and play their music as well."</post>
   <post id="9fc95f3c-b805-4c0f-8eee-7978a535f80d" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"Setan said: ↑ All devices would talk over a local WiFi setup just for this with no access to the internet. Click to expand... I had a couple suggestions, but this rules them out since the remote apps I d recommend require an internet connection. Is this because your cottage has no internet connection? It kind of complicates this. If you do have internet and need to keep this isolated, can you explain more about why exactly?"</post>
   <post id="750bd1d9-90e5-4706-9575-56d9af4461ba" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"BubbleUPnP should be able to do what you want. If you install it on one device you can control it from another instance of the app on a different device."</post>
   <post id="6d230510-01cd-4082-bf70-260e2fb1d8d3" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"CEpeep said: ↑ I had a couple suggestions, but this rules them out since the remote apps I d recommend require an internet connection. Is this because your cottage has no internet connection? It kind of complicates this. If you do have internet and need to keep this isolated, can you explain more about why exactly? Click to expand... Yep, cottage is remote without Internet access."</post>
   <post id="53a57a09-c96a-437c-8912-9c700e3153bb" section="Smart Phones and Devices" discussion="Android Music Player (tablet) with Android Remotes (phones)">"Snowknight26 said: ↑ BubbleUPnP should be able to do what you want. If you install it on one device you can control it from another instance of the app on a different device. Click to expand... You sir, are the man! BubbleUPnP is exactly what we needed and works great. Thank you very much. Can t tell how long I ve been trying to find something."</post>
   <post id="fd29a390-387c-4e4d-8c3a-32c503b1df04" section="Smart Phones and Devices" discussion="What function is accessed or activated by booting device into QCOM">"1. What happens when one boots their device into QCOM? 2. Is the option to boot into Factory Mode the same as the "Wipe data/ factory reset" option that is seen in Recovery Mode? I know what the remaining below options are. Thanks Start / Restart Bootloader / Recovery Mode / Power Off / Factory Mode / Barcodes / BP Tools / QCOM / Bootloader Logs Moto X Pure Android 6.0 (device has never been rooted or had bootloader unlocked)"</post>
   <post id="6d0cf307-548f-4309-8ce7-834910ef80fe" section="Smart Phones and Devices" discussion="What function is accessed or activated by booting device into QCOM">"Can someone please supply me with the answers? Thanks"</post>
   <post id="3d2547fd-100b-4aba-95bd-6de01e6ae82d" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"I think I got my plan over 10 years ago when it was $30/mo, had a Blackberry Curve. I still have it today but it has gone up $20/mo, first $10 increase was for the SERO Premium which included Any Mobile Anytime. The second $10 increase was when I got the iPhone 4s, this fee was for Premium DATA, aka 4G fee, which the 4s didn t have, but you were forced to get Premium DATA if you wanted the iPhone. I upgraded to the iPhone SE last month and during online activation it said that my new monthly payment would be $60. I was confused since there was no mention of a plan change when I was upgrading and ordering my phone. I called up and told them that I didn t want to change my plan and that there was no mention of a plan change when I ordered the phone. So the nice rep from the Philippines did a device swap so that my plan wouldn t change, and inquired about the activation fee since it was waived if you ordered and activated the phone online, and she said there would be no activation fee since she did a device swap. Cool. I don t use my phone much since I am home pretty much all the time, still recovering from my bilateral hip surgery."</post>
   <post id="89e63089-0a34-4a53-8d4f-c184eeb03f94" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"I had mine up till a few months ago, I finally gave it up &amp; switched to google fi."</post>
   <post id="3520e7d8-830c-4d57-99df-40d57ffd6cb8" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"Still have mine! Its not the incredible deal that it once was after the price hikes, no free upgrades and having to deal with corporate. However for a single only line its still the cheapest."</post>
   <post id="cd1ea37f-98a2-4137-97e6-f177670d19c2" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"Ogre67 said: ↑ Still have mine! Its not the incredible deal that it once was after the price hikes, no free upgrades and having to deal with corporate. However for a single only line its still the cheapest. Click to expand... I got my new iPhone SE for $50, would have been free if I chose the 16GB model. I ordered it online with no issues, but during the online activation when I got it, it wanted to change my plan to a $60/mo plan, called up and said that I don t want to change my plan, I just want my new phone activated, and she did the device swap and I kept my plan as is."</post>
   <post id="6e3b8165-a3e7-4745-811a-c009d06fddba" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"Still have mine x2. Sometimes I wonder if I should just get a family line for my wife and I, but I never do it"</post>
   <post id="c680911e-67d7-47dd-b401-5461c93c8dc7" section="Smart Phones and Devices" discussion="Who still has a Sprint SERO plan?">"Still have my SERO plan as well."</post>
   <post id="64c68bf2-8381-43e9-ad68-39db8dbbc8e5" section="Smart Phones and Devices" discussion="Android error?">"Edit: Help: HTC M8 Music app on HTC 10? My wife wants the HTC Music app that came off of the M8 on her HTC10. I was able to find the M8 s .apk s but everytime I try to install the music .apk I get the following error. Now, I know what you re thinking... just get a different app. Believe me when I say, I already tried...lol So, Java wizards - what s the issue here?"</post>
   <post id="6dcd05b3-d5f1-46ca-a2d3-89ed48b8e9a6" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"2015 smartphones have been launched by now, and in the rear view mirror. Some highlights were the Note 5, Nexus 6P, I guess the iPhone 6S Plus possibly, and the affordable OnePlus X, and Moto X. So coming soon in 2016, what has you drooling and ready to purchase some sweet SD820 phones ? My list in order of release; - HTC One M10 ( Hopefully HTC is still around, and can finally put out a killer phone, that wow d us like the One M8 ) - LG G5 ? I m hoping they have a OLED display, and keep the small form factor. - OnePlus Three ( SD820 with an AMOLED display, and build like the One X ) - iPhone 7 ( I m most interested in if iOS 10 is revamped and is just revised a ton, and of course the design of the phone itself should be a top notch style ) - Note 6 should be killer - Nexus-N ( Hopefully 5.7" screen size, maybe made by Sony ? )"</post>
   <post id="966ab385-2c2d-478f-80a2-a75fcd766f1d" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"It s time for a Surface Phone. Skylake + option to run full blown Windows 10 = no more having to settle for junky apps from Google Play and App Store. Software in those mobile OS has been in a standstill for quite some time now. It s time to move on to something superior."</post>
   <post id="f5e821b3-a10b-4df6-b046-e603a20e61d7" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"HTC One M10"</post>
   <post id="49e616f3-25ab-41ff-a9e7-9d445ba9b768" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"As long as it can be rooted on Verizon and has front facing speakers, that s about all I care about anymore. Pretty much every phone checks all the other blocks for me at this point. Oh, and I need at least 64GBs of storage."</post>
   <post id="af056c12-5926-434c-b0b0-ecca62ecd07a" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Zorachus said: ↑ HTC One M10 Click to expand... Have no fear Z. I hear the good people at HTC are hard at work making the M10."</post>
   <post id="d3216ebe-bac5-461f-bd32-445641a9325e" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"iPhone 7 and Note 6. Nothing else matters."</post>
   <post id="49e7e02a-7b83-499a-89b0-efc364245d3d" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Tyler-Durden said: ↑ iPhone 7 and Note 6. Nothing else matters. Click to expand... You forgot the Galaxy S7 line!"</post>
   <post id="d58a1327-c226-4dec-96f1-1bb6394bb97f" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"At this moment if someone told me "Pick any smartphone and I ll buy it for you..." I d take a BlackBerry Priv above most everything else that s available. I m just a bit sick of plain old Android smartphones and I d like to try something different so, with the Priv I d get Android yes but I d also get a lot of BlackBerry related tools - I currently own a BlackBerry Z10 and I love it, I really do. It s a fantastic device that is snappy and responsive in ways one might not expect from such an older device and it runs pretty much every Android app that I happen to use including the Play Market and Google Services too. But I like the Priv - I like the look, the form factor, the whole package and that s what I d choose at this time and for the near future. Not sure what the hell the major players are going to do with their next flagships but I know there won t be anything so astonishing or even creative that it would matter to me. I find most every current modern Android device pretty damned boring, to be honest. I figure if BlackBerry took the time to create the Priv then it wouldn t be so bad to take some time to appreciate it. Supposedly they ll be available in AT&amp;T corporate stores on Friday so I m going to call around and find one where I can go do a proper hands on for a bit and see what all the hubbub is about. Been keeping up with all the info and articles and early reviews from leakers that have access to the production hardware but obviously the only person that can say for myself if it s worthy of consideration is obviously me, myself, and I."</post>
   <post id="3e7c1f4d-8f50-4d6b-a071-80c2f6b65315" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"iPhone 7 with shrinked bezels.. 4.7" with smaller form factor or 5" with better use of space."</post>
   <post id="30b4117b-9976-4143-989c-e01f053f994c" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Tyler-Durden said: ↑ iPhone 7 and Note 6. Nothing else matters. Click to expand... This. No phone with the SD820 has me interested. I am interested to find out what the next gen SoC from Apple is and how Samsung competes. I m hoping they include a better GPU, there were rumors that Samsung would move away from Mali again."</post>
   <post id="36bbcfcf-366f-449d-907e-d40d133d27da" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"I would be looking forward to the iPhone 7, but not if they continue upgrading with iOS 9. Needs a rewrite. I will be very happy if they can solve the battery issue. Give us a damn better battery! This technology has been kicking our asses for a long time. Make better batteries!"</post>
   <post id="64c999b9-ba15-4a66-8c3b-31ec39289e8d" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Still looking forward to the Microsoft Unicorn x86. With USB Type-C Thunderbolt port, not just USB 3.1. Intel radios with WiDi would great. The future of smartphones could really be a belt buckle that houses the main components, but the display with separate wireless displays (with their own batteries) through WiDi in a number of extremely thin form factors (watch, phone, tablet)."</post>
   <post id="fb8a939e-a061-4519-ae87-a7cf3851b8a5" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"ReCOde said: ↑ I would be looking forward to the iPhone 7, but not if they continue upgrading with iOS 9. Needs a rewrite. I will be very happy if they can solve the battery issue. Give us a damn better battery! This technology has been kicking our asses for a long time. Make better batteries! Click to expand... iOS 9 was clearly about cleaning things up, getting the OS to run more effectively rather than changing its core mechanics. I m not counting on a rewrite, but iOS 10 seems like a prime opportunity to introduce some major new concepts and features. Me? I m looking forward to the iPhone 7 the most, since a 6 is my daily driver. However, I m really curious to see if HTC can redeem itself with the next One flagship, and if Samsung goes back to the drawing board after the S6 and Note 5 failed to turn things around. And of course, I d like to see what the 2016 Nexus line looks like."</post>
   <post id="d29a8bcd-0b5a-4c08-b0db-14e4c2c31f23" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"If someone could figure out how to have wireless charging with a metal body (with a plastic or glass logo box/circle to house the wireless charging plates), I will bet on HTC. I also hope for more shatterproof designs."</post>
   <post id="5100bcd9-c9e3-4bd5-836f-e5c9c9d2fefb" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Going to continue my migration into the Apple realm, so iPhone 7 for me. Moving out from android."</post>
   <post id="db7c82ee-0270-47bf-84b2-540e2da8c4d7" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"iPhone 7 with transparent aluminum body and sapphire screen."</post>
   <post id="bbbbe19f-996d-4b43-8e44-a40ce4fe5165" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Yakk said: ↑ Going to continue my migration into the Apple realm, so iPhone 7 for me. Moving out from android. Click to expand... Is this you on Disqus? Slightly different name I know, was just curious, heh."</post>
   <post id="deea61ee-4436-4908-ac2e-09ef83f3879b" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"Next gen Windows phones and Huawei Honor 8. Though... I m rather happy with my Honor 6."</post>
   <post id="d0a9fa3b-ccab-404f-a045-40e7847aa033" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"T4rd said: ↑ Is this you on Disqus? Slightly different name I know, was just curious, heh. Click to expand... That s pretty funny actually! No it s not. I only read/write on a few sites, and never thought I d be using Apple stuff, but you never know I guess And Disqus is disabled by default on my rigs."</post>
   <post id="84bb31e2-f9c8-4c8a-b291-b1abb88c1611" section="Smart Phones and Devices" discussion="What 2016 phones are you looking forward too ?">"My upgrade is in June(2016), so I think I ll go for the LG G5. By then, it should practically be free, since rumors speculate a Jan or Feb release. (And, a Zerolemon case should be available for it by then. So I should be good to go.) I ve loved my LG G2 since I ve had it. I ll definitely stay with the G series, atleast one more time around. My vote, the LG G5."</post>
   <post id="8096f7dc-e78e-40e9-aeef-573222175bcc" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I have the "no sim inserted" issue with my Galaxy S4 happen to me several times a day. The poor bugger also seems to give me no service and then slap back to giving me service on and off intermittently. The screen is also cracked on it. The charging cable I have for it is severed. You get the point, I think it may finally be time to put my poor dear old friend down to rest for good. What are my options for a replacement that is $150-$200? Would a refurbished Galaxy S5 for $170 be a good bet or bargain? Tell me about refurbs and whether or not they are a terrible mess waiting to happen. Also, I really like having extra storage on my phone for music, as well as an aftermarket battery that gives me about 15 hours of juice. I m using either a 5200 mah or a 7800mah battery as opposed to the stock 2600mah battery. I suppose my query is this: $200ish dollars, expandable battery and expandable memory? The S5 doesn t give me that does it?"</post>
   <post id="71a00f42-8c7d-4db5-b140-8966c1617784" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"TouchWiz sucks. Try the LG G4. New Other LG G4 5.5" 32GB Hexa-Core 4G LTE GSM Unlocked Black US Model for $279.99 + FS (quickshipelectronics via eBay) 04-10-2016 $280 new, $175ish used."</post>
   <post id="4cf5c19c-e918-4292-bfcf-c011d664753a" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I d go down to a store and go hands on with some new phones. So many of them are far larger than the S3/S4 which I still feel is just about the perfect size. I had nothing but trouble with the LG G4 which was otherwise a potentially great piece of hardware. Google G4 boot loop for the sad story. You may have to end up with a larger phone than you want, and making do with 64GB internal memory."</post>
   <post id="d3e62bdc-5cd0-43c2-a7b6-0e6a24a4ce8d" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I really want to recommend the Nexus 5X. Pity about the SD card and battery."</post>
   <post id="1e18f1f0-944b-4835-933d-98d6f6461123" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"Get a Nexus 5X and external portable charger like an Anker, external OTG flash drive, there are some USB-C or get an A to C cable."</post>
   <post id="2f6200e6-0c45-413b-86d3-660d77720d17" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"Try swappa.com man. I had to replace my broken Moto X and didn t want to get into another contract / big buy, so I bought a used S5 for 150ish I think. Only downside was that it was gold colored - which $2 dollars plus an order from eBay later fixed (somewhat, I replaced the backpanel with a blue one but the edges / trim are still faux gold)."</post>
   <post id="5099273f-ad86-4e54-a05b-104907aa1ba6" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"Oh and the S5 has a removable battery and microSD slot, but you have to pull the cover to get at both (at least on the Verizon one it does)."</post>
   <post id="5b65cc76-f787-4245-b996-90c700badfd9" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"Question - are refurbished phones decent or am I looking for trouble by going that route? No warranty on an item that has a high failure rate, etc."</post>
   <post id="cd783694-0f7f-405b-b378-ac67b5e41748" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"topslop1 said: ↑ Question - are refurbished phones decent or am I looking for trouble by going that route? No warranty on an item that has a high failure rate, etc. Click to expand... Depends on the vendor and luck of the draw I guess. I got a used GS4 off ebay about a year back for $150.00 and have had zero issues with it. Just make sure they have good reviews/feedback and that they accept returns."</post>
   <post id="8213ab6d-c0b1-4879-a554-f18167985f9a" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I really want to recommend the Xiaomi Mi5...,..it s too good"</post>
   <post id="7aff871b-7855-48cb-a2c2-24baf475ad33" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I think the LG G3 is one of the better phones made in recent years, and should be unlockable / let you install custom ROMs if you re willing to jump through some hoops. I loved my G3, just killed it (screen cracked) and let an idiot do the replacement... it lasted about 3 more weeks. Gave up and got the Galaxy S7 Edge, which I m happy enough with after extensive tweaking, but is it worth the $800 I ll be paying Verizon for it (I guess technically 300, if you re willing to accept the "$20/month discount" as real) but eh. I think they run $150 used in good condition? The stock ROM tends to give mediocre battery life, but I had good luck with alternates. It also has all the stuff power users really like -- big screen with small bezels, big 3000mAh removable battery, microSD support, wireless charging (via a replacement back cover), still fast Snapdragon 801 quad core."</post>
   <post id="8a6dd3c4-7f45-4880-b814-8d5b270d2cba" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"john smith said: ↑ I really want to recommend the Xiaomi Mi5...,..it s too good Click to expand... The Xiaomi Mi5 would probably be a terrible choice, to be frank. It s a good device from early indications, but telling someone to import a Chinese phone that likely won t support LTE data where they live? That s asking for trouble. Go get a refurb or check out sites like Swappa. Brand new phones under $200 are still going to be budget devices like the Moto G."</post>
   <post id="37f3b687-a43f-4479-98eb-6159c2e41cc7" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"I ll also second (or third?) the Swappa recommendation. Used them a bunch of times with good results. The LG Flex 2 is available for decent prices, if you can get over what has become a sort of standard of larger sizing."</post>
   <post id="e852930a-2d95-4af4-b2f3-a80ab2937321" section="Smart Phones and Devices" discussion="Galaxy S4 dying slowly, recommendations?">"ok....let be check it...."</post>
   <post id="81a567a6-429d-47e4-b7d8-0f9b118c35c7" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"I was browsing a facebook pc page and someone there mentioned that Sprint gives a free Router to use for Wifi Calling. I went ahead and called and asked about it last week and they said I could get one so the put in an order and it arrived today. I set it up as an AP since I have another router upstairs handling the DHCP stuff. I am in the garage most of the day and I use my phone while I am in here so having the AP in here is the best choice. Oh, Sprint owns the router for the 1st year, if you cancel your service before a year you have to either give them back the router or pay $85 to keep it, after the 1st year it is yours to keep."</post>
   <post id="bade07d3-dfd6-4d22-957e-1341984e9b59" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"I think you can get the same router from T-Mobile as well. But T-Mo s router has a proprietary firmware that locks you out of loading a 3rd party firmware like Tomato or DD-WRT. Not a big deal for most, but I wonder if this one is locked down as well."</post>
   <post id="f61835d6-54e5-4029-83ab-1774ec061c1a" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"It is still a nice router for as old as it is. Mine is still kicking. Have had Merlin s firmware on it since day one. To get a nicer router will cost 4X as much today and not net you a whole lot...unless you re wanting to VPN encrypt on the router itself."</post>
   <post id="057bf01e-a7cf-44bc-810d-ea45b9e97bfe" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"I am just using it for WiFi in the garage in AP mode. I ve got a Linksys router upstairs connected to the modem, then a wire coming down to the family room to a Verizon router that is used as a switch and WiFi for downstairs, then a wire from there into the garage. I was reading that you can flash the stock Asus firmware onto this unit, so I you may be able to use other firmware as well."</post>
   <post id="990ec172-5235-4676-82f8-bc9068365d3e" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"What number did you call for this?"</post>
   <post id="8fa32385-0c59-47cf-86f1-02c3661cd42a" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"866-275-1411 is the number I called, but this is number of the dept I talked to, (866) 556-7310, it s Airrave Support. You have to have a WiFi Calling enabled device on your account. Just tell them that you would like a WiFi Connect device for your home."</post>
   <post id="86bfc6e9-818b-4961-a9f3-1e23359d37cf" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"T4rd said: ↑ I think you can get the same router from T-Mobile as well. But T-Mo s router has a proprietary firmware that locks you out of loading a 3rd party firmware like Tomato or DD-WRT. Not a big deal for most, but I wonder if this one is locked down as well. Click to expand... People are replacing the T-Mobile firmware, and have been for the past, what, year or so since it s been offered? 1 source, from as early as 2014 - How to flash other firmware on the T-Mobile Cellspot WiFi router - Pocketables"</post>
   <post id="1cbaf778-8d25-4937-a2a1-3af802f7278b" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"entropism said: ↑ People are replacing the T-Mobile firmware, and have been for the past, what, year or so since it s been offered? 1 source, from as early as 2014 - How to flash other firmware on the T-Mobile Cellspot WiFi router - Pocketables Click to expand... Cool, was just repeating what a friend with the T-Mo router said (which was over a year ago at least). I didn t care to look it up to see if anything had changed."</post>
   <post id="d227c9fd-f258-437e-a14b-039adea9b53b" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"Great routers but I ve been able to bog one down with 10 devices attached. For free it s super badass and fast enough but if you want a much better one the AC68U or Nighthawk is the way to go."</post>
   <post id="5dc6bd22-fd16-45a3-a320-8ddbe4ac9c9d" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"The T-Mo "Cellspot" is the AC68U. But it s also no longer free. Correct me if I m wrong."</post>
   <post id="ac0df102-acad-47d2-83b5-e9a72b5b172b" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"I got my R7000 nighthawk for $80 on a Walmart miss price. If you can get a 68U for the same price is recommend that instead."</post>
   <post id="9cfeb274-33fc-4107-af2b-8bbc6a90541d" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"CHANG3D said: ↑ The T-Mo "Cellspot" is the AC68U. But it s also no longer free. Correct me if I m wrong. Click to expand... I believe it s a $25 deposit, but if you ask, you ll get it for free. $99 if you keep it or buy it outright."</post>
   <post id="f02d8749-289a-4c72-bf54-20b27f6382de" section="Smart Phones and Devices" discussion="Sprint users can get a free Asus AC66U router">"Zepher said: ↑ 866-275-1411 is the number I called, but this is number of the dept I talked to, (866) 556-7310, it s Airrave Support. You have to have a WiFi Calling enabled device on your account. Just tell them that you would like a WiFi Connect device for your home. Click to expand... This just worked for me, thank you fine sir"</post>
   <post id="b0b8c139-c084-4ed9-b900-96f0d012aac8" section="Smart Phones and Devices" discussion="Cracked and Locked Screen on a Galaxy S5">"EDIT: SOLVED, SEE POST #2. Howdy all, I ve googled this and tried everything I could think of so I am posting here in hopes someone has some insight on what I can do. I got a cracked screen on a S5 and I am trying to recover data. The only method I have found to be able to do this is to purchase an HDMI connection kit and plug in HDMI to display on the TV and a mouse to unlock the screen. Problem is I can see it fine on the TV but the mouse doesn t show up. I plug in a keyboard and that doesn t work either. I tried two different mice and two different keyboards and I can t get the screen to unlock. The mouse lights up red on the bottom so I know it is getting power and the USB port is working but the mouse pointer doesn t show up on the TV. I ve tried SDK/command line as well with no luck. This just seems ridiculous that I am unable to recover any data off the phone. I m ready to throw in the towel on this thing and declare it a lost cause unless someone has any helpful ideas I might try."</post>
   <post id="cb4f309e-4d3a-4953-ba93-1173785e69e4" section="Smart Phones and Devices" discussion="Cracked and Locked Screen on a Galaxy S5">"I tried one last thing and it worked. For the phones with a pin, you need the HDMI connection kit from above and you have to plug in the keyboard only. Don t plug in power to the kit. Only one I/O will work, either the HDMI or the USB. So, if you plug in the HDMI that is all that works, the USB port will not take in any data. So, all you need to do is plug in phone + USB keyboard tap in the pin and it will unlock. Plug it into a computer and use the Samsung Switch software to backup the data."</post>
   <post id="1991f09c-81e7-45d9-9dd2-29ab410993ac" section="Smart Phones and Devices" discussion="iPhone SE">"I m surprised there isn t discussion about an A9 phone, 2GB RAM and fast storage for a much lower price than a 6S. What do people think about their 5S but overclocked on processing and GPU? Or are 5S units breaking? iOS versions overwhelming their latest phone processor is far off."</post>
   <post id="7ea29545-fcca-4e02-b43b-609d5c629c92" section="Smart Phones and Devices" discussion="iPhone SE">"My 5S works fine on the latest OS. I ordered the SE 2 weeks ago since it was only $50 for the 64GB model, the 16GB would have been free for me, but 16GB is so limiting. I should get it next week, as it was back ordered till the 17th."</post>
   <post id="35587b75-2b02-4411-bac6-2de76581a173" section="Smart Phones and Devices" discussion="iPhone SE">"I like it, size is perfect for me, and will probably be changing over to the 5SE. Just waiting for the teething bugs to be ironed out first."</post>
   <post id="15ca88d9-3cc4-467a-b7f6-85d75755b74c" section="Smart Phones and Devices" discussion="iPhone SE">"I thought it was interesting, but I realized I couldn t go back to such a small screen size."</post>
   <post id="a26fc520-5c0c-425e-91ed-88b96f035a76" section="Smart Phones and Devices" discussion="iPhone SE">"My girlfriend has the SE and adores it. It s not so much the performance or updated camera as the battery life. Her previous iPhone, the 5s, would conk out after a few hours of heavy use. The SE? She can go all day and still have a bit of juice left. It seems like the A9 (plus that slightly bigger battery) does wonders for people with her usage habits."</post>
   <post id="6af9ac88-457d-4b9d-aba1-bbc7820f8b73" section="Smart Phones and Devices" discussion="iPhone SE">"Aurelius said: ↑ My girlfriend has the SE and adores it. It s not so much the performance or updated camera as the battery life. Her previous iPhone, the 5s, would conk out after a few hours of heavy use. The SE? She can go all day and still have a bit of juice left. It seems like the A9 (plus that slightly bigger battery) does wonders for people with her usage habits. Click to expand... It could also be her 5S battery was worn out. I got my 5S in 2012, so it s almost 4 years old, I don t use it heavily, just sits there, but the battery does last quite a few days."</post>
   <post id="56480040-ee95-4e8e-9aef-e96e2dc58a9b" section="Smart Phones and Devices" discussion="iPhone SE">"The SE has NVMe storage like the 6s?"</post>
   <post id="afb492c4-3b92-4fb3-8964-fb55dc44a5e8" section="Smart Phones and Devices" discussion="iPhone SE">"I love my 5S, but the camera is flaky. This might be my next phone. An A9 and the same 12MP camera from the 6S is a steal at $399."</post>
   <post id="8bb0c8c1-0292-48f3-a35e-7fb8f0d6d1a9" section="Smart Phones and Devices" discussion="iPhone SE">"Currently using the SE right now and loving it. My 6S is up for sale on H/Swappa right now. I tried it at first and didn t like it, but now that I ve given it a few days I enjoy my SE a lot now. And yeah the battery is pretty crazy on this little thing, some people are getting near 6 Plus battery times."</post>
   <post id="0d28df5e-eaba-42b9-8167-a53c3fb7bd54" section="Smart Phones and Devices" discussion="iPhone SE">"Zepher said: ↑ It could also be her 5S battery was worn out. I got my 5S in 2012, so it s almost 4 years old, I don t use it heavily, just sits there, but the battery does last quite a few days. Click to expand... Was the 5S really out in 2012? Surely you mean the 4S? Edit: Problably just a typo for the year. At any rate, I suspect a bad battery as well. My 5S lasts a whole day with a good amount of activity."</post>
   <post id="4cd27da4-faf9-4c17-a2db-e2638098f540" section="Smart Phones and Devices" discussion="iPhone SE">"singe_101 said: ↑ I m surprised there isn t discussion about an A9 phone, 2GB RAM and fast storage for a much lower price than a 6S. What do people think about their 5S but overclocked on processing and GPU? Or are 5S units breaking? iOS versions overwhelming their latest phone processor is far off. Click to expand... I m slightly interested in this phone, but honestly my 5S is doing just fine on even the latest OS. I don t feel the need to upgrade."</post>
   <post id="d0b9fe99-5ee2-4d75-8644-93d4b212cbbc" section="Smart Phones and Devices" discussion="iPhone SE">"jbltecnicspro said: ↑ Was the 5S really out in 2012? Surely you mean the 4S? Edit: Problably just a typo for the year. At any rate, I suspect a bad battery as well. My 5S lasts a whole day with a good amount of activity. Click to expand... Ya, it was 2013, for some reason I thought I got it in 2012."</post>
   <post id="b5fdd9cf-6147-4025-a4a7-901a2a0a2b8f" section="Smart Phones and Devices" discussion="iPhone SE">"Jeese I d get it if I could get it for free too."</post>
   <post id="04e9b804-5240-46f6-9f69-cec4dd1f2aa2" section="Smart Phones and Devices" discussion="iPhone SE">"Zepher said: ↑ It could also be her 5S battery was worn out. I got my 5S in 2012, so it s almost 4 years old, I don t use it heavily, just sits there, but the battery does last quite a few days. Click to expand... Nah -- it was like that from the start, and she got a replacement phone that exhibited the same behaviour. It s just a question of near-constant access. I m wondering if this is partly due to the extra RAM, actually -- 2GB means that it s not shuffling things in and out of memory as often."</post>
   <post id="8af78bf3-380d-4b88-be10-f794624bc311" section="Smart Phones and Devices" discussion="iPhone SE">"Aurelius said: ↑ Nah -- it was like that from the start, and she got a replacement phone that exhibited the same behaviour. It s just a question of near-constant access. I m wondering if this is partly due to the extra RAM, actually -- 2GB means that it s not shuffling things in and out of memory as often. Click to expand... Apple doesn t shuffle access to memory, the only time data goes in or out is if your surfing a lot or closing/opening a ton of apps. The 5S had the best battery life at its time of release but it also had a lot of phones that had issues with battery life due to some (probable and unconfirmed rumor btw) battery issues. It was believed that Apple moved to some Chinese maker."</post>
   <post id="83a6619e-934d-419f-b6cc-8931f51b7c2c" section="Smart Phones and Devices" discussion="iPhone SE">"Trimlock said: ↑ Apple doesn t shuffle access to memory, the only time data goes in or out is if your surfing a lot or closing/opening a ton of apps. The 5S had the best battery life at its time of release but it also had a lot of phones that had issues with battery life due to some (probable and unconfirmed rumor btw) battery issues. It was believed that Apple moved to some Chinese maker. Click to expand... Well, that s the thing... she typically has several apps open, and a lot of browser tabs. I m a techie by trade, and she makes me look like a casual user sometimes! Whatever the cause, she s delighted with the upgrade."</post>
   <post id="48183098-f39a-4cb7-9ab0-664c599a7ace" section="Smart Phones and Devices" discussion="iPhone SE">"Have any of you guys end up getting one yet? I held onto my iPhone 5 until AT&amp;T announced the end of 2-year contracts. I like the 6s other than the size. Small children in the house so I use an Otterbox and they just add a lot of bulk to phones. It doesn t fit as well as the 5 did in my pockets. I m tempted to give my wife the 6s, get her 6 replaced from AppleCare+ due to water damage, and then sell the replacement to buy an SE outright for me. I don t use TouchID and while the 3D Touch is nifty, also not a must-have."</post>
   <post id="84af1b5f-a98e-4801-813b-e1c1b58827db" section="Smart Phones and Devices" discussion="iPhone SE">"I know many people who traded in their 6 and 6S for the SE, they primarily did it for the familiarity with the 5/S design type."</post>
   <post id="802fa6f1-aa7c-4e48-afe3-d2c8548b60c5" section="Smart Phones and Devices" discussion="iPhone SE">"I got mine and love it. the rear camera is much much better too. No one believed me when I said I got a new phone since it looks exactly like my old 5s."</post>
   <post id="411bef6a-daa5-48a7-bca8-8c7890df06e9" section="Smart Phones and Devices" discussion="iPhone SE">"Wife has been waiting for it for a while, so I got it for her the day it came out from Tmobile. I think its a piece of shit compared to the nexus 5 she had. She loves the battery life and the camera. I think the UI sucks(no back button), I dont like the apps, I dont like how every apps settings are in the phones settings. No home screen, just an app drawer and getting her favorite ringtone on it took entirely way to long. I also dont like that you cant customize that screen to the left, where it has nearby, siri suggestions and whatever. I have no idea what people are having kittens over, iOS blows compared to Android. But hey, happy wife, happy life. At least now I dont have to listen to her piss and moan, I just say, well I cant do shit about that. Where as before, anything was possible. Obviously, the build quality is superb and fingerprint reader is fast. But that only takes you so far. On the other hand, I will concede, the Air 2 with cell that we have(also the wifes idea) is excellent as far media consumption goes. That surprisingly works very well to watch netflix, plex, surf the web, facetime with the family (they are all suckers who got iOS devices too, except my dad, we are the only smart ones)."</post>
   <post id="16df32e8-b9d0-4d7c-9f78-2d78adeba05c" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"http://www.cnet.com/news/google-htc-vets-prep-friggin-awesome-smartphone-for-sept-1-launch/ Google, HTC vets  friggin  awesome  smartphone for 9/1 launch http://nextbit.com/ Sounds interesting but no leaks or not much info floating around other than a lot of bold claims"</post>
   <post id="d8a4e80f-5c10-486f-b701-53704d8a1dc0" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"I don t really understand what he means by the phone will be better over time through software enhancements... Also really worried me about getting security updates. But this phone is on my radar as well. Nexus 5 (2015) and this can t come soon enough. I m using an iPhone right now, and I really want to switch back as long as I would get quick security update and quick bug fixes. The HTC One M8 s 5.0.x experience is ridiculously bad; it s Google s fault. 5.1 fixed it, but I had to root my phone to get it. And HTC is not going to update it until end of this year for the M8 model. And HTC is probably the second best at updating behind Motorola right now. This was one of the greatest driving factor for me to get the iPhone."</post>
   <post id="ccba1334-84ec-4d3c-bee2-38b35270aaa1" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Better over time typically means rushed and unoptimized software at launch. ie AMD drivers."</post>
   <post id="79755875-3678-41f9-96e9-7eb874586ccc" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Nextbit is a small band of rebels who want to free people from the limits of today&amp;#8217;s mobile technology Click to expand... This is their claim. It s right in the middle of the page as you scroll down and seems to be their claim to how they are going to be different. Anyone want to make a bet? I ll put down $20 in PayPal that the phone doesn t have at least one of these features that should be on every 2015 phone. Nfc Wireless charging Front facing speakers Micro sd card slot 1080x1920 screen that has decent viewing angles and good brightness Some form of quick charging Stock android or a very light modification like Motorola iteration of android."</post>
   <post id="c4b662d7-1ed4-427b-be34-6603ad9e5bbb" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"I m curious, but Nextbit comes across as another OnePlus: it s promising a lot, but whether or not it delivers is another matter."</post>
   <post id="32066154-e1c5-4c0c-a6f0-ff96303667f9" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"9/1 is pretty close and no one has been talking about this phone until now? That seems pretty weird."</post>
   <post id="d597d783-16bb-4930-809b-5dd2195a71a7" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Early versions of this phone are showing up. Lets see how my prediction ended up. Nfc Wireless charging Front facing speakers Micro sd card slot 1080x1920 screen that has decent viewing angles and good brightness Some form of quick charging Stock android or a very light modification like Motorola iteration of android. Click to expand... Not terrible. I don t think they went in the right direction though. Infrequently used apps uninstall themselves to "save space". They did this to address the problem with phone storage. It ships with 32gb of internal storage and 100gb of cloud storage. I don t really understand how this will be useful because apps are generally only a few megabytes and wont free up too much space by removing them. To compound things, this system only works on wifi so if you are out and about and want to use an app that was automatically uninstalled, you are out of luck. I like that they are trying to solve problems. I just don t think they went about fixing them the right way. A microsd slot would have made more sense.\ https://www.youtube.com/watch?v=LSbwNF6vF7U"</post>
   <post id="f28a0cf1-29eb-4a34-9d79-ec6bc71bd142" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"lloose said: ↑ To compound things, this system only works on wifi so if you are out and about and want to use an app that was automatically uninstalled, you are out of luck. Click to expand... I checked out the youtube link you put up and it says it will work on Wifi and cell data. It s a damn shame they couldn t fit a 3000mah battery"</post>
   <post id="227e9ae1-7245-4705-a8a6-708218086e17" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Another square phone, smh"</post>
   <post id="32bc298f-f2ad-4973-82c5-cb09f1a85193" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Bman123 said: ↑ Another square phone, smh Click to expand... Agreed. I would much prefer a phone in the shape of a triangle Oh well, should be interesting to see the software enhancements Nextbit is promising."</post>
   <post id="581082a6-3308-4b92-a0f5-715901ddf9ce" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"The only cloud-first smartphone. It gets smarter everyday and makes running out of space history. Click to expand... Instead I run into my data cap in record time. Unless telecoms change, this isn t going to end well."</post>
   <post id="2a37f8f8-04d2-4613-8d62-e674ec53718c" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"ChronoReverse said: ↑ Instead I run into my data cap in record time. Unless telecoms change, this isn t going to end well. Click to expand... Default settings use Wi-Fi..."</post>
   <post id="a9012a90-86ab-4f33-a062-c9c7a47a8646" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"eallan said: ↑ Default settings use Wi-Fi... Click to expand... Standard fare but not using the space saving tricks (that aren t very good in the first place) half the time isn t exactly exciting. You know how you can end storage anxiety? 128GB storage default. But then you won t use their cloud services ever and give them a revenue stream, which is what this is really about."</post>
   <post id="94618e08-4c4b-4966-ab0d-7c8fccfc7d00" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Looks like they completed the negotiations with Verizon."</post>
   <post id="ed5479d4-41e5-45de-9c3f-c25dbe16f590" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"I bit on a VZW one today... 32GB internal is plenty of storage for me, and it just seems like a cool concept to support. I have unlimited data so that makes the decision easier..."</post>
   <post id="b031b4eb-f860-4d1b-ae5a-25032b7429ac" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Its a start up making BIG promises. I don t buy a single word they are saying."</post>
   <post id="41b107a8-070c-4bd4-9a4e-2b63e9a6d731" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Phones are already nearly 100% cloud so sounds like hype and it kind of looks like a child s toy. Only attraction is the low $300-350 price and maybe non-carrier bloat but questionable if they ll be around to update it. Might as well get a Nexus without the risks."</post>
   <post id="ec7bd04b-1207-4d35-a957-65beddc61bce" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Nextbit Robin Factory Unlocked Phone - Mint (U.S. Warranty) $299"</post>
   <post id="f601d1ca-c4e2-4c02-9d32-5a72b4883863" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"That s a lot of big promises for a first product. I m all for revolutionary new gear but most of them don t live up to the hype. I ll keep my fingers crossed that this succeeds but, personally, I m happy with my iphone."</post>
   <post id="a1174473-285c-4d08-a06e-0bc62ad3cc0b" section="Smart Phones and Devices" discussion="Nextbit? Google, HTC vet prep  friggin  awesome  smartphone for 9/1 launch">"Here s the thing: I m just happy that Nextbit s first phone is a genuinely competent, unique device. It s hard to stand out in the mobile world, even if you have veterans at the helm."</post>
   <post id="940548fe-1ae7-4464-b33e-0053e3a3ebc5" section="Smart Phones and Devices" discussion="The strangest probkem ive ever encountered">"Hi guys. I have a strange issue with one of my devices. A galaxy s5 not a year out of the box is totally UN usable. Its incredibly slow. But. Let me explain. I ve done a factory reset. Cinpletley wiped it. Cache too. Now it s still slow. Screen takes about 4 seconds to respond. Even stranger. Is that even when the phone is off and charging. The battery animation also lags and moves about 1 frame every 2 seconds. The boot animation is the same story. Any ideas? It was dropped about 14 hours prior to this but all seemed fine. Please any advice would be great as this HTC one is killing me!"</post>
   <post id="cf29c0a2-98d2-41f7-a094-369b433164a2" section="Smart Phones and Devices" discussion="The strangest probkem ive ever encountered">"RIP slow performance on a phone is almost always flash storage issues"</post>
   <post id="54c15fed-1ab9-4866-a714-0ad5300e8d4a" section="Smart Phones and Devices" discussion="The strangest probkem ive ever encountered">"That was my first thought. Which is why I removed all external storage. But a year out of the box? Should be covered under warranty something like that no?"</post>
   <post id="6b25206f-9aa1-4d5b-862c-5b56f1c993be" section="Smart Phones and Devices" discussion="The strangest probkem ive ever encountered">"grandfatman said: ↑ That was my first thought. Which is why I removed all external storage. But a year out of the box? Should be covered under warranty something like that no? Click to expand... If it s within a year, yes. If not, then no."</post>
   <post id="7b254a4b-3abb-4dd9-a54b-2cf1249ce3c2" section="Smart Phones and Devices" discussion="The strangest probkem ive ever encountered">"grandfatman said: ↑ It was dropped about 14 hours prior to this but all seemed fine. Click to expand... I guess things weren t all fine after all. Might get denied warranty if there s any physical signs of dropsm"</post>
<post id="39091d12-8adf-4477-9a19-efd085f92fb5" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Welcome to the new, simplified [H]ard Forum Storage Showoff Thread Anyone can post here regardless of system specs, but only standout systems will be shown in the "featured" systems section. For example: 50TB+ 10+ Drives Unique setups Clean systems To be considered for the featured section, you must have: Pictures of your actual hardware (not a screenshot of disk management) Full system specs Photos must be hosted on http://imgur.com/ unless you have your own hosting and are an established forum member Your post should include the following information (Make sure you have the storage amounts in bold text and at the front of your post): Amount of total storage Case PSU Motherboard CPU RAM Controller Cards (if any) Hard Drives (include full model number) Operating System (A short paragraph here describing what you use your storage for and how you handle backups and organizing) Click to expand... FAQ unhappy_mage said: ↑ Is the "advertised" space before or after raid? Suppose I have 10 1TB drives in raid6 for 8TB of "advertised" space after raid, does this count? I think the intended meaning in the thread is "sum advertised space of drives in your system" (e.g., 10 * 1TB =&gt; 10TB), but it could mean "compensate for advertising overhead on the amount of usable space you have" (e.g., 7.6TB because drives are smaller than 1TB each =&gt; 8TB). Click to expand... The sum of the manufacturer stated capacity for all your drives. Ignore RAID, formatting, etc. lundrog said: ↑ Clarification, at home or work? And Paid for by personally or by work? Click to expand... You can post anything, but specify if it s work Old threads http://www.hardforum.com/showthread.php?t=1146317 http://www.hardforum.com/showthread.php?t=1393939"</post>
   <post id="59df2335-e987-49a8-80dd-bc0d7e5da832" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Featured Systems: 1) houkouonchi (458TB) http://hardforum.com/showpost.php?p=1041328488&amp;postcount=5"</post>
   <post id="39ea5c36-ae60-4bee-bcea-bf9d09d5bb27" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"...."</post>
   <post id="2db9bfa2-11d2-4d18-b7e1-35e1370c2580" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"...."</post>
   <post id="83ec8243-6ec5-4443-97e9-d7eef69c9c08" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Total multiple system storage 458 TB Total single/internal system storage 108 TB Picture is a bit old: I will be taking some new pictures when I get a chance. Some of the storage is off-site (myth machine at my dad s house) and colo box... Local Machines In order of machines in picture: Router box/zeroshell (labeled  zeroshell  top machine in rack - 1u): Total Storage 3 TB Code:"</post>
   
   <post id="087b5798-f662-40ad-ac76-9f70f924013b" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"houkouonchi said: ↑ Total multiple system storage 458 TB Will have entire specs post done within 15-20 min.... Click to expand... WOW. Please include system wattage if possible. A TB/watt would be an interesting stat to include here."</post>
   <post id="e71021be-5167-422a-b79b-ff8931d1d792" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"longblock454 said: ↑ WOW. Please include system wattage if possible. A TB/watt would be an interesting stat to include here. Click to expand... A lot of the machines do not run anywhere near 24/7. Here is the power usage of my rack currently: So about 1200 watts. Although quite a bit of extra power is being sucked by one machine that has 2x10 core CPU s and is hammering the CPU most of the day (atleast 150 watts) and another box which is 2x8 core CPUs (although much more idle). This is with 85 disks powered on in 5 chassis. The disks are: 53x 4TB 5K4000 Hitachi/HGST coolspin disks. 30x 3TB 5K3000 Hitachi/HGST coolspin disks. 2x 1.5 TB seagate 7200 RPM disks. So 305 TB disks powered on using 1.2 kilowatts so that is about 4 watts per TB."</post>
   <post id="7db40892-1743-4ac1-92bb-6dd2417d244f" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Total: 87T One Case: 63T Code: Supermicro SC846E16 &amp; 2 x SE3016 SAS expanders"</post>
   <post id="2d47228e-632a-448c-b024-3a528489a73f" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"30 TB storage, expanding to 44 TB Soon Nanoxia Deep Silence 1 case with a Coolermaster 4 in 3 drive holder for the external bays. Due to the locks the door can t close all the way but it does close enough to keep the noise down. Corsair TX 750w power supply. It had enough sata cables to power each drive, and it was cheap. Definitely overkill for this system. Asrock FM288M-HD+ Micro ATX board, with support for 8 sata devices A6 7400K set to 45w TDP 8GB DDR3 PC1600 Vantec 6 port Sata 6gb/s PCIe Raid Host card. 4 ports internal, 2 esata out. Needs PCI express x2 slot or better. Various hard drives ranging from 2TB (older Samsung), 3TB (Toshiba DT01ACA300) to 4TB (HGST Deskstar) Windows 8.1 with Flexraid Transparent raid This machine s main purpose is to run SABnzbd, and the usual apps (couch potao, sonarr, headphones) The majority of the drives currently are not in a raid, as it s things I won t miss if a drive dies. Currently the only part that s in a raid is 8TB which is music, SD movies and various files. My future plans is to use the esata ports and buy two external drive enclosures (more than likely the Vantec Nexstar HX4) and fill them with 4 or 8TB drives, if they are cheap enough. The vast majority of my data is video and will never change so the cheaper archive drives will be adequate. If I go with 8tb drives I ll raid all of it."</post>
   <post id="7be9e4fe-e638-43a9-a28c-f6054d670d6a" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"**blind**"</post>
   <post id="9f2a7b9a-2f0c-4e05-abb0-dd917c66224b" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"very nice build. One day I will be......"</post>
   <post id="3e2107bd-3969-49c2-90f7-7d07901be4d8" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Current total is about 120TB. Primary server consists of the following: Supermicro 846E16 Supermicro A1SRi-2558F and 8gb ECC RAM Intel 320 40gb SSD Areca 1882i 24 x 2TB Hitachi disks Secondary server consists of the following: Supermicro 847E1 Supermicro X8DT3-F with Xeon L5630 and 8gb ECC RAM Imation 32gb SSD Areca 1880i 26 x 2TB Hitachi disks 10 x 1TB Hitachi disks File servers #3 and #4 only have a couple disks each, so won t bother mentioning them. Third (and fourth, not pictured) 4U chassis aren t in use at the moment, but should be soon seeing as I m completely out of space. Have only ~3TB total free. Secondary server has been moved to colo, but it just functions as an offsite backup."</post>
   <post id="bde816f4-845d-4d14-a9f7-71854a931722" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Subd"</post>
   <post id="be40807b-b02b-46f0-b32e-f531f9290e7b" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"My SFF addition 36TiB total, 32.7TiB usable for storage iStarUSA S-915 case (modded) - 17L of volume ASRock C2550D4I 32GB Unregistered ECC memory IBM M1015 20x Seagate M9T 2TB HDDs (one big Z2 set) for storage Silverstone 450W Bronze PSU to push all of the 5VDC needed"</post>
   <post id="0b50260a-6820-4c29-9c10-1b1e7525d27c" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Amount of total storage in picture: About ~147Tb Systems from top to bottom: HyperV #1 Case: Sun X4170 PSU: Dual 760W Proprietary Motherboard: Proprietary CPU: Dual Xeon L5520 RAM: 24Gb DDR3 ECC Controller Cards: Sun OEM Adaptec ASR-5805 w/Battery Hard Drives: 2x 146Gb 10k SAS RAID1 (Hitachi HUC10141CSS300) 2x 120Gb SSD RAID0 (Intel 330) Operating System: Hyper-V Server Click to expand... HyperV #2 Case: Sun X4170 PSU: Dual 760W Proprietary Motherboard: Proprietary CPU: Dual Xeon X5570 RAM: 24Gb DDR3 ECC Controller Cards: Sun OEM Adaptec ASR-5805 w/Battery Hard Drives: 6x 146Gb 10k SAS RAID5 (Hitachi HUC10141CSS300) Operating System: Hyper-V Server Click to expand... HyperV #3 Case: Sun X4170 PSU: Dual 760W Proprietary Motherboard: Proprietary CPU: Dual Xeon X5570 RAM: 24Gb DDR3 ECC Controller Cards: Sun OEM Adaptec ASR-5805 w/Battery Hard Drives: 6x 146Gb 10k SAS RAID5 (Hitachi HUC10141CSS300) Operating System: Hyper-V Server Click to expand... HyperV #4 Case: Sun X4600 M2 PSU: Quad 950W Proprietary Motherboard: Proprietary CPU: 8x Opteron 8389 RAM: 128Gb DDR2 ECC Controller Cards: Sun LSI SAS 106x based RAID Onboard Hard Drives: 2x Intel SSD RAID0 (Intel 330) 2x 146Gb 10k SAS RAID1 (Hitachi HUC10141CSS300) Operating System: Hyper-V Server Click to expand... DAS1 Case: EonStor Fiber Channel Attached Array PSU: Dual 400W Motherboard: Proprietary CPU: Embedded RAM: 512Mb DDR Controller Cards: Proprietary Hard Drives: 16x 1Tb Seagate 7200.11/7200.12 Drives RAID6 Operating System: Embedded Click to expand... DAS2 Case: EonStor Fiber Channel Attached Array PSU: Triple 405W Motherboard: Proprietary CPU: Embedded RAM: 1024Mb DDR Controller Cards: Proprietary Hard Drives: 16x 2Tb Western Digital WD20EADS/FALS Green Drives (I know) RAID6 Operating System: Embedded Click to expand... DAS3 Case: EonStor Fiber Channel Attached Array PSU: Triple 405W Motherboard: Proprietary CPU: Embedded RAM: 1024Mb DDR Controller Cards: Proprietary Hard Drives: 24x Hitachi 2Tb UltraStar Drives, 2x 12 Drive RAID6 Operating System: Embedded Click to expand... DAS4 Case: EonStor Fiber Channel Attached Array PSU: Triple 405W Motherboard: Proprietary CPU: Embedded RAM: 1024Mb DDR Controller Cards: Proprietary Hard Drives: 24x Hitachi 2Tb UltraStar Drives, 2x 12 Drive RAID6 Operating System: Embedded Click to expand... This equipment is in a colocation facility but I paid for it myself and own it"</post>
   <post id="e9f971b4-1c44-41e1-b337-ddeeb4f3f4d2" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"FLECOM said: ↑ reserved also imgur? really? ugh Click to expand... best free hosting I ve found, do you have an alternate to recommend? and what do you have against imgur?"</post>
   <post id="d352d0ad-f57e-4eaa-9919-1a44af05aa73" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"I think he s more alluding that most of the people on here with a lot of storage have colocated servers and don t need to rely on third party hosting."</post>
   <post id="7374bc2a-3908-482f-989e-547c68036893" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"Blue Fox said: ↑ I think he s more alluding that most of the people on here with a lot of storage have colocated servers and don t need to rely on third party hosting. Click to expand... I think the fact that it was listed as a requirement to be considered as a  featured system  is what probably prompted the negative connotation. I have, and always will, use my own hosting which is on hardware owned by me (colo d) which I have control over and is backed up to my home machine everyday. I have way more faith in my own hosting than a free third-party one that could potentially go  poof  some day. I get that the issue is probably we don t want broken links. I do have to say BlueFox that you should at least have some hostname associated with your image links as going strait to an IP like that guarantees its going to stop working some day in the future."</post>
   <post id="c6dc3e8a-1d48-474c-89f0-cd5216c0896a" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"houkouonchi said: ↑ I think the fact that it was listed as a requirement to be considered as a  featured system  is what probably prompted the negative connotation. I have, and always will, use my own hosting which is on hardware owned by me (colo d) which I have control over and is backed up to my home machine everyday. I have way more faith in my own hosting than a free third-party one that could potentially go  poof  some day. I get that the issue is probably we don t want broken links. I do have to say BlueFox that you should at least have some hostname associated with your image links as going strait to an IP like that guarantees its going to stop working some day in the future. Click to expand... You could always upload it to imageur AND host it yourself - Something like this? Code: [url =YOUR_HOSTING][img]IMGUR_HOSTING[/img][/url] (Honestly, just saving myself a spot on the front page. I did some alterations since the last thread. Got yelled at for having my UPS on the carpet, so it s sitting at the top of the stack. I ll update this post when I get some new photos up.) Please excuse the mess: ~96TB total storage Code: Supermicro SC822T"</post>
   <post id="-E3-1230" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-X9SCL-F" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-4x8GB DDR3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-1x320GB WD RE2" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-ESXi 5.5 Host" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Supermicro SC822T" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-E3-1230v2" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-X9SCL-F" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-4x8GB DDR3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-1x320GB WD RE2" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-ESXi 5.5 Host" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Supermicro SC846" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-E3-1220v3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-X10SL7-F" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-4x8GB DDR3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-AOC-S2308L-L8e" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-24x2TB Seagate SAS" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-ESXi 5.5 Host (NAS and Infrastructure)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Supermicro SC846" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-E3-1220v3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-X10SL7-F" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-4x8GB DDR3" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-AOC-S2308L-L8e" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-24x2TB Seagate SAS" section="##2##" discussion="##3##">"##4##"</post>
   <post id="-ESXi 5.5 Host (Backup)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="The NAS VM has a 2308 passed through with all 24 drives on it. It s the datastore for the rest of the setup. It s rsync d nightly to the Backup VM on the other SC846, which also has a 2308 passed through. Snapshots are taken every night, and retained for 30 days. The two SC822Ts are clustered together, and contain the majority of my &quot;real&quot; VMs: Spoiler: VMs Code:" section="##2##" discussion="##3##">"##4##"</post>
   <post id="centos                      A   192.168.0.35 # VM for Linux desktop stuffs" section="##2##" discussion="##3##">"##4##"</post>
   <post id="chan                        A   192.168.0.22 # Imageboard" section="##2##" discussion="##3##">"##4##"</post>
   <post id="forum                       A   192.168.0.26 # Old vBulletin forum" section="##2##" discussion="##3##">"##4##"</post>
   <post id="ftp                         A   192.168.0.19 # FTP server (obviously)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="irc                         A   192.168.0.25 # IRC server (obviously)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="mail                        A   192.168.0.16 # Mail server (obviously, but inactive right now)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="minecraft                   A   192.168.0.34 # Minecraft server (obviously)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="nis                         A   192.168.0.20 # NIS and DNS server (On the top SC846)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="ntp                         A   192.168.0.27 # NTP server (On the top SC846)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="pxe                         A   192.168.0.18 # PXE and DHCP server" section="##2##" discussion="##3##">"##4##"</post>
   <post id="tim-and-sarah               A   192.168.0.28 # Web site 1" section="##2##" discussion="##3##">"##4##"</post>
   <post id="vcsa                        A   192.168.0.13 # vCenter Server Appliance (on the top SC846)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="voice                       A   192.168.0.23 # Teamspeak, Ventrilo, etc" section="##2##" discussion="##3##">"##4##"</post>
   <post id="vpn                         A   192.168.0.17 # OpenVPN" section="##2##" discussion="##3##">"##4##"</post>
   <post id="webproxy                    A   192.168.0.24 # Proxy (Apache) for my two sites" section="" discussion="##3##">"##4##"</post>
   <post id="wiki                        A   192.168.0.21 # Wiki page (not really used)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="win10                       A   192.168.0.36 # Win10 testing VM" section="##2##" discussion="##3##">"##4##"</post>
   <post id="win81                       A   192.168.0.37 # Win 8.1 VM for RDP (My home away from home)" section="##2##" discussion="##3##">"##4##"</post>
   <post id="www                         A   192.168.0.29 # My main web site" section="##2##" discussion="##3##">"##4##"</post>
   <post id="2c9ab591-6bae-41a0-af46-fd5c90211e52" section="SSD and Data Storage" discussion="[H]ard Forum Storage Showoff Thread 2015">"houkouonchi said: ↑ I get that the issue is probably we don t want broken links. I do have to say BlueFox that you should at least have some hostname associated with your image links as going strait to an IP like that guarantees its going to stop working some day in the future. Click to expand... that s it, seems like I see a lot of photobucket or other crap hosting used and then the pics are gone a few months later I ve modified that requirement for you guys that are established and have your own hosting"</post>
   <post id="b95c810d-b0bd-4012-840e-94ed06875b80" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Fall 2015 Solid State Drive Technology Update - Since our last SSD update article, the last 7 months have seen no shortage of exciting announcements, and the enthusiast market has rapidly evolved in both positive and confusing ways. Let’s get up to speed on U.2, NVMe, 3D XPoint, M&amp;A, and the rest of the buzzword soup that make up this market."</post>
   <post id="1003e6c9-fb67-4bbc-9ca2-db51c667b800" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"So it seems that the real issue for anybody who wants to go faster than a couple of Sata drives in RAID is the PCIe bottleneck. One or two GPUs, whether for gaming or rendering, will starve these things for bandwidth. Other than trying to force people onto -E or -EP chips, is there any real reason for Intel persisting with the low number of lanes? It s like the US cable companies shifting more things onto streaming without boosting speed or data caps."</post>
   <post id="a10deaef-a741-4d74-8bc2-ccd94998bb32" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Awesome write up just the right amount of detail and length to sum it all up. Thanks for the time and effort."</post>
   <post id="d16c7544-c810-4b13-aea2-29f4aba12217" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"I m hoping on a 950 Pro [H] test in the near future! The 512GB version certainly has my interest."</post>
   <post id="d236b116-d2a3-455d-9b37-77f42360c8ee" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Excellent article - had to read most of it really slowly but that s a good thing!"</post>
   <post id="49a2338c-9a44-4f76-a17c-2166ca8dfa2c" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"great overview. I m still cloudy on a few things with my asus deluxe z170 but I ll worry about that if I actually want a PCIE ssd. For now I m sticking with my 850 pro."</post>
   <post id="2f6ac86d-caf1-4299-8db8-abf6463f365d" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Teenyman45 said: ↑ So it seems that the real issue for anybody who wants to go faster than a couple of Sata drives in RAID is the PCIe bottleneck. One or two GPUs, whether for gaming or rendering, will starve these things for bandwidth. Other than trying to force people onto -E or -EP chips, is there any real reason for Intel persisting with the low number of lanes? It s like the US cable companies shifting more things onto streaming without boosting speed or data caps. Click to expand... Ideally the mainstream Core i processors should have at least 24 PCI-E lanes from the processor (16 for graphics and 8 for PCI-E based storage, or some combination thereof). I don t see that happening though as it would cut into sales of the E series chips."</post>
   <post id="21f3306d-589c-41d4-b6f5-f5c628535a27" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Loving my Intel 750. Looking forward to what comes next, but I can honestly say the speeds I get today I will be happy with for the next several years."</post>
   <post id="2a7f65f5-1a9c-4634-8dfe-427a7cf9fb36" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Awesome article, [H]! Thanks for putting in the time for this. \m/"</post>
   <post id="35621edd-ac2b-4707-ba4d-1d54076e868c" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"I dont have any heat issues throttling my SM951 that I am aware of. Would like to see a comparison with SM951 and 950 Pro both m.2"</post>
   <post id="f264465a-7562-44a1-8a76-e3e1250fe37b" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Good article, it surely can be confusing. I just helped my friend build a comp for his friend; picked out all the parts and sent him a list...he deviated from the list and screwed it up bad LOL. They went to fry s, had a 5820K on sale for the same price as a 4790K so he bought it, but kept the same mobo for the 4790. Doh. Then went with a refurbed m.2 which the motherboard didn t have. Bought a cheapo PS because he wanted to keep his budget. Doh. which wouldn t have even booted with the 980Ti and 5820K. They went back that night and stuck to the list, it s a super nice machine. Needless to say, SSD standards are confusing, this was a clear and concise article, well done. Anyone see that article about NAND on a DRAM board? I think it was Intel who conjured it up, looked cool. I ve always wondered when would transition to something like that."</post>
   <post id="dda6df83-a199-4c30-b83b-546ae3f18829" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Anantech reviewed the 950 Pro last week -- and yeah its fast as hell! For normal consumer type IO it is faster than the Intel 750 -- but when you really throw tons of IO -- especially on a drive in  steady state  the Intel 750 handles it much better -- really showing it s roots as a server based SSD."</post>
   <post id="5ced8bc9-b2cd-4d90-aa61-8aede5c5403f" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Sparky said: ↑ I dont have any heat issues throttling my SM951 that I am aware of. Would like to see a comparison with SM951 and 950 Pro both m.2 Click to expand... http://www.legitreviews.com/samsung-sm951-512gb-m-2-pcie-ssd-review_161689/3"</post>
   <post id="8b8ba88f-12b7-4cd6-88b5-02985bcaaab5" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"The 950 Pro reviews pretty much show that - for consumer market - the performance gains are not that big of a deal imho, and the price/performance takes a big hit. I d stick with SATA drives for now, you can get a 1TB drive for close to 30 cents per gig, not too shabby."</post>
   <post id="6463725f-e06c-4a06-a9c9-7d44c8c7846e" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"But back to the top of the heap. Can the Samsung 950 Pro or one of the other scrappy challengers unseat the mighty Intel SSD 750? Will developers finally give us a reason to care? Stay tuned, and brace for impact. Click to expand... I don t really want the 950 Pro to beat out the 750, I want the 950pro to be more price competitive instead of being priced similarly. I also think we have enough reasons to care right now for faster storage but none of them are on the gaming side, or even the consumer side. I would love to see mother boards for data centers/VMLabs that have tons of connectors for m.2/u.2 drives. Great article Chris/Kyle, its always nice to get something that brings together all the technologies and compares them. Its real easy to forget about some other the other tech that s been release with all that s been going on."</post>
   <post id="82162930-d033-4901-9018-ab3369ddde46" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Now that s what I call a refresh on current SSD tech. Seriously appreciate the time spent on this bad boy. It ll save many of us so much trouble when we go past SATA-spec stuff. Cheers!"</post>
   <post id="32a4db69-23e6-4a61-b5de-77de6c84d50e" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"Thanks guys. Hoping to get a 950 Pro in soon."</post>
   <post id="ed12f378-5314-46b0-bb5f-bfcfb2b86c3a" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"extide said: ↑ Anantech reviewed the 950 Pro last week -- and yeah its fast as hell! For normal consumer type IO it is faster than the Intel 750 -- but when you really throw tons of IO -- especially on a drive in  steady state  the Intel 750 handles it much better -- really showing it s roots as a server based SSD. Click to expand... Intel released new firmware for their 750 on Oct.23 and I don t think Anandtech used this firmware. It does speed up the drive. https://downloadmirror.intel.com/18455/eng/Intel_SSD_Toolbox_3_3_2_Release_Notes_325993-021US.pdf"</post>
   <post id="2a44a3b0-cb0a-4925-b095-2b0a8f3ff3f0" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"yep i agree i ve had mine since before they came across the pond and i hammer mine hard everyday and has not throttled once!.but i have a 540 air which imo is a great case for cooling.most people that complain about throttling are using crappy cases and mutiple video cards.all my stuff is water cooled so that helps too i m sure."</post>
   <post id="78f206eb-f0c4-4d60-8d6b-5f4e8faff70d" section="SSD and Data Storage" discussion="Fall 2015 Solid State Drive Technology Update @ [H]">"This new stuff is a bit confusing. Thanks for the chart it helps make sense of it."</post>
   <post id="88b93f47-6067-44ea-a80c-cc0973136719" section="SSD and Data Storage" discussion="SSD raid1 on promise controller [AMD]">"Anybody attempt this and does it work? I have a older Gigabyte UP4 with two raptors in raid1 but was thinking of going SSD. Most of the latest SSD; s have garbage collection good enough that trim is not completely needed. I am aware with Intel trim does not work with RST but can t find anything about promise. Nothing in their raidxpert doc states anything directly about SSD s. Under win10 the currently raid1 drives could be converted into storage spaces, basically a virtual drive. Thoughts?"</post>
   <post id="c61bcd52-ece8-4be3-bdc0-74437ce4d6f3" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Why is it that the chassis is the hardest component to pick when looking for a storage solution that contains between 24-45 disks? I ve had all the other components picked out for several months now, but it s very hard to settle on what chassis to use, how many disks it should have, should it be backplane or direct connect, etc. I have a 20TB home backup storage server RAIDZ1, and need to upgrade urgently, hemorrhaging data. I ve mulled over the following choices: NORCO RPC-4224 (24 disks) Supermicro 24/36/44/45 disk chassis in server or JBOD configuration Storinator (backblaze pod) 30/45 disks with Rocket 750 card Some of the problems that I can t solve: -price point is a pretty big factor, and it s hard to argue against reliability and safety but still -number of disks, not sure I would need 45 disks, might not fill up all of them by the time SSD technology or other storage technologies start becoming affordable at large scales, by the next upgrade I d be using non-SATA3 drives and this chassis would not work... -power, paying for electricity is a significant expense per month ~$40, JBOD or server, cannot run multiple servers with multiple storage pools due to $$ and split archives -direct attach vs backplane, direct seems more convenient and safer, no backplane to deal with but harder to work with if a cable goes wrong. NORCO backplane might not be very reliable, Supermicro backplane should be reliable especially with the redundant backplane components but expensive... I m hoping to get 8TB WD Reds, 8-12 hdds for the first round to start, should be sufficient for a few years. I also have 6 4TB disks in another server that might make sense to migrate into the new server to save power, or should I use existing server to control a JBOD, that would save ~$800 worth of various components."</post>
   <post id="39f09e32-88ba-4e96-9cc4-8b302b3017e6" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"I would stay away from NORCO. They are much cheaper for a very good reason. I love my Supermicro and considered the NORCO for a while before deciding on the Supermicro. Biggest factors for me was I want redunandant PSU and the Supermicro comes with it, NORCO did not and that alone brought the prices much closer. I wanted a JBOD SAS backplane and Supermicro did not have the reported issues that NORCO has. In short if you search NORCO you will find many quality control issues and once you add in the cost of a good PSU the prices are not that far apart."</post>
   <post id="5d244cf2-a2a9-4b66-8f24-312c9367fcab" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Yeah, that s what I ve seen for NORCO JBODs, they re only a few hundred cheaper than Supermicro, but like a $1000 more than a non-JBOD NORCO. Doesn t make sense, $400 for a 24 bay NORCO PC case without PSU or $1500 for the same thing with a PSU and a backplane with external connectors (JBOD). Don t believe the extra JBOD and PSU add up to a $1000. Problem with going with PC case route is that you ll spend extra on PC components up to $800, and then pay the utility bill, (ignoring solar comments) which is like paying for a 200W light bulb 24/7 per month."</post>
   <post id="0a579fb9-f229-4563-b737-4af106707b08" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"A good redundant PSU and the backplane are not exactly cheap. The PSU will run you around $500 by itself easily. Backplane though should not be more than $100 at most. So that gets you within $400."</post>
   <post id="125cef45-420e-440a-b1fa-c42831858301" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Supermicro chassises are today available for less than Norco on Ebay! And they come with two PSU s."</post>
   <post id="fcdcd0ca-b587-400b-9027-74707f4a0b7d" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Yea, I picked up a 36 bay supermicro server for $600. Dual quad L5420, 32gb RAM, dual PSU, and full of disk trays. Added an M105 and done. Still only have 10 drives populated, but with 36 bays I have more than enough room to grow at 4-6TB per drive."</post>
   <post id="65b4fea7-1561-4ac4-b11c-ac1710bbb4d3" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Yeah, I m leaning towards staying away from NORCO. Ebay seems to have the old SAS1 backplanes which seems like it s going to be a bottleneck, I want SAS2. Not that many choices on ebay though. Anyone have a guide to interpreting Supermicro s model numbering system? Their retarded site doesn t have a good comparison tool and so you have to open the ones you think you want and visually compare the differences and even then it s not clear, so you have to open the manual and look for it there, but even then sometimes it s not explicitly stated so you have to guess. Interested in - Super Micro Computer, Inc."</post>
   <post id="7e2c6bfb-65e1-47d2-9bd4-747be9937ac1" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"You can pick A or TQ. 3 controllers performs better than a SAS2 expander. And 3 pcs of for example Dell H310 is only $150."</post>
   <post id="d80e50d7-fce7-4778-b31f-f198acc7d6b8" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Dont forget Craigslist, I bought a 16bay supermicro chasis for $75 that included fans and both PSUs Granted I trolled CL for 3 months before I found this deal."</post>
   <post id="71031f05-1fb9-424a-8bff-eb19e0b84757" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"kandrey89 said: ↑ Yeah, I m leaning towards staying away from NORCO. Ebay seems to have the old SAS1 backplanes which seems like it s going to be a bottleneck, I want SAS2. Not that many choices on ebay though. Anyone have a guide to interpreting Supermicro s model numbering system? Their retarded site doesn t have a good comparison tool and so you have to open the ones you think you want and visually compare the differences and even then it s not clear, so you have to open the manual and look for it there, but even then sometimes it s not explicitly stated so you have to guess. Interested in - Super Micro Computer, Inc. Click to expand... I thought this too. i went from a 20 port sas2 expander to a 36 sas expander and the results with 16 2tb drives were identical."</post>
   <post id="0d55afb1-3884-43f1-a807-64ee02bc4cb6" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Master_shake_ said: ↑ I thought this too. i went from a 20 port sas2 expander to a 36 sas expander and the results with 16 2tb drives were identical. Click to expand... How were you running the drives in a ZFS? Individually? olavgg said: ↑ You can pick A or TQ. 3 controllers performs better than a SAS2 expander. And 3 pcs of for example Dell H310 is only $150. Click to expand... 3 PCs? No thanks, which part of the power bill didn t you get? Why would I pay 400W extra in CPU/MOBO/RAM for the 2 computers, that s like $50 per month."</post>
   <post id="5be2e212-d478-4229-8def-7b836d1d81d7" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Found a naming convention explanation, though the X special features will still need to be deciphered. Super Micro Computer, Inc. - Product Naming Conventions Has anyone used supermicro chassis in their bedrooms? Can they be, assuming I replace all the fans? Is the PSU fans loud, because can t replace those."</post>
   <post id="45750847-1f46-4bec-a4ea-7e71544c9924" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Main : Norco 4224 + m1015 &lt;-&gt; LSI 9211-8i fw p18 IT + HP SAS Expander Jbod : -&gt; 25x 2,5" : HP StorageWorks Smart Array MSA70 418800-B21 : HP StorageWorks Smart Array MSA70 418800-B21 Dual Power Supply/Fans NO HDDS -&gt; 12x 3,5" : HP StorageWorks Smart Array MSA60 448062-B21 : HP StorageWorks MSA 60 418408-B21 12 x SAS 3.5" LFF Hotswap Drive Array 12-24TB"</post>
   <post id="f509fac3-611d-4f68-9636-af62b808b937" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"kandrey89 said: ↑ 3 PCs? No thanks, which part of the power bill didn t you get? Why would I pay 400W extra in CPU/MOBO/RAM for the 2 computers, that s like $50 per month. Click to expand... 3 pieces, not PCs. The H310 is a controller."</post>
   <post id="0c593df1-6668-4a8d-86c5-66eb7761c22c" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"kandrey89 said: ↑ How were you running the drives in a ZFS? Individually? Click to expand... kandrey89 said: ↑ 3 PCs? No thanks, which part of the power bill didn t you get? Why would I pay 400W extra in CPU/MOBO/RAM for the 2 computers, that s like $50 per month. Click to expand... nope RAID 6"</post>
   <post id="c7b1803c-2dd9-48a1-aee9-9b02742f2bf9" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Do you need 24 bays for expanding past 20TB? Drives will grow over time just as they always have. 20TB is like 5 drives now a days."</post>
   <post id="aad0eb1a-1efd-4ead-a01d-847346975d67" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"Yes, I need 24 or 36 drive bays. I ll initially start out with ~10 drives +-2, depending on the total # of drive bays and RAIDZ# I choose. WD Red 8TB, are looking good right now."</post>
   <post id="1abdca8d-4cb7-40ca-852e-d561e6d2cbeb" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"I wouldn t put a supermicro in my bedroom. I wouldn t even put it next to my bedroom. You re talking 7k rpm 80mm fans, and even when in the low speed setting are doing 2k+. That doesn t take in the PSU fans either. And I rewired the fans in the rigs I have to pull power off the mobo since you couldn t control speed from the backplne. I think so.eone said they fixed that in newer editions. They also make a quiet or super model of their boxes, but I have no experience with those."</post>
   <post id="386e21cc-8f46-4a40-ad31-da3d977e5fc9" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"The 24 bay Supermicro chassis aren t that bad if you have one of the more modern models and high efficiency PSUs. The 36/45 bay ones will never be quiet though."</post>
   <post id="7f612fba-9618-44bc-a610-8dfcc7a55828" section="SSD and Data Storage" discussion="Hardest component to pick in a massive Home Storage Solution">"I mentioned that I would replace all the fans with Noctua models regardless, PSU fans though are not replaceable without voiding the warranty and opening up the case, plus they typically use non standard fans in server PSUs. Actually the more I look into backplanes the more dissuaded I get by the price and complexity. Going to look for a direct connection backplane without expanders. Expanders increase the price of the system 2-4 fold."</post>
   <post id="5e713d21-d8ed-48dd-98a6-a929f354e340" section="SSD and Data Storage" discussion="Seagate 10TB Helium Drive - ST10000NM0016">"Does anyone have one yet? Can Kyle tell me if there will be a review of this drive? I know it is Seagate but I am curious about this drive and how it compares to the HGST/WD Helium drives."</post>
   <post id="2d41e975-b4fd-41ac-95f0-95555ca4f1f7" section="SSD and Data Storage" discussion="Seagate 10TB Helium Drive - ST10000NM0016">"I do not care that it is seagate. That is all I have and I dont have issues. Seagate had a string of bad luck but they are on par with the rest of them now."</post>
   <post id="f941e9a8-a2ac-47ca-826c-1bdaac316ec3" section="SSD and Data Storage" discussion="Seagate 10TB Helium Drive - ST10000NM0016">"Bad luck or a jordan12 said: ↑ I do not care that it is seagate. That is all I have and I dont have issues. Seagate had a string of bad luck but they are on par with the rest of them now. Click to expand... business decision of cost of returns v/s disposing of damaged parts? Guess they were not insured..But it was also their business decision to sell limited firmware d drives that performed poorly even for the purposes it was sold for.. I know they can make and sell high performance long lasting drives. But their business decisions sometimes are very poor.. I seen these kinds of people. They only look at things on paper and make their decisions. Comes from the bottom line beign more important than customer satisfaction.."</post>
   <post id="ad5b77a5-280c-4f87-8047-9c81a906501e" section="SSD and Data Storage" discussion="Seagate 10TB Helium Drive - ST10000NM0016">"Personally, I m not a huge Seagate fan from years back. Still not sure what the Helium has to do with anything really."</post>
   <post id="aac19b22-7e6a-412f-a2d3-500249ea9eed" section="SSD and Data Storage" discussion="Seagate 10TB Helium Drive - ST10000NM0016">"10 TB is a lot of data to bet on Seagate. I won t touch a Seagate product. First-hand failure rates are beyond acceptable. MongGrel said: ↑ Personally, I m not a huge Seagate fan from years back. Still not sure what the Helium has to do with anything really. Click to expand... It allows less drag on the discs, and also allows the read head to sit closer to the platter. in total this has the net effect of allowing the discs to sit closer together."</post>
   <post id="97d7597f-8f38-4609-8e38-fb732c2ef903" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"The HP SAS Expander is a game changing device for home media storage enthusiasts and business customers alike - combine it with a low-cost RAID or HBA adapter and you ve got 32 ports of harddisk connectivity for only a few hundred dollars. Overview: The HP SAS Expander is based on the PMC Sierra PM8005 SAS-2 chip which features 36 x 6Gbps ports and 6G/3G multiplexing, SAS 2.0 zoning, self-configuration, table-to-table routing, and an integrated MIPS processor for SES and enclosure management support. Full specs here: http://www.pmc-sierra.com/products/details/pm8005/ FAQ Q: What s so special about this card? A: The PM8005 chip has proven to be more compatible in more HBA/Drive configurations than previous generation expanders like the LSI-based Chenbro CK series. While HP intended this card be used in their enterprise products (HP Proliant servers, etc) the card is driverless and essentially "universal" since it follows SAS/SAS-2 specs and can be used with non-HP branded RAID and non-RAID HBA cards. What s unique is the ability to connect 32 drives at a relatively low cost, when combined with a low cost 4 or 8 port RAID or non-RAID HBA. Q: Where do I purchase this card and why do I want the green card and NOT the yellow card? A: There are multiple hardware versions of this card, available from Amazon, ebay, etc. The yellow PCB version is the oldest hardware revision, has a smaller heatsink, and CANNOT be flash upgraded from its v.0.20. The green PCB cards are the newer hardware revision. I ve bought green PCB cards from ebay and they came with firmware v1.00. I ve bought a card from Amazon and it came with v1.52. Shipping firmware will depend how old your source s inventory is. To work correctly at 3Gbps with newer SATA2 drives you need firmware v1.52 firmware or higher. Click thumbnail to see a side-by-side of both cards. DO NOT buy the yellow PCB card, it is useless and will not work. Q: How do I install the HP SAS Expander and what are the power requirements? A: The card needs an x4 PCIe slot on a motherboard and draws 11 watts of power. The card doesn t require software drivers, it is invisible to the operating system and motherboard. A common dilemma is people needing to use this card in an empty chassis like a Norco RPC-4220 to create a JBOD enclosure. Some people have resorted to using an old motherboard serve as a power source and ON/OFF switch for the chassis - such a solution costs significantly less than buying a prefab expander chassis. Unfortunately this card has no external 4-pin Molex power connector like the Intel RES2SV240, another highly recommended SAS expander card, but in exchange you re getting 36 ports instead of 24 on the Intel. Q: How do I connect harddisks to the HP SAS Expander? A: There are 9 ports total which can connect four harddisks each. The external SFF-8088 port is Port #1. The internal SFF-8087 are Port #2 through Port #9. I recommend populating drives beginning with internal Port #2. To uplink the expander to your RAID/HBA, connect to Port #8 on the expander with an SFF-8087 cable from your RAID/HBA. If your RAID/HBA has an external SFF-8088 connector, connect to Port #1 on the expander with an external SFF-8088 cable. Q: How many cables do I need to connect the HP SAS expander to my RAID or HBA card? A: You only need 1. However some newer SAS-2 based RAID and HBA cards support link aggregation with two SFF-8087 cables connected between the RAID/HBA and ports #8 and #9 on the expander, effectively doubling bandwidth. Q: How many harddisks can you attach to the HP SAS expander? A: Up to 32. I ve stress tested various configurations including a RAID6 array with 32 x 1Tb drives and had no issues. Q: Why do I need firmware 1.52 or higher on the HP SAS Expander? A: The most notable change in firmware 1.52 brought upgraded SAS/SATA speeds from 3Gbps/1.5Gbps to 6Gbps/3Gbps respectively. Most newer harddisks ship defaulted to 3Gbps, and for compatibility and performance reasons firmware 1.52 or higher is recommended. Q: How do I update the firmware on the HP SAS Expander? A: A flash update requires a newer HP branded RAID card- P212, P410, P411, or P712. If you have a green PCB card with lower than firmware v1.52, you can post in this thread and someone may be able to flash it for you. Q: Which RAID adapters, HBA cards and motherboards have been tested with the HP SAS Expander? A: In general if your card is SAS compliant and vendor specs state that it supports expanders, it *should* work, but there are some exceptions. In general if your card is SAS 2.0 compliant it should also support dual-linking (2 x SFF-8087 uplinks). The following devices were tested by me personally unless stated otherwise. RAID Adapters Areca ARC-1880 series: YES (dual linking supported) Areca ARC-1680 series: YES IBM M1015 (SAS2008): YES (SAS2008 based card, dual linking supported) 3ware 9690SA Series: YES (verified by SeanG) Highpoint 4320 SAS: YES (verified by Dgephri) [B}LSI 9260-8i (SAS2108)[/B]: YES [B}LSI 9265-8i (SAS2208)[/B]: YES Adaptec 5085: No Adaptec 5805: No HP P212, P410, P410i, P411, P411i, P712: YES* (requires minimum of 256MB cache on RAID controller card) Non-RAID HBA cards LSI SAS 9211-4i, 9211-8i (SAS2008): YES (dual linking supported on 9211-8i model) LSI SAS3081E-R: YES Intel SASUC8I (cross-flashed to LSI 1068e firmware): YES Supermicro AOC-SASLP-MV8: YES SuperMicro AOC-USAS-L8i: YES (Confirmed by Tau) Areca ARC-1300-4X: YES (Not recommended due to mediocre performance and no SMART passthrough) Adaptec 1045 (1 x SFF-8088): No Adaptec 1405 (1 x SFF-8087): No Motherboards Supermicro X8SI6-F (SAS2008): YES (Dual Linking supported) Supermicro X8DTH-6/X8DTH-6F (SAS2008): YES (Dual Linking supported) Supermicro X8DT6/X8DT6-F (SAS2008): YES (Dual Linking supported) Supermicro X8DA6 (SAS2008): YES (Dual Linking supported) *Note: In theory any motherboard with the LSI SAS2008 chip should work. KNOWN ISSUES 1) HP SAS Expander will only negotiate SATA-III harddisks at 3G (SATA300) even though it is capable of 6G (SATA600). It does however negotiate SAS disks at 6G. 2) In combination with an Areca 1880 series controller, certain Western Digital harddisks (Velociraptor, etc) when configured in a raid volume will cause Areca boot-time firmware initialization to hang when connected to the HP SAS Expander. This is an issue Areca needs to resolve, but something to be aware of. * CHANGE LOG * 9/8/2011: LSI 9260 and LSI 9265 RAID controllers added to HCL 3/23/2011: Added KNOWN ISSUES section 3/9/2011: IBM M1015 (SAS2008) added to HCL 2/28/2011: New firmware 2.08 10/23/2010: Confirmed several Supermicro motherboards with integrated LSI SAS2008 chip supported 10/23/2010: Added motherboard section to HCL. 10/15/2010: Confirmed dual-linking supported with LSI 9211-8i More info here. 10/10/2010: Confirmed dual-linking supported with Areca 1880i. More info here. 10/9/2010: Areca ARC-1880 series added to HCL 10/8/2010: LSI SAS 9211-xx series added to HCL 10/7/2010: Intel SASUC8I and LSI SAS3081E-R added to HCL 10/6/2010: LSI SAS 9211-xx series added to HCL"</post>
   <post id="0b6e7aec-694c-4822-8e11-a25014d092fc" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"-reserved-"</post>
   <post id="47c3e170-83b5-4c15-a307-d39635687d33" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"I ll be documenting my findings with the HP Smart Array P410 array controller and the HP SAS expander in my topic here."</post>
   <post id="9cf74494-01d8-42d8-8eef-7d25d35d4683" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"As i am very interested in this card, i would like to ask: Which cost-effective SAS card should i buy in order to connect it to the HP SAS expander? My needs are: 1)Connecting 24 Internal sata drives on a Norco 4020. 2)No raid config, i just want the raw drives presented to me without me needing to create any 1-disk RAID-0 volumes(This i called "JBOD" mode, or IT mode i think) 3)All SMART values should be readable by the OS 4)Good linux compatibility 5)Good bandwidth to each disk when they are used at the same time, as i will be using a Flexraid - unraid type solution.(about 24x100MBytes/sec should be enough) So I probably will need to connect the SAS expander to the SAS card using 2 cables. I see that the LSI SAS3442E-R is mentioned a lot."</post>
   <post id="62ebcabb-c06d-4882-8c5a-8e9f69fa0881" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"What are people paying for this card and where can you find it? I m not really convinced by the prices on eBay yet."</post>
   <post id="db85541c-ef2b-451c-a20b-18388a356708" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"odditory, what drives are you using. I ve had a lot of problems w/ drive detection using Seagate drives with SAS expanders (I have the Chenbro SAS expander based on the LSISAS chip). Samsung and WD I ve had less problems with. I haven t tested any Hitachi drives."</post>
   <post id="a2aa712e-a2ac-4664-bce9-6d6e41d28f04" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"I m using an LSI SAS3442E-R connected to my HP SAS expander (via an SFF-8484 to SFF-8087 cable), and everything works fine. I have 6 Hitachi disks connected, and can get ~400 MB/s of traffic to them while using ZFS."</post>
   <post id="1cddfe13-8a52-468b-943c-39478d66d442" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"* DELETED * Information merged into OP."</post>
   <post id="b28691f4-b2e5-4845-a79c-270d4c8fd79f" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"Try connecting port 9c to the controller as well. Are all cables on 2C-7C are the same length?"</post>
   <post id="084aeec7-b8de-45ec-add4-f2142749d130" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"* DELETED * Information merged into OP."</post>
   <post id="b3e83573-5805-48d0-9b88-c41b5142365f" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"If you have a breakout cable you might try that to cut out the HP-&gt;Norco backplane connection, or update the expander s/5805 s firmwares if it s not the most recent. Other than that you might have an incompatibility between the controller and expander, or maybe the HP expander is tied to HP systems somehow."</post>
   <post id="cf5e7ccd-9750-4e40-b808-3c2e50cd89e6" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"* DELETED * Information merged into OP."</post>
   <post id="618530ff-ff9c-4681-b720-671df8f9606c" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"Is there any other way of seeing (in the OS) the card is installed? I bought a used card from eBay and some cheap SAS cables from China but the expander does not show up in the HP Smart Array Manager (I have a HP P410 card) and it also does not show any drives I attach to it (I tried my Seagate 2TB LP s and a WD drive). The HP firmware update CD also does not detect the expander card (it does detect the P410). I ve tried connecting it to the P410 with one and two SAS cables. The only sign of life I get is 4 of the small led s turning green so at least it is taking power from the PCIe slot."</post>
   <post id="fafcf7d3-3aa0-40a0-89c0-6f09e282193b" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"odditory said: ↑ Q: To anyone else with this expander, what firmware is yours running? Mine is v0.20. Apparently the firmware can be upgraded but supposedly only with an HP P410 raid controller. Click to expand... I think mine is reporting 1.00. Here s what I get from  prtconf -v  for it: Code: ses, instance #5"</post>
   <post id="Hardware properties:" section="##2##" discussion="##3##">"##4##"</post>
   <post id="name= inquiry-revision-id  type=string items=1" section="##2##" discussion="##3##">"##4##"</post>
   <post id="value= 1.00 " section="##2##" discussion="##3##">"##4##"</post>
   <post id="name= inquiry-product-id  type=string items=1" section="##2##" discussion="##3##">"##4##"</post>
   <post id="value= HP SAS EXP Card  BENN0 said: ↑ Is there any other way of seeing (in the OS) the card is installed? Click to expand... You could try prtconf, lspci, or lshw." section="##2##" discussion="##3##">"##4##"</post>
   <post id="9e0c8089-cfa3-437b-a24d-8333d8d73174" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"I just ordered one. What the heck. If it works... that would be great port count. Will test with the various hardware I have (although odditory clearly has many more drives/adapters to play with)."</post>
   <post id="a4e74d96-ad5f-48ea-8e3d-80f7458d3379" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"who did you order from? i m starting to think there s a guy on ebay selling junk cards based on feedback from BENN0 and my own findings. I ordered one off amazon for way too much which I ll likely return, just to have a known working card to be able to compare to. i should know tomorrow/wednesday if there s a certain ebay seller to be avoiding."</post>
   <post id="7e26fc73-cebf-4f75-b888-312e3a87be7b" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"I did the ebay guy that is selling them for $200. I have probably 4-5 different cards to try it on.. We ll see what happens. If the three of us bought from the same person, and none of ours work, then we know something is fishy."</post>
   <post id="f0b7c756-898f-402f-b36e-277045543f2c" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"Are most people buying these off ebay? Are regular e-tailer channels or HP selling them directly? Is the Chenbro SAS expander still hard to find, which is why people are getting the HP instead? I special ordered mine from Provantage - it was rather hard to find in stock anywhere. I heard that they were coming out with the SAS 2.0 version which is why they might not be replenishing stock."</post>
   <post id="f1e14a00-37c0-44a6-8dd9-20b2239f62f5" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"Just came across this thread from AVSForum. I have an HP SAS expander hooked up via the external port to one of the ports on a 3ware 9690SA-8E card. It sees my eight 2TB Hitachis just fine. I ve copied large amounts of data back and forth to the array (RAID 5 for testing) with no problems. Now as expected, the performance isn t all that great since 3ware controllers aren t exactly top performers (although very reliable in the past 6 years of using them). I have an Areca ARC-1680ix-12 coming in soon to see what performance I can get out of it. Also, as a side note I did a little test trying to maximize the amount of drives I can hook up to this expander. I originally had the eight 2TB HDs hooked up to ports 0-7 with no problem. I was curious what would happen if used ports 8C and 9C. The 3ware controller still sees the drives listed under ports "PHY 255". I wonder if I can get 32 drives recoginized? Unfortunately I dont have enough drives to test with."</post>
   <post id="c4269e8d-982d-4b79-96dd-8a7f86cfcbf0" section="SSD and Data Storage" discussion="HP SAS Expander Owner s Thread">"The only other thing I can think of is that a (very) old firmware revision of the card does not support SATA300 drives. I think I read something along those lines somewhere but I ll have to see if I can find the release notes for the firmwares. If you have SATA150 drives or are able to jumper a drive into SATA150 mode maybe that is something to try. Edit: from the release notes here: "Support for 6GB SAS / 3GB SATA HDD" seems to be added as of firmware version 1.52 (released August 7th 2009)."</post>
   <post id="c001b4b4-cd7e-44c5-9586-6d9f2c81c260" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"PC Perspective has posted a video review of the Western Digital Red 8TB helium filled consumer drive today. These things look pretty sweet, if you are upgrading your storage, you might want to watch this review."</post>
   <post id="910573fe-c936-4ae5-9274-26ea4fdb233a" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Here is what I m seeing as a price per TB... NewEgg is used for reference, and I am looking at Western Digital Red drives: 1TB $63 - $63 per TB 2TB $90 - $45 per TB 3TB $110 - $36.60 per TB 4TB $150 - $37.50 per TB 5TB $195 - $39 per TB 6TB $245 - $40.83 per TB 8TB $380 - $47.50 per TB Please note that NewEgg regularly runs 2fer specials which can drop the price of TB. The reason why I m keeping a eye on this is because I want to build a FreeNAS box later on this year."</post>
   <post id="88a51896-3290-4593-90f3-0aec757e6a6a" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Good thing about them releasing an 8TB drive, is that the 6TB drive cost per GB drops since it s no longer the largest drive I ve started using 6TB drives in some of my servers now that the price per GB has come down, although I m mostly buying 2TB &amp; 4TB as they are big enough and the cost/GB is better. Don t think I ll be buying any 8TB drives until the costs comes down and I see their reliability."</post>
   <post id="6db96f0e-362a-43fb-9eab-ee6598a05c0d" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Best Buy has the 8TB externals for $250.00. WD - My Book 8TB External USB 3.0 Hard Drive - Black"</post>
   <post id="1437e643-b63f-4081-baab-47604723fe4f" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"in the future i will need to replace my aging storage drives. i like the price of the 3TB."</post>
   <post id="7f693f3e-b581-479e-8976-dee4c153eb92" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"ZLoth said: ↑ Here is what I m seeing as a price per TB... NewEgg is used for reference, and I am looking at Western Digital Red drives: 1TB $63 - $63 per TB 2TB $90 - $45 per TB 3TB $110 - $36.60 per TB 4TB $150 - $37.50 per TB 5TB $195 - $39 per TB 6TB $245 - $40.83 per TB 8TB $380 - $47.50 per TB Please note that NewEgg regularly runs 2fer specials which can drop the price of TB. The reason why I m keeping a eye on this is because I want to build a FreeNAS box later on this year. Click to expand... Have you considered WD Red Pro drives? I invested in 8x WD Red 6TB last year - but if WD Pro equivalents were available (which they are now) I would have probably opted for them. Longer warranty, faster...although certainly more expensive."</post>
   <post id="a1126506-99c4-49f1-942c-f0be6b12d99b" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"8GB holly crap I put in some 4TB drives a year or so ago and am getting nervous about size of data per drive. Seems awesome to have more space per drive but at what point do we have to worry about failure rates replacing/filling these drives? hmmm maybe mirroring will be the answer... Wonder what the risk would be for 4x8GB drives in mirror vs 4x6GB in a typical single drive parity config. (yes I know not same size but close)."</post>
   <post id="85485046-cdc9-46e7-ac56-bcf0ae6e5b95" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"dandirk said: ↑ 8GB holly crap I put in some 4TB drives a year or so ago and am getting nervous about size of data per drive. Seems awesome to have more space per drive but at what point do we have to worry about failure rates replacing/filling these drives? hmmm maybe mirroring will be the answer... Wonder what the risk would be for 4x8GB drives in mirror vs 4x6GB in a typical single drive parity config. (yes I know not same size but close). Click to expand... Like anything else it depends on the application and criticality. For me, I run 8x 6TB in a RAID6. Gives me two drives for parity - in case one fails I have one left during the (long) recovery. I also always have a cold spare 6TB drive on hand so I can rapidly replace drives. I backup all of my data to another NAS here locally every night. I backup my critical data (around 2TB) real-time to Crashplan."</post>
   <post id="db83c22a-5330-4e7e-a935-deb8211f7604" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"1815+? Think I have the same setup, plus a 4 bay JBOD backup box with a common 6TB red shelf spare. Might buy an expansion box later this year if the 6TB prices drop."</post>
   <post id="ee2e5422-ded5-4b1e-a53a-29b836aab021" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"These look nice and all, but here is what I don t get. Why does one 8TB drive cost MORE than two 4TB drives. It should cost LESS than two 4TB drives... With every other hardware out there, the bigger one you buy, the cheaper per unit it becomes."</post>
   <post id="e15401d9-a9e7-4fe8-ab60-4b5ef25ec720" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"sk3tch said: ↑ Like anything else it depends on the application and criticality. For me, I run 8x 6TB in a RAID6. Gives me two drives for parity - in case one fails I have one left during the (long) recovery. I also always have a cold spare 6TB drive on hand so I can rapidly replace drives. I backup all of my data to another NAS here locally every night. I backup my critical data (around 2TB) real-time to Crashplan. Click to expand... Yep, redundancy is the way to go. Since June 2014 I have been running 12x 4TB Reds in dual 6x RAIDz2, so it winds up being a ZFS RAID60 equivalent. Been very happy with the setup. For me absolutely EVERYTHING I care about goes on volumes with at least some sort of redundancy these days. I boot off of single SSD s, but semi-frequently image those to my NAS, and don t keep anything but OS, installed programs and temporary working files on them. All of my real data is stored to my redundant NAS. I haven t used a hard drive - any hard drive - in a non-resundant mode in almost 7 years."</post>
   <post id="83c7fb79-bb4f-4d5a-be1e-08160144bb4a" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Zarathustra[H] said: ↑ These look nice and all, but here is what I don t get. Why does one 8TB drive cost MORE than two 4TB drives. It should cost LESS than two 4TB drives... With every other hardware out there, the bigger one you buy, the cheaper per unit it becomes. Click to expand... Why Is There a Helium Shortage? Helium?"</post>
   <post id="95a549a4-0cc2-4241-aa78-6b0cf3c9a9f5" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Zarathustra[H] said: ↑ These look nice and all, but here is what I don t get. Why does one 8TB drive cost MORE than two 4TB drives. It should cost LESS than two 4TB drives... With every other hardware out there, the bigger one you buy, the cheaper per unit it becomes. Click to expand... Density, tooling costs, mass production etc makes it that way. The smaller drives have been around for a while so they have sold enough to pay off the tooling/infrastructure costs allowing lower of pricing, not to mention normal market forces of "older tech". Plus new and shiny!"</post>
   <post id="e43ccd2b-fce5-4093-846e-d81d1fd615da" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"WetMacula said: ↑ 1815+? Think I have the same setup, plus a 4 bay JBOD backup box with a common 6TB red shelf spare. Might buy an expansion box later this year if the 6TB prices drop. Click to expand... 1815+, yup. Btrfs now, too...very happy with it."</post>
   <post id="cbbc818d-ddf8-4dbd-b039-b6e498a4f7e7" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"dandirk said: ↑ 8GB holly crap I put in some 4TB drives a year or so ago and am getting nervous about size of data per drive. Seems awesome to have more space per drive but at what point do we have to worry about failure rates replacing/filling these drives? hmmm maybe mirroring will be the answer... Click to expand... I say that for data you absolutely do not want to lose multiple backups are the answer regardless of the size of the drive. For data like htpc recordings I find this is unnecessary so some redundancy (provided by dual parity using SnapRAID) is a cheaper and better solution for me."</post>
   <post id="9a6cae0d-c41a-4959-9e34-47c19bc16917" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"How are they addressing the issue of the drives physically leaking the helium? Helium is notorious for being hard to store long-term. Sure, it s not under any pressure inside the drive, but hundreds or thousands of spin-up/spin-down cycles can t be good for it."</post>
   <post id="7ee05088-fb01-4364-8a83-cef1b4f572ec" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"With the cost of Enterprise SSD dropping and capacity surpassing mechanical, I guess they are still trying to make money on old tech."</post>
   <post id="2aee8806-d9d9-4083-9854-f11a11e3707b" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"Mohonri said: ↑ How are they addressing the issue of the drives physically leaking the helium? Helium is notorious for being hard to store long-term. Sure, it s not under any pressure inside the drive, but hundreds or thousands of spin-up/spin-down cycles can t be good for it. Click to expand... Plug-ins?"</post>
   <post id="02dd9984-5b96-48a0-8f08-0192ed886ebf" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"CRaschNet said: ↑ With the cost of Enterprise SSD dropping and capacity surpassing mechanical, I guess they are still trying to make money on old tech. Click to expand... I say it will be a long time (possibly decades) before an 8TB SSD hits $380 if it ever happens."</post>
   <post id="198b76f2-cc80-4cdb-92d3-eb85788b4117" section="SSD and Data Storage" discussion="Western Digital Red 8TB Video Review">"drescherjm said: ↑ I say it will be a long time (possibly decades) before an 8TB SSD hits $380 if it ever happens. Click to expand... I m more optimistic and give it about a decade. At present, the largest SSD with a SATA interface is 2TB with a price range of $500 to $880 per NewEgg. And, the largest SSD available is a Fixstars 13TB SSD for $19,000. (YEOWCH!)"</post>
   <post id="3e016348-2970-452c-ac88-b96b17167c0a" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"Got one of the new 4TB 2.5" drives from Seagate/Samsung. It is just under 15mm thick, so definitely a beast. Still, not bad for $0.044 per GB in a 2.5" drive package. SMR doesn t seem to have much impact on the first test run (248.7GiB transferred at an average of 126MiB/sec), but I am preparing a full 3.64 TiB copy to see if this isn t some quirk of the controller (spacing data out for the first X data to avoid the adjacent shingle penalty)."</post>
   <post id="d7e351de-9d82-432c-b69d-0e1dc58a27d1" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"SMR will really hit you when you copy a whole bunch of small files and rewrite old data. You absolutely have to use some kind of cache so it dont update the fat all the time. Does this drive have the new SMR specs they have been working on? That way there is a standard way to speed up the drive and the operating system will also know how to deal with such drives. Which is where caching the fat comes in as that part gets updated a lot during use. Does it have NCQ? there were problems with using NCQ with SMR if not properly implemented would cause the drive to actually be much slower than without NCQ. Does this drive fit inside a lap top? Would be great to have all your stuff during travels even with all the problems."</post>
   <post id="51a7c58c-8807-4e99-b8b1-9002f81cbfab" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"I doubt it has all of the refinements you are speaking of -- the previous test used ~25GiB files, so part of the 3.63TiB test is 50k or so smaller files... your words seem prescient: 29MiB/sec average during the small file transfer. Unfortunately, it is too tall to fit in my sager laptop (12mm maximum for the two drive slots), but it will fit in my SFF NAS just fine (have a couple mm to spare on each of the 18 bulk drive slots. No need to upgrade quite yet (don t need 60TiB usable at this particular juncture, and at $170/drive that would be a pretty penny), but will be interesting down the road!"</post>
   <post id="81651836-d503-4830-a3d6-a8a8d6b2dd2c" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"Thanks for the info.. Guess we are stuck with 2TB drives for now. Which is almost enough for most things but 4TB would have meant that we could put most stuff for a month or so on the lap top itself and give up on carrying extra drives around. But the slow speeds would still be a headache to copy stuff to it at such slow speeds. Maybe in another 2 years."</post>
   <post id="4360e0ef-d88a-49aa-906a-ece4cb1b6a9f" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"Yeah, I was fine for a year-long (2014) trip with a pair of 2TB M9T s and a 1TB 840 EVO mSATA in my laptop."</post>
   <post id="e893c1e6-f0fd-4e1e-8522-d3b59c1a2584" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"Machupo said: ↑ Got one of the new 4TB 2.5" drives from Seagate/Samsung. It is just under 15mm thick, so definitely a beast. Still, not bad for $0.044 per GB in a 2.5" drive package. SMR doesn t seem to have much impact on the first test run (248.7GiB transferred at an average of 126MiB/sec), but I am preparing a full 3.64 TiB copy to see if this isn t some quirk of the controller (spacing data out for the first X data to avoid the adjacent shingle penalty). Click to expand... It doesn t have an impact because this drive does not use SMR. Anandtech s testing found no SMR and I checked the product manual for the drive used - ST4000LM016 and it states perpendicular (PMR)."</post>
   <post id="64836806-ce8a-47f9-99b9-138d441cb151" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"If it is indeed PMR, an enterprise version of this would be a pretty wicked NAS drive."</post>
   <post id="c7d6bf2f-dd75-4d0d-9779-bfe8e8893351" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"indiekiduk said: ↑ It doesn t have an impact because this drive does not use SMR. Anandtech s testing found no SMR and I checked the product manual for the drive used - ST4000LM016 and it states perpendicular (PMR). Click to expand... Machupo said: ↑ I doubt it has all of the refinements you are speaking of -- the previous test used ~25GiB files, so part of the 3.63TiB test is 50k or so smaller files... your words seem prescient: 29MiB/sec average during the small file transfer. Click to expand... hmm... who is right?"</post>
   <post id="e431dced-71ba-44d3-b0ed-ec05abaff018" section="SSD and Data Storage" discussion="Seagate/Samsung Momentus ST4000LM016">"Seagate says Perpendicular in their product manual, so I was wrong I have been using this as a great media drive for laptop/travel without issue for the past (almost) year. Key lesson from this is don t believe all initial reviews / whitepapers!"</post>
   <post id="0ed8b4d9-02a9-4e08-a860-6110a0fb5d99" section="SSD and Data Storage" discussion="Using storage spaces like raid 0 + mirroring?">"Hi, I have a few drives I d like to use but I d get more space out of them if (this assumes its possible) I could set the two smaller drives up like raid zero, then have the "raid 0 drive" mirror a larger drive rather than putting them all in a pool. Thing is, I am not sure that is possible? Thoughts (on how to do it). Thanks!"</post>
   <post id="df83f22e-3fb9-4d3f-97d3-cb8eb5b094da" section="SSD and Data Storage" discussion="Using storage spaces like raid 0 + mirroring?">"You can use Storage Spaces to have a "simple" storage space, spreading the information across multiple drives. From there, I d recommend running a backup utility (crashplan locally, Windows Backup, you name it) to backup the information to a separate volume."</post>
   <post id="9ddd576c-a053-4e7b-85a2-ee9d55d75003" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Purpose is for storing critical photography work (my profession). I care about reliability and cost over speed, although I will be working off of these drives, so being completely dog slow is not preferable. Looking to spend about $150 a drive. I d like 2 total (for redundancy). So $300 total. Recommendations? I notice there are several options from Seagate and WD. Not sure if HGST and Toshiba are still around. I haven t been paying attention to all the acquisitions and merging as of late."</post>
   <post id="581d2cc1-329f-46c3-b095-d89091c67060" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"HGST 4TB NAS. Reliable, relatively cheap and 7200rpm. Win. I cant recommend anything else, the above is the best. Dont go near Seagate. WD own HGST/Hitachi now but the drives are still independent."</post>
   <post id="18c8112e-dbd1-40ad-8230-44efbb9f813d" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Okay I ll definitely check  em out. I think what was getting recommend a while ago was 5TB Toshibas... might ve been HGST s... honestly I can t keep it straight anymore. Will they have degraded performance when not operating in a NAS? I know it s a simple question, but I also know they really optimize drives for specific purposes these days."</post>
   <post id="cf90ea0d-a7c9-4ac7-8c09-69c7749c5794" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"I will second the HGST NAS. But if you choose 5TB and up options, try to make 6TB your minimum because those drives have double the cache. I run the 6TB version as a single drive. Only had it a few months but it is active daily and has had no hiccups. Just because they market it or optimize it for NAS doesn t mean it will lose performance as a single drive. I bought it for the increased vibration tolerance under long term operation and the RAID support. I will convert it to a chipset RAID 1 some day when prices fall some more. However, I am also running 2x 3TB Seagate NAS drives in a RAID 1 and they have been terrific for over two years. I saw that Newegg had a promo code selling the 4TB version for $105, but it expired 2 days ago. The model number has "VN" in the middle of it. I know people bash on Seagate all the time, but I ve honestly never had a single Seagate failure so I can t dock them, whereas two WD Blacks have failed on me."</post>
   <post id="ad1edb35-3064-4b61-b359-ffc987136ac1" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Also, if you re going to be working off the RAID, you should consider trying an SSD for Intel SRT if your platform supports it."</post>
   <post id="40e17879-990d-4397-8949-0bbed2fa5d46" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"rastaban said: ↑ Also, if you re going to be working off the RAID, you should consider trying an SSD for Intel SRT if your platform supports it. Click to expand... In a perfect world I d be able to afford a Thunderbolt DAS w/ Raid 1, but that currently isn t in the budget. I ll be using a Thunderbolt dual-dock and use software to duplicate the information between drives."</post>
   <post id="6f2488e5-f1b9-49ef-93a0-9993a430c348" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"UnknownSouljer said: ↑ In a perfect world I d be able to afford a Thunderbolt DAS w/ Raid 1, but that currently isn t in the budget. I ll be using a Thunderbolt dual-dock and use software to duplicate the information between drives. Click to expand... How much RAM are you running? I read that TB speeds really scale with memory."</post>
   <post id="b1a26bac-7ef7-4034-82ba-b52e1b12186c" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"rastaban said: ↑ How much RAM are you running? I read that TB speeds really scale with memory. Click to expand... Currently 16GB. I don t have plans to move to 32GB. Maybe if it gets super cheap, but I d have to replace all my RAM as all my slots are populated, raising cost. Last time I checked it was $300 for 32GB in 4x 8GB DDR3 SODIMMs. Currently I have to say that running drives off the Thunderbolt Dock is imperceptible versus my internal HDs. Which of course is optimal."</post>
   <post id="ae1a03ad-a06a-49ed-a31f-b4ca11d655f8" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Like everyone else here has said, go with HGST, they are the best and most reliable drives but if they are out of your price range than go with Toshiba. I have more than 100 Toshiba drives and every drive I have put into use has worked with no issues. I want to clarify that most of my Toshiba drives have not yet been put into service but all of the Toshiba drives that I have used thus far have worked without issue. I don t trust any WD drives except for the Red Pro s or their Helium drives and I certainly don t trust Seagate even though I have used many of the 4TB desktop drives without any failures (yet)."</post>
   <post id="1d5573e0-0a4c-4fa1-818e-1cc2533ec07c" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Toshiba &gt; HGST &gt; WD &gt; Seagate"</post>
   <post id="947a40bb-c774-4f83-aaf2-4ad6fef3b2c8" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"UnknownSouljer said: ↑ Okay I ll definitely check  em out. I think what was getting recommend a while ago was 5TB Toshibas... might ve been HGST s... honestly I can t keep it straight anymore. Will they have degraded performance when not operating in a NAS? I know it s a simple question, but I also know they really optimize drives for specific purposes these days. Click to expand... Drives specced as NAS are a quality tier higher. They are designed to cope with being left on permanently. You can use them however you like without penalty, except for say seeing how long a PC will last inside a nuclear reactor."</post>
   <post id="eaa0b6b4-922c-4714-8a1f-4d8877cb7b23" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"That s usually just PR-bs unless you re going for server-grade drives, I have dozens of Toshiba drives running in RAID-arrays and whatnot just fine and several ppl here and on other storage forums are using their HDDs just fine."</post>
   <post id="53959119-1cd0-477b-9696-2bf7655f6877" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Well I guess that seals it. HGST it is. I think Samsung was the other one I was thinking of. Still might of been Toshiba. I ve been pretty lucky though. I ve only ever had a few drives fail. 2 IBM Deathstars back in the early 2Ks. And one 250GB WD that was in service for over 7 years. I d rather not try my luck however, for obvious reasons."</post>
   <post id="b57becb9-26c4-4895-8e2d-762841be8b90" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Keep in mind that RAID != backups."</post>
   <post id="c4d3477a-0afd-4074-a17a-0ddd2659164f" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"diizzy said: ↑ Keep in mind that RAID != backups. Click to expand... Technically I won t be running RAID, but similar to. I ve heard the mantra, but I don t have another solution I can use to back anything up. I get the "concept" that true backup would include states previous to changes and alterations, but with the exception of getting a virus, there isn t going to be a need to have that kind of redundancy."</post>
   <post id="7a1c39cf-4b5a-42af-bfe6-1f3e6e26edc4" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Only non-SSD drives I use are WD Black. Never had a single one fail in over a dozen builds. Newegg had a special on the 5TB, a few weeks ago. $175 shipped. Bought two for my current PC."</post>
   <post id="c8b31503-a016-4eac-95ea-2908041ac586" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Seagate enterprise drives are actually robust. I have some ES.3 drives that have been updated by Seagate to the V4 line. I also have 4 HGST NAS drives for over a year and rock solid as well. Enterprise drives will of course cost much more. Stay away from Seagate consumer drives."</post>
   <post id="3747bb11-0cc8-4080-b205-74b4f1eb8aca" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"Where is the best place to buy? Is it newegg still, or should I go some place else? I live in SoCal so I could go to micro center or frys. Also I guess there is Amazon."</post>
   <post id="3cb123a7-8101-473b-b694-7f87ec61abc2" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"I have some awesome old Toshiba drives that are 7+ years old and still work fine. I more recently purchased a 5TB Toshiba and I would not recommend it purely on the fact of how loud it is. It sounds like a 5 1/4 floppy being read if you know what that s like."</post>
   <post id="3fc9d7bc-3adf-4082-84af-6ccdc8efecdf" section="SSD and Data Storage" discussion="4-5TB HD recommendation">"UnknownSouljer said: ↑ Where is the best place to buy? Is it newegg still, or should I go some place else? I live in SoCal so I could go to micro center or frys. Also I guess there is Amazon. Click to expand... Jet has some good prices, especially if you can use one of their 20% off coupon codes. I snagged an M.2 950 Pro 512GB for $237 from Jet several months ago."</post>
   <post id="e2393fe9-3cbc-4247-a92a-a0bee8e0fd09" section="SSD and Data Storage" discussion="To RAID or not to RAID">"Right now in  the desktop  I ve got an 250gb 840 EVO, 2x 512 850 EVO s and a 1TB WD Black. Currently all of these drives operate independently. The 840 EVO is taking a dump, has a couple of SMART errors and I m working on getting an RMA. There really is no valuable data on this machine. Everything is backed up. My thinking so far has been keep the drives separate to avoid any que depth issues. Not that this is generally a problem. But there are some instances where say a game is installing and a query is being run and games are being played. But mostly to keep the OS separate. I m not so much worried about raw numbers. Latency is more important. Is RAID 0, 5 or 10 even worth it these days? Or is RAID 0 and a mirror of that image the best implementation? Hardware vs Software RAID? Or is the current setup the best to give the best  feel ?"</post>
   <post id="0fd14ebc-62b8-4460-8552-0b99376f1abc" section="SSD and Data Storage" discussion="To RAID or not to RAID">"Latency is more important. Is RAID 0, 5 or 10 even worth it these days? Click to expand... If you are concerned with latency don t RAID."</post>
   <post id="f41afbac-6ab5-483c-ab9f-20c3b4d1b176" section="SSD and Data Storage" discussion="To RAID or not to RAID">"First off Raid 0 is for performance gain only. All other forms of Raid is for fault tolerance and don t let anyone tell you it s a form of backup. Fault tolerance and backup are very different. Fault tolerance is all about up time and avoiding downtime in the event of hardware failure. Backup is all about total loss (house fire for instance) or virus/software issue or user error and want to roll back to a previous copy. So the real question is what is your reason for raid? fault tolerance or performance? I will assume performance - Raid 0 With raid 0, your volume size is limited by the smallest capacity drive multiplied by the number of disks. So your two 512 850 EVOs would be perfect because they are same size. I have experience with both software and hardware raid 0 - you will see a performance increase in both instances, but more reliability and even better performance long term with hardware raid. As for mirroring that raid 0 - you could create a partition on the 1TB equaling the raid 0 and set it up raid 1 which would be raid 10. I wouldn t bother though because there will be a performance hit and it would easier to setup an OS backup at night that saves to the 1TB instead. I have not noticed latency in raid 0. other forms of raid there will be latency."</post>
   <post id="17ac74fb-b662-4acd-bbe3-c4be9c3e8143" section="SSD and Data Storage" discussion="To RAID or not to RAID">"I would recommend the following setup: Use a 512GB SSD for your OS drive. Then setup your remaining SSD and HDD in a Simple storage pool with Windows Storage Spaces. Storage spaces can be expanded / drives swapped out / modified to the Nth degree. It does not insist that all drives be the same model / size. Windows does some pretty slick memory / SSD caching within Storage Spaces. It also lets you keep a D: drive for storage / games instead of having a million different letter drives. I m running that style of setup both at work and home, and it works wonderfully. Please note: I do keep backups of everything, so if a drive dies I m not going to lose anything."</post>
   <post id="e120826b-660e-45c9-b813-3449dd03d51c" section="SSD and Data Storage" discussion="To RAID or not to RAID">"iamwhoiamtoday said: ↑ I would recommend the following setup: Use a 512GB SSD for your OS drive. Then setup your remaining SSD and HDD in a Simple storage pool with Windows Storage Spaces. Storage spaces can be expanded / drives swapped out / modified to the Nth degree. It does not insist that all drives be the same model / size. Windows does some pretty slick memory / SSD caching within Storage Spaces. It also lets you keep a D: drive for storage / games instead of having a million different letter drives. I m running that style of setup both at work and home, and it works wonderfully. Please note: I do keep backups of everything, so if a drive dies I m not going to lost anything. Click to expand... Will have to check out storage spaces - thanks!"</post>
   <post id="3d8941db-6f4c-44ce-b043-a075d3716f15" section="SSD and Data Storage" discussion="To RAID or not to RAID">"Try Drivepool instead of Storage Spaces. A Much better program. And worth the very small fee..."</post>
   <post id="1566dbad-27a9-4641-a553-19bbd3841e31" section="SSD and Data Storage" discussion="To RAID or not to RAID">"I will give this a try! Thank you all for the advice and information I m going to give Raid 0 a go with daily incremental backups for the array, and on the fly backups for the important stuff. Regarding que depth, when does this become an issue? Is there a benefit to putting the OS on a separate drive so that it never needs to wait? Thanks again!"</post>
   <post id="1552526a-5a60-493b-b9f4-1b5b8fdeea5b" section="SSD and Data Storage" discussion="To RAID or not to RAID">"Repeating what drescherjm said, if latency (aka low queue depth performance) is what you re after, then don t RAID. Using RAID 0 to improve performance in low queue depth scenarios only worked on spinner hard drives, and does not work for SSDs."</post>
   <post id="a8b90c8e-42e2-4b8e-9f05-4d9cba8f90b3" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"The Modders Inc. gang has the ADATA SP550 240GB SSD on the test bench today. If you are looking for an affordable SSD, this just might be the drive you are looking for. With current storage controllers having no problem saturating the SATA interface, a different kind of race emerges; one that is unusually focused towards the bottom with an eye on delivering the lowest per GB cost. The previously reviewed ADATA SX930 with its 4-channel JMicron JMF670H controller paired with 16nm Micron MLC NAND is fairly affordable already at $0.33-per-GB, but using 16nm TLC NAND with Silicon Motion’s SM2256, the price is driven even more affordable at less than $0.25-per-GB."</post>
   <post id="f20616eb-00f1-4ae0-88f8-a67f8b03dd2d" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"This SSD is interesting because the 960GB version has been going on sale for as low as $188."</post>
   <post id="b20b56d8-b79f-4cfb-b3ce-a50964e8246a" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"I bought that exact drive to replace my work laptop mechanical drive. For $60 at the time I bought it, it s well worth it."</post>
   <post id="9fa4668d-1092-4bc4-820a-aba278000b57" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"evilsofa said: ↑ This SSD is interesting because the 960GB version has been going on sale for as low as $188. Click to expand... Didn t see your post. That is an even more amazing buy but I didn t need such a large drive in my case."</post>
   <post id="e95e1ca6-28df-45c2-8735-3f6c692c670f" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"Just put the 480GB version in my workstation. Seems pretty good so far, but all I ve done is load Windows, apps, and updates."</post>
   <post id="04ed4335-2ae7-411f-916d-fa7afecfcc0a" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"I have the 512GB model, running for over 13 months now neveranottaproblemo"</post>
   <post id="17c20eb5-093a-4934-a366-7ba66cfe4173" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"Is the power draw low enough to make it good for battery powered use, compared to Samsung?"</post>
   <post id="b3662e5a-7525-4f50-9a7d-c27315a3e563" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"Power consumption is very close to the Samsung 850 line, according to the Anandtech review."</post>
   <post id="f97c9467-e497-41ae-9b43-14f55189a460" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"Have three of these, two 480gb models and a 120gb, fast and reliable, love them.m"</post>
   <post id="a2c656cb-2809-4341-98d1-51ecea7de966" section="SSD and Data Storage" discussion="ADATA SP550 240GB SSD Review">"The 480GB version is $94 on Newegg s eBay account now."</post>
   <post id="0e4c745e-eadb-4260-8e6e-b6c1d6ddae78" section="SSD and Data Storage" discussion="Upgrade home storage... what would you do?">"Ugg.. been going back and forth on this for awhile and just can t make a decision. I m currently running an installation of OpenIndiana with the following; A pool of 6 3TB drives in mirrored pairs shared for general storage (music, video, documents, etc.) A pool of 4 320GB drives in mirrored pairs shared via iSCSI as a VMWare datastore A pool of 4 240GB SSD drives in RAIDZ1 shared via iSCSI as a VMWare datastore This is currently being run as a standalone server in a Norco 4224 case, using a Supermicro X8SIL-F, XEON x3430, 16GB RAM, 2 M1015 storage cards and a QLogic 2462 providing fiber for two ESXI hosts (only one is currently in use). Due to some issues with the OS (which has been limping along), I need to rebuild and I m currently looking at the following options. 1) I have a spare X8SIL-F, xeon x3440, and 32GB RAM. I can get everything set up (using OmniOS/Linux/FreeBSD/whatever). The downside to this is the PCIe slot limitation on the motherboard. With the QLogic card and two M1015 controllers, I m out of slots and stuck with only the two onboard NICs, unless I replace the two M1015s with something like a LSI 9201-16i which is too pricey right now. 2) I have two unused Dell R710 servers (one with a single X5550 and 64GB RAM, the other with dual X5650s and 64GB RAM). I would need to pick up an external HBA (looking at an LSI 9201-16e) and a couple 8088-8087 adapter brackets so I can re-purpose the Norco case as a JBOD case for the drives (already have a JBOD board to control the power). With either option I m leaning towards moving back to an "All-in-one" setup to be able to run a few other VMs with the storage that are essential (storage, AD, vCenter, and maybe Plex). I guess the pros/cons between deciding are; X8SIL/x3440 Pros = lower power (about 80-90W average usage), storage and processing in same box Cons = 3 PCIe slots max, limited to 32GB RAM, only 2 onboard NICs R710 Pros = 4 PCIe slots, 4 onboard NICS, dual proc support, 64GB RAM (have memory to increase up to 96GB), able to run additional virtual systems Cons = no 3.5" storage, need external SAS cabling, more power (170W with X5650 s or 140W with the single X5550) plus additional power to run the hard drives in a JBOD case."</post>
   <post id="fb1d40cb-4995-4b5c-bdc0-490419d0ef4b" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"I need to get an SSD for a laptop. It s been a couple years since I have looked at drives so I am not sure how much has changed and what to look for. This will be in a Dell Inspiron 500 with an i7, Win 10 Pro. I would like to stay under $200 unless the Samsung 850 Pro is a MUCH better drive for the money. My main concern here is reliability as in not having a total catastrophic incident. 5 drive comparison at NE I have always been partial to Samsung drives The only drive that I didn t include in the compare (limited to 5 drives) is the SAMSUNG 850 PRO 2.5" 512GB SATA III 3-D Vertical Internal Solid State Drive (SSD) MZ-7KE512BW @ $207 I am not up to date with the vertical tech or the "3D V-NAND". I m also disappointed that the compare leaves so many fileds not completed like the comparison on idle vs active wattage, warranty, etc. Also, the controllers are newer than what I am acquainted with. Any advice or pointing out areas I might want to look at are greatly appreciated!!"</post>
   <post id="4a21ff33-0413-46c0-a9b4-20a8d97e3b64" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Hello! The Samsung 850 EVO is my recommendation. The additional performance the PRO affords is not worth the price of admission."</post>
   <post id="2a83a465-ca44-4d6d-a624-4bb34a6117cf" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"That does look like the drive for my budget. Thanks for the suggestion!"</post>
   <post id="24a8c5e4-25e9-450c-b1f7-267905c7980e" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Quite frankly, for general OS/application (ie, real world) use, you d probably not notice a difference between any of those drives. However, out of those, my vote is for the 850 EVO."</post>
   <post id="387b2fcd-0893-4014-ae23-1260c4d0138b" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Rocking two 850 EVOs in RAID. Would bang 11/10."</post>
   <post id="45edd5b6-8105-4412-a2f4-7d2ba7907de7" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"If you re looking for a rock solid SSD, I would say forget Samsung only because they don t have power loss protection. Go with the Intel SSD 730. It is a bit older and it was never the fastest. But it is based on a controller similar to the one in the enterprise class DC S3500/S3700 from 3 yrs ago which imo has stood the test of time. You should not notice much perceptible performance difference between it and the newer Samsungs. Note that "power loss" is not the same as "power failure." I m not well versed at all on the details but I understand that it should help with avoiding corruption issues. I recommend looking into it."</post>
   <post id="181d1f8b-a093-483f-b4ce-d1964d6ac263" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Out of the SSDs listed and prices I d only consider the 850 EVO or MX200. If you actually have a workload that can leverage it then you can consider the 850 PRO as well. The Sandisk Ultra II is a paltry $5 savings once normalized for capacity but uses &lt;20nm TLC NAND. Saving s for sure aren t passed onto the consumer in this case. The other Crucial drive prices are way over inflated."</post>
   <post id="64d97d1c-dcfb-4283-ac1f-d7d938ea9134" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Crucial MX200 by far, Marvell (well proven controller) and decent TBW."</post>
   <post id="c6c885dd-eb39-47b8-8c36-48d8170c321d" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"I really liked the Crucial s ?X100 drives, but $200 is insane. That s where the 850 Pro looks like a reasonable upgrade."</post>
   <post id="96b12b5b-b9c3-49e2-ad13-fdf324657738" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Thanks for all the replies guys, that helps make some things clearer!"</post>
   <post id="a86ba8cd-00c2-4670-94a3-16007b09d83f" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Also, the Plextor M7V-series might be worth looking at if you re into the budget segment."</post>
   <post id="8f86ce4c-4716-42d8-9f94-c8fc4c2257fe" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"diizzy said: ↑ Also, the Plextor M7V-series might be worth looking at if you re into the budget segment. Click to expand... PNY 480gb is a good drive and can be had for 110.00 on sale at best buy if they still have the sale still going"</post>
   <post id="ce78e168-d24c-47df-8d6e-192b42d2f9c5" section="SSD and Data Storage" discussion="Comparing mid-level ~500GB SSD s - please help!">"Phison S10 controller.... I would be a bit careful around not very widely used (tested) controllers..."</post>
   <post id="9b7cc27c-9ebe-4cd3-bd91-bc5f94df0db0" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"How to setup a ready to run OpenSolaris derived ZFS Storage Server +configure it + add a WEB-GUI within minutes more: napp-it mini HowTo 1 - setup a ZFS Server How to setup a All-In-One Server - VMware ESXi based + virtualized ZFS-SAN-Server + virtualized network Switch + other VM s like Windows, Linux.. more: napp-it mini HowTo 2 - setup a all-in one Server with main focus on free systems i will keep this initial post up to date, please re-read from time to time !! ZFS is a revolutionary file-system with nearly unlimited capacity and superior data security thanks to copy on write, checksums with error-autofix, raid z1-3 without the raid5/6 write hole problem, with a online filecheck/ refresh feature and the capability to create nearly unlimited data snapshots without delay or initial space consumption. ZFS Boot snapshots are the way to go back to former OS-states. ZFS is stable, availabe since 2005 and used in Enterprise Storage Systems from Sun/ Oracle and Nexenta. Features like Deduplication, online Encryption (from ZFS V.31), Triple Parity Raid and Hybrid Storage with SSD Read/ Write Cache Drives are State of the Art and just a included ZFS property. Volume- Raid and Storage Management are Part of any ZFS System and used with just two commands zfs and zpool. ZFS is now part not only in Solaris derived Systems, but also in Free-BSD. There are efforts to include it in LInux ( ZoL). Even Apple (The days before they transformed from Apple Computers to the current iPod company) had planned to integrate ZFS but cancelled it just like they have done with their Xserve systems. But Solaris derived Systems are more. ZFS is not just a file-system-add-on. Sun, inventor of ZFS, had developed a complete Enterprise Operating System with a unique integration around ZFS with other services like a Kernel-integrated AD Windows ACL compatible and fast SMB and a fast NFS Server as a ZFS property. Comstar, the included iSCSI Framework is fast and flexible, usable for complex SAN configurations. With Crossbow, the virtual Switch Framework you could build complex virtual network switches in software, Dtrace helps to analyse the system. Service-management is done the via the unique svcadm-tool. Virtualisation can be done on application level with Zones. All of these fetaures are from Sun- now Oracle, perfectly integrated into the os with the same handling and without compatibility problems between them - the main reason why i prefer ZFS on solaris derived systems-. In 2010 Oracle bought SUN and closed the free OpenSolaris project: There are now the following Operating Systems based on (the last free) OpenSolaris 1. commercial options - Oracle Solaris 11 (available 2011) - Oracle Solaris 11 Express (free for non-commercial and evaluation use) wth GUI and time-slider download http://www.oracle.com/technetwork/server-storage/solaris11/downloads/index.html the most advanced ZFS at the moment, the only one with encryption (based on "OpenSolaris" Build 151). I support it with my free napp-it Web-Gui download http://www.napp-it.org/downloads/index_en.html Solaris Express 11 testinstallation http://www.napp-it.org/pop11.html -NexentaStor Enterprise Storage-Appliance stable, based on OpenSolaris Build 134 with a lot of backported fixes storage-only-use with the Nexenta Web-Gui download trial at http://www.nexenta.com -based on NexentaStor, there is a free Nexentastor Community-Edition (=NexentaStor, with the same GUI but without Service, without some add-ons, limited to 18 TB RAW capacity and storage-only use) NOT allowed for production use - home use only - download at http://www.nexentastor.org Compare different Nexenta Versions at: http://www.nexenta.com/corp/nexentastor-overview/nexentastor-versions 2. free options best suited for a napp-it system: -OmniOS a minimal server distribution mainly for NAS and SAN usage, stable release with weekly betas free with optional commercial support, very close and up to date with Illumos kernel development download http://omnios.omniti.com/ -OpenIndiana (the free successor of OpenSolaris), based on OpenSolaris Build 151 with GUI and time-slider currently beta, usable for Desktop or Server use. download http://openindiana.org/download/ other options: -NexentaCore 3, end of live was based on a OpenSolaris Kernel Build 134 with a lot of backportet fixes from newer builds. CLI-only (without the NexentaStor Web-Gui) but running with my free napp-it Web-Gui up to napp-it 0.8 -Illumian, base of NexentaStor 4 is available. http://www.illumian.org Illumian is based on Illumos (like OpenIndiana and uses the same binaries) but with Debian-like software installation and packaging -other distributions like Bellenix, Eon or Schillix All of the above are based originally on OpenSolaris. Further development is done either by Oracle. It was told, that they will freely publish the results after final releases If so, we may see new Oracle-features also in the free options with a delay. On the other side, there is the Illumos Project. It is a free community driven fork of the OpenSolaris Kernel with the Base-OS-functions and some base tools. They will be as close as possible to Oracle Solaris, use their new features, when they become available but also do their own development and offer Oracle to eventually include them. Illumos is mainly financed by Nexenta and others with a focus on free ZFS based Systems. Illumos is already base for Schillix and will become the base of next Eon, Bellenix, Nexenta* and OpenIndiana. Illumos is intended to be completely free and open source. 3. Use cases: Although there is a desktop-option with OpenIndiana, Solaris was developed by Sun to be a Enterprise Server OS with stability and performance at first place, best for: NAS -Kernel based high speed Windows Cifs/SMB Fileserver (AD, ACL kompatible, Snaps via previous version ) -opt. also via Samba -Apple File-Server with TimeMaschine and ACL-support via netatalk SAN -NFS and iSCSI Storage for ESXi and XEN Webserver -AMP Stack (Apache, mySQL, PHP) Backup and Archiv -Snapshots , Online File-Checks with Data Refresh , Checksum Software based Virtualization via Zones and of course Enterprise Databases -one of the reason, Oracle bought Sun Appliances -All OpenSolaris derived systems could be used as appliances and managed remotely via SSH or Browser and Web-Gui (Nexenta/ Nexentastor or napp-it on the others). 3.1 All in One Solutions You could run OpenSolaris based systems not only on real hardware but also virtualized, best on (also free-version) ESXi with pci-passthrough to SAS Controller and disks. With ESXi 4.x you will have quite the same performance like you would have on real hardware - if you could add enough RAM to this VM. It is possible to integrate the three usual parts of a professional solution like Virtual-Server, virtualized NAS/SAN-Server and virtualized LAN/SAN/vlan-network-switch build on ESXi features in one box. If you need hot-snaps of your VM s -create snaps within ESXi, then with ZFS; delete ESXi snap In case of problems, restore ZFS snap. You could then restore hot-snap within ESXi. If you need higher availabilty, use two all-in one-boxes and replicate your vm s from the first to the second box via smb-copy from snaps or ZFS-send Links about all-in-one: http://wiki.xensource.com/xenwiki/VTdHowTo http://www.servethehome.com/configure-passthrough-vmdirectpath-vmware-esxi-raid-hba-usb-drive/ http://www.napp-it.org/napp-it/all-in-one/index_en.html 3.2 short how for my All-In-One concept: -use a mainboard with Intel 3420 or 5520 chipset + one or two Xeons -you need a second Disk-Controller, best are LSI 1068 or 2008 based SAS/SATA in IT-mode (flash it to IT-mode, if you have a IR/Raid flashed one) -Install esxi (onto a &gt;= 32 GB boot drive, connected to sata in ahci mode) -activate vti-d in mainboard bios -activate pci-passthrough for this SAS controller in esxi, reboot -use the remaining space of your boot drive as a local datastor, install a virtualized Nexenta/Solaris on this local datastore; add/ pass-through your SAS Controller to this VM -connect all other disks to your SAS/Sata Controller. Nexenta/ Solaris will have real access to these disks due to pass-through. -set this VM to autostart first and install vmware-tools -create a pool, share it via NFS and CIFS for easy clone/move/save/backup/snap access from Windows or from console/midnight commander. -import this NFS-Share as a NFS datastore within ESXi and store all other VMs like any Windows, Linux, Solaris or BSD on it -share it also via CIFS for easy cloning/ backup of a VM s from your ZFS folder or via Windows previous version. 4. Hardware: Opensolaris derived Systems may run on a lot of current systems. But often it’s not a trouble-free experience. But there are a few always trouble-free options, mostly based on current Intel Server Chipsets, Intel Nics and LSI 1068 (ex Intel SASUC8I) or LSI 2008 based SAS/ Sata HBA (JBOD) Controller. Avoid Hardware-Raid at all and 4k drives if possible (They will work but may have lower performance, TLER disks are not needed). See http://www.sun.com/bigadmin/hcl/ http://nexenta.org/projects/site/wiki/About_suggested_NAS_SAN_Hardware Cheap and low power Intel Atom or the new HP Proliant Micro Server N36 (4 HD bays, max 8 GB ECC Ram, pcie 16x und 1x slots) with 1 GB+ RAM are ok but are running with reduced performance. But you should not use some goodies like deduplication, ZFS Z1-3 or encryption or it will become really slow. But it is suggested to add as much RAM as possible. If possible, I would always prefer server-class hardware best are the X8 series from SuperMicro with 3420 or 5520 chipset like a micro-ATX Supermicro X8-SIL-F. It is relatively cheap with i3 CPU, fast but low power with L-Class Xeons (40W Quads), can hold up to 32 GB ECC Ram with fast Intel Nics and 3 x pci-e 8x slots and ipmi (browser based remote keyboard and console access with remote on/off/reset - even when ih power-off state). It also supports vti-d, so you may use it as a ESXi virtual server with pci-passthrough to a embedded, virtualized Nexenta or Solaris-based zfs storage server. read about that mainboard http://www.servethehome.com/supermicro-x8silf-motherboard-v102-review-whs-v2-diy-server/ minimum is 4 GB Bootdrive + 1 GB RAM + 32 Bit CPU (Nexenta) best is 64 Bit Dual/ QuadCore, 8 GB ECC Ram+ (all used for caching) If you want to use deduplication, you need 2-3 GB Ram per TB Data Usually i would say: Trouble free = - X8 Series from SuperMicro with 3420 or 5520 Intel server-chipsets (up from 150Euro), - X-Class or L-Class low power Xeons (Dual, better Quads) - Onboard SATA with Intel ICH10 (ahci) - use always Intel Nics - LSI Controller based on 1068e (always the best) or SAS2 LSI 2008 with IT firmware about onboard LSI1068 or LSI 2008 controller they are per default flashed in Raid-mode, think about reflash to IT mode (native SAS without Raid functions) see http://www.servethehome.com/flashing-intel-sasuc8i-lsi-firmware-guide/ - Avoid expander when not needed (you need it for external enclosures or if you have more disks than you can supply with additional controller) and hardware raid at all for datapools, avoid other controller or use only if others have reported success Use mainboards with enough 4x or 8x slots for needed NICs (1Gb now /10Gb next) and needed Storage Controller. If you follow these simple rules, you will have fun. I would avoid SAS2 Controller ex LSI 2008 when not needed because of the WWN problem. (LSI 2008 will report disk related WWN instead of controller based ID) read http://www.nexenta.org/boards/1/topics/823 4b. some general suggestions: -keep it as simple as possible -performance improvements below 20% are not worth to think about more than a moment -if you have the choice, avoid parts that may have problems (ex. expander, 4k disks,hardware-raid, realtek nic etc.) -do not buy old hardware -do not buy very new hardware -do not buy it too small -do not buy to satisfy "forever needs", think only up to 2 years but think about growing data, backups or if you need virtualization follwow the best to use suggestions whenever possible (with ZFS there are not too many) or if i should say it in german: "Geiz ist geil" ist genauso blöd wie "Mann gönnt sich ja sonst nichts - wobei ich schon weiß, wie man Mann schreibt" 5. ZFS Server-OS Installation (Nexenta.*, Solaris Express 11 or OpenIndiana with suggested easy to use Live edition or with text-installer) NexentaCore is CLI only. With OpenIndiana or Solaris Express i would prefer the GUI-Live version because they are much more user friendly and you will get the time-slider feature (You can select a folder and go back in time, really nice to have) Download ISO, boot from it and install OS to a separate opt. mirrored boot-drive (use always ahci with onboard sata) You will always use the whole boot disk, so installation is ultra easy. just answer questions about your time-zone and keyboard and preferred network settings On Nexenta3 there is currently a bug with dhcp. After Installation with dhcp, you have enable auto-config via: svcadm enable nwam To configure a Ready ro Run ZFS-Server with all tools and extras like Web-Gui AMP and AFP, you could use my online installer script 6. First time configuration or update your NAS with the napp-it web-gui, toolss and additional NAS/www-services Install NexentaCore, OpenIndiana or Solaris Express 11, reboot and login as root (or as user, enter su for root access from your home-directory) and enter: wget -O - www.napp-it.org/nappit | perl The nappit online installer will configure your os (user, permissions and smb-settings), add a web-gui + minihttpd, add/ compile tools like netcat, mc, iperf, bonnie and smartmontools Thats all, your NAS is ready to run. Manage it via browser http://ip:81 You could setup most things via web-gui, some like acl-settings or snapshot access via previous version are more comfortable within Windows. 7. add-ons: On top of a running napp-it installation you could add AMP webserver stack via: wget -O - www.napp-it.org/amp | perl The amp online-installer will setup Apache, mySQL and PHP or add Apple AFP+Time Machine support via: wget -O - www.napp-it.org/afp | perl The afp installer will compile and configure a netatalk AFP Server with Time-Machine support. Share settings are included in the napp-it web-gui in menue folders. 8.Some useful Links about ZFS: excellent summary on practical tipps about ZFS http://www.nex7.com/readme1st newest docs from Oracle http://docs.oracle.com/cd/E23824_01/ Manuals from Oracle Solaris 11 http://www.c0t0d0s0.org/archives/6639-Recommended-SolarisSun-Books.html (recommended books) http://hub.opensolaris.org/bin/view/Main/documentation (overview about docs) http://www.c0t0d0s0.org/pages/lksfbook.html (less known features) http://dlc.sun.com/pdf/819-5461/819-5461.pdf (ZFS manual) http://www.solarisinternals.com/ (best source of Howtos) http://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide (best practice guide) http://www.solarisinternals.com/wiki/index.php/ZFS_Evil_Tuning_Guide (best tuning guide) http://www.oracle.com/us/products/servers-storage/storage/storage-software/031857.htm (oracle info) http://hub.opensolaris.org/bin/view/Project+cifs-server/docs (cifs server) http://nexenta.org/projects/site/wiki (Nexenta wiki) http://www.zfsbuild.com/ (howto and performance tests) ten-ways-easily-improve-oracle-solaris-zfs-filesystem-performance (10 ways to improve performance) favorite-oracle-solaris-performance-analysis-commands (analysis tools) http://download.oracle.com/docs/cd/E19963-01/index.html (Oracle Solaris 11 Express Information Library ) http://constantin.glez.de/blog/2011/03/how-set-zfs-root-pool-mirror-oracle-solaris-11-express (mirrored bootdrive on Solaris/OpenIndiana) german ZFS manual (Handbuch) http://dlc.sun.com/pdf/820-2313/820-2313.pdf (ZFS Handbuch) about silent data corruption (schleichende Datenfehler) (german, translate via google if needed) http://www.solarisday.de/downloads/storageserver0609nau.pdf http://www.fh-wedel.de/~si/seminare/ws08/Ausarbeitung/02.zfs/funktionen.html#n17 Help forums, wiki and IRC http://echelog.matzon.dk/logs/browse/openindiana/ http://echelog.matzon.dk/logs/browse/nexenta/ http://echelog.matzon.dk/logs/browse/illumos https://forums.oracle.com/forums/forum.jspa?forumID=1321 http://wiki.openindiana.org/oi/OpenIndiana+Wiki+Home https://www.illumos.org/projects/site/boards FAQ Q What are the three biggest advantages of ZFS? A1 Data security due to real data checksums, no raid-write hole problem, online scrubbing against silent corruption A2 nearly unlimited datasnaps + systemsnaps and writable clones without initial space consumption due to copy on write A3 easyness, it just works and is stable without special raid-controller or complex setup Q Can I expand/ shrink a pool A You cannot shrink (who wants?) A A pool is build from one or more vdevs/ RaidZ A You can expand a pool by adding more RaidZ/vdevs but you cannot expand a single Raidz of a pool Q Is ZFS faster than other systems? A ZFS was developped mainly to satisfy needs in datacenters with higest data security in mind A With a single disk its mostly slower than other systems with much better data security A It scales perfectly up to hundreds of disks in Petabyte ranges. Performance becomes better with any vdev you add to a pool. Q On which platform can I use ZFS A Newest features are from Oracle Solaris*, but you must pay for a support contract if you need patches or use it commercially A Best free alternative is OpenIndiana or Nexentacore (dead see -&gt; Illumos iCore project) or commercial NexentaStor A On non-Solaris platforms you can use FreeBSD, I would not use current implementations on Linux A Newest or all ZFS features are only available on Solaris based systems Please read my miniHowTo s napp-it mini HowTo 1 - setup a ZFS Server napp-it mini HowTo 2 - setup a all-in one Server Gea"</post>
   <post id="9753e03c-65ae-4091-aaad-36e39f04edaa" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Good to see you back, Gea. Hopefully no over-ambitious moderator bans you this time! By the way, what are your thoughts on ZFS with drives that have 4KB sectors but emulate 512B sectors (and report 512B sectors to the OS)? How is the write performance in Solaris-based ZFS systems?"</post>
   <post id="d43e62a9-907b-4c11-be44-7b22dd62ef41" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"i do not use any of them but i know a lot of people use them because they are are cheap. i expect them to work on any of the above systems with better support on newer ZFS releasea: Solaris Express 11 &gt; OpenIndiana &gt; Nexenta 3 I expect 4k drives to be standard in the near future, so the 4k problem should be obsolete with newer os-versions. any benchmarking is only valid for a few weeks or months. so if you could buy, non 4k drives, its the best at the moment or you must be aware about some performance problems up to the next major os-updates."</post>
   <post id="0b0961f0-322c-4d32-9689-0b826463e65b" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"sub.mesa has implemented a workaround for 4KB/512B emulation drives in his GUI for FreeBSD ZFS (I don t have a reference, but I m sure sub.mesa can supply it if you need one). I was wondering if you are aware of any temporary workarounds for 4KB drives with Solaris-based ZFS systems, while we await a more permanent solution."</post>
   <post id="d685176d-5c6a-404f-afac-d8fadaede408" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Gave that Napp-IT GUI a shot on Solaris 11 Express in VirtualBox. Pleasantly surprised. Enabled encryption and created SMB share/user. I did find that I could take snapshots, but there was no way to rollback via the gui. I had to use cmd line, which worked of course. Between this and sub.mesa s project, ZFS NAS opportunities are looking good."</post>
   <post id="812f9ff2-eed0-469e-b037-ca0da320e745" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"I ve been lurking Hard Forums for about a year now, so I thought it was time to register and share my goodies for some fun and advice. Using Bonnie I got the following benchmarks of a 5 disk, Hitachi HDS721010CLA332 raidz1-0 with the included hardware: Code:"</post>
   <post id="System release: SunOS openindiana 5.11 oi_148" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Memory size: 3840 Megabytes" section="##2##" discussion="##3##">"##4##"</post>
   <post id="System Configuration: MSI MS-7623" section="##2##" discussion="##3##">"##4##"</post>
   <post id="BIOS Configuration: American Megatrends Inc. V11.5 08/10/2010" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Processor: AMD Athlon(tm) II X2 250 Processor CPU1" section="##2##" discussion="##3##">"##4##"</post>
   <post id="------Sequential Output------ --Sequential Input-      --Random-" section="##2##" discussion="##3##">"##4##"</post>
   <post id="--Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--" section="##2##" discussion="##3##">"##4##"</post>
   <post id="Size  K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP" section="##2##" discussion="##3##">"##4##"</post>
   <post id="7672M  71814 94 221845 59 111435 31 54921  97 424945 51 408.8   2" section="##2##" discussion="##3##">"##4##"</post>
   <post id="And a Crystal Mark test result over SMB/CIFS from W7 running in Hyper-V over a cheap &quot;green&quot; gigabit switch: I ll have to research it some more to see if this is any good before I move any of my data over, or go with another solution (FreeBSD.) ZFS is interesting though. Maybe a beefer chip and some more RAM will boost results." section="##2##" discussion="##3##">"##4##"</post>
   <post id="91919778-f283-4682-8b32-da8d0404bc85" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"That CDM over SMB sequential read looks horrible. I would have expected 100+ MB/s. Did your virtualized Win7 boot from the SMB volume? Because I don t know how to set CDM to use a Samba share unless it was the boot volume. Anyway, if it was the boot disk, then maybe that is affecting the speeds?"</post>
   <post id="43e7d5aa-c49e-4a1e-9b93-9f24cb7d589e" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Welcome back Gea. Napp-It on Solaris Express 11 working awesome. Vielen dank! Your GUI is actually helping me to learn command line, by removing the "barrier to entry" to set everything up initially, and then finding out which cmdline options i need to use to maintain it. If I had to set it all up from cmdline to start with I would have never bothered. @Ruroni: re: snapshots. You do realize if you re using a Windows client to connect to an SMB share on your ZFS pool, you can right-click a folder that s been snapshotted and use the "Restore previous versions" function? Works great. Works just like Volume Shadow Copy Service on windows server."</post>
   <post id="3be08f01-949f-48e9-922c-c2055823f7d9" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"odditory said: ↑ Welcome back Gea. Napp-It on Solaris Express 11 working awesome. Vielen dank! Your GUI is actually helping me to learn command line, by removing the "barrier to entry" to set everything up initially, and then finding out which cmdline options i need to use to maintain it. If I had to set it all up from cmdline to start with I would have never bothered. @Ruroni: re: snapshots. You do realize if you re using a Windows client to connect to an SMB share on your ZFS pool, you can right-click a folder that s been snapshotted and use the "Restore previous versions" function? Works great. Works just like Volume Shadow Copy Service on windows server. Click to expand... Actually, I tried the previous version thing on the share itself rather than a folder contained within. Didn t do anything (I snapshotted before adding files, then added a single file), but the previous versions functionality was enabled (buttons not greyed out). Now that you say this, perhaps if I had folders within that share this would ve worked. I ll give it another shot."</post>
   <post id="29b49efb-9b05-46c1-ae85-33f2d60b4c06" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"For comparison s sake, here are my CDM results. They aren t going to be perfect, as I had other network traffic going during the benchmark, but should give you an idea, and I wanted to benchmark them before my new hardware arrives. iscsi : 4 drive WD 7200rpm RAID10 smb: 5 drive Seagage 7200rpm RAIDZ1"</post>
   <post id="522a423f-3798-4575-8be3-a2f74f0911ac" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Here is another test, on dedicated hardware: Looks no better, so my guess is the switch (DGS-2205 5-PORT 10/100/1000) being "green" is causing some performance issues. Gonna try and upgrade it this weekend and see if I can get some better results before moving everything over."</post>
   <post id="007ebc43-8d59-48ff-8708-157451e8634d" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"It could also be 1) crappy nic/ bus bottleneck, 2) SATA controller bus bottleneck."</post>
   <post id="c47b3637-f66c-4c5c-9238-ee90a1b92dbb" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"adi said: ↑ It could also be 1) crappy nic/ bus bottleneck, 2) SATA controller bus bottleneck. Click to expand... I went with a Intel PWLA8391GT and all drives are connected to the onboard sata, operating as "IDE", not "ACHI," so maybe i ll change that first."</post>
   <post id="d616a6a9-1e3d-42ff-b0ad-58ac00b3075d" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Ruroni said: ↑ Actually, I tried the previous version thing on the share itself rather than a folder contained within. Didn t do anything (I snapshotted before adding files, then added a single file), but the previous versions functionality was enabled (buttons not greyed out). Now that you say this, perhaps if I had folders within that share this would ve worked. I ll give it another shot. Click to expand... Alright. I report success. Too awesome."</post>
   <post id="4dd9a196-c76f-48a1-aab1-eb07a49902e0" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"some things like snapshot access or acl settings are so comfortable within windows. not worth to add a menue item in napp-it now. but i know there are people without windows (ex san usage or mac only) so i will add these items some day - when the more important things are done, like menue-driven async ZFS-replication between host, i am currently working on. gea"</post>
   <post id="cf8be502-cf63-4b71-9ce3-ce498f2a847d" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"nicka said: ↑ I went with a Intel PWLA8391GT and all drives are connected to the onboard sata, operating as "IDE", not "ACHI," so maybe i ll change that first. Click to expand... Changed onboard from IDE to ACHI, won t boot now.. Gonna re-install and see."</post>
   <post id="58e714a1-a22e-4d0a-a13c-876f010ed296" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Hi, my apology in case it is present but I miss it. Suggest an easy menu-option for CIFS sharing to allow guestok=true by default, or default value during initial setup. Maybe this is helpful for home users completely new to Solaris ZFS filer so that they do not need to wonder about security mapping between Windows client and the ZFS host and can go straight to file sharing. Cheers"</post>
   <post id="8b5ffe70-bb94-4236-9940-6d0f1790ad64" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"there is a menue option for guest access in menue folder, either on menue folder - create or on the folder overview if you share a folder via smb. if you want to have guest access per default, you may edit that menu item. you will only need minimal perl/php or html knowledge to adjust the html form. napp-it web-gui is fully user editable or extendable - see also mernue extend. -activate menue editing (menue napp-it-setup, set editing to on or always) -in editmode=on, there is a edit-link in the right top, klick on it -klick on the "e" right of the menue item, you want to edit/modify if something goes wrong, there is a 3-step undo in editing or just do a update via wget.. the old menues are still available after a update (selectable via napp-it setup from folder /zfs_date) on the other hand, Solaris-mapping is quite easy. create a local user administrator, add him to smb-group administrators. now verify that you have a mapping winuser:administrator=unixuser:root (should already be created from napp-it) see http://www.napp-it.org/pop_en.html now its quite the same handling like a real wndows-box. connect as administrator and set permssions from windows. gea"</post>
   <post id="fca69771-7eda-4667-9419-88e98ef9f9e6" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"Thanks so much for creating this thread, it will be very helpful. Maybe it is just me but, this link isn t working for me? -based on NexentaStor, there is a free Community-Edition (=NexentaStor without Service, without some add-ons, limited to 18 TB and storage-only use ) download at http://www.nexenastor.org I think you might have forgotten a  t ? Should it have been http://www.nexentastor.org/ instead?"</post>
   <post id="b8259e33-6db8-45bc-87f1-cb3e25b38fda" section="SSD and Data Storage" discussion="OpenSolaris derived ZFS NAS/ SAN (OmniOS, OpenIndiana, Solaris and napp-it)">"thanks, fixed the typo"</post>
   <post id="8dbb13a4-3dcf-41a9-adbd-addecff11534" section="SSD and Data Storage" discussion="LaCie network space 2 almost catch fire">"So this is my history: I bought this drive some years ago (2014 i think). I use this drive to manage my time machine backups. Some days ago, after left home to work, i forgot my laptop and had to go back home. Then i found my External HDD as you can see on video and photos. Was a miracle i had to go back... I contacted Lacie and the final answer was this: "Reading over your case and viewing the attachments, I agree to be upset and worried. As an Electrical Engineer you have good knowledge of what happened. Obvious the heat source s at the power supply connecter at the drive, molten and smoking plastic. This indicates the low resistance causing the heat development is at the connection point. As shown in the attachment the power supply is designed to several safety and qualification standards e.g. CE, UL, C-Tc, GS/ nemko approved for indoor use The Power Supply has a build in over heat protection in the electronic module; it does not detect a connector heating that is not physical connected to the electronic module. The Power Supply has an over current protection, if the current gets to high the power supply shuts down. Obvious the current supply did get not to high; the power supply did not shut down. All the power went into the “short at the low Ohm circuit” at the connection point, heating up the teal and melting the plastic. This plastic melts at about 70 or 80 deg. Celsius and is self-distinguishing, meaning it will melt but not ignite to flames as ualified by standards I feel sorry that it happened, but at this moment there is not much I can do. As you mentioned your worry is about defective power supply, that possible could be a hazard. As the setup is it is within all regulation and meet all standards for indoor use safety standards. We appreciate bringing your case to our attention." So, if my house burn cause of bad power supply there is nothing i can do. This history have no moral, but Lacie could at least send me a new drive..."</post>
   <post id="7a5de90b-14d7-4809-8c0e-89a6a3657f55" section="SSD and Data Storage" discussion="LaCie network space 2 almost catch fire">"LOL, English was shit from that rep, wrong words all over. That s why you don t buy Lacie, PoS."</post>
   <post id="803accdd-fa59-417b-8629-b5a2c91b7c33" section="SSD and Data Storage" discussion="LaCie network space 2 almost catch fire">"Does Lacie have a Twitter account? Post this on it, maybe it ll go viral. Also, Reddit."</post>
   <post id="901abbcf-3655-40f3-bfd1-3b4cca360220" section="SSD and Data Storage" discussion="Deskstar vs Ultrastar?">"looking at a couple of refurbished 3 TB drives on newegg -- $70 for the Deskstar and $90 for the Ultrastar. what s the actual difference between the two other than branding? is the Ultrastar worth the extra $20?"</post>
   <post id="1055c2a5-0371-4c03-830f-97551095ab68" section="SSD and Data Storage" discussion="Deskstar vs Ultrastar?">"Ultrastar are Near Line Enterprise drives. They have 5yr warranty when new. Believe they are made to run in close proximity of other drives, as in raid enclosures."</post>
   <post id="8eb0d197-0c76-4328-aa4f-c69f8708befb" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"I ve been waiting to build out a new system to replace my Synology 1812+. Here s what I have planned. Case: Lian-Li PC-Q26B MB; X10SDV-4C+-TLN4F PS: Seasonic SSR-450RM MEM: Kingston 16GB ECC STOR: LSI SAS 9210-8i Boot: 32GB USB Flash OS: ESXi + Passthrough contrller to Xpenology or just straight Xpenology.. Otherwise RockNAS or Ubuntu?! I don t consider ZFS as an option since you can t grow your array in a nice way, but I really want the benefits that ZFS provides.. Also, I ve grown fond of the amazing Synology interface. So, the plan would be as follows: Use Synology Hybrid RAID and Btrfs to have a very dynamic and easily expansible Array... 8 drives dedicated to the Raid 6 Hybrid array... Different size drives (like drobo) 2 drives mirrored for the OS, downloads and so the other drives can sleep more often to save power. Performance isn t a huge concern.. mainly need a safe place to store things, with the ability to flexibly grow and swap out drives one at a time as they get cheaper or I need more space. Any thoughts? This is a bit of a sanity check.. it all seems like it should work, but I m not aware of anyone else going this route as of yet. Thanks"</post>
   <post id="f128ebf7-7b59-42ff-b251-a848077d6e87" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"Unless you re dead set on that Supermicro board. Grab a barebone Dell T20 (new), rip out the motherboard (mATX) and place it in your case of choice. I need an power adapter for the mobo which is ~10$ off eBay or Aliexpress. That would be cutting the cost down ~70% (179$ and 35% discount over @ dell.com right now), no 10G eth but Intel Gbit at least. Drop ESXi and I would be very hesitant to use an USB flash as boot drive, just grab a Plextor M7V drive if you want something cheap that works... I think you also should consider the Fractal XL and a hotswap 2.5" bay which will end up about about the same price as the case also being less noisy. Google ICY DOCK MB994SP-4SB-1 HDD Accessory - Newegg.com"</post>
   <post id="eb4ec62f-7be0-454c-b743-b8d7769b1567" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"Sorry for not clarifying this. I ve already bought the supermicro board and I already have the Lian Li Case. I wanted a small build and the lian li holds 10 3.5" hard drives.. pretty spectacular for a mini-itx case. 10G Ethernet is important to me since I ll be keeping this around for a good 6+ years.. A 10G nic would be all I need to upgrade my desktop.. and 10G switches keep getting cheaper.. Going with a different boot drive might be the way I go.. However, if I m running ESXi and or Xpenology it s not a big deal since if you lose the flash drive, as you can rebuild very easily and your data should be fine. I intend to spend a week or two playing with different configs before I decide on the ideal one. Also, the ICY Dock you posted has 2 40mm fans. I personally wouldn t go below 80mm if you re looking for something quiet as the smaller fans have to spin faster. What s really nice about the Lian Li is it came with 3 120mm fans. Which could be replaced with some really quiet ones if need be. Really, the only thing I m not sure of is the exact os configuration.. With btrfs and the ability to grow volumes being the main requirement"</post>
   <post id="9b48aa6a-d1b8-4038-8d46-9d9f1f945eb8" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"I m not sure about your measurements but a 5.25" bay isn t 80mm (or more) in height which means what you ll never be able to use such fans unless someone drunk made the design. You sure are aiming high if you re going to except hardware to last 6+ years, I wish you the best of luck in that regard. You do realize that ESXi and Xpenology are completely different software and what they accomplish? I m not sure what you have against ZFS which is proven however. Mixing drives is a bad idea and power saving will make your array unstable/corrupt at some point most likely (which is why LSI doesn t support it)."</post>
   <post id="4586686a-0f8c-41e2-b64a-68061458ca13" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"As an example.. Here is an ICY Dock with a 92mm fan: ICY DOCK MB155SP-B FatCage MB155SP-B 5x3.5" in 3x5.25" Hot Swap SATA HDD Cage - Newegg.com I considered a 9 x 5.25" case before settling on the Lian Li. I feel like the drive get a bit better airflow in the open Lian Li vs tightly packed in a Hot Swap Cage. I have had many machines last 6+ years.. consumer grade stuff too, since the Supermicro is Server Grade, I don t see why it wouldn t.. It also won t be on all the time. The drives lasting 6 years is another story.. I think 3 to 4 years would be more likely. Yes, I know what ESXi and Xpenology are. They are very easily used in conjunction with each other. ZFS is awesome, and if I wanted to buy 8x 8TB hard drives today, ZFS would be great. I would much rather buy drives and add them to a Raid 6 Array as needed... Yes, mixing drives sucks, but for a Hybrid Raid it isn t the end of the world. This NAS is going to be more of a Deep Cold Storage Unit. LSI doesn t support power savings on drives? If a controller is flashed into IT mode, doesn t the OS control the drive?"</post>
   <post id="8e9fedef-7a66-4fce-abe9-2e4768786cf4" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"diizzy said: ↑ I m not sure about your measurements but a 5.25" bay isn t 80mm (or more) in height which means what you ll never be able to use such fans unless someone drunk made the design. You sure are aiming high if you re going to except hardware to last 6+ years, I wish you the best of luck in that regard. You do realize that ESXi and Xpenology are completely different software and what they accomplish? I m not sure what you have against ZFS which is proven however. Mixing drives is a bad idea and power saving will make your array unstable/corrupt at some point most likely (which is why LSI doesn t support it). Click to expand... I could be mistaken but Supermicro has a 7 year hardware warranty on that series. Same with the C2758 s as they re marketed for telco appliance deployment. But I totally agree with you on all other points."</post>
   <post id="20d130fc-3ce6-4fb4-9a9e-3170ba8ab40e" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"The Lian-Li hot swap back panes just arrived. Really liking this case.. Pricey as hell, but it should last forever. I still have a 12+ year old Lian Li case.. Looks as good as the day I bought it."</post>
   <post id="50142eca-504e-43f1-b8e4-2d4e5bf8a9e7" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"Phantum Product life != Warranty "Supermicro provides a three-year warranty for labor and one-year warranty for parts. This limited warranty includes advance part replacement service covering a period of 30 days from Supermicro invoice date. Upon expiration of the one-year parts warranty, the remaining 2-year labor warranty covers general technical support including, but not limited to, general RMA requests, phone support, one-way shipping and handling, but does not include labor specifically associated with the repair or replacement of out-of-warranty parts for which additional service charges will apply." Miele for instance claims that their white goods are made to last for 20 years, they still only give you 1y warranty (and they rarely last 20y fyi). LatexRat Uhm... I m aware that there are larger enclosure s but getting 3.5" for 2.5" drives (as I suggested SSDs very resonably priced ones) doesn t make any sense. It doesn t matter whether the OS supports power saving or not if the controller doesn t support it and I doubt you ll find any controller doing that running an array or even spinning down for that matter. I would be worried if metal cases would start to degenerate in normal indoor environments. ;-)"</post>
   <post id="9b621f69-19f7-4d46-8e6c-25969b666e2c" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"I stand corrected."</post>
   <post id="5b22b8b0-4362-4c47-981f-e88065723eff" section="SSD and Data Storage" discussion="New Storage Build. Btrfs/Xpenology?">"Sorry, I didn t realize you were suggesting the 2.5" dock for the boot drives. My focus was on the mass storage portion of the build. When you install Xpenology, you bootstrap from a usb drive but it actually puts the OS on your storage drives.. Regarding power saving on the LSI controllers.. does the LSI SAS2008 not let the OS spin down the drives? The card would be running in IT mode, so I wouldn t think this would be an issue. Steel cases tend to rust out eventually thanks to high humidity and living next to the ocean (salty air)."</post>
   <post id="bb7a11e7-bbfb-4325-a280-2874acfbc67c" section="SSD and Data Storage" discussion="Confused about ZFS performance on SSD">"tldr: What is going on with these benchmarks, and do I really need a P3700 to get decent performance for VM s hosted on SSD ZFS pools? Ceph: how to test if your SSD is suitable as a journal device? | Sébastien Han So I have a proxmox host that currently has the following configuration: 2x240GB mirrored ZFS Sandisk Extreme II SSD s 2x480GB mirrored ZFS Sandisk Extreme II SSD s The 240GB drives are mostly empty, hosting just proxmox itself, and my VM s live on the 480GB mirror. I recently noticed that samba file transfers under one of my Windows 10 VM s were stalling when copying files from my NAS to itself over 10Gbit. I ran this simple DD write test (with compression disabled on the filesystem) on the 480GB pool (which I know isn t terribly accurate): Code: dd if=/dev/zero of=tempfile bs=1M count=4024 conv=fdatasync,notrunc"</post>
   <post id="4024+0 records in" section="##2##" discussion="##3##">"##4##"</post>
   <post id="4024+0 records out" section="##2##" discussion="##3##">"##4##"</post>
   <post id="4219469824 bytes (4.2 GB) copied, 35.0058 s, 121 MB/s I saw as low as 80MB/s in further tests. Chalking this up to the lack of trim in ZoL and the fact the pool became probably close to 80% full at one point I destroyed the 480GB pool and forced a trim on them with: Code: mkfs.ext4 -F -E discard /dev/sda And performance restored to ~450+MB/s or so in the same tests when I rebuilt the mirror. I wasn t able to secure erase these drives because they are frozen and in a machine I don t have easy physical access to, so trim was the best I could do. Long story short i m considering getting some newer SSD s that will perform better (especially without TRIM) and stumbled across this post showing benchmarks for a ton of drives: Ceph: how to test if your SSD is suitable as a journal device? | Sébastien Han I m horribly confused about what s going on there. How is an 850 Pro only writing at 1.5MB/s and how will that affect someone like me, a hobbyist without very demanding needs? I just want a system that s reasonably quick and responsive, but by looking at that page you d think you need nothing less than a P3700 to pull that off? Thank you for any help!" section="##2##" discussion="##3##">"##4##"</post>
   <post id="0f5ab241-09ea-477a-a4ac-24111888402e" section="SSD and Data Storage" discussion="Confused about ZFS performance on SSD">"I actually think that the low write rate of the Samsung consumer SSDs is a rather good sign for the firmware implementation of the drives. When a cheap consumer class SSD like the Kingston v300 or the Intel 535 can achieve such a high sustained random 4K performance I get skeptical. Such a throughput without a proper power-loss-protection most probably means that the SSD does a heavy write-caching in its RAM, which would mean that a power loss can have bad implications on your file-system integrity - something ZFS cannot deal with very well. I run some VMs on an mirror of Samsung 830 256 GB SSDs for several years now and the performance is still good. While you can really see the performance degrading a bit during the time the SSD fills up and internally fragments, you can counter that a bit with overprovisioning (I use only 200 GB). The 830 was an early SSD and the garbage collection seems to be not as good as the 840 Pro I also testet. It is still enough for my home server. Whether this is enough for you depends on your requirements - number of VMs, expected workloads, etc."</post>
   <post id="c14ea493-93c7-4f64-b837-fee1db7ea85e" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"I ll be building a system soon using the Intel 750 (PCIe add-in card version). Ideally I would go with the Gigabyte Z170 UD5 with Thunderbolt, but I haven t found any compatibility information on Gigabyte s site. Does anyone know if all boards this generation support NVMe over PCI-e? Is this implied if the manufacturer states "NVMe compatible over M.2 PCI-e x4" ? I noticed MSI words it the same way in their spec tables, but at least they have a storage device compatibility list that has the 750 on it. *note, I m not looking for alternate board suggestions, I m really only interested in the UD5. Thanks."</post>
   <post id="bc454673-ab8a-402b-8feb-112f17734a4a" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"update: I just submitted this question to Gigabyte support. Hopefully they will have a response."</post>
   <post id="7b6f0af9-8d39-4c93-ba02-4949dd573a91" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"What makes you think it won t work?"</post>
   <post id="8fa0ccab-58f5-40b2-8a63-11ac369fe5c3" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"It should work in pretty much any motherboard with a PCIe slot. You will generally need Z97/X99 or newer to support booting off the card however (some older boards support it too). You should be fine."</post>
   <post id="ac3fa76e-b7e4-4bd5-9553-75cf3b1748ab" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"Ocellaris said: ↑ What makes you think it won t work? Click to expand... So Gigabyte s wording is this: PCIe Gen3 x4 M.2 Connector with up to 32Gb/s Data Transfer (PCIe NVMe &amp; SATA SSD support) Click to expand... I m thinking, why not just state "NVMe support" as an umbrella feature? I m concerned that they only mention NVMe when speaking of their M.2 Connector because that s the only port that is compatible. I don t know how NVMe is implemented so just being cautious before pulling the trigger."</post>
   <post id="2dbefad9-dee0-475f-bbbd-c48a9e9b715c" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"They only need to mention it for the M.2 slot because not all of those will support PCIe devices. Nothing special needs to be done to support NVMe devices when they re using a normal PCIe slot (booting aside). It s just like any other PCIe card."</post>
   <post id="419ecca7-0ccc-4ffa-bf32-c908ab0388ca" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"Blue Fox said: ↑ They only need to mention it for the M.2 slot because not all of those will support PCIe devices. Nothing special needs to be done to support NVMe devices when they re using a normal PCIe slot (booting aside). It s just like any other PCIe card. Click to expand... I see. I should have clarified that I was looking for booting from an NVMe device over PCIe slot. So what is it about Z97 and Z170 that allows them to support NVMe booting while Z87 does not? (even if Z87 runs Win10) The availability of BIOS updates for Z87 compatibility suggests it s a board feature and not a CPU feature correct? can I also assume that it s not a chipset feature because the 750 is typically run off the CPU PCIe lanes?"</post>
   <post id="31afdd7f-2498-454c-82c7-8a6b93c8880b" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"The board needs to have UEFI (so older BIOS only boards are out) and the NVMe driver (UEFI driver that is). It s not dependent on anything else really. Older boards often don t support it because manufacturers seldom bother releasing updates for old boards. If you don t mind tinkering with things a bit, you can actually add the driver yourself. I can post a link on that if you d like."</post>
   <post id="5664d410-361e-4de5-b92c-81a3e06c2e5b" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"Thanks for the clarification. I actually came across the DIY driver thread the other day while I was trying to read up. So in the case of my Z87 (in sig), it clearly already uses a UEFI BIOS...is it out of ignorance that owners are asking MSI for a BIOS update to support NVMe boot, because it is only a driver that is required? I just updated the drivers on this board yesterday and it seems MSI has kept up with them pretty well for existing components."</post>
   <post id="78038eed-ca85-42b2-83fa-cdea94c2aba9" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"Don t waste a PCI-E Slot if the motherboard has a M.2 slot. Get the Intel 750 in 2.5 inch form factor. It has a U2 connector which you can connect to the M.2 slot with a U2 to M2 adapter."</post>
   <post id="74e76bb7-518e-4afc-baa3-c59534664c99" section="SSD and Data Storage" discussion="Mobo compatibility for PCI-e NVMe (Intel 750)">"The thing is I d rather have the 750 in a PCIe slot so it connects directly to the CPU PCIe lanes. A U.2 version will connect through the chipset. It will also end up costing more to buy a Hyper Kit which is incredibly inelegant imo."</post>
<post id="af53e2f4-4a9e-4695-8ebd-a93972278dee" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Tom Clancy s The Division Gameplay Performance Review - We take Tom Clancy s triple A title, The Division, and find out how AMD s and NVIDIA s high end video cards  performances stack up and what image quality settings it takes to truly be immersed. We will see what level of GPU is needed at what resolution to enjoy this game with high graphics settings and image quality."</post>
   <post id="a29d4f79-24a9-4cb5-a75a-780c04d83943" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Great performance review. Unfortunately the community for this game has dwindled down to almost nothing on PC. It s a ghost town after just two months."</post>
   <post id="1e139c8f-3c8e-4278-9bd0-e68709b00d59" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"The Division definately looks beautiful unfortunately it got boring real quick. I thought I d be playing this game for months and months being as that I really enjoy third person cover based shooters, the story seemed interesting and the production value is solid. Unfortunately none of the gameplay elements feel fleshed out and it s extremely repetitive with almost no driving force to keep people playing. I hit the wall before I even hit the level cap."</post>
   <post id="2ffd7fc7-9e32-4088-98a8-c79aeaeff4de" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"First off, is a 4 gb video card 4000 mb, 3814 mb (like hdd conversion) or 4096 mb? I always get confused with binary conversion. Vram usage is still confusing as ever. The GTX 980 ti, 390, and 390x have the most available in their categories, yet they have the lowest minimum frame rate. The 980 is not even using all available at 1440p, yet the 980ti uses much more. Pretty much a random bunch of numbbers."</post>
   <post id="2b8b6a01-5773-453e-a17a-77f4daf30cbc" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Cmdrmonkey said: ↑ Great performance review. Unfortunately the community for this game has dwindled down to almost nothing on PC. It s a ghost town after just two months. Click to expand... what are you talking about? there are several thousand players online even at the lowest, and that s just steam numbers. combine that with uplay and there are probably at least 50% more at any given time. it takes a few seconds to get a full party for missions and DZ instances work by transferring you to the ones nearest full capacity (24 players) so you re always going to be in a DZ instance that has plenty of people in it. i play the game every day and have never had any issues with amount of players and i even block chinese and australian servers. the game has lost a huge amount of players but it isn t enough (yet) to actually affect gameplay."</post>
   <post id="5458a49e-d52f-46fc-aea4-1e63ade53a76" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"So where are the GTX1080 benchmarks?"</post>
   <post id="ba66d6fb-71e3-4d2e-aa5a-15d2a681b892" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Nihilus1 said: ↑ First off, is a 4 gb video card 4000 mb, 3814 mb (like hdd conversion) or 4096 mb? I always get confused with binary conversion. Vram usage is still confusing as ever. The GTX 980 ti, 390, and 390x have the most available in their categories, yet they have the lowest minimum frame rate. The 980 is not even using all available at 1440p, yet the 980ti uses much more. Pretty much a random bunch of numbbers. Click to expand... 4096MB hdds are smaller due to the formatting process. a 4GB hdd is 4GB before partitioning and formatting but only 3.8GBs after."</post>
   <post id="63f1bb3d-3a6a-4df6-b78b-522cb9b80fdb" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Great article. Thanks for testing it at 4K"</post>
   <post id="7d9c114d-0781-4d6d-a2a5-262b8b173e63" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"PCSS is a mixed bag. Sometimes regular shadows looks better iirc."</post>
   <post id="b9a6395a-4878-4bde-bfd3-27703b2d7b99" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"If a tree falls in the forest, and there is no one there to hear it.................. /down to 9,088 players on steam at this moment with a 24 hour peak of 11,186. (all time peak of 113,877) Tom Clancy s The Division - Steam Charts"</post>
   <post id="3fbcd1d6-43c9-4d15-bc10-314822dfeafc" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Lith1um said: ↑ If a tree falls in the forest, and there is no one there to hear it.................. Click to expand... a hipster will still buy the album. saw that somewhere made me laugh..."</post>
   <post id="fd7ecada-7e3b-4ad7-b55c-1630de4cab40" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Lith1um said: ↑ If a tree falls in the forest, and there is no one there to hear it.................. /down to 9,088 players on steam at this moment with a 24 hour peak of 11,186. (all time peak of 113,877) Tom Clancy s The Division - Steam Charts Click to expand... Yeah that is a really steady decline. They have a new incursion coming up this month, I think. And then we get into the DLCs this summer. It will spike back up to 20k-25k probably, but man how low is it going to stabilize? 5K? It s seriously on-track to be dead. Seriously regretting my Gold Edition. I got a solid 300+ hours out of the game but now it s just a vegetable. edit: Oh also that number doesn t include UPLAY. I imagine there s a lot of people there, too."</post>
   <post id="804c8af6-106b-48e7-afbb-794fd139891e" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"I bought the season pass......."</post>
   <post id="d0268b25-0a98-421b-91dd-392b3d23f579" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Lith1um said: ↑ I bought the season pass....... Click to expand... /trout slap"</post>
   <post id="7c8e8b50-0539-458a-9c2e-59bc32ff3575" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"nterestingly the dynamic VRAM on the AMD Radeon R9 Fury and Fury X is not utilized in this game, it seems to rely only on the dedicated VRAM on board. This might mean that AMD has not specifically tweaked its drivers to utilize the dynamic VRAM capability of the Fury and Fury X in The Division. We have found that when specific optimizations are not in place this is the result, only dedicated VRAM is used and dynamic VRAM is not. Click to expand... I was under the impression only dx12 games were using the larger amounts of dynamic VRAM. Seems to be the case with my card anyway"</post>
   <post id="647b6f72-36fc-4173-8902-3ce9c06ca3bc" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"pendragon1 said: ↑ 4096MB hdds are smaller due to the formatting process. a 4GB hdd is 4GB before partitioning and formatting but only 3.8GBs after. Click to expand... no, HDDs are "smaller" because the advertised size is gigabytes when what windows and most everything else uses is gibibytes, ie base 2."</post>
   <post id="73bc5e83-a1ad-4a6d-9b30-4288a10df489" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Odellus said: ↑ no, HDDs are "smaller" because the advertised size is gigabytes when what windows and most everything else uses is gibibytes, ie base 2. Click to expand... Yes HDD use the 1000 not 1024, but the available space you have also depends on formatting between how the format heads files, stores a master record of files and cluster size for storage you get slack and thus waste loss of "expected" capacity. The two combine to really confuse people on where all their storage space went."</post>
   <post id="ea280a1e-b195-4ebb-b848-215c9fa42927" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"These game series reviews are not only interesting but very informative as well. Getting to understand what the game setting is doing and how the hardware handles it is really perfected here at HardOCP. As for forward looking, maybe graphically but since it does not use DX12 or Vulkan (probably for a good reason since development probably started way before the API was finalized) it to me is short term. When will we get this type of quality development in DX12 is probably a long way off. Maybe BattleField 5, Dues Ex will start to make DX12 shine better."</post>
   <post id="c88ec641-d6e9-48d6-9aa7-0dbc46fb1c65" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"Have they improved the performance at all since release? I only played the beta."</post>
   <post id="115f6f90-3dc0-4a14-b79e-7b1bf14091b4" section="Video Cards" discussion="Tom Clancy s The Division Gameplay Performance Review @ [H]">"husker4life said: ↑ Have they improved the performance at all since release? I only played the beta. Click to expand... maybe a little bit? not really."</post>
   <post id="22d1a123-d230-4524-8f21-37b3061a40ad" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"Rise of the Tomb Raider DX11 vs. DX12 Review - Rise of the Tomb Raider has recently received a new patch which adds DX12 API support, in addition the patch adds NVIDIA VXAO Ambient Occlusion technology, however just under DX11. In this evaluation we will find out if DX12 is beneficial to the gameplay experience currently and how it impacts certain GPUs."</post>
   <post id="19729ef9-9527-4732-a5e4-6ca2c885b011" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"nice article. everything DX12 is gonna take time to mature, we will obviously see improvements as development continues but its a good start. going by the 390/390x/970 numbers and how many options were lowered, they look more suited to 1080p for this game."</post>
   <post id="fed81ef2-9a97-47f6-a615-415345d2f7b7" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"while I could be wrong, my take on Dx12 is it more on the dev side to optimize the game for AMD and Nvidia . With dx12 the graphic driver mainly just opens pathway to the low level HW , my fear with Dx12 is many games , at least starting out, will just do a generic dx12 optimize and not spend time tweaking each (AMD-Nvida HW). Over time though it probably get better as I am sure AMD and Nvidia will help point to were and better optimize for each of there HW . Dev s just have to work with each one. PS: thumbs up for doing review without fps, it still was/is very informative."</post>
   <post id="1a3a8950-57d2-4be4-a3dc-352c1e2521c3" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"One comment on the format: Work the resolution into all of the tables or present the table that has them first, as it is supposed to provide quick info on where you guys found the limit of what was acceptably playable at what settings."</post>
   <post id="8e1a971e-07ad-42bd-8d56-37f5cfae6d89" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"EdKiefer said: ↑ while I could be wrong, my take on Dx12 is it more on the dev side to optimize the game for AMD and Nvidia . With dx12 the graphic driver mainly just opens pathway to the low level HW , my fear with Dx12 is many games , at least starting out, will just do a generic dx12 optimize and not spend time tweaking each (AMD-Nvida HW). Over time though it probably get better as I am sure AMD and Nvidia will help point to were and better optimize for each of there HW . Dev s just have to work with each one. PS: thumbs up for doing review without fps, it still was/is very informative. Click to expand... Its like DX9, DX10, DX11 all over again. But in this case game devs will also need to optimize their games for DX12 not just drivers specially if they want to exploit all DX12 potential"</post>
   <post id="ae99a0d7-c4eb-4a32-8698-3a785cf70ef3" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"The main issue is that a lot of the DX 12 implementations right now are "tack ons" - as in, the game wasn t designed with DX12 in mind, but they are adding support to do a couple things and get on the hype train. We won t really know what DX 12 has under the hood until we start getting the run of games built with DX12 in mind - from what I heard, there are a lot of low level calls and optimizations that to get the most out of DX12, you need to be programming for it from the beginning. Seems like DX 12 is a tradeoff - more complicated by now than DX11 to implement due to a lot of interfacing directly with the hardware, but because of that low level interaction, it gives the game creators a much larger degree of control, and can push games harder without framerate loss. I don t think we will be seeing any of those true DX12 games until later in the year."</post>
   <post id="ec128a3b-5c99-462f-b701-ef84311345bb" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"The encouraging sign from the dev in this case is that they ve said pretty clearly that they aren t done optimizing for DX12, so it will be interesting to see how much more performance they can achieve."</post>
   <post id="7756c3e0-6fe8-48b6-a02e-eb309f4e455d" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"dewbak75 said: ↑ The encouraging sign from the dev in this case is that they ve said pretty clearly that they aren t done optimizing for DX12, so it will be interesting to see how much more performance they can achieve. Click to expand... Well, let s see exactly what the devs did say instead of a paraphrasing your own words. Jurjen Katsman, Studio Head at Nixxes Software [Our developer blogs lift the curtain on the creation of Lara’s first tomb raiding expedition, and the technology we use toconstantly improve it. Following the release of Rise of the Tomb Raider for PC, the title will be one of the first in the industry to integrate DirectX 12 support, allowing fans with older PCs or newer rigs to run at higher framerates and higher graphical settings. Nixxes Studio Head Jurjen Katsman dives deep into the new technology below.] Pushing the boundaries of technology on PC has always been a passion of the development team at Nixxes, and Crystal Dynamics and Square Enix have been great partners for us in doing so. One of the challenges with PC development is guaranteeing players on as many different PC configurations as possible can have a great experience. For us this means ensuring that users with older PCs can still get a great gameplay experience, but also that users with higher-end machines can get the most out of their hardware, including the highest quality visuals, frame-rate, and other technical enhancements. One thing we are very excited about to help us further realize those goals is the new DirectX 12 graphics API that is available on Windows 10. In the patch released today on Steam – and coming soon to the Windows 10 Store – we will be adding DirectX 12 support to Rise of the Tomb Raider. At Nixxes we have a long history of working with consoles as well, and one of the large differences between developing for consoles and developing for PCs is the level of access to the hardware available to us. We can leverage every single hardware feature and every bit of CPU power available in the most efficient way possible. With DirectX 12 we are taking a massive step forwards for bringing a lot of that flexibility to the PC as well. For Rise of the Tomb Raider the largest gain DirectX 12 will give us is the ability to spread our CPU rendering work over all CPU cores, without introducing additional overhead. This is especially important on 8-core CPUs like Intel i7’s or many AMD FX processors. Let me explain how this helps the performance of your game. When using DirectX 11, in situations where the game is under heavy load – for example in the larger hubs of the game – the individual cores may not be able to feed a fast GPU like an NVIDIA GTX 980 or even NVIDIA GTX 970 quick enough. This means the game may not hit the desired frame-rate, requiring you to turn down settings that impact CPU performance. Even though the game can use all your CPU cores, the majority of the DirectX 11 related work is all happening on a single core. With DirectX 12 a lot of the work is spread over many cores, and the framerate of the game will run at can be much higher for the same settings. Check out the picture below for a visual example of how the CPU work is distributed: As an example to illustrate the point, below is a screenshot of a scene in the game running on an Intel i7-2600 processor with 1333Mhz memory, paired with a GTX 970. Using DirectX 11 at High Settings we would only get 46 fps. Now look at the same location the new DirectX 12 implementation, we can lift it up to 60! The above advantage we feel is the most important one for Rise of the Tomb Raider, but there are many more advantages that make us excited about DirectX 12. Another big feature, which we are also using on Xbox One, is asynchronous compute. This allows us to re-use GPU power that would otherwise go to waste, and do multiple tasks in parallel. And there is a never before seen level of control over NVIDIA SLI and AMD CrossFireX configurations, which means that as a developer we can take full control over those systems and ensure users get a great experience with them. Being one of the first game titles out there using DirectX 12 there are still many more optimizations to make and DirectX 11 is available for the most predictable and proven experience. However, as seen above there are large gains to be found already, and we encourage you to check out DirectX 12 for yourself in our latest patch!"</post>
   <post id="ef930d06-b0ed-412e-b7f1-75f2c3e642a8" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"DX12 looks like a red herring for CPU optimisation with this game. Using DX11, my 6700K @ 4.6GHz with HT on shows all cores heavily used with a clocked 980ti, averaging around 91fps @ 1080p with the benchmark. (all settings maxed, MSAA, no motion blur... cant check if anything else is changed because their crap servers dont work!) What can DX12 improve here? I am getting pissed off with this game. Every day before I can play it insists I go to their server, copy a code into a box, get the return code, paste that in the games box and I m away. Thats annoying enough. Today, I enter the code and wait for the return code and their website does nothing. ffs, they better stop this crap or I wont buy their next game."</post>
   <post id="4cfab116-681e-457e-ba94-de68dca8feec" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"Nenu said: ↑ DX12 looks like a red herring for CPU optimisation with this game. Using DX11, my 6700K @ 4.6GHz with HT on shows all cores heavily used with a clocked 980ti, averaging around 91fps @ 1080p with the benchmark. (all settings maxed, MSAA, no motion blur... cant check if anything else is changed because their crap servers dont work!) What can DX12 improve here? I am getting pissed off with this game. Every day before I can play it insists I go to their server, copy a code into a box, get the return code, paste that in the games box and I m away. Thats annoying enough. Today, I enter the code and wait for the return code and their website does nothing. ffs, they better stop this crap or I wont buy their next game. Click to expand... Yea the pirates don t have to deal with this issue. Just another reason DRM hurts the paying customers. At this point in time, they should just patch those checks out since the game has been out for awhile."</post>
   <post id="9a28d59b-8142-4233-844a-da440b8f6b48" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"Tomb Raider just doesn t hit the CPU hard enough to get a good feel for DirectX 12 s supposed benefits. Its basically the same thing: Test with a slower CPU or write an application that requires more CPU than is available. Until then, who knows? I do think testing on slower CPUs even in a GPU test will be interesting just as additional data points, to see if DirectX 12 is even doing what it claims or not."</post>
   <post id="82102693-6a40-4015-98a7-0cf433bef616" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"EODetroit said: ↑ Tomb Raider just doesn t hit the CPU hard enough to get a good feel for DirectX 12 s supposed benefits. Its basically the same thing: Test with a slower CPU or write an application that requires more CPU than is available. Until then, who knows? I do think testing on slower CPUs even in a GPU test will be interesting just as additional data points, to see if DirectX 12 is even doing what it claims or not. Click to expand... It does if you get high enough framerate. With a 6600K @ 4.7GHz in DX11, the last 2 levels of the demo maxed all cores out for a few seconds,and made the first few seconds of the levels jerky. With a 6700K @ 4.6GHz in DX11, the CPU maxes out on 4 cores and the other cores are at 98% ish for a split moment. It no longer jerks at the start of the levels. This is averaging 91fps with a clocked 980ti."</post>
   <post id="69564163-1563-41ee-a57b-bdced0e04f8a" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"EODetroit said: ↑ Tomb Raider just doesn t hit the CPU hard enough to get a good feel for DirectX 12 s supposed benefits. Its basically the same thing: Test with a slower CPU or write an application that requires more CPU than is available. Until then, who knows? I do think testing on slower CPUs even in a GPU test will be interesting just as additional data points, to see if DirectX 12 is even doing what it claims or not. Click to expand... I cant play it. Instead of having a nice time chilling and gaming for an hour, I ve been trying to fix their stupid problem and swearing. fucking idiots."</post>
   <post id="b94510ac-3017-460c-948b-02abb011a6f3" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"based on the info kyle just posted from the devs, to get a true feeling for the dx12 benefits you need a lower powered CPU/GPU combo, even lower RAM speeds. So people with high-end and enthusiast grade systems are going to see little benefit, other than visual improvements but people like myself with lower-mid range systems should see a good improvement. or did I interpret that wrong?"</post>
   <post id="901326a4-b375-4b77-aed1-096ac7399693" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"I disagree with the [H] stance that frame rates are finally unimportant, as they have been predicting for 13 years. I believe that frame rates are more important today than ever. It has been shown that frame rates above 90hz are critically important to VR immersion and preventing motion sickness. Those frame rate over time plots will be essential for actual developers as they optimize their games to ensure nothing causes rates to dip below 90hz. Consumers will need to know what hardware and game combinations will maintain 90+hz. If there was ever a time that frame rates were important it is now. They are no longer a subjective, or snobby, issue. They are essential to the gaming experience."</post>
   <post id="5960fd9f-29fa-4436-900c-ccb05b1dbe65" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"pendragon1 said: ↑ based on the info kyle just posted from the devs, to get a true feeling for the dx12 benefits you need a lower powered CPU/GPU combo, even lower RAM speeds. So people with high-end and enthusiast grade systems are going to see little benefit, other than visual improvements but people like myself with lower-mid range systems should see a good improvement. or did I interpret that wrong? Click to expand... This is exactly what I took from the dev s comments."</post>
   <post id="8f9acf98-0182-44fb-bf29-61dfbb57275f" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"Dunnlang said: ↑ I disagree with the [H] stance that frame rates are finally unimportant, as they have been predicting for 13 years. I believe that frame rates are more important today than ever. It has been shown that frame rates above 90hz are critically important to VR immersion and preventing motion sickness. Those frame rate over time plots will be essential for actual developers as they optimize their games to ensure nothing causes rates to dip below 90hz. Consumers will need to know what hardware and game combinations will maintain 90+hz. If there was ever a time that frame rates were important it is now. They are no longer a subjective, or snobby, issue. They are essential to the gaming experience. Click to expand... with VR possibly this is the case. Idk, haven t used a single unit, ever. but on a monitor FPS is not everything. some games I can play for hours at 60FPS(T-Raider 2013, GTAV, Grid: AS) but others like the AC series, Dirt Rally, and MOST First Person Games running at 60FPS give me a headache and eyestrain. if its lower, like 45ish no headache/eyestrain. so it has to be the smoothness of those frames(frame time?) don t know why. and that 90Hz is combined, its 45 per eye. is it not?"</post>
   <post id="83e5e1ae-d327-4451-b436-f1c29b0659fa" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"pendragon1 said: ↑ with VR possibly this is the case. Idk, haven t used a single unit, ever. but on a monitor FPS is not everything. some games I can play for hours at 60FPS(T-Raider 2013, GTAV, Grid: AS) but others like the AC series, Dirt Rally, and MOST First Person Games running at 60FPS give me a headache and eyestrain. if its lower, like 45ish no headache/eyestrain. don t know why. and that 90Hz is combined, its 45 per eye. is it not? Click to expand... Raw monitor FPS is not an issue for most people, except in the cases of tearing. There is a percentage of people that get headaches at refresh rates below 60hz. I think that frame consistency should always be the more heavily weighted factor on 2D monitors. Frame dips, stalls and tears are much more objectively bad than 45hz vs 60hz."</post>
   <post id="d7411a0e-d0f2-4076-ad87-a2cb3878b8d0" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"I run with vsync and 60FPS cap in Radeon settings."</post>
   <post id="7685930a-5073-4c5a-a661-5d004992c17d" section="Video Cards" discussion="Rise of the Tomb Raider DX11 vs. DX12 Review @ [H]">"pendragon1 said: ↑ and that 90Hz is combined, its 45 per eye. is it not? Click to expand... 90 per eye."</post>
   <post id="8ebcb3cc-05ac-4c7d-a82a-69d1d3c5667f" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Hitman 2016 Performance Video Card Review - Hitman (2016) supports the new DirectX 12 API. We will take this game and find out if DX12 is faster than DX11 and what it may offer in this game and if it allows a better gameplay experience. We will also compare Himan performance between several video cards to find what is playable and how AMD vs. NV GPUs compare."</post>
   <post id="c4b66211-45aa-438d-8ed7-57d22cd00972" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Great write-up!"</post>
   <post id="51698ac4-45d3-407a-8ece-842076694c27" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Oh boy. This is gonna be a hot topic. I am curious to the DX12 playability issues."</post>
   <post id="3bbf9420-23a2-44ef-a873-a104b179c88c" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"JustReason said: ↑ Oh boy. This is gonna be a hot topic. I am curious to the DX12 playability issues. Click to expand... A quick Google search will show you a LOT of people having this issue. Lots of home remedies posted on how to get DX12 to work, however, none that worked for us that did not change how we would evaluate overall. What is really "bad" about the whole thing is just how the game looks. Brent called it looking 3 years old graphically, but honestly, it struck me as being about 5 in terms of overall feel. This is not the DX12 poster child you and I are looking for."</post>
   <post id="b5baf401-d44f-412a-bdfc-8e1f77199caf" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"This isn t the first time I ve seen GCN 1.2 lose performance in DX12, the 380 and 380X had a similar problem in other recent DX12 games. Weird. Expected bigger gains than &lt;5% for the other GPUs as well."</post>
   <post id="bf27a540-8736-4959-a289-fe75a95d8f25" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"It crashed for me under DX12 in the middle of a mission on day one. I mothballed the game for now as DX12 runs so much nicer than DX11 for me. I don t even want to play it under DX11. I can of course. Just that when you ve seen paradise; you don t want to go back to pedestrian life."</post>
   <post id="d9a5ef68-b52f-4140-a38b-c2bbd54e2f09" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"TaintedSquirrel said: ↑ This isn t the first time I ve seen GCN 1.2 lose performance in DX12, the 380 and 380X had a similar problem in other recent DX12 games. Weird. Expected bigger gains than &lt;5% for the other GPUs as well. Click to expand... Well someone has to use and do something exciting with it first. These developers are forming the building blocks for game design and game engines into the distant future. As the say, "There will be bugs.""</post>
   <post id="30ee47e8-aa48-4403-bbc1-21c95121209e" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"I just came upon this - HITMAN Lead Dev: DX12 Gains Will Take Time, But They re Possible After Ditching DX11 Async Compute in particular has received a lot of attention from PC enthusiasts, specifically in regards to NVIDIA GPUs lacking hardware support for it. However, in the GDC 2016 talk you said that even AMD cards only got a 5-10% boost and furthermore, you described Async Compute as “super hard” to tune because too much work can make it a penalty. Is it fair to say that the importance of Async Compute has been perhaps overstated in comparison to other factors that determine performance? Do you think NVIDIA may be in trouble if Pascal doesn’t implement a hardware solution for Async Compute The main reason it’s hard is that every GPU ideally needs custom tweaking – the bandwidth to compute ration is different for each GPU, ideally requiring tweaking the amount of async work for each one. I don’t think it’s overstated, but obviously YMMW (your mileage may vary). In the current state, Async compute is a nice &amp; easy performance win. In the long run it will be interesting to see if GPU’s get better at running parallel work, since we could potentially get even better wins. Click to expand... That pretty much backs up my theory I posted in the conclusion R.E. Async Compute."</post>
   <post id="68546e7c-b47f-45a7-834a-f850b598a2c6" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Yeah, before the 1.03 patch I couldn t even run in DX12 mode without crashing. Now it ll run, it just runs like garbage. This game has bigger issues, though, because if you set Shadow Resolution to High you get extreme FPS drops (down to sub-10 FPS) when looking at certain mirrors / angles. Graphically, it basically looks like Absolution. I think someone disagreed with me in the Hitman thread but I finished up Absolution right before playing the new game and they look practically the same."</post>
   <post id="eb7d1553-28d3-4eae-9976-eda99ce4dc9a" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"is it weird that the first thing that popped in my head from this review was.. "where is the amd cpu numbers!!!??!!" Probably still in shock from seeing the previous article lol. Seriously though, i had read the game is totally broken in dx12 so i am amazed you even managed to run some of the benchmarks. Your conclusion about async is something i wondered about. I think it makes sense but nothing anyone ever thought of really since i haven t seen anything performance numbers on older hardware. As for the game...it looks rather dull... and isn t this an episodic game now too?"</post>
   <post id="980fc9d5-8308-4576-8669-fd4e574ba1cf" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Can someone point me somewhere were this dynamic vram on Amd cards is explained? I ve seen it in the last few reviews but I havent seen any real information on it. To the review. Sine both amd and nvidia crash under dx12 I would assume it is a game side issue? Great write up. There is a ton of information in there, I need to go back and read some parts again."</post>
   <post id="fb465791-b982-4776-9014-213fb713d548" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Yes I dont understand the 2 vram columns either. This was a great article. It is surprising that the 390x nearly matches the Fury in dx12, once they get fit to work properly. Amd definatley dominates here, dx11 or otherwise. Am I to understand that the new AMD and Nvidia cards will be less focused on Compute than the older Hawaii cards? Does this include Dual precision? If that is the case, the 5 year old Tahiti cards will still be the dual precision champs!"</post>
   <post id="365782a5-17a7-4645-a5cb-1bc89865168e" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Nihilus1 said: ↑ Yes I dont understand the 2 vram columns either. This was a great article. Click to expand... trick0502 said: ↑ Can someone point me somewhere were this dynamic vram on Amd cards is explained? I ve seen it in the last few reviews but I havent seen any real information on it. Click to expand... Here ya go. Instead of swapping textures in your pagefile, which is more than likely located on a SSD or worse if on a conventional hard drive; the AMD driver uses System Ram, as it is a lot faster than the afore mentioned solutions. This is from the [H]ardocp Tomb Raider review. AA VRAM Usage - Rise of the Tomb Raider Graphics Features Performance The AMD Radeon R9 Fury X VRAM behavior does make sense though if you look toward the dynamic VRAM. It seems the onboard dedicated VRAM was mostly pegged at or near its 4GB of capacity. Then it seems the video card is able to shift its memory load out to system RAM, by as much as almost 4GB at 4K with 4X SSAA. If you combine the dynamic VRAM plus the on board 4GB of VRAM the numbers come out to equal numbers much higher than the AMD Radeon R9 390X and closer to what the GeForce GTX 980 Ti achieved in terms of dedicated VRAM. So in the future when building a system, an enthusiast needs to value other parts of their system like Ram speed and latency just as much as they would a video card or processor. Battlefield 4 Loves High Speed Memory"</post>
   <post id="e6055a3c-c84d-4e87-ab02-f826741f4c00" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"cageymaru said: ↑ It crashed for me under DX12 in the middle of a mission on day one. I mothballed the game for now as DX12 runs so much nicer than DX11 for me. I don t even want to play it under DX11. I can of course. Just that when you ve seen paradise; you don t want to go back to pedestrian life. Click to expand... Seems to me if you like the style of game you might as well play it in 11. 12 doesn t add anything other then performance, and that is seeming pretty questionable for this title. Not sure you got a hint of paradise, or if you simply have fallen victim to number envy."</post>
   <post id="dd5055ab-b925-417a-b6c9-613af08ce9dc" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Remember people: DX12 shifts responsibility to the developers, and away from NVIDIA/AMD. This type of problems is both expected and predicted."</post>
   <post id="d42e73bf-ed23-4388-97b2-00d85debd2f9" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"ChadD said: ↑ Seems to me if you like the style of game you might as well play it in 11. 12 doesn t add anything other then performance, and that is seeming pretty questionable for this title. Not sure you got a hint of paradise, or if you simply have fallen victim to number envy. Click to expand... It s an episodic affair stretched out over several months. I m in no rush to spoil my experience. I can wait for them to get DX12 right."</post>
   <post id="ea317167-6a1a-439e-92a5-b0a3d195802a" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Not a game that interests me, but I did enjoy reading the article. I was very disappointed to see the fragility of DX12. I wonder if this is a game issue, a driver issue, or a basic DX12 issue. Thank you for including VRAM usage figures. Fixed, thanks."</post>
   <post id="91e00673-9ed0-45c4-a457-970955c2f552" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"gamerk2 said: ↑ Remember people: DX12 shifts responsibility to the developers, and away from NVIDIA/AMD. This type of problems is both expected and predicted. Click to expand... Definitely, problems to be expected, this doesn t change the fact that game is a piece of shit; if the developer is incapable/unwilling to hire programmers with some experience in low-level programming then they simply shouldn t use DX12, or at least use a DX12 engine built by a dev with the appropriate resources Then again, in this case, even DX11 performance is shameful so IO Interactive really get no absolution *chuckle* for their technical sins Forgive me if I seem bitter, I just really loved the old Hitman games and this is just the nail in the coffin for the series for me. Always online DRM, shitty performance, shameful "dx12 support", looks like a 5 year old game. Basically IO is saying : "wait for a new version with the DRM removed so you can pirate it, game isn t worth the spare change you ve lost in your couch""</post>
   <post id="e8318a64-348d-45e4-a5e8-50f5602f751f" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"Brent_Justice said: ↑ I just came upon this - HITMAN Lead Dev: DX12 Gains Will Take Time, But They re Possible After Ditching DX11 That pretty much backs up my theory I posted in the conclusion R.E. Async Compute. Click to expand... This confused me Why is the 980Ti almost 30% faster in the first graph ? Are these not run at the same settings ? Same with AMD results, something is wrong here"</post>
   <post id="dfcccddc-b73f-4792-a2fa-66f9d4530acc" section="Video Cards" discussion="Hitman 2016 Performance Video Card Review @ [H]">"^ Right, bar graphs are the built-in "Benchmark" run and the average FPS result it provides. The highest playable settings table / graph in DX11 is an actual real-world in-game physical manual run-through as we normally do. Every result that is in bar graph form is from the benchmark. Every result show on page 5 and 6 is a manual run-through using FRAPs, not the benchmark. As I indicated on the first page the benchmark results do not match up to real-world gameplay. The benchmark results are typically a lot higher than actually playing the game. I made sure to point that out in the intro page. Page 3 and 4 - Benchmark data Page 5 and 6 - Manual Fraps Run-through data Page 7 - Manual in-game real-world analysis Page 8 - Benchmark data"</post>
   <post id="633f61e1-ccb4-4f29-a64d-19c419ebeeb3" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Previous installment: AMD Failure rates We re back again, this time April 2015 to October 2015. Cartes graphiques - Les taux de retour des composants (14) - HardWare.fr The numbers: R9 270 2.83% 3.13% R9 270X 0.00% R7 370 R9 280 4.62% 2.25% R9 280X R9 285 3.39% R9 380 2.06% R9 290 8.71% 8.88% R9 290x R9 390 3.60% GeForce GTX 660 0.00% GeForce GTX 760 1.36% GeForce GTX 950 0.54% GeForce GTX 960 1.53% GeForce GTX 970 2.30% GeForce GTX 980 1.71% 3.53% GeForce GTX 980 Ti 3.63% GeForce Titan X Click to expand... AMD: 3.947% avg Nvidia: 1.825% avg Once again, AMD s failure rates top double Nvidia s. Notably, the numbers are down for both brands. A poor showing from the 290 and 290X, which is unsurprising. You can see MASSIVE improvement on Grenada thanks to improved board/cooler designs from the AIBs."</post>
   <post id="ab9e0be5-3b57-4753-b0af-2b29cbce08a4" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Interesting, but I note that most of the sample data that gives AMD a bad rep is made up of Sapphire cards. My experience with Sapphire cards has been disgusting, far worse than indicated by the hardware.fr results, whereas other AMD brands haven t been nearly as bad. I wonder what their failure rates would look like with Sapphire excluded... Also interesting to see Inno3D perform so poorly, and Gainward so well (my Gainward card is a very tacky low quality product)."</post>
   <post id="70286ea4-9381-48f9-b6c1-095f91bd5b77" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"they lack some info there. The 290X shows only 2 listings for failures which inflates their avg greatly, where as the 980Ti has 5 where although still less than the 290X they weren t that far behind for their 2 worst. Also Not sure how anyone can blame AMD or Nvidia when some manufacturers list 0-very small issues (ASUS) to other that have issues across the board (Sapphire and Inno). Maybe they should get definitive info on what failed. Sure a great deal of those are users ocing too heavily or in poorly ventilated cases. I guess it makes it easy to tell which vendors to stay away from: Sapphire, Inno, MSI (debatable)."</post>
   <post id="12fa5fa4-21c3-474e-bf93-92ddf1d0ffa7" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Oh and why is XFX not listed, or is it under another name."</post>
   <post id="91020505-2d24-4660-a5ba-5740ed2d117c" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"hmm how strange. Failure rates at my place are AMD: 0.00% avg. NVidia 80% avg. Statistics = awesome!"</post>
   <post id="2c3a2832-546f-46ef-b948-c48ba9ea8883" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Zuul said: ↑ hmm how strange. Failure rates at my place are AMD: 0.00% avg. NVidia 80% avg. Statistics = awesome! Click to expand... It s based on minimum 500 units sold per GPU. The numbers are also very similar to last year s, which suggests a trend. The mining excuse won t fly this year; AMD has a problem. ~8% failure rate on Hawaii is a travesty."</post>
   <post id="2377a40e-faab-44b8-aa60-b07e27f18067" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Too bad all the EVGA GTX970 s with heat sinks that didn t fit or the 3.5 GB fiasco don t count as failures. Might even out the numbers a little. /fanboyrant Either way, under 4% for either brand is still pretty good. Means you ve got a &gt;96% chance of getting a solid card from either brand. Pretty good odds if ya ask me."</post>
   <post id="4e7c4681-3cb8-45ba-a48b-8629ad0427dc" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"MacLeod said: ↑ Too bad all the EVGA GTX970 s with heat sinks that didn t fit or the 3.5 GB fiasco don t count as failures. Might even out the numbers a little. /fanboyrant Either way, under 4% for either brand is still pretty good. Means you ve got a &gt;96% chance of getting a solid card from either brand. Pretty good odds if ya ask me. Click to expand... AMD s numbers would inflate if the Fury X were included (pump issues)."</post>
   <post id="d1407355-ba35-4128-ab2a-e1cf025908d0" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"better reliability than hdd going by backblaze which seem to be in the 5-30% range other than hitachi which is mostly 1-3% with some models reaching 8% seem to see a lot more gigabyte 290\390 cards go back for rma on au forums than other brands another thing that would contribute to 290 rma rates is the number of them used for mining"</post>
   <post id="15abcb3e-3059-45ec-bf6b-31d6763485a7" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Pretty sure these results only cover the 12 month warranty period rather than lifetime which may explain Backblaze s stats. It also doesn t cover faulty hardware that goes unreported and isn t returned to the retailer, which would inflate all the statistics by a certain amount. My experience would suggest that 2% average motherboard failures &lt;12 months is on the low side, but it d certainly grow sharply from there. I d probably put the industry average in double digits if you went as far as, say, 4 years."</post>
   <post id="27b4944a-5cd6-45c1-9f61-462448ea41e8" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"TaintedSquirrel said: ↑ AMD s numbers would inflate if the Fury X were included (pump issues). Click to expand... Not by much. The EVGA issues were on all their cards and the 3.5 issue was on all 970 s. That ll far outweigh some bad pumps on the Fury X that wasn t that widespread. My fanboy-fu is stronger than yours. I was mostly kidding anyway. I dont think failure rates are a problem with either manufacturer really. Like somebody else posted, its a hell of a lot lower than hard drives and probably motherboards too."</post>
   <post id="ca703b41-7dd8-4d0d-923a-a7b430251862" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Motherboards and graphics cards are the two components I find most likely to be faulty on a new build and I d also say are the most likely demises for older PCs. The average stats assuming all brands equal (which of course they won t be) from the stats posted in that article put them in this order: Motherboards 1.99% Graphics cards 1.91% Power supplies 1.22% Mechanical storage 0.86% Solid state storage 0.65% RAM 0.60% I imagine CPUs don t make the list because they are so rarely returned."</post>
   <post id="d7ab28ad-ac84-4d87-8ec3-fb5d8a1508b5" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Even though I know it kinda pointless to say this here but I haven t had a single AMD product fail that I didn t kill by pushing an OC too hard or by crushing a die..."</post>
   <post id="51d2039a-5a95-468c-b9e0-4e4532f5299f" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Of the 18 AMD cards I ve owned, 4 have been faulty, 3 of which I returned, one I didn t bother. (Two DOA Sapphire 4GB HD5970s, a DOA Sapphire HD3870 and the card I didn t return was an Asus HD3870 which had an odd software issue where it corrupted the OS of any machine it was installed in). I also returned the 290X not because it was definitively faulty but because it was incompatible with my UP3214Q. The Sapphire cards were the more exciting ones, one of the 5970s produced an intense  electronics burning smell  as soon as the PC was powered up, and the HD3870 worked for a couple of days before sparks started coming out of it. I do also have to concede the one working HD3870 was destroyed by having its die crushed trying to fit an Accelero S1 cooler to it, so that made 0 for 3!"</post>
   <post id="f3daf7d5-24d2-401f-8069-75be750f17d4" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Bad drivers, 290x black screens that a vbios update can fix, wake from sleep issues, sapphire s infamous coilwhine are the key ingredients why these are being called failures. XFX had some serious VRM heat issues on the DD with the 290, reference cards are louder than a jet engine. I can go on and on. What AMD needs to do (like Nvidia already does) is set a more strict set of guidelines to what components can be used to build them. I know this sounds stupid but take a look at Nvidia s box art and tell me what Nvidia AIB retail boxes have in common. The same logo branding. AMD would let the AIBs draw smiley faces with marker that s how lenient they are. They need to take a page from Nvidia s book and maybe this new 10 year Nvidia veteran AMD hired will help with that."</post>
   <post id="2c9cab79-5dd7-45b4-850b-f814297d88cc" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"Rvenger said: ↑ I know this sounds stupid but take a look at Nvidia s box art and tell me what Nvidia AIB retail boxes have in common. The same logo branding. AMD would let the AIBs draw smiley faces with marker that s how lenient they are. Click to expand... have you not seen this: What a non Founder s Edition card looks like."</post>
   <post id="38573159-ec8e-4ed3-8e9b-135dfaf5f4f4" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"nvidia gave the green light for them to make the non-founder as shitty looking as possible. XD Wouldn t surprise me if the non-founder edition have loose screws and unplugged fan pin. Haha"</post>
   <post id="469e370e-bb58-4020-a668-ee0d3c0f6374" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"pendragon1 said: ↑ have you not seen this: What a non Founder s Edition card looks like. Click to expand... Look at the box though. "Geforce GTX 1080" branding, you will see that exact same graphic/font on every single nvidia AIB box since Kepler. Consistency. The Galax cooler was just like MSI s stripped down cooler for the GTX 980ti but without cheesy stickers. MSI GeForce GTX 980TI 6GD5 V1 - Newegg.com EDIT: OK, MSI s looks a little better."</post>
   <post id="ffbe64c6-3e59-485d-9a20-4dcad97db9ab" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"As others have pointed out I have a feeling the high failure rate on the 290s in particular was because they were used for mining. Running a card 100% 24/7 is bound to cause more failures than a card that sits idle most of the time. It s anecdotal but I ve had one graphics card ever that failed within 1-2 years, and that was the one card I did folding on (running it 100% 24/7). That could just be a coincidence but it was enough that I won t ever do any GPU folding/distributed computing again. Meanwhile all my cards that I didn t fold on tend to last 5+ years (in secondary PCs, given to family members, etc). My old X850XT (AGP) is still running in someones PC and I bought that card more than 10 years ago."</post>
   <post id="cef2dcb1-3667-43ad-a4dc-eb6056eca874" section="Video Cards" discussion="AMD s Failure Rates, Part Two (2015 Edition)">"been using AMD for 20 years and I have had only 1 card fail during that time. Those statistics cannot even be remotely close to accurate as they don t differentiate between the GPU and the rest of the more crap components used to put it together."</post>
   <post id="5bfc2d44-0041-43f7-a2ed-98fd681f34cb" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"NVIDIA GeForce GTX 1080 Official Slides Leaked - Async Compute, SMTP VR Processing, Higher Efficiency and More Detailed"</post>
   <post id="c7298b13-1a00-4f7d-9f1f-40569d608d9a" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Overclocking headroom on the 1080 looks to be massive, if that report is to be believed. over 2ghz with a water block."</post>
   <post id="d9b9aa0f-827f-41be-91d9-ebcf233c5785" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"harmattan said: ↑ Overclocking headroom on the 1080 looks to be massive, if that report is to be believed. over 2ghz with a water block. Click to expand... depends on how far past 2 GHz it goes. it needs to hit at least 2100 MHz to overclock as well as a 980 Ti (+25%)."</post>
   <post id="0b047c98-e727-4cbd-bc96-20c3c726abcf" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"If it hits 2 ghz at all it seems would pretty be impressive. We ll see."</post>
   <post id="ac17fbc3-2b1a-4cd8-9501-5ff06abf82b4" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Tell me more about this GP100 and getting it in my puter."</post>
   <post id="ce4539be-5190-4fc9-bc90-0830560bd81b" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"I m shocked they changed the SM configuration... If each SM has double the amount of SPs as gp100... Then the number of registers per sm is exactly the fucking same as maxwell hahaha"</post>
   <post id="4c0aaa38-8270-4f52-ae89-8b197a587f27" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"MongGrel said: ↑ If it hits 2 ghz at all it seems would pretty be impressive. We ll see. Click to expand... Weren t they running at 2.1 GHz on the stock cooler in the public demo?"</post>
   <post id="1343de66-f9b9-4dd8-8e95-4a809e58a1a6" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Yep they were, pretty sure this card will be able to do more than 2ghz on water, if you can deliver enough power to it."</post>
   <post id="680ed861-854c-416c-9a69-2edea013eacf" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"razor1 said: ↑ Yep they were, pretty sure this card will be able to do more than 2ghz on water, if you can deliver enough power to it. Click to expand... Exactly 1 8pin isn t enough if you want to hit 2.5ghz which some people claim. Bring on the MSI Lightning card!"</post>
   <post id="261bc0a4-89c3-4829-9172-08d464e3be78" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Hhhgghbbbb I think this is how it will work. Pascal SM s still cannot do graphics + compute concurrently because of the expensive context switch. The solution is to partition the GPC (so at the level of single SMs) to do graphics + compute. The problem with maxwell is that the SM partitioning (afaik) could only be altered at each drawcall, whereas with Pascal s pixel, Triangle and instruction level preemption the repartitioning can be done with finer granularity. I expect this to work on maxwell as well, but there will need to be careful profiling to avoid pipeline stalls gs Also anyone notice how the witcher 3 is featured on their async compute slide?"</post>
   <post id="d2fbd311-84b2-4b6c-a040-8b2a46d422ea" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"64 rops.. what a disappointment."</post>
   <post id="b9793b5e-06e3-45c4-aee0-f7d15a092a94" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Byle_Kennett said: ↑ 64 rops.. what a disappointment. Click to expand... 64 pixels per clock 2000mhz"</post>
   <post id="4d18e45e-111b-49a1-b5f8-798a2077816c" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"What s the 980 TIs?"</post>
   <post id="681e7514-9cfb-4fdc-98de-f1a78a19c466" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Byle_Kennett said: ↑ What s the 980 TIs? Click to expand... 96"</post>
   <post id="0033d618-6d5b-4c91-b150-68cefb92f225" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Ieldra said: ↑ 96 Click to expand... Yeah but coulda been 96 pixels per clock... at 2000 mhz."</post>
   <post id="867709db-0df4-4ebd-8494-8fb45db219c0" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Byle_Kennett said: ↑ Yeah but coulda been 96 pixels per clock... at 2000 mhz. Click to expand... That would require increasing the rop:bus-width ratio which they already did with maxwell This will be fine man, it s memory bandwidth that is the question mark"</post>
   <post id="3f4bec05-42cf-46af-b4a5-655b21c09e0b" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Ieldra said: ↑ Hhhgghbbbb I think this is how it will work. Pascal SM s still cannot do graphics + compute concurrently because of the expensive context switch. The solution is to partition the GPC (so at the level of single SMs) to do graphics + compute. The problem with maxwell is that the SM partitioning (afaik) could only be altered at each drawcall, whereas with Pascal s pixel, Triangle and instruction level preemption the repartitioning can be done with finer granularity. I expect this to work on maxwell as well, but there will need to be careful profiling to avoid pipeline stalls gs Also anyone notice how the witcher 3 is featured on their async compute slide? Click to expand... Pascal s SM s can now do both compute and graphics kernels, at the same time its in the slides, this was not doable with Maxwell, as a whole you can have different queues on different SM s, but trying to force one SM on Maxwell to do both, you end up with major under utilization of the ALU s if the scheduler predicts incorrectly, hence the performance penalties when doing heavy compute tasks, as the graphics queue would have to wait."</post>
   <post id="5a3e91ab-3173-4efc-9662-f7d7040e6112" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"razor1 said: ↑ Pascal s SM s can now do both compute and graphics kernels, at the same time its in the slides, this was not doable with Maxwell, as a whole you can have different queues on different SM s, but trying to force one SM on Maxwell to do both, you end up with major under utilization of the ALU s if the scheduler predicts incorrectly, hence the performance penalties when doing heavy compute tasks, as the graphics queue would have to wait. Click to expand... Can you link to the specific slide? I didn t see anything to this effect This suggests the context switch penalty has been reduced"</post>
   <post id="4dff71d7-19f2-4dd6-a7c2-ca7d0f020ef1" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Ieldra said: ↑ That would require increasing the rop:bus-width ratio which they already did with maxwell This will be fine man, it s memory bandwidth that is the question mark Click to expand..."</post>
   <post id="e74f2a60-4cde-468c-81db-49c8ab9c1f7c" section="Video Cards" discussion="GTX 1080 NVIDIA presentation leaked">"Ieldra said: ↑ Can you link to the specific slide? I didn t see anything to this effect Click to expand... Well check the dynamic load slides. There is more.... just hasn t been leaked yet."</post>
   <post id="001cd27c-50d1-4444-b4f0-06a7631e4a4a" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"I m almost certainly going to get a 1080 as an upgrade to my 280x...but I m also planning on grabbing Doom. I m still deep in Fallout 4, so no real hurry. Anyone willing to speculate on whether or not their could be a GTX 1080/Doom bundle in a month or so?"</post>
   <post id="bf5945a7-87bb-4dea-800c-6be5b41e0acd" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"Sure, it might happen. Or they might release the card with no bundled game. Or they will do another bundle with Tomb Raider."</post>
   <post id="385264c1-460b-4ce9-a0bd-1e569b59f05c" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"I wouldn t expect a game bundle until end of August at the earliest. Sep - Oct is more likely. Reason being, demand is always incredibly high during the few few months of a GPU launch, they don t need extra incentives during that time to move stock."</post>
   <post id="293453e2-0e67-4016-a088-1f4d3026c734" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"Considering ID keeps flashing 1080 benchmarks, I d say it s highly likely. How soon, hard to say.... (Bound to be at least a month after release)"</post>
   <post id="abb04068-3daa-49b6-94d1-bd67ee32bf91" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"Don t know about DOOM and the 1080, but there s rumour there could be an AMD Vega + Battlefield 1 bundle, coinciding with the rumour that AMD has move Vega s release to October."</post>
   <post id="c69b02c9-e7db-4ed7-8a6c-be506076be09" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"x3sphere said: ↑ I wouldn t expect a game bundle until end of August at the earliest. Sep - Oct is more likely. Reason being, demand is always incredibly high during the few few months of a GPU launch, they don t need extra incentives during that time to move stock. Click to expand... Exactly right. Typically no bundles to start."</post>
   <post id="d212b2cf-f502-4622-bf1e-ea42f864b7d6" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"cdkeys.com has doom ~$35-$40 if that helps any?"</post>
   <post id="849d265e-59fa-45b2-97a8-86fdf107c631" section="Video Cards" discussion="What are the chances of a GTX1080/Doom bundle?">"Perhaps,i wouldn t be surprised. Seems like a natural fit."</post>
   <post id="801fb3b1-bd62-441a-ac4b-e2ceec089b9d" section="Video Cards" discussion="DOOM (2016) first benchmark review">"Doom (final) im Benchmark-Test: Schaurig-schöner Splatterspaß - Benchmark-Ticker läuft http://i.imgur.com/KMPOzaa.png"</post>
   <post id="7d16f69b-fc53-479d-8e67-9d170c946e0f" section="Video Cards" discussion="DOOM (2016) first benchmark review">"Hmm... looks like maybe a 1080 could get 50-60 fps at 4K. I guess at 4K you can dial back AA a bit."</post>
   <post id="73fea118-6586-4846-b4f6-9678b42a0ee7" section="Video Cards" discussion="DOOM (2016) first benchmark review">"R9 390 performing worse than a R9 380x? Something is clearly wrong with that."</post>
   <post id="9a87182c-7238-496c-8e3b-84717cd621fb" section="Video Cards" discussion="DOOM (2016) first benchmark review">"exlink said: ↑ R9 390 performing worse than a R9 380x? Something is clearly wrong with that. Click to expand... It s OpenGL. What do you expect from AMD?"</post>
   <post id="7911bfcc-7075-4ff0-99d2-33d5d7e1c8ac" section="Video Cards" discussion="DOOM (2016) first benchmark review">"exlink said: ↑ R9 390 performing worse than a R9 380x? Something is clearly wrong with that. Click to expand... all the GCN1.1 cards are doing badly, GCN 1.2 does much better maybe geometry limited ?"</post>
   <post id="63615611-5425-4a5b-9a77-a698f0bd37ac" section="Video Cards" discussion="DOOM (2016) first benchmark review">"That is what it looks like its only at lower resolutions where GCN1.1 cards have issues, so pixel shader and compute shaders are becoming more of a bottleneck as the res increases."</post>
   <post id="ca0e0205-8ec2-4bae-8719-c2a1c5113ba5" section="Video Cards" discussion="DOOM (2016) first benchmark review">"Is there a Timedemo one can benchmark with in Doom?"</post>
   <post id="11976cc4-c734-4bc8-b1d9-396c3d2e8ff9" section="Video Cards" discussion="DOOM (2016) first benchmark review">"not sure haven t bought it yet, only going to buy it after the single player reviews are out lol."</post>
   <post id="a08041d1-8a28-46e3-8398-9f447a86fa4c" section="Video Cards" discussion="DOOM (2016) first benchmark review">"razor1 said: ↑ That is what it looks like its only at lower resolutions where GCN1.1 cards have issues, so pixel shader and compute shaders are becoming more of a bottleneck as the res increases. Click to expand... it seems like a bug now, lots of people tested with tesselation off in drivers and it makes no difference, maybe raw polythroughput ? but difference shouldn t be as pronounced (between Fury and Hawaii for example) as it is in this benchmark razor1 said: ↑ not sure haven t bought it yet, only going to buy it after the single player reviews are out lol. Click to expand... same haha, but everyone i know is saying SP is great"</post>
   <post id="c9ec58d5-457c-4c24-8ed6-a46d40e5bc4a" section="Video Cards" discussion="DOOM (2016) first benchmark review">"razor1 said: ↑ That is what it looks like its only at lower resolutions where GCN1.1 cards have issues, so pixel shader and compute shaders are becoming more of a bottleneck as the res increases. Click to expand... I was thinking the settings used TSSAA 8TX favored the nvidia cards? Cause my goodness I had hardly a problem playing the multiplayer around 75fps at 1440p...This chart is showing 33fps lol yea ok. No way this game will be any harder performance wise to run than the last few Wolf Games"</post>
   <post id="b7d04d47-f858-4160-bf4d-a63b72cd85d7" section="Video Cards" discussion="DOOM (2016) first benchmark review">"razor1 said: ↑ not sure haven t bought it yet, only going to buy it after the single player reviews are out lol. Click to expand... Me too primetime said: ↑ I was thinking the settings used TSSAA 8TX favored the nvidia cards? Cause my goodness I had hardly a problem playing the multiplayer around 75fps at 1440p...This chart is showing 33fps lol yea ok Click to expand... In the beta?"</post>
   <post id="d5705c75-ec69-46bf-a235-54bfb42d1709" section="Video Cards" discussion="DOOM (2016) first benchmark review">"Ieldra said: ↑ Me too In the beta? Click to expand... yes....what else? lol I see now it had a frame cap at 60 so it was that instead.....I know i remembered it not having much issues running near max frame cap"</post>
   <post id="35dd36e1-b43f-491e-b83c-88b35eec3e5d" section="Video Cards" discussion="DOOM (2016) first benchmark review">"primetime said: ↑ yes....what else? lol I see now it had a frame cap at 60 so it was that instead.....I know i remembered it not having much issues running near max frame cap Click to expand... The beta was running at unknown settings, this is at max settings"</post>
   <post id="11397502-c460-4fd7-beca-5e9743766f4a" section="Video Cards" discussion="DOOM (2016) first benchmark review">"WOW 670 takes a Big Drop"</post>
   <post id="cd70d8fc-64ee-431e-945d-db1f6b5e976e" section="Video Cards" discussion="DOOM (2016) first benchmark review">"So one real-world game performance result we have for 1080 albeit still just summary info goes back to the announcement last week. They showed Doom obviously using beta drivers with Vulkan and the game on absolute top settings (nightmare) running between 130fps to a brief peak near 190fps. pcgameshardware has done a recent review of Doom and the results are interesting even at 1920x1080 (which was the presentations setting as well); they used the setting below nightmare so less shadow detail. In their test an AIB 980ti Palit Super Jetstream had a minimum 125 and average 158.7 - See OP chart, thanks Ieldra. So that is a surprising result, OK the 1080 was using Vulkan but considering the optimisation benefits are yet to translate to healthy boost in DX12 for NVIDIA this still looks impressive (or at least Vulkan is working better than DX12 lol), especially as the 1080FE was on the very top setting and the 980ti was a notch below and also 1080FE on beta drivers. Fingers crossed pcgameshardware will repeat their test once the Vulkan patch is rolled out for a better comparison. But looks like it should raise some eyebrows regarding initial real-world result for Founders Edition 1080, anyway better information IMO than any supposed "leaked" results popping up on the internet. Cheers"</post>
   <post id="1c51a808-d44e-4252-8ecd-112dc521b68f" section="Video Cards" discussion="DOOM (2016) first benchmark review">"R9 Fury X trading blows with the GTX 980. Whoa, this definitely seems off."</post>
   <post id="b47b81df-c6f3-455b-a12a-cc92fef75104" section="Video Cards" discussion="DOOM (2016) first benchmark review">"UnimatrixZero said: ↑ R9 Fury X trading blows with the GTX 980. Whoa, this definitely seems off. Click to expand... Something probably with the AMD drivers, more of a concern with AMD is just how low the 390 is..... It is below the much cheaper 380x and also around the 960. Also to say regarding 1080/980ti. Bear in mind the average is probably anywhere between 135-148fps for the 1080FE on nightmare setting against 158 for the AIB 980ti on ultra shadows. BUT and this is important, the max nightmare settings do hit the GPUs hard; according to the review need over 6GB VRAM to use them. In the review link provided by Ielda, they showed a quick and dirty comparison between nightmare and ultra; Ultra shadows was 76fps and nightmare was 56fps. Full-HD Klickvergleich"</post>
   <post id="ff7fb50f-6111-43da-9e4d-582260f5a828" section="Video Cards" discussion="DOOM (2016) first benchmark review">"UnimatrixZero said: ↑ R9 Fury X trading blows with the GTX 980. Whoa, this definitely seems off. Click to expand... lol i bet money we dont see these results when [H] tests lol"</post>
   <post id="aaa58a4f-b0b4-499f-8ac5-afca1d88c217" section="Video Cards" discussion="DOOM (2016) first benchmark review">"CSI_PC said: ↑ Something probably with the AMD drivers, more of a concern with AMD is just how low the 390 is..... It is below the much cheaper 380x and also around the 960. Also to say regarding 1080/980ti. Bear in mind the average is probably anywhere between 135-148fps for the 1080FE on nightmare setting against 158 for the AIB 980ti on ultra. BUT and this is important, the max nightmare settings do hit the GPUs hard; according to the review need over 6GB VRAM to set them. In the review link provided by Ielda, they showed a quick and dirty comparison between nightmare and ultra; Ultra was 76fps and nightmare was 56fps. Full-HD Klickvergleich Click to expand... This is actually nightmare settings with ultra shadows essentially, who knows when the vulkan version will launch, afaik its just a vulkan wrapper"</post>
   <post id="3bb21948-4c29-4043-922c-4d841280f028" section="Video Cards" discussion="DOOM (2016) first benchmark review">"Ieldra said: ↑ This is actually nightmare settings with ultra shadows essentially, who knows when the vulkan version will launch, afaik its just a vulkan wrapper Click to expand... Yeah, which is why it nearly is ok to compare with the 1080FE, and at least they showed how much of a hit they experience setting Nightmare shadows (link I provided opens that up shows it to be a fair chunk). I assume they did not benchmark with Nightmare setting also for Shadows due to needing 6GB, which is only supported by a few cards on their list. Cheers"</post>
   <post id="542bca1c-4975-4d30-87b6-763bf29add21" section="Video Cards" discussion="Windows stated resolution doesn t match displayed resolution? Wha?">"I m on a laptop with a native resolution of 1440x900. That s also what Windows shows but it doesn t look right to me. I install Powerstrip. That what it shows I m running. BUT... It doesn t look right to me. So I checked it online, and it shows 1152x720 (res, not window : ) This is true with current Chrome, FF, and IE. Hmm. My zoom is set a flat 100%. - I open up Paint and set a new image to 1280 width. Huh. It fits. - I open up an image that s 1280 width online. WTF? It doesn t fit. ???"</post>
   <post id="3d2012d8-3427-40af-ba1c-bfeeeed20a37" section="Video Cards" discussion="Windows stated resolution doesn t match displayed resolution? Wha?">"Time to get a laptop that isn t trash? More seriously, find a newer / different version video driver. Something is clearly wrong."</post>
   <post id="d10d26ba-4681-4d14-84c4-5697e8ea5f1f" section="Video Cards" discussion="Windows stated resolution doesn t match displayed resolution? Wha?">"True words SC. True words. ...but it s paid for and works. That makes it a perfect Netflix/email/browsing machine for the family... made even better if I can figure out what the heck is up with the resolution. So maybe delete the current driver/display and see what happens upon a restart? I can t wipe it and go with a better OS for about a month, so nobody dies if I can t sort this, it s just the first time I ve seen something as weird as this with video. Not showing the right res is one thing. Showing it s running the right res but displaying something else (most of the time anyway) is something else. Must NSAware. That s what it is."</post>
   <post id="a8306b1e-8d8c-410c-8ffe-6d69d9cc7d5b" section="Video Cards" discussion="Windows stated resolution doesn t match displayed resolution? Wha?">"Yeah, go in to device manager, uninstall and delete driver, reboot, try to find the newest version of the driver (this Intel / AMD integrated or discrete?) and go from there."</post>
   <post id="d9c04dab-3b90-46ee-9c2d-a7732a248701" section="Video Cards" discussion="Windows stated resolution doesn t match displayed resolution? Wha?">"What was wrong? *shrugs* Deleted the display and video device and now it works great. ...so really, do I care what was wrong anymore? No. No I do not. Thanks. A mighty 1440x900 is mine once more."</post>
   <post id="4efd8cb9-9761-498b-b58f-b0280306cd3c" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Myself and a bunch of my buddies all built rigs at the same time; 2011 when the i7-2600K was all the rage. The PC has been solid since then. The specs are in the sig but other than maybe some more Ram, it s held up with everything... After getting married, buying a house, having a kid...I transitioned from PC gaming to console gaming just due to cost. However, with some newer titles coming out (Doom, BF1, etc) I m contemplating on what it would take to get back in the game on the PC end. With that said, I have: i7-2600K @ 4.2 Asus P8P67-Pro 8GB Ram 256GB Samsung Pro SSD 750W PCP&amp;C PSU (way back in the day!) If I was to buy a card such as the GTX 970 or GTX 1070 when released...how much am I bottlenecking it due to the CPU? I currently game at 1080p. No desire for 4k anytime soon...maybe a new monitor at 1440p but that would be a while... Thanks!"</post>
   <post id="4d8ca163-6547-4f1a-869d-b243c4fc6a72" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"I would think you would be fine. My 2500k@4.2 with a 980ti played the doom beta at 60fps+ at 1440p."</post>
   <post id="4e4acfb6-26b0-4bf7-b039-a9216b7f5c66" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"you ll be fine. go for it"</post>
   <post id="7311e603-dee6-4cd0-a741-4a8adadb5e64" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"2600k? That s a Sandy Bridge CPU, most likely running on a P67 or Z67 chipset. Well, I d say the CPU is fine, but the P67/Z67 chipset is showing its age. I think you ll be fine with a single card, but if you want to run SLI, I d upgrade for PCI-E 3.0. Running a card at PCI-E 2.0 x16 is like running one at PCI-E 3.0 x8... which is roughly the performance hit people take from SLI, barely enough to hurt the card s performance. But SLI would be a bad idea because then you re cutting that in half again. Here s my little reference/cheat sheet... Yorkfield/Core 2 Extreme -- You re really pushing it. Upgrade soon. Gulftown/Core i? 9xx (1st gen) -- You re kind of pushing it. Upgrade when you have about $800. Sandy Bridge/Core i? 2xxx (2nd gen) -- The CPU is fine, but the P67/Z68 chipset is showing its age. Ivy Bridge/Core i? 3xxx (3rd gen) -- You re probably okay, although that could change any year now. Haswell/Core i? 4xxx (4th gen) -- You re definitely okay, this processor is being used by OEMs in new computers. Broadwell/Core i? 5xxx (5th gen) -- You re ahead of the curve, this is a fairly new architecture. Skylake/Core i? 6xxx (6th gen) -- This is the newest architecture, and it will be until later this year."</post>
   <post id="52f7b54a-0356-44e3-856d-35fe6aa62e0f" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"As someone running 980Ti SLI with a 2500K i5 at 4.5Ghz, you ll be fine. My numbers are usually within 1-2FPS of reviews with much newer PCIe 3.0 capable chips/boards, often even X99 setups with full 16x/16x PCIe 3.0. I ve considered picking up a newer chip to enable PCIe 3.0, or selling the board/ram/CPU combo and going Skylake or X99, but it s just not worth the hassle and expense involved to gain 1-2FPS. Now, to be clear, are there some titles where it would make a bigger difference? Yeah, as I understand GTA V would thrash my system if I started turning things way up... but I don t play it and have no desire to. So it s really down to what you want to do."</post>
   <post id="4fa31bb3-999a-486d-9bae-cbfa549e9315" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Only difference I noticed was my min fps. I went from 2500k to 6700k. Before it would drop to low mid 20s...now it doesn t drop below 60."</post>
   <post id="b6fc2ee6-a4f7-464d-bb69-f50a218b2c57" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"athenian200 said: ↑ 2600k? That s a Sandy Bridge CPU, most likely running on a P67 or Z67 chipset. Well, I d say the CPU is fine, but the P67/Z67 chipset is showing its age. I think you ll be fine with a single card, but if you want to run SLI, I d upgrade for PCI-E 3.0. Running a card at PCI-E 2.0 x16 is like running one at PCI-E 3.0 x8... which is roughly the performance hit people take from SLI, barely enough to hurt the card s performance. But SLI would be a bad idea because then you re cutting that in half again. Here s my little reference/cheat sheet... Yorkfield/Core 2 Extreme -- You re really pushing it. Upgrade soon. Gulftown/Core i? 9xx (1st gen) -- You re kind of pushing it. Upgrade when you have about $800. Sandy Bridge/Core i? 2xxx (2nd gen) -- The CPU is fine, but the P67/Z67 chipset is showing its age. Ivy Bridge/Core i? 3xxx (3rd gen) -- You re probably okay, although that could change any year now. Haswell/Core i? 4xxx (4th gen) -- You re definitely okay, this processor is being used by OEMs in new computers. Broadwell/Core i? 5xxx (5th gen) -- You re ahead of the curve, this is a fairly new architecture. Skylake/Core i? 6xxx (6th gen) -- This is the newest architecture, and it will be until later this year. Click to expand... So you are recommending a new system for 5 maybe 10% increase in performance? really? OP you are just fine about the only thing I d do is getting 16gb of ram and that s about it."</post>
   <post id="23182a3e-1c8e-4906-b592-acbf9e9f9fed" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Stoly said: ↑ So you are recommending a new system for 5 maybe 10% increase in performance? really? Click to expand... No, I actually said he shouldn t upgrade if he s only running a single card. And the CPU isn t the issue, it s the PCI-E 2.0 thing, which is only a big deal if you re running SLI. I said that Sandy Bridge is fine if you re NOT running SLI, and the OP seems to be saying that he isn t. So that means he doesn t need to upgrade."</post>
   <post id="020ec81f-94bc-44bb-a856-44955c731553" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"...and I m saying, as someone who s actually running SLI on a Sandy Bridge system, that it s fine for that too 90% of the time. I m still getting 60+ FPS in The Witcher 3 and Rise of the Tomb Raider at 3440x1440 with everything but motion blur (cause I hate it) on."</post>
   <post id="01dcbe96-2590-4b84-855d-11712375a555" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"athenian200 said: ↑ No, I actually said he shouldn t upgrade if he s only running a single card. And the CPU isn t the issue, it s the PCI-E 2.0 thing, which is only a big deal if you re running SLI. I said that Sandy Bridge is fine if you re NOT running SLI, and the OP seems to be saying that he isn t. So that means he doesn t need to upgrade. Click to expand... Even if he was going SLI, he wouldn t need to upgrade."</post>
   <post id="2fc53bd6-62f7-4ac5-ad3a-f416b73b4c26" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Op, a clocked 2600K is still a great chip. If you want minimum fps to be 60fps in all games, upgrade. If you dont care that your fps drops a bit, keep what you have. I upgraded from a 2500K to a 6600K because Project Cars was jerky when it dropped below 60fps due to being CPU limited. This was an extreme case. If you dont suffer in this manner dont upgrade. You might as well get the new gfx card and see how you get on. No point in jumping the gun."</post>
   <post id="3326fe33-cc65-47ae-ab3d-e8e37037c201" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"There is a video on Youtube showing crysis 3 on a 387989734k or whatever the later quad cores were after our 2600k and a 5920 or 5930k. Sorry I can t find it or i d link it. The 59X0 has easy 12-15fps lead in almost every scene, especially busy ones. So no, our 2600ks are not enough for a modern 1440p or up game to be absolutely maxed out, even when heavily clocked, when using the absolute top of the range GPU(s). But that said, is 10-15FPS worth a 1-2k upgrade? I d wait for the new high end GPUs from both sides either mid or Q1 next year and jump then if you can t budget to just do it anyway now. As you ll then have the latest Intel xyzsuperduper storage solid state stuff compatible with the systems, which I think will be a huge boost if it s so tied to the CPU.. it s like a huge ram pool almost. Games out of ramdrives are amazing.. there is no comparison, so doing that for everything, would be wicked! disclaimer- 4 hours sleep."</post>
   <post id="e3d8062c-bc66-461f-badb-a63a9124188d" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"I suspect games going forward (dx12) will use that older cpu just fine. Get one of those new cards coming next month and your set"</post>
   <post id="130a399f-dd9d-49ff-a415-e371ff0d42b6" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Digital Foundry recently investigated this and you definitely would see an improvement going from OC sandy bridge to even non-OC skylake with a modern GPU. Interestingly, RAM speed matters too-- "common knowledge" was that it didn t. There is a bottleneck at the extreme high-end. Is it finally time to upgrade your Core i5 2500K? This is the article that finally convinced me to upgrade my positively ancient i920 a couple months ago."</post>
   <post id="7cdaf619-2fdf-4207-8695-01d54ff03171" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"Stoly said: ↑ Even if he was going SLI, he wouldn t need to upgrade. Click to expand... I don t agree that PCI-E 2.0 is good enough for running modern graphics cards in SLI, but I guess we ll just have to disagree on that one."</post>
   <post id="d9470be5-cd2b-40e8-802d-cc57c6b1dde6" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"A wealth of info here, thanks guys! Definitely not into SLI. I always only run one card...so that s no issue. I may look to budget out an upgrade...thanks all!"</post>
   <post id="4f494aa6-12f9-482e-9ed9-8e931fc6a203" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"This is a good question. If it were just about CPU only and if I would upgrade the RAM to fastest and lowest latency DDR3 there is, which I am going to at some point, I could put my 2500K @ 4.8ghz (24/7 clocks, no turbo) against any i5 Skylake and it would not be badly left behind, in a ways that would matter anyway. But being limited to PCIe 2.0 is a problem. People have noticed it bottlenecking slightly with current high end cards when they SLI them. Considering how fast Nvidia claims GTX 1080 to be we might see it bottlenecking in single card solutions too. Unless AMD pulls a miracle with Polaris (which I actually hope, I want to go back to Team Red for a change) I AM going to buy 1080 at the end of this year. A little bottleneck wont worry me, the performance jump from my good old GTX 770 should be massive either way."</post>
   <post id="c9722a90-148d-4b48-b5d1-b14432e3b275" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"60 fps you will have no issues, 120 fps or higher you will be bottlenecked in newer games."</post>
   <post id="e1d170f7-bd6f-488d-a171-dcad0e55b875" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"schizo said: ↑ Digital Foundry recently investigated this and you definitely would see an improvement going from OC sandy bridge to even non-OC skylake with a modern GPU. Interestingly, RAM speed matters too-- "common knowledge" was that it didn t. There is a bottleneck at the extreme high-end. Is it finally time to upgrade your Core i5 2500K? This is the article that finally convinced me to upgrade my positively ancient i920 a couple months ago. Click to expand... That article brought up an interesting alternative. Sandy Bridge is starting to show its age there is no question but i7 3770K Ivy Bridge does not, not yet atleast. As far as CPU dependent situations go it keeps up with Skylake remarkably well when overclocked. Now, Ivy may be notoriously worse overclocker than Sandy was but despite that it is still newer and faster CPU and it is a simple drop-in replacement. You will still have to deal with PCIe 2.0 limitations though."</post>
   <post id="fc308fa9-e9d5-4185-825e-aa5c175f8e35" section="Video Cards" discussion="How much is the i7-2600K holding me back?">"jnick said: ↑ A wealther of info here, thanks guys! Definitely not into SLI. I always only run one card...so that s no issue. I may look to budget out an upgrade...thanks all! Click to expand... Well, then I wouldn t worry about upgrading just yet. I mean, you might have to upgrade in 2018 when Volta comes out, but I wouldn t get in a rush. There s at least a good 2 or 3 years left in Sandy Bridge, maybe more. Especially with an i7, those are aging better than the i5s."</post>
   <post id="615a4c2a-347c-4c01-862c-bc87854e8a3c" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"Sold my Asus ROG w/880m few months back and been using one of my extra s for work , as wanted to get a new replacement. I ve got a desktop gaming system , but as an engineer who also teaches Cisco/Networking classes a couple nights a week , there s often time for gaming while at work at various times so I ve always liked having the option. I noticed there was zero mentioned about mobile Pascal at the recent conference , and wondered if anyone has heard any rumors at all when it might be released ? Have seen some 980m laptops dropping in price a bit and tempted to pull the trigger on one if it looks like its going to be a good ways off."</post>
   <post id="64f3a59f-cf68-47ad-b14a-13b1b6851e68" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"I d imagine big updates are coming soon. Much lower wattage for either equal perf or more."</post>
   <post id="9d90a6c5-6db1-4137-8cfa-b93d4ad6ca83" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"No word other than the AMD rebrands. Computex should have the new stuff."</post>
   <post id="0f1791c4-3e1b-4fe5-902f-28b3089f937a" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"Dahkoht said: ↑ Sold my Asus ROG w/880m few months back and been using one of my extra s for work , as wanted to get a new replacement. I ve got a desktop gaming system , but as an engineer who also teaches Cisco/Networking classes a couple nights a week , there s often time for gaming while at work at various times so I ve always liked having the option. I noticed there was zero mentioned about mobile Pascal at the recent conference , and wondered if anyone has heard any rumors at all when it might be released ? Have seen some 980m laptops dropping in price a bit and tempted to pull the trigger on one if it looks like its going to be a good ways off. Click to expand... I don t think any new mobile GPU will be significantly faster than the desktop 980 MXM versions, at least in the beginning. They ll probably release the mainstream mobile GPUs first which will be at best as powerful as a 980M (guesstimate), which is still way short of the desktop 980. If you have the cash to splash you can always get the SKU with 980 SLI from MSI, lol. That ll blow away any upcoming mobile GPU for a while yet. One caveat to think about is that the new mobile GPUs will be very power efficient, so you can probably have 3-4 hours of 980M performance on a modest 15" instead of the monster 17/18 inchers."</post>
   <post id="97ab68d4-d53b-4f26-80e9-2d3c14561898" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"I think you can expect Polaris varients incoming in June or July. Rumors vary, but there will likely be a P11 (mid-range; x470m, x480m) and P10 (high-end; x490m) cards. There will also be an m485x bit that s hardly worth mentioning since it s just a refreshed m285x/m385x. Just guessing, but you re probably looking at desktop 390 performance in the m490x which is quite a step up from your 880m. As for nV, there will surely be a Pascal refresh. I m guessing the top end will be a cut-down 1070. Let s call that GTX1080m As usual, nV top end mobile card will likely out class AMD s, but will be a good deal pricier."</post>
   <post id="0a11242b-d4d5-48bc-8539-1f46abe4d1a9" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"There is a little bit of information for the M400 series on AMD s wesite: AMD Radeon™ R9 Series Graphics Click the M400 Series Specs tab. Model | Compute Units | RAM | Mem type | clock speed | memory-interface R9 M485X | 32 | 8 GB | GDDR5 | 1250 Mhz | 256 bit R9 M470X | 14 | 4 GB| GDDR5 | 1500 Mhz | 128 bit R9 M470 | 12 | 4 GB | GDDR5 | 1500 Mhz | 128 bit"</post>
   <post id="55e5dd7f-6644-4752-80aa-d9d288016d82" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"Only as above. Wait till next month, AMD mayyy have something out at computex for mobile but I doubt it."</post>
   <post id="bc7b5d47-b264-4bf2-b954-edb757399e21" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"Any of you guys think that there will be a 1070 Mini in the market by third parties? Kind of like the 970 minis?"</post>
   <post id="f32f4a6e-b27c-4c9b-a38e-eab765e4020c" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"Appreciate the info and advice. I keep up usually on the desktop side of things , and moderately on the laptop side just seemed like a bit of confusion on the AMD upcoming with rebadges just released and so on. Not really stressed about the weight/power issue , as I ve got some crappy leftover laptops to use in a phone closet hooked up during cuts or whatever , but am thinking about instead of waiting for Pascal mobile keeping eyes out for a sale on one with a 980m or something. Will be sticking at 1080p (desktop is 4k) , so thinking the 980m would hold out for a while at least."</post>
   <post id="a0ea205b-f1e4-4573-a5cb-6beca37ec463" section="Video Cards" discussion="Any concrete news on mobile GPUS incoming ?">"HopkinsTea said: ↑ Any of you guys think that there will be a 1070 Mini in the market by third parties? Kind of like the 970 minis? Click to expand... The 1080 draws 180W, so 1070 probably draws 160W or less. Basically identical TDP to the 970 so it shouldn t be a problem. However, the thing is that PCBs have to be redesigned to meet the more strict power delivery requirements of Pascal, so it might be a while yet."</post>
   <post id="ea96a9ec-1a22-4763-be7d-832f063d26f4" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"Hi, From what I recall the gtx 780ti was the equivalent to the gtx 980ti when it came out in terms of being "top of the line". However, when the gtx 900 series came out, specifically the gtx 970, the gtx 780ti lost its value quickly after to a much cheaper card ( the gtx 970), that would trade blows with the 780ti while being cooler and using less performance. What are the chances of this scenario playing out again between the gtx 980ti and the gtxs 1070? I currently own a 980ti, but I would be happy to sell it before its value goes down, get a gtx 1070, and have some money left over. Can anyone with some experience in the field, and that has been following the trend answer this question? Thanks!"</post>
   <post id="46ca8dcd-3e23-4288-b251-a6cb8ee63940" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"I m pretty sure we can expect stock 980 Ti performance from the 1070, Overclocked comparisons are still up in the air."</post>
   <post id="487a3819-dcd5-46db-9b65-9b8a2ef1216e" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"This guy got 6% faster than a Titan X using the leaked 2048 SP value and pulling data from previous benchmarks. Here is how GTX 1070 will perform against GTX Titan X and GTX 1080 It also shows a 150W TDP! Just crazy."</post>
   <post id="d5943a3c-88c1-4baa-9b0f-6c8c413e7dc0" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"I might get a 1070 to tide me over until GP100 comes out and by then hopefully I ll have a better understanding of what I want to do display-wise."</post>
   <post id="23531e0d-f6d9-423b-950b-9613252e54b3" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"TaintedSquirrel said: ↑ This guy got 6% faster than a Titan X using the leaked 2048 SP value and pulling data from previous benchmarks. Here is how GTX 1070 will perform against GTX Titan X and GTX 1080 It also shows a 150W TDP! Just crazy. Click to expand... Why is that "crazy"? If its a hair faster than the Titan X then that means its about 55% faster than the 970 it replaces at roughly the same TDP. To me that is a joke for using a new architecture on a process nearly half the size and with super high clocks to boot."</post>
   <post id="5090e68b-2bf8-4ab7-a424-2bea2f3d6a34" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ Why is that "crazy"? If its a hair faster than the Titan X then that means its about 55% faster than the 970 it replaces at roughly the same TDP. To me that is a joke for using a new architecture on a process nearly half the size and with super high clocks to boot. Click to expand... why?.. what other card do you know that could offer +55% performance versus the direct replacement?."</post>
   <post id="f7947ce0-e20f-4382-8acc-be6f2e7c1371" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"Araxie said: ↑ why?.. what other card do you know that could offer +55% performance versus the direct replacement?. Click to expand... Congratulations on missing the whole freaking point. Here is a hint...read the second sentence closely. If you are still confused then let me also say that the 1070 is a pathetic 50% increase in performance per watt over the 970."</post>
   <post id="c8ce5318-49a4-4ec5-8bfa-af4875674d72" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ Congratulations on missing the whole freaking point. Here is a hint...read the second sentence closely. If you are still confused then let me also say that the 1070 is a pathetic 50% increase in performance per watt over the 970. Click to expand... Does nobody listen to me on this forum? Nvidia WON T give you an amazing wowie-zowie blow-your-pants-off product without competition. With no competition they re going to throttle the improvements as much as possible so they can create as many iterative generations as they can to profit from."</post>
   <post id="0925a1c7-d790-420d-a858-0b94e873c80d" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ Congratulations on missing the whole freaking point. Here is a hint...read the second sentence closely. If you are still confused then let me also say that the 1070 is a pathetic 50% increase in performance per watt over the 970. Click to expand... Let s take time to remember that Pascal is a compute-focused architecture, while Maxwell was a gaming-focused architecture. Looking at the block diagram you can see why."</post>
   <post id="b1f3b9a4-c487-457f-af76-6ba0c64dd2ad" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"I d suggest it probably depends on the resolution, the 980 Ti as a good chunk more memory bandwidth to play with."</post>
   <post id="eba45a20-cf88-4a89-8e9d-83967d26c615" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ If you are still confused then let me also say that the 1070 is a pathetic 50% increase in performance per watt over the 970. Click to expand... I m curious: When was the last time that nVidia gave us a a 50% or more performance improvement from x70 to (x+1)70? I was skimming Anandtech s GPU Benches back to 2012 and it seems like the biggest increase that I could find was 570-&gt;670, and that was ~36% (35.2 -&gt; 48). If all you care about is perf/watt, then yes, there have been better generational jumps. Then again, there have been worse ones too. 670-&gt;770 was something like 19% *worse* perf/watt. But we re talking about cards that haven t been benchmarked yet. I suppose all of this is meaningless speculation at this point. Bring on the benches!"</post>
   <post id="1935be21-4071-445e-9d20-c660d8153ef0" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"Pyroja said: ↑ I m curious: When was the last time that nVidia gave us a a 50% or more performance improvement from x70 to (x+1)70? I was skimming Anandtech s GPU Benches back to 2012 and it seems like the biggest increase that I could find was 570-&gt;670, and that was ~36% (35.2 -&gt; 48). If all you care about is perf/watt, then yes, there have been better generational jumps. Then again, there have been worse ones too. 670-&gt;770 was something like 19% *worse* perf/watt. But we re talking about cards that haven t been benchmarked yet. I suppose all of this is meaningless speculation at this point. Bring on the benches! Click to expand... Well, what was the jump like between the gtx 770 and the 970, given the gtx 780ti was matched by the gtx 970? Right now the 980ti is about 40% faster than the gtx 970 is it not? If the gtx 1070 matches or beats the 980ti, wouldn t you say that it has a 50% (around) performance increase over the gtx 970?"</post>
   <post id="150caf06-ebb3-4f9b-9da7-941e2c74936b" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"mald said: ↑ Well, what was the jump like between the gtx 770 and the 970, given the gtx 780ti was matched by the gtx 970? Right now the 980ti is about 40% faster than the gtx 970 is it not? If the gtx 1070 matches or beats the 980ti, wouldn t you say that it has a 50% (around) performance increase over the gtx 970? Click to expand... According to the 2014 benchmark, 770 - &gt; 970 is a ~18% increase. That chart has the 780ti outperforming the 970 by about 11% too. The 2015 benchmark has the 980ti ~44% faster than the 970. So yes, that would mean a 50% increase over the 970 is into 980ti/Titan X territory."</post>
   <post id="8ef3cf21-a807-4396-9796-58d52a89e194" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"Pyroja said: ↑ According to the 2014 benchmark, 770 - &gt; 970 is a ~18% increase. That chart has the 780ti outperforming the 970 by about 11% too. The 2015 benchmark has the 980ti ~44% faster than the 970. So yes, that would mean a 50% increase over the 970 is into 980ti/Titan X territory. Click to expand... Based on what I have seen in a few reviews the difference between the 770 and 970 is around 30%, and the difference between the 780ti and gtx 970 is around 1-2% in favor of the 780ti. ASUS GTX 980 Ti STRIX Gaming 6 GB Review (many of their reviews had very similar numbers) If this trend continues the gtx 1070 should be ~ the gtx 980ti. This is all at 1440p, which is the res I play at."</post>
   <post id="9784dc05-223f-40c1-aaeb-510381725ed1" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"mald said: ↑ Hi, From what I recall the gtx 780ti was the equivalent to the gtx 980ti when it came out in terms of being "top of the line". However, when the gtx 900 series came out, specifically the gtx 970, the gtx 780ti lost its value quickly after to a much cheaper card ( the gtx 970), that would trade blows with the 780ti while being cooler and using less performance. What are the chances of this scenario playing out again between the gtx 980ti and the gtxs 1070? I currently own a 980ti, but I would be happy to sell it before its value goes down, get a gtx 1070, and have some money left over. Can anyone with some experience in the field, and that has been following the trend answer this question? Thanks! Click to expand... NVIDIA s GTX 1080 GPU is faster than Titan X, lands May 27 It will not only perform better than the current king TitanX, but it will be 3 times more power efficient. Now that s what I call a revolution in GPU. I hope AMD soon launches a competitor to 1080, otherwise they will be behind the race, which is bad for the consumers"</post>
   <post id="9e3d8571-30ad-400e-83c3-4c9b85990f7a" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"maverick786us said: ↑ NVIDIA s GTX 1080 GPU is faster than Titan X, lands May 27 It will not only perform better than the current king TitanX, but it will be 3 times more power efficient. Now that s what I call a revolution in GPU. I hope AMD soon launches a competitor to 1080, otherwise they will be behind the race, which is bad for the consumers Click to expand... Sarcasm or are you really that out of the loop? The 3 times more efficient claim was in relation to VR."</post>
   <post id="dd522f5b-e093-441d-ab26-eddec37c81d7" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"KazeoHin said: ↑ Does nobody listen to me on this forum? Nvidia WON T give you an amazing wowie-zowie blow-your-pants-off product with out competition. With no competition they re going to throttle the improvements as much as possible so they can create as many iterative generations as they can to profit from. Click to expand... That is the goddamn stupidest thing I have ever heard. (Well actually not on edit but I will leave it for emphasis.) You think when they sent off 2000 engineers 4 years ago that was the goal? Just enough to beat an AMD without Raja or Eric Demers? Kor said: ↑ I d suggest it probably depends on the resolution, the 980 Ti as a good chunk more memory bandwidth to play with. Click to expand... Huh?"</post>
   <post id="160a7bd2-bb5e-488e-9c81-1256d2a9a746" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ Sarcasm or are you really that out of the loop? The 3 times more efficient claim was in relation to VR. Click to expand... Sarcasm, yes these cards will be power efficient according to nVidia claim. But this statement looks out of loop "The GTX 1080 is the "largest GPU endeavor, largest chip endeavor, largest processor endeavor, in the history of humanity," said NVIDIA CEO Jen-Hsun Huang. He added that the R&amp;D budget for the new card was "several billion dollars" over the span of more than two years. "I m pretty sure you can go to Mars [for that]," he said.""</post>
   <post id="ea734c36-77de-4851-8e99-5c18af1798bc" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"If this is all they can come up with for that kind of investment it is damn sad. A whole new architecture and 75% smaller process and all they got was around a 60% increase in perf per watt. As for as non VR gaming goes its really nothing more than a 980 with 25% more cores running at higher clocks and with faster memory. Heck it actually looks slower per clock then Maxwell. And then on top of that they raise the prices and then have the nerve to jack it up another 100 bucks on top of that for the reference cooler. lol"</post>
   <post id="892f37f5-d421-4a24-834d-5c252ec33910" section="Video Cards" discussion="Would the gtx 1070 be around the gtx 980ti in terms of performance?">"misterbobby said: ↑ If this is all they can come up with for that kind of investment it is damn sad. A whole new architecture and 75% smaller process and all they got was around a 60% increase in perf per watt. As for as non VR gaming goes its really nothing more than a 980 with 25% more cores running at higher clocks and with faster memory. Heck it actually looks slower per clock then Maxwell. And then on top of that they raise the prices and then have the nerve to jack it up another 100 bucks on top of that for the reference cooler. lol Click to expand... Its no brainer that nVidia always launch price of its X80 series GPUs within the price range since GTX 780 series. They first launch an expensive 1000$ GPU like titan series, then they try to justify that, those who cannot shell out 1000$ can go for CHEAP option of 699$ by going for X80 series GPUs, with performance almost identical to the titan series"</post>
   <post id="26d2bbd0-456f-4512-a257-a4727395d8e9" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"Well, I ve recently bought a 2 titan x s for extremely cheap. I recently had a 690 gtx and used dvi cable. Now I use display ports on my titan x s since I heard its better but its been pain in my butt but don t know if that s the issue. I usually leave my computer on over night and with my old card I turn both of my display s off and my secondary (right side) has all my stuff open aka apps etc. and when I turn it back on it stays right where I left them. Now with the new cards when I turn them off and turn it back on, everything moves to the main monitor (left side). I really need help fixing this, this is a pain in the butt. Thank you!"</post>
   <post id="c3628b32-1568-4da3-915c-5e1793245391" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"I am having a similar issue unfortunately. I have 3 monitors hooked to my 1st 980ti one is hooked up by DisplayPort adapter with a hdmi cable. I can turn off my main or secondary monitor and everything is fine, but when i turn off my 3rd monitor the one thats running thru displayport and it acts as if I am physically unplugging the monitor. My screens go black and everything is moved to the other monitors. I m guessing its something to do with NV drivers. They are not nearly as smooth as Amd s. I am referring to running 2+ monitors, in order to run 3 monitors they all have to be hooked up to the same card, well that is if you don t want to enable surround. I don t because my monitors are all different sizes, 42", 27" and 24". I usually play games on my 27 and 42, only one at a time. I never had a problem with setting up 3 monitors when i was using my 7970s. Its not really a big deal just a tad annoying. Sorry I couldn t be of much help. I was thinking about it and it may have something to do with display port. I changed the display port around to my main monitor, because I never turn it off, and when i turned off the 3rd monitor it didn t give me any issue. Its running on a DVI-D port now with a Dvi-D cable. Thanks -Stay [H]"</post>
   <post id="c792bf3e-8861-419f-bbc4-db6464754338" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"I ve noticed that with DP, when you turn them off, they disconnect from the PC, like you unplugged the cable. I used to just put my monitors to sleep so that they don t re-arrange everything. Try this, turn off your main display and I bet the secondary screen becomes the main one."</post>
   <post id="fe6f346f-650a-4d33-9e05-8dce5ff4f4a3" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"Yeah, stupid plug and play."</post>
   <post id="5c5da060-3f25-489a-8051-0702018325a3" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"Happens to me with a mini display port to display port cable from a R9 280X, so not just an nVidia issue. Really annoying."</post>
   <post id="2f03f5dd-ca4d-48ed-b645-e2069d81a5b4" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"It s just how the DisplayPort standard works. No way around this, short of conversion to another standard (DVI is probably your best bet). I d imagine using powered display port to DVI-D adapters and keeping them powered at all times would eliminate the unwanted re-arranging. No guarantee even then though -- depends if the adapter actively senses if the display connected to it is turned on."</post>
   <post id="e91dc1d7-ac5e-45c4-90c9-e247daf8919b" section="Video Cards" discussion="2 monitors displays issue. Turn them off at night and everything on second monitor moves to main.">"Thanks for reply, I ll check it out."</post>
   <post id="95b3ac51-47c7-454d-937d-1ea858f4241e" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Article is from 2006, thought it was interesting anyway since I never heard about this. Did Nvidia Hire Online Actors to Promote Their Products? I was told that if I accepted the job, I was to have at LEAST 50 identities on as many forums as I could muster (they wanted 100 eventually), with a goal of 5 posts an hour. The posts had to be well thought out, and the idea was that I was to establish multiple identities with a history on the forums, so that when the timing was right a well written but subtly placed marketing post could be finessed in. And regular visitors would recognize the post as coming from a long time poster. Click to expand..."</post>
   <post id="60dfef99-d3a4-41b8-9ace-69968fac1c8d" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Based on this forum, AMD has already been doing this Did they want to invent a time machine to do this? People can spot a newbie shilling for a brand a mile away..."</post>
   <post id="0cbfe9be-9359-475c-9697-0c09926f33ab" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Ocellaris said: ↑ Based on this forum, AMD has already been doing this Did they want to invent a time machine to do this? People can spot a newbie shilling for a brand a mile away... Click to expand... Interesting idea cause i had no idea they went that far with that crap....lol...actually their has been a few nvidia trolls here i could swear were all the same person (like 2 or 3 of them) and surprisingly they all been gone for about 6 months"</post>
   <post id="9158ffde-d620-463a-a0fc-2fc7ef5cf935" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Yeah, The Prime suspects are no longer posting. It is Unknown what has happened to them. Maybe the went to chase some other Golden opportunity. Ocellaris said: ↑ Based on this forum, AMD has already been doing this Did they want to invent a time machine to do this? People can spot a newbie shilling for a brand a mile away... Click to expand... Not really. I ve had infractions and temp bans for calling out undercover vendor employees on this forum."</post>
   <post id="f577b684-a094-435b-b609-13d512a0972e" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"LOL you left a few out but that was clever."</post>
   <post id="263150b7-3006-43d0-a13b-9dcd8d36ec9a" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"As amusing as that was those cases don t really fit the profile as described in the OP, especially for a certain someone. subtly placed marketing post could be finessed in Click to expand... I d suspect that posters who first come to mind as possible candidates poorly fit that criteria. TaintedSquirrel said: ↑ Article is from 2006, thought it was interesting anyway since I never heard about this. Did Nvidia Hire Online Actors to Promote Their Products? Click to expand... Even back these types of marketing concepts were no longer rather secretive. Nowadays I d think it s for sure brought up even in entry level marketing classes."</post>
   <post id="3b897eb7-f2c6-4182-af75-f85627daf895" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"I think it s pretty obvious at this point who s who and what s what."</post>
   <post id="52790a7e-9160-449d-92d1-f6c7156b57c2" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Buy Nvidia. Nvidia is best Nvidia."</post>
   <post id="44b77568-f256-4bd2-9529-c09174ab884b" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Nvidia will make graphics processing great again"</post>
   <post id="43aebf2b-11d8-4236-bdfb-445449216a6b" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"It s not if companies do this that is the question to me. Of course they do. What I wonder about is the percentage of users."</post>
   <post id="5796cd37-cd29-47a5-acc2-f67f287e02f7" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"All I know is that a LOT of the usual suspects disappeared a few months to one year ago with NO talk about it from [H]ard staff. My tinfoil hat theory: [H]ard staff caught on, called the vendors on the tactic, said they wouldn t make a fuss if the actors just went away, otherwise they ll make it a news piece. Boom. No more shills... for now."</post>
   <post id="66931107-0432-4a0c-8f54-d2074208d0c5" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"cthulhuiscool said: ↑ Nvidia will make graphics processing great again Click to expand... AMD will make GPU s affordable again, frankly anything over $250 is beyond my price range."</post>
   <post id="ef4198ea-7c42-40b1-92e3-3a27da046967" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"BlouBulle said: ↑ anything over $250 is beyond my price range. Click to expand... - said by MOST gamers. you d be surprised how quickly the market drops off once prices go over $300 US."</post>
   <post id="8e3e6199-5ed4-4e24-a86d-4ffb6dc78ef0" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"BlouBulle said: ↑ AMD will make GPU s affordable again, frankly anything over $250 is beyond my price range. Click to expand... Last I checked there were already GPUs available for $250."</post>
   <post id="32b86ca8-2478-4898-823c-44f3d630253f" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Lots of volunteer shilling for AMD at WCCF though. Almost every comment is guranteed anti-nvidia. XD"</post>
   <post id="06153c88-678f-4865-8712-87427eb51670" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"MangoSeed said: ↑ Last I checked there were already GPUs available for $250. Click to expand... I think it s supposed to be a joke? If not it s off topic... I think it s a Bernie Sanders joke in response to the Trump joke earlier in the thread."</post>
   <post id="2137c45f-e24f-4982-a761-8afb0d57091d" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"primetime said: ↑ Interesting idea cause i had no idea they went that far with that crap....lol...actually their has been a few nvidia trolls here i could swear were all the same person (like 2 or 3 of them) and surprisingly they all been gone for about 6 months Click to expand... Of course they do. Both sides have been managing this "secret" war for years through proxy marketing firms. There are shills here, both ones who were hired to work for marketing firms, and other established members who have been appropriated. I know people who used to manage a number of well-established usernames at other (non-PC) hardware sites in return for product. I ve actually seen the guidelines they were given and they read like espionage instructions. A couple points I remember of the guide (am paraphrasing): never state outright that the competition is bad, use misdirection if you are being called out on something, phrase your negative post titles as a question to indicate impartiality, stress positive points provided in press packets. Sound familiar? No doubt it s happening here too. Shout out to KazeoHin for his clever post above"</post>
   <post id="e7b167e9-9db1-45f4-afeb-09849dae9b9c" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"I was sure 3DFX was victim to this kind of stuff back in 1998-2000, mostly I remember arguing with people about Voodoo 2 vs Riva TNT, especially as it related to Quake 2. I just was certain a few were paid shills, nothing could explain the love they had for Nvidia and the pedestal they put them on."</post>
   <post id="d9b9d319-0855-463d-ab45-822597cba1c3" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"Both companies have plenty of paid and unpaid shills running around the forums. The paid ones might be scarce, but there are lots of unpaid ones here from both camps."</post>
   <post id="830a4680-a2ed-49ba-ba31-a0809ccbde21" section="Video Cards" discussion="Did Nvidia Hire Online Actors to Promote Their Products?">"DooKey said: ↑ Both companies have plenty of paid and unpaid shills running around the forums. The paid ones might be scarce, but there are lots of unpaid ones here from both camps. Click to expand... That may be but around here lately it seems like the staff ran off the worst offenders and or had talks with the others.....Its huge improvement over last couple yeas. Still have some idiotic fan boys but they dont try to hide the fact either lol"</post>
   <post id="6fbd85b0-558e-4a08-89d3-2628386e09ef" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Been looking at upgrading the old video card and in order to hook up my TV I need a DVI-I or DVI-A port, seems all the ones I have looked at only has DVI-D. I use a DVI to VGA cord to hook up my TV."</post>
   <post id="c4e079f6-77f3-46f0-9852-93fc388177a4" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Why not just get a different adapter? Amazon.com: StarTech DVI to VGA Cable Adapter, M/F (DVIVGAMF): Electronics Amazon.com: VicTsing Gold-plated DisplayPort(DP) Male To VGA Female Cable Adapter for PC Laptop Macbook - Retail Packaging - Black: Computers &amp; Accessories Amazon.com: VicTsing Gold-Plated HDMI to VGA Converter Adapter for PC, Laptop, DVD, Desktop: Computers &amp; Accessories Unless I m completely misunderstanding you."</post>
   <post id="618e575f-c33f-4a4d-b0b9-63e84d58f254" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Apparently he wants to hook it up with an adapter cable he already has? Im amazed he has a tv without hdmi. Not to mention they used to include basic adapters with new cards. They not including those anymore?"</post>
   <post id="15adea87-cff1-48e3-ba80-539cf12033f6" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"I ll check, but I don t think my Nitro 390X came with anything for VGA. Maybe though."</post>
   <post id="840be1d9-59eb-4cd0-b0e6-7947988f2eae" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Those cheap DVI -&gt; VGA connectors will only work if the DVI port has an analog signal to begin with. They aren t doing any digital to analog conversion."</post>
   <post id="69f3aeb2-764b-46ef-8cc8-ae0796890dd3" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"DedEmbryonicCe11 said: ↑ Those cheap DVI -&gt; VGA connectors will only work if the DVI port has an analog signal to begin with. They aren t doing any digital to analog conversion. Click to expand... pretend like we all know what that means. Are you saying he needs an active adapter because dsub vga is analog on tv s? help me out"</post>
   <post id="e54b3b3a-cd3d-4705-b481-2fd7a2579d6b" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"primetime said: ↑ pretend like we all know what that means. Are you saying he needs an active adapter because dsub vga is analog on tv s? help me out Click to expand... The HDMI -&gt; VGA adapters linked by anther member do digital -&gt; analog conversion. They *should* work fine (read the reviews and don t sue me if they don t). The DVI -&gt; VGA adapter linked doesn t have a chip inside it doing DAC. It would need a DVI-I (digital + analog) or older DVI-A (pure analog) port on the graphics card to produce the necessary analog signal. If he wanted to use a DVI-D (digital only) port from his graphics card he would need an adapter such as this: Amazon.com: gofanco® DVI-D to VGA Active Converter - with 3 Feet Micro USB Power Cable for BETTER compatibility and up to 1920x1200@60Hz Black MALE to FEMALE: Computers &amp; Accessories"</post>
   <post id="424e40db-65ae-44bc-a661-91567300b7af" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Wait 2 months and see if the AMD 480 has what you need. Supposedly the 480s will be on par with the 390s in terms of performance, but prices the same as the 380s."</post>
   <post id="4ab67540-fc8b-4816-ab4c-340e639c8125" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"What resolution/refresh rate has the monitor?"</post>
   <post id="801097e9-d876-4732-883a-15c1d64886d7" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"PontiacGTX said: ↑ What resolution/refresh rate has the monitor? Click to expand... lol thats a good question cause i have yet to see a tv with better than 720p on the vga port. Im going to guess it not op s primary display"</post>
   <post id="09c25919-2d77-4157-b486-153a82751887" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"primetime said: ↑ lol thats a good question cause i have yet to see a tv with better than 720p on the vga port. Im going to guess it not op s primary display Click to expand... A DVI-D port with with a VGA Cable with DVI-A/VGA adapter(if tv input is vga) should work fine with 1080/60"</post>
   <post id="d72a54f9-c916-40d7-b632-35e0f01de4a1" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Looks like I am getting a VisionTek Radeon R9 380X 4GB. The price is right, it had both DVI-I and DVI-D and 2 6 pin power ports. I will be buying it Monday or Tuesday when the money gets here unless you all can think of something better for me to get $250."</post>
   <post id="a9270ade-5317-47ad-938f-c2f905550875" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"Diablo2K said: ↑ Looks like I am getting a VisionTek Radeon R9 380X 4GB. The price is right, it had both DVI-I and DVI-D and 2 6 pin power ports. I will be buying it Monday or Tuesday when the money gets here unless you all can think of something better for me to get $250. Click to expand... in newegg there was a reference r9 290 for 200usd. but if you can hold for AMD polaris, do it"</post>
   <post id="105b9c60-046e-4a6e-89e0-2e26299d4777" section="Video Cards" discussion="Do any Radeon R9 390X cards have a DVI-I port?">"PontiacGTX said: ↑ in newegg there was a reference r9 290 for 200usd. but if you can hold for AMD polaris, do it Click to expand... Thanks for the lookup but the the R9 390s wont work for me. Ended up buying XFX R9 380X DD XXX OC. The [H] review of the card was favorable except for the lack of overclockability, but I wont be overclocking it anyway."</post>
   <post id="b54a9aa5-a64d-4d5b-8e47-8c8d42d07c46" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Nintendo NX will powered by an NVIDIA Tegra processor, not an AMD chip"</post>
   <post id="eb72a967-4248-41e6-a23f-b1615feca0f9" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"With nVidia it likely revolved around a price/performance ratio when it came to console mass production. Nintendo is known for being a great negotiator when it comes to business deals. I am sure much debate and negotiation went into this decision. Either way I am glad to see it!"</post>
   <post id="901be3aa-a203-4d0f-bfaa-4aa0f7aad180" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Wow. Just when you thought Nintendo is struggling to get ports... well now developers have even more excuse to not make ports for them."</post>
   <post id="60ae0af5-39f1-4fdb-a42a-a31b6318921a" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"This rumor originally showed up on SemiAccurate. It s also a rumor for their handheld. Nintendo NX is suppose to have a separate console and handheld that share the same OS."</post>
   <post id="d3dcf18e-d5de-4c23-9f60-66080192f23b" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"realworld said: ↑ Wow. Just when you thought Nintendo is struggling to get ports... well now developers have even more excuse to not make ports for them. Click to expand... Meh, who knows. The rumor from Charlie D. was that the handheld would use a Tegra processor. And since mobile gaming is already established on ARM it seems like the right move to make for the handheld. Then going from a handheld to a full-blown console shouldn t be too much harder and you ll probably want them using the same basic tech under the hood. I know I mention it often, but as long as you re developing for a non-retarded OS using a non-retarded graphics API, moving between x86 and ARM is trivial and any developer worth a salt would have little problems doing so."</post>
   <post id="50a9ed3c-bfea-4273-a02b-3ef0ff8985f7" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"AMD already announced three new custom gaming SoC. So either Nintendo is putting one in the console, or there s going to be another competitor enter the console market."</post>
   <post id="ce4ae93e-8d6e-4e5b-adb8-db2dc77a67d8" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"I certainly think this would be an interesting choice, because a beefed-up Tegra based on ARM would be the best alternative to x86 for gaming. But I really would have expected Nintendo to go with an AMD APU and an x86 processor like everyone else, if only to ensure they get ports because it s trivial. I m not liking how the market these days forces everyone to use similar designs so there s no real choice."</post>
   <post id="3bc5ec5e-d1b2-40bc-811d-ade8479a6d00" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Hopefully its more successful than the last time devices used tegra processors."</post>
   <post id="9633d2d8-13d0-4e1a-8c5b-d3b77e5dd2df" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Looking into this more. I wonder if some of the published rumour-news about this goes back to Emily Rogers: So about NX… She has leaked a fair bit in the past regarding Nintendo (better than average and better than usual rumour leaks), Cheers"</post>
   <post id="35410ea4-b801-4097-b899-b3bddd454de5" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"LOL and I read yet another critique from semi-accurate even to this rumour. They see this as a negative for NVIDIA because according to them and their source NVIDIA is desperate for a console win and in effect the contract works out potentially as a financial loss with big commitment of internal resources to support Nintendo.... I could go along with that analysis if NVIDIA had put everything into and winning the PS4 contract (that would be big and worth it), but considering the impact Nintendo has in this space in comparison... well.... As I said in another thread, semi-accurate has to do a negative article each week on NVIDIA no matter what the news or actually unfolds such as real products given out to reviewers. Still not entirely sure about Nintendo using Pascal-Tegra type solution rumour, although it could work also maybe a hook-up to the NVIDIA streaming technology as well *shrug*. Anyway here is a link where someone opens up a bit with what was said in the semi-accurate article: SemiAccurate: Nintendo NX handheld to use Nvidia Tegra-based Soc Worth pointing out Semi-accurate seem to think it is only the handheld with NVIDIA being desperate, but Emily Rogers blog I linked earlier post suggests the main console is not x86 architecture and so that could be hinted at being NVIDIA with the Pascal/Tegra. I give her more credit than Charlie, considering the dire reports he continues about NVIDIA/Pascal/HBM2/Tesla... according to him everything is falling to pieces for NVIDIA and been repeatedly saying that for the last 6-8 months now..... Cheers"</post>
   <post id="43352d4f-e64f-4518-8919-47f88b1e6d3a" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"CSI_PC said: ↑ LOL and I read yet another critique from semi-accurate even to this rumour. They see this as a negative for NVIDIA because according to them and their source NVIDIA is desperate for a console win and in effect the contract works out potentially as a financial loss with big commitment of internal resources to support Nintendo.... I could go along with that analysis if NVIDIA had put everything into and winning the PS4 contract (that would be big and worth it), but considering the impact Nintendo has in this space in comparison... well.... As I said in another thread, semi-accurate has to do a negative article each week on NVIDIA no matter what the news or actually unfolds such as real products given out to reviewers. Still not entirely sure about Nintendo using Pascal-Tegra type solution rumour, although it could work also maybe a hook-up to the NVIDIA streaming technology as well *shrug*. Anyway here is a link where someone opens up a bit with what was said in the semi-accurate article: SemiAccurate: Nintendo NX handheld to use Nvidia Tegra-based Soc Worth pointing out Semi-accurate seem to think it is only the handheld with NVIDIA being desperate, but Emily Rogers blog I linked earlier post suggests the main console is not x86 architecture and so that could be hinted at being NVIDIA with the Pascal/Tegra. I give her more credit than Charlie, considering the dire reports he continues about NVIDIA/Pascal/HBM2/Tesla... according to him everything is falling to pieces for NVIDIA and been repeatedly saying that for the last 6-8 months now..... Cheers Click to expand... Everything has been falling to pieces man, they have a 610mm 16nmFF gpu in production, and they were first to announce their consumer lineup. They re royally screwed"</post>
   <post id="80106aed-1826-405c-abd3-40b20b511259" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"CSI_PC said: ↑ according to him everything is falling to pieces for NVIDIA and been repeatedly saying that for the last 6-8 months years now..... Click to expand... FTFY. Nvidia was officially doomed with Fermi. They re done. They ll never have a profitable quarter again."</post>
   <post id="b33c05bd-1f8e-4180-bfdf-d286b15901db" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"You people forget Nvidia has Denver if they need beefcake cores. But given how powerful A72 is they ll probably jsut use that, as it s offers more consistent performance than VLIW. And they have tons of experience integrating pretty powerful graphics into their set top box, and also their car chips. You know, areas where you can go above 5w TDP, liek a fucking console"</post>
   <post id="79b132c2-9fa6-4385-be62-8f2029783180" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Nintendo is still relevant? But seriously the last Nintendo anything I bought was a Gameboy Advance SP, which came out at least 10 years ago."</post>
   <post id="fa53b560-f879-45ca-982d-544c09c18d06" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"n=1 said: ↑ Nintendo is still relevant? But seriously the last Nintendo anything I bought was a Gameboy Advance SP, which came out at least 10 years ago. Click to expand... Nintendo DS released 12 years ago."</post>
   <post id="e95652a8-513c-4d35-97db-b4d63a3ca9fe" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Wouldn t it make more sense for this to be a new handheld device? I don t know what Nintendo has been up to recently."</post>
   <post id="901f5c4d-b782-483e-97ca-344eb8bf5d98" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Nolan7689 said: ↑ Nintendo DS released 12 years ago. Click to expand... Shows you how much I care about Nintendo heh."</post>
   <post id="6438241e-4ad3-4272-8555-19f8b84d830a" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"TaintedSquirrel said: ↑ Wouldn t it make more sense for this to be a new handheld device? I don t know what Nintendo has been up to recently. Click to expand... That is the consensus. The console is still an AMD APU with the tegra in the handheld portion."</post>
   <post id="0e41dc82-518d-41a1-8fc0-3a09f61863e4" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"JustReason said: ↑ That is the consensus. The console is still an AMD APU with the tegra in the handheld portion. Click to expand... Not sure about that consensus, considering Emily Rogers comments now and also in the past. Rumours/leaks are usually hit and miss, but I would say she has been more accurate regarding Nintendo than Charlie and few others. TBH it is not worth NVIDIA s time to just have the handheld, and if they were desperate it would be for the console not handheld; console brings back strength to their PC GPUs from a soft benefit perspective and the handheld does not - another aspect that makes Charlie s analysis strange. But then I would say Nintendo are more desperate with their situation than NVIDIA, and probably this deal IF it happens is because NVIDIA get the margins (albeit quite small) with other aspects they wanted. In theory Nintendo doing business with NVIDIA may make sense when you consider they want a console and portable device, and possibly a game streaming tech that works very well. NVIDIA Shield is all of those already and with a game streaming service, so there is a base there for Nintendo to build upon with their own requirements and hardware spec with newest gen Pascal/Tegra. Cheers"</post>
   <post id="41f5d797-6cdc-47a7-bbe9-b79553670210" section="Video Cards" discussion="Nintendo NX with NVIDIA Tegra ? Nandato !?">"Yeah, MIXED console and handheld architectures? Who came up with that dumb thing? I thought the whole point of the NX was supposed to be a a unified platform for portables/console?"</post>
   <post id="ff2b2052-4b5a-4882-81bc-f0690e245c09" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"When I say 3D gaming, I mean games that run on 3D monitors. I know VR is all the rage, but the selection of supported games and hardware that support 3D seems to be almost non existent now. This reflects a trend in consumer TV s where 3D is once again a niche item that is only offered by a few manufacturers on top end models. Some manufacturers have dropped 3D all together."</post>
   <post id="90b21b45-fb24-47bd-9d8f-42951b2b55f6" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Was it ever really alive? Always seemed like a PR fad that only existed because companies kept pouring money into it."</post>
   <post id="4e84deb3-8437-4641-913a-3b7fb204b010" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Consider that practically all high calibre games are internally rendered in 3D, its never been dead. The problem for me has been low res unless you get poor quality 120Hz+ monitors and needing dual fast gfx cards. Icing on the cake (for now) would also be passive glasses. I have a passive 1080p LG TV and its an easy watch, just the res sucks. Some games are ok with effective 720p per eye but not many. Even the current VR headsets are too low res, mine is about to be returned due to that and some damning quality issues. The capability to give a good experience on almost everything exists, its just taking a long time to reach us. I havent yet tried a 3D 4K TV with passive glasses. A decent quality 4K TV should be able to do 60Hz per eye @ 1080p if the Stereo software can drive it. But this will need dual fast cards to keep the quality settings high. Or maybe the new 10xx series cards will change this."</post>
   <post id="eee5af37-b151-4f2e-9c09-24bf873f7fc1" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Nenu said: ↑ Consider that practically all high calibre games are internally rendered in 3D, its never been dead. The problem for me has been low res unless you get poor quality 120Hz+ monitors and needing dual fast gfx cards. Icing on the cake (for now) would also be passive glasses. I have a passive 1080p LG TV and its an easy watch, just the res sucks. Some games are ok with effective 720p per eye but not many. Even the current VR headsets are too low res, mine is about to be returned due to that and some damning quality issues. The capability to give a good experience on almost everything exists, its just taking a long time to reach us. I havent yet tried a 3D 4K TV with passive glasses. A decent quality 4K TV should be able to do 60Hz per eye @ 1080p if the Stereo software can drive it. But this will need dual fast cards to keep the quality settings high. Or maybe the new 10xx series cards will change this. Click to expand... Perhaps i haven t given it a fair chance. VR and 3D were always tough sells to me."</post>
   <post id="8788fd9d-dc3a-46c8-a301-e9a3bad2a25c" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"There are 3 big problems with 3D gaming. 1.) Tri Def software found out that after they sold us software, they had to provide support for titles for free. Most of the Tri Def software came free with monitors; at least my AMD setup did. I purchased an updated license, but there really wasn t a way for them to monetize their product after the initial sale. 2.) Gaming titles like Tomb Raider really push the power of video cards. Then you tack on the load of trying to do 3D, and it all goes downhill from there. Your 60 frame target suddenly becomes 45 fps or 30 fps. Here is a Black Desert Online profile that a fan created that runs at 24 fps. 3.) If game developers took the time to write a Tri Def profile it would be a great system. Forcing Tri Def to write profiles for games years later is a failed business model without some form of compensation. 3D was a great feature. AMD  s version allowed most any game to be 3D if you were willing to make a profile in Tri Def. I wish that more people had given it a chance. I think that the Microsoft Hololens is the future of 3D gaming. I d love to play Black Desert Online in my living room. Edit: I wanted to add that if Tri Def had released their software onto Steam, and allowed that community to create profiles in the same manner as the Steam Controller, it would be much more useful as a tool."</post>
   <post id="c08e055d-a21f-42d0-9cf3-6876b1d0173d" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"3D gaming isn t dead, it just isn t fully supported in everything. You can get TriDef going for most games and it works great. Certainly better than Nvidia s crap. You need a niche setup to get 3D working well these days, but you can still get most new releases working in 3D if you want, it just takes a bit of work to accomplish since they don t ship that way by default. Rise of the Tomb Raider for example looks pretty good in TriDef s  power 3D  mode which requires considerably less GPU power than its standard 3D mode, which needs 2x power. 3D got hampered by the garbage HDMI 1.4 standard limiting every 3D TV to 720p @ 60 Hz or 1080p @ 24 Hz; obviously unacceptable resolutions and framerates for gaming. But in 2014, Samsung released TVs that fixed this problem. Samsung s 2014 and 2015 model 4K TVs support a side-by-side 4K signal at 60 Hz, giving you an effective 3D gaming resolution of 1920x2160 @ 60 FPS, on a TV. Unfortunately it came a little too late, but I think if 3D gaming weren t hampered by the garbage HDMI standard it would ve been more popular. Here s an example of Rise of the Tomb Raider running at 4K and in 3D using TriDef: Per the YouTube video s description: Here is a brief video of Rise of the Tomb Raider on PC using the following setup: GTX 980 Ti (x2) Core i7 4770K 32 GB RAM TriDef 3D Ignition software for stereoscopic 3D; using the Tomb Raider (2013) profile For some reason, Power 3D looks better than standard 3D mode for this title. This is outputting to a SAMSUNG 65JS9500 2015 Series 4K TV -- Samsung s 2014 and 2015 model 4K TVs are the only displays on the market that can support stereoscopic 3D at 4K resolution! This is accomplished by using the TriDef 3D software and outputting a 3840x2160 side-by-side 3D signal at 60 Hz, which the TV supports via its HDMI 2.0 inputs. All other 4K TV manufacturers only support stereoscopic 3D at a maximum resolution of 1080p@24 Hz, or 720p@60 Hz because they do not support side-by-side 3D at 4K resolution like Samsung does! NVIDIA 3DTV Play also does not support side-by-side 3D like TriDef does, so achieving resolutions higher than 720p@60 Hz on a 3D TV is impossible if using 3DTV Play Click to expand... So yeah, if everybody got to experience 3D properly, using a setup like this, I don t think you would find nearly as many denouncing it... their opinions of 3D were ruined by garbage displays that could only do 3D @ 720p resolution instead of a quality niche setup that can do 3D @ 4K resolution like this. 3D is on a life support but if you put a bit of effort in you can play most everything new in 3D if you want and of course you have thousands of older PC games you will always be able to play in 3D as long as you keep a 3D display."</post>
   <post id="ebec2913-1ec6-4ca6-8f6d-afcfe1796353" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Google Zebra Imaging. If they can get that in motion 3D will make a comeback"</post>
   <post id="69e98fde-cc3e-41a5-8786-2ce35e9632c5" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"I played a few games that way (using Nvidia 3DTV Play or the PS3/360) and found that either visual quality or performance suffered. It s also reliant on the type of 3DTV you have, the type of glasses you re using, angles, etc. I don t think the concept is inherently bad, but it s a niche of a niche that can play these games well. I tend to think VR is a better solution anyway."</post>
   <post id="4c330980-fbc6-4128-83a8-5f596fb9943f" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Not sure it was ever truly alive behind manufacturer s marketing. A few hours of 30 fps per eye flickering is enough to give a lot of people a good sized headache. I much rather a silky smooth 100+ fps than other options currently available."</post>
   <post id="760d0a9f-6f56-49a0-94b7-b5507ca43a5e" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"I have a feeling we re going to see similar threads about VR in a year or two."</post>
   <post id="ad14b896-7a0b-4175-8c48-b4ac65deeb25" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"I don t think so ^. VR is in a primitive stage right now, almost very similar to how 3D gaming is/was. I will say that when I used NVIDIA 3D glasses it was actually a lot of fun (more so than without) but had some issues. I have faith that they can combine the two ideas into something that s good at both, and create something really interesting in a couple years max. I played the original Tomb Raider in 3D (100% of the game) and it blew my mind. To this day, I haven t had a gaming experience like that, but it could be perfected a bit."</post>
   <post id="a19e8e44-4c81-4b37-85f8-589f92da19bf" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Mystique said: ↑ I don t think so ^. VR is in a primitive stage right now, almost very similar to how 3D gaming is/was. I will say that when I used NVIDIA 3D glasses it was actually a lot of fun (more so than without) but had some issues. I have faith that they can combine the two ideas into something that s good at both, and create something really interesting in a couple years max. I played the original Tomb Raider in 3D (100% of the game) and it blew my mind. To this day, I haven t had a gaming experience like that, but it could be perfected a bit. Click to expand... Until the cost for a decent headset isn t 1k then i have to say it ll remain a niche."</post>
   <post id="aa49d40c-f852-43c8-9254-6a6ce2026f6a" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"{NG}Fidel said: ↑ Until the cost for a decent headset isn t 1k then i have to say it ll remain a niche. Click to expand... Exactly. And people are saying "the costs will go down" But they completely forget: look at all the crap that Oculus DOESN T have yet? Higher resolution, motion controllers, infinite floors created by smart treadmills - those are just the beginning of that increasing list of "NEED." But without those there s only so much you can do with your VR "experience." Every time a new revision comes out it will add a piece of that missing puzzle, and add cost. There s not that much price reduction in integrating big sensors and electronics together. EDIT: the only real price-reduction long-term may be beaming things direct to your retina, and that s a big MAYBE: something that precise may cost MORE than a high-resolution screen. You ll still need the rest of the elements to immerse your body."</post>
   <post id="22abe9fe-6eb4-4fb4-a988-337c13b794c0" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"I m still out until it s a good experience. Seems like it s just bragging rights now, hey I just spent a bunch of money on something sub par. They just got rated B and C- in Game Informer."</post>
   <post id="1be451ac-a6dc-4e6f-a298-affb5e04dc56" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"{NG}Fidel said: ↑ Was it ever really alive? Click to expand... What is dead can never die!"</post>
   <post id="76a8284f-9de7-4959-984a-b00bc28e5bbd" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"It ll be interesting to see if people are more willing to drop major $ into VR. 3D was a fun gimmick, but I don t think it wow d anyone enough to go out and specifically buy a TV that had it. At least unless they needed a new TV. It s not like you could buy a new model that didn t have it. VR offers a different experience, but it requires and will continue to require a much larger commitment. That s everything from a headset, to hardware to power it, to control mechanisms, to everything else. I do find it pretty compelling (I ve only used the Samsung phone headset version) but that price is pretty steep for something everyone knows will likely be obsolete in a year. It makes the Apple Watch seem like an investment for the future."</post>
   <post id="e93715b1-51aa-45f5-9a1d-c66973f2fa5c" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Domingo said: ↑ It ll be interesting to see if people are more willing to drop major $ into VR. 3D was a fun gimmick, but I don t think it wow d anyone enough to go out and specifically buy a TV that had it. At least unless they needed a new TV. It s not like you could buy a new model that didn t have it. VR offers a different experience, but it requires and will continue to require a much larger commitment. That s everything from a headset, to hardware to power it, to control mechanisms, to everything else. I do find it pretty compelling (I ve only used the Samsung phone headset version) but that price is pretty steep for something everyone knows will likely be obsolete in a year. It makes the Apple Watch seem like an investment for the future. Click to expand... I think it will need consoles to push it into that mainstream."</post>
   <post id="336988b6-259e-42e3-9bc1-2e9ce1605b57" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Domingo said: ↑ I played a few games that way (using Nvidia 3DTV Play or the PS3/360) and found that either visual quality or performance suffered. It s also reliant on the type of 3DTV you have, the type of glasses you re using, angles, etc. I don t think the concept is inherently bad, but it s a niche of a niche that can play these games well. I tend to think VR is a better solution anyway. Click to expand... Another person whose opinion of 3D was ruined by incompetent manufacturers, Nvidia s crappy 3D software, and the pathetic HDMI 1.4 standard that topped out @ 1080p24 or 720p60. I too thought 3D was shit... but that was when I could only play 3D games at 60 FPS at a maximum resolution of 720p. That was before Samsung s 4K TVs and HDMI 2.0 and TriDef. After I played stereoscopic 3D at 4K resolution and at 60 FPS on my Samsung 4K TV using HDMI 2.0... it became abundantly clear to me that this was a very impressive technology which greatly improved video games. It is such a shame that 3D at proper resolutions came out into such a small niche within a niche well after peoples  opinions had been soured by HDMI 1.4 s limitations. The shitty HDMI 1.4 standard ruined 3D gaming, but I ll always treasure my Samsung JS9500 and use TriDef when I can for 3D PC gaming @ 4K, getting to enjoy something really cool but only a very tiny number of people on this planet will ever get to enjoy unfortunately... so the 3D haters will never understand when I praise 3D because the ability to do proper 3D is now in such a small niche, they ll never get to experience it for themselves."</post>
   <post id="7b072bb0-6032-41fa-9523-36f3998daf6f" section="Video Cards" discussion="Opions: Is 3D Gaming Dead?">"Going to have to try this out on my Samsung 40js7500 when I get my new cards. Figure dual 1070s should be enough for most games. ."</post>
   <post id="a3de57d0-128d-49cd-a0aa-089064dc4143" section="Video Cards" discussion="Shadow of Mordor at 10K with 3-way and 4-way Titan X SLI">"Hi guys, I decided to share with you two cool videos. During these videos you can see raw performance of 3-way and 4-way Titan X SC at stock at crazy 10K resolution (10880x5760). Video has all the answers such to any questions including how I got such resolution and etc... Enjoy!"</post>
   <post id="f96769aa-f335-47ed-8c2b-0e6c2a1fffa7" section="Video Cards" discussion="Shadow of Mordor at 10K with 3-way and 4-way Titan X SLI">"Impressive resolution! If you have time and don t mind doing so, would you be able to post a comparison of Ultra setting results at the typical resolution intervals like 1080p, 1440p, 2160p, and 4320p so we can see how tri-SLI scales across resolution increases?"</post>
   <post id="d7efb5a2-81c3-456f-aea6-bcc9c55cf421" section="Video Cards" discussion="Shadow of Mordor at 10K with 3-way and 4-way Titan X SLI">"DejaWiz said: ↑ Impressive resolution! If you have time and don t mind doing so, would you be able to post a comparison of Ultra setting results at the typical resolution intervals like 1080p, 1440p, 2160p, and 4320p so we can see how tri-SLI scales across resolution increases? Click to expand... 3-way SLI does not scaled well at 4K, but god it does like gods at 8K and above. at 3-way it does like 3x times!!! and 4-way it is almost 4x times. Stay tuned@! iPlay4K, Peace! Love this forum."</post>
   <post id="23498d5f-807a-4231-9ea7-bd5da8056dc1" section="Video Cards" discussion="Shadow of Mordor at 10K with 3-way and 4-way Titan X SLI">"DejaWiz said: ↑ Impressive resolution! If you have time and don t mind doing so, would you be able to post a comparison of Ultra setting results at the typical resolution intervals like 1080p, 1440p, 2160p, and 4320p so we can see how tri-SLI scales across resolution increases? Click to expand... Yes, 2-way, 3-way and 4-way Titan X SLI vs Dual Radeon Pro Duo vs Geforce GTX 1080 in 1080,1440,2160 and 4320 is coming and I will post the videos on this forum when benches will be done. Stay tuned. Thanks."</post>
   <post id="8a28863b-e8a7-4352-a433-d863cacd9418" section="Video Cards" discussion="iPlay4K - my roadmap preview before GTX 1080 - do not miss yummy benches">"Dual Radeon Pro Duo crossfire vs 4-way Titan X SLI. GT80S Titan Laptop review from MSI Dual Radeon Pro Duo in 8k?"</post>
   <post id="8f25809a-ce97-4a9e-8965-0e3c896231a6" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"Ive got a Asus GTX980ti Matrix driving my 55" 4K monitor. I d like to set up my 2560x1600 monitor to watch streams, browse the forums, etc while I game on the 4K monitor. Nothing very graphically demanding but I don t want to sacrifice any of the 980ti s power away from the 4K monitor. I don t see running anything on the 2560 x 1600 more demanding than TWITCH or YT. Any recommendations for a small GPU for driving the 2560 x 1600 monitor?"</post>
   <post id="9342cc19-d327-4918-86f1-c59db7958146" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"380/380x and 7970/280x amd or Nvidia 960/950...i guess the 960 would be more beneficial for Nvidia physics games if they even still make those....looking at your sig you appear to already have a card to do it?"</post>
   <post id="893e67c1-2397-4ce6-b1fc-16175dcddb9e" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I really need to get in there and edit my sig, it s an old build. That being said I still have the 7970 as well as a pair of GTX 970 s, but I was looking for the  lightest  solution for driving the 2560 X 1600 for desktop apps (no gaming). I m afraid I didn t make that very clear in the op. I d planned on selling the 7970 and both 970 s but maybe I ll keep one of the 970 s, but it seems like overkill for what I need. Would something like a GeForce 210 work ASUS GeForce 210 DirectX 10.1 EN210 SILENT/DI/1GD3/V2(LP) 1GB 64-Bit DDR3 PCI Express 2.0 x16 Low Profile Ready Video Card - Newegg.com"</post>
   <post id="97541777-44cc-4234-8b5e-d366dcb8005d" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"what CPU are you using right now? if you any anything newer than sandy bridge, then.. why not just iGPU? it will be enough for your task."</post>
   <post id="53870845-2969-4189-a066-29caa2f4a20d" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I ve got a 4790k. Can you use the iGPU at the same time as the discrete GPU. I want to game on the GTX970/4K monitor, while using the 2560x1600 for YouTube. Would doing so sap any of the 4790 s processing power or is the iGPU completely seperate?"</post>
   <post id="f88ca5dd-d6a4-4fe8-8bd7-0cff087d2317" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"Just hook up the monitor to onboard video and turn on igpu. It s a completely separate graphics processor on the cpu so no real loss of processing power, some of your ram will be used for the igpu s video memory (i think you can adjust how much) and your cpu will run a little hotter. If you re over clocking you may have to redo your voltages."</post>
   <post id="7af73604-180b-44a7-ae81-c7a12b36d12f" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I think you d be just fine using it off the 980ti. I play games off my 290 at 3440x1440 and have a secondary 1920x1080 monitor running Netflix regularly and haven t noticed any difference."</post>
   <post id="522a6d3e-8aa0-4ac8-9071-3a68cc377f60" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"If it s not actually doing anything meaningful then yeah... like the others said just turn on the iGPU and plug it in there."</post>
   <post id="9f8080a7-255c-4323-9247-7669aee79fe9" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"Use the integrated graphics or buy a GT210 / similar GPU."</post>
   <post id="15c6d9d1-42ad-42b8-a0cf-7530e92ec9bd" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"DO NOT BUY A GT210 fuck sake. Anyone recommending that has not had to be tortured on a 2560 screen with one of them before. They can t even run aero, they lag and tear web browsing and can t play 1080p without lagging either. Either iGPU or 7970 for 10 bit support (assuming it s a 10 bit panel) and be done."</post>
   <post id="223494cd-ed65-4631-b7aa-cb755cd609a0" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"N4CR said: ↑ DO NOT BUY A GT210 fuck sake. Anyone recommending that has not had to be tortured on a 2560 screen with one of them before. They can t even run aero, they lag and tear web browsing and can t play 1080p without lagging either. Either iGPU or 7970 for 10 bit support (assuming it s a 10 bit panel) and be done. Click to expand... Thanks for the warning. I m just going to give the iGPU a shot. If it didn t work I ll most likely keep one of my 970 s. This brings up another question, is there any advantage to using the 970 as a physics card or is that basically a dead technology."</post>
   <post id="a770108d-3664-4169-8f28-25242023c421" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I would do it with a Raspberry Pi 3."</post>
   <post id="cde0b7ed-33b5-4e5f-a1a4-ca2107fcbf82" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"IMHO get a Chromecast or something else like that and use it, instead. I have three monitors, one on my 980ti, and two on the iGPU in my 4790K. When I play a video, either Youtube, Twitch, or local, on one of the monitors on the iGPU, not only does it use the iGPU but it also bumps up usage of the 980ti to 8-9%. May not sound like much, but trying to also play a 3D game on the main monitor basically turns it into a slideshow, even if the game can run without using the entire GPU to the fullest. Only really, really basic games don t seem to have any problems."</post>
   <post id="29d8bc3a-acfa-4c8b-8c62-d156c1d95039" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"As stated, you can and should simply use the IGP on your 4790k. That s how I have my 2nd monitors connected on boy my Sandy Bridge and Ivy Bridge boxes. You will need to use the display port output for that resolution, I don t believe Intel supports higher then 1080 or 1200p using DVI."</post>
   <post id="01ea1150-4f03-4509-85e6-efad6c91ae1d" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"RamonGTP said: ↑ As stated, you can and should simply use the IGP on your 4790k. That s how I have my 2nd monitors connected on boy my Sandy Bridge and Ivy Bridge boxes. You will need to use the display port output for that resolution, I don t believe Intel supports higher then 1080 or 1200p using DVI. Click to expand... Well that wouldn t be good, I m trying to use a 30" Apple ACD, no display port, just dual link dvi"</post>
   <post id="06239d03-a89c-4d2a-bc24-1daec0a6ca49" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"bobthfd said: ↑ Well that wouldn t be good, I m trying to use a 30" Apple ACD, no display port, just dual link dvi Click to expand... You can get a DP to Dual Link DVI adapter, you just cant run it directly off the DVI port on the board."</post>
   <post id="e5bb6575-6d92-48a8-bd98-4617ad037084" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I m still willing to give iGPU a try but I was digging around in a closet and found a pair of GTX460 s. I might throw one of those in, or would a 970 be a better option I terms of power usage and noise."</post>
   <post id="aea4f420-254e-45a6-9698-7bc67e31a68e" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"If it s not loaded (not being used for 3D stuff) it really shouldn t matter. Spending the money for a 970 for a secondary display that isn t used for intensive tasks makes no sense."</post>
   <post id="4e985cb1-dd26-497a-9b37-997af6d152ad" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"I ve already got the 970, actually a pair of them. Just debating keeping one of them vs selling them both. I ve never been good about selling old kit, but I ve got a pair of 970 s, a 7970, and a pair of 460 s sitting in a closet. Not sure which, if any should be repurposed and which should be sold"</post>
   <post id="530cd6e5-d2a1-4fac-8dbf-1ad8fa844336" section="Video Cards" discussion="GPU for 2560 x 1600 monitor">"You re still better off using the IGP. If you re not gaming you won t notice the difference and using either the 970 or 460 means more power then using the IGP as well as dropping your PCIe down to 8x on your primary video card. The benefit of using them is you can set them up as a dedicated PhysX card."</post>
   <post id="8fa0f846-44be-4d11-a0eb-c48d2c14afe9" section="Video Cards" discussion="Video card for dual 4k - no gaming">"Hi, I have a Dell T7910 workstation which I d like to attach a pair of 4k monitors to, it only has a single port card at the moment. Any suggestions as to a suitable card? I m not a gamer, I use the machine for VM s &amp; office apps. Thanks Rob"</post>
   <post id="a315b19e-00a0-4dd1-9fb0-22ad69c0379c" section="Video Cards" discussion="Video card for dual 4k - no gaming">"Slightly confusing because every card that ships with that Workstation has at least dual DisplayPort...but oh well. Okay, just get a GTX 950. There are several models with triple DisplayPort. This should work: EVGA GeForce GTX 950 02G-P4-2951-KR 2GB GAMING, Silent Cooling Gaming Graphics Card - Newegg.com You don t need a "professional" card unless you are running CAD programs."</post>
   <post id="8c0dbac4-9a12-4b48-9bc1-0cd8f7ed0117" section="Video Cards" discussion="Video card for dual 4k - no gaming">"Thanks for that, it was an outlet purchase in Europe which may explain the odd spec. Cheers! Rob"</post>
<post id="5b31921d-a90d-484e-9512-8b587f357a88" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"[H] has the true graphic whores like me, I want my shit to be crisp and playing on sharp, beautiful (flat) screens all my life. I can just imagine this huge drop in visual fidelity is going to be an issue for me, I ve read that it s easily forgotten about when you re actually immersed in a game. Is this the case? Or is it just not good enough?.. I mean i get it, GPU s just aren t up to snuff yet for these HMD s to be pushing out 4+k resolutions, even for most enthusiasts. There was no way around it. But is it so bad, that I should wait till the hardware is there? or is dropping $800 worth it at this point in time?"</post>
   <post id="20f4083d-9bf8-443a-9741-d73c88add834" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"From my experience with nvidia 3d vision it shouldn t be an issue since you are looking at things in stereo your brain does its own magic to anti alias things. I think the only things you would have issue with are fresnel lens flares and the small screen door effect. I game on a 4k display and I m not worried. Honestly you are gunna pay 800 for top of the line regardless of when. If you wait for then to bump up the specs I m sure the new high end model is going to cost that much."</post>
   <post id="c3c0a21b-3b6a-47f1-8278-e00c52583f87" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I ve used the dev rift and gear VR. Bad software bothered me alot more then the resolution. The visual different between alot of the software is huge also. Your gonna play some stuff and get eye strain or nausea, your not gonna care about the resolution much."</post>
   <post id="ec8d1244-5d8e-4192-94f3-3825cf220588" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I own the consumer Rift and just as evilgrin pointed out, resolution will be the least of your worries."</post>
   <post id="d541938b-8737-4795-81ea-d96cd3b1983a" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"evilgrin said: ↑ I ve used the dev rift and gear VR. Bad software bothered me alot more then the resolution. The visual different between alot of the software is huge also. Your gonna play some stuff and get eye strain or nausea, your not gonna care about the resolution much. Click to expand... My experience is the same. I have a DK1 (640 x 800 per eye) and my first reaction was that the jaggies were intolerable. But after a short while I ignored that and I was blown away from being inside a game world. I haven t tried the retail Rift or Vive, but now that they are at 1080x1200 per eye, I don t see resolution being an issue at all."</post>
   <post id="ed33aa0d-19d7-4808-aa21-25ec1ddfa953" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"Very interested in this as well. Especially experiences if you have better than 20/20."</post>
   <post id="dd87679f-ce4c-441d-acd2-9323d7847bd1" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"It will depend on the game. Most seem to be developed around the limitations, so in practice, the lower resolution won t be as apparent as it would be in a traditional game. When I m looking at stuff that s reasonably close to me in the game world it looks very sharp and detailed. It s when you re looking far out in the distance that things look somewhat blurry. So far I ve not really been bothered by the lower res, coming from a 3440x1440 monitor."</post>
   <post id="3ad24505-ab99-4195-9197-5fbe233b217a" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"BeavermanA said: ↑ Very interested in this as well. Especially experiences if you have better than 20/20. Click to expand... I m also interested in this. I have 20-10 vision and when I tried the DK2 I considered the resolution a deal breaker. But I didn t even use it for 5 minutes, maybe I could get used to it. After that I planned on waiting for future higher resolution models before I buy one. An interesting thought I had was if there was an eye exam type "game" where you could see how VR vision compares to real life vision."</post>
   <post id="ad6be372-e89b-42ff-9d1d-47106ddd3d50" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I wouldn t pretend I didn t notice it, but at least I had tried both dev headsets beforehand so it didn t come as a surprise. Of course I d love a sort of "retina display" headset, but you d probably be looking at something insane like 20k resolution. It is what it is. Games that aren t compromised by the resolution (less fine detail, like small text or whatever) do tend to be more effective. Honestly I would prioritise a higher field of view over resolution. I would like to try the StarVR and see how that feels. It s not that it s restrictive, since you just move your head to see more, but I think it limits the immersion. Unless you re playing something like TheBlu, where you can just pretend it s a scuba mask."</post>
   <post id="cb986fb6-0265-47fb-a8f2-6ee6b0b27b5f" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I can fully attest to the shell shock you will get if you have never put on a VR headset before and have no basis for comparison the first time you stick a Rift or Vive on your headset. The disparity of image quality of what you "expected" to see vs what you WILL see might even be greater if you are a graphics whore and have never put on a VR headset. It took be about 2 days to get over it. I have a 980 Ti, and the minimum recommended specs of a gtx 970 made my expectations pretty high. That said, the magic of VR is... it transcends all of that. After I accepted that the Rift s resolution is what it is, I had a blast. Last time I was this amazed and awe struck was when I played Quake for the first time on a Voodoo."</post>
   <post id="1fe02595-11ab-44de-9164-a5a537a105c6" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"Oscar Meyer said: ↑ Last time I was this amazed and awe struck was when I played Quake for the first time on a Voodoo. Click to expand... I remember where exactly I was standing in the map the first time I saw 1024x768. It was glorious. I am very much looking forward to my hardware finally getting here... one day."</post>
   <post id="b60e156e-839d-44e1-b782-82ef8d3e780d" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I got the vive yesterday. The resolution bothers me when i first put it on, and when I try to read text. When I am playing though I dont really notice it."</post>
   <post id="47570e3c-0667-4459-be28-fccd39a1c0f0" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"Laffles said: ↑ [H] has the true graphic whores like me, I want my shit to be crisp and playing on sharp, beautiful (flat) screens all my life. I can just imagine this huge drop in visual fidelity is going to be an issue for me, I ve read that it s easily forgotten about when you re actually immersed in a game. Is this the case? Or is it just not good enough? Click to expand... My eyes get so fatigued due to the low resolution and blurring of the Fresnel lenses. Even though I LOVE VR, I may sell the Vive as the low resolution is just too distracting. And this is still the case over ten hours use later."</post>
   <post id="a0b609c5-b7ab-42b3-85d0-87545bd7cae8" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I played with the Vive for about four hours on Friday and was never bothered by resolution in any of the games I played."</post>
   <post id="47c07141-bb97-4bda-9042-075892de7be8" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I spent about 20 minutes with a Gear VR via an S6. It felt like looking through a VHS camcorder. I ve no idea how the  real  rigs compare, but I wanted at least a factor of two increase in linear density."</post>
   <post id="66a46a70-fc17-47f3-9a7e-30a6dec09f0d" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I ve noticed something strange whilst using the Vive in desktop mode and moving some windows around. There seems to be quite a lot of pixels that aren t even visible when the visor is in a normal position. If I drastically pulled the visor up or down to a position you would never use, I could see pixels that you would never see in the normal position. This, combined with only central vision being "clear", really makes the device seem low resolution even though it has ~2.5 mil pixels. The clarity "feels" like 800x600 in each eye."</post>
   <post id="aea6be3f-b1f0-4464-bed2-27b27c3a9a33" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"alex_di said: ↑ I spent about 20 minutes with a Gear VR via an S6. It felt like looking through a VHS camcorder. I ve no idea how the  real  rigs compare, but I wanted at least a factor of two increase in linear density. Click to expand... VHS sounds about right. I think content developers for this first gen are going to have to rethink how they draw up graphical detail in these games. I find the games with the MOST graphical content, such as Eve Valkyrie, actually "look" worse than games with less graphical detail. It is because all those extra bells and whistles and minute detail in the distance actually make the blurriness even more distracting."</post>
   <post id="1bac9af2-c84f-4133-99bb-43ff1dcd2fc5" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"I find that if you are moving your head and doing things in vr, the resolution is great. The only problem comes from applications like watching a video or streaming static content on a screen in front of you through the hmd. Then the sde and resolution come into play more. I think this will someday be solved with 4k, but it really isn t much of a factor for VR games, especially on the Vive when so much of what you do is movement based."</post>
   <post id="f7bed332-9d55-403b-a429-16009acfdf8b" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"The resolution worries me, so I m currently playing through my backlog of 90s console/handheld games, to try and lessen the blow &gt;_&lt;"</post>
   <post id="48d8d459-2965-492c-a581-38d2a7d3a236" section="VR and Head-Mounted Displays" discussion="So, be honest, does the resolution bother you?">"The Gear VR for my Samsung Note 4 has a theatre mode and Netflix for movies. It s kind of amazing to look around at the theatre seats around you and hear the ambience. That said the resolution is low for movies but I tend to forget about it as the movie progresses. Do the PC VR systems have a theatre mode too? Any of you folks tried movies in VR?"</post>
   <post id="cf8ebac6-0741-4951-8aa9-4245b382ea5b" section="VR and Head-Mounted Displays" discussion="Starbreeze teams up with Acer to manufacture the StarVR headset">"Starbreeze partners with Acer for StarVR headset manufacture - Graphics - News - HEXUS.net I personally thought this VR headset would never make it into production, happily it looks like I was wrong."</post>
   <post id="88e960b4-c111-429f-9d7b-cfb8107df480" section="VR and Head-Mounted Displays" discussion="Starbreeze teams up with Acer to manufacture the StarVR headset">"Yeah, I expect a lot more other brands to pop up now that manufactures see that they can sell them for $500-$600 bux."</post>
   <post id="8a91264c-0e02-4dce-92ed-7dbf312723df" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"$600 vs $800 Rift store vs Vive store Seated vs 15 x15  The actual specs on both devices look similar, so I m thinking these are the biggest three differences. I want to make the plunge but I want to make sure I am plunking down the money on the right one for me. Is there much else to consider when comparing these two? My gut tells me just spend the extra 200 bucks and get the Vive. Does the Rift have any advantages for a seated experience or does the Vive pretty much perform the same in that area? Will vive users be able to purchase games from the Rift store?"</post>
   <post id="d266f49f-3915-43d8-9a99-b474be5970b1" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"That $200 difference is basically the Vive including motion controllers which the Rift doesn t. If you want to interact with stuff in a vaguely natural way, rather than with a regular xbox controller (included with the Rift) then that s a big thing to consider. If you re just doing seated stuff then it may not be an issue. Aiming down the sights of a virtual gun that you re holding in your hand is awesome, though. Cross-headset compatibility is a big question mark. Of course there s no technical reason you shouldn t be able to use either, like with video cards, it s just marketing."</post>
   <post id="813a721e-6ad2-433d-b83d-03bc8214a0b4" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"What games look most interesting to you? Don t forget about that.."</post>
   <post id="44db1dbf-3460-4735-b1b1-c441b983239f" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"Well, I have a HOTAS for games like Elite, and I have a FFB wheel for racing games and such. I see myself using a VR headset in a seated position for many games where you are in a  cockpit . For games like Elite or Project Cars, if both headsets are more or less equal for those types of games then I really think I d rather pay an extra $200 and have the ability to do the room stuff. I m leaning towards the Vive and ordering one tonight. For me personally I don t see why the Rift would be a better option outside of being $200 less, ~3 lbs lighter, and the possibility of the Rift store having some killer app that a Vive owner cannot play."</post>
   <post id="fc943418-d9b0-4666-8e1f-99e1302cc9e7" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"The Rift will have motion controllers as well, they just won t be out for a few months. I m still leaning towards the Rift as it has better FoV and is a lot more comfortable to wear. In 3 or so months when the motion controls come out I can look at what games are available and determine at that point if it s worth dropping another $200. I also like the look of the Rift controllers better. I highly doubt we will see true exclusives for either headset, especially after the Rifts controls come out. I do think that eventually movement based VR will be the way to go, I just don t see it leaving the "gimmick" phase in the next 3 years. I think developers are going to perfect the seated experience while in the process of figuring out how to make movement based VR work for real, full fledged games. For me I ll worry about all the movement stuff with the second generation of hardware but right now I just want good 3D, FoV and head tracking."</post>
   <post id="286216e1-4f3a-4bb3-99f8-0c5f65095bd4" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"Other considerations are The Vive weighs more (some reviewers didnt like this) and has more cables hanging off the back of your head. Vive is slightly higher res and has a slightly wider field of view. Rift is owned by Facebook and they have declared that you agree to be permanently connected to their servers for data collection on your physical stats and how you use your PC. If you develop anything that uses Rift, they give themselves the right to use it in full for whatever they want without any compensation and you cannot take them to court, only arbitration. I cancelled my Rift order after finding out that last bit, I cannot agree to spying and being cheated! I ve ordered the Vive but am not sure its worth going for the first gen."</post>
   <post id="54329428-f3b8-487f-83bf-c7f40558a4f7" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"Nenu said: ↑ If you develop anything that uses Rift, they give themselves the right to use it in full for whatever they want without any compensation and you cannot take them to court, only arbitration. Click to expand... So it s literally identical to the Steam platform s EULA in regards to community created content, right down to the arbitration restriction?"</post>
   <post id="ce0757b6-ff71-47ad-b1e2-3db6d199c8f7" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"Ryan7968 said: ↑ $600 vs $800 Rift store vs Vive store Seated vs 15 x15  The actual specs on both devices look similar, so I m thinking these are the biggest three differences. I want to make the plunge but I want to make sure I am plunking down the money on the right one for me. Is there much else to consider when comparing these two? My gut tells me just spend the extra 200 bucks and get the Vive. Does the Rift have any advantages for a seated experience or does the Vive pretty much perform the same in that area? Will vive users be able to purchase games from the Rift store? Click to expand... Yeah, the Vive apparently has a wider FOV, although it also has this radial glare from the lenses that the Rift doesn t: Also at launch at least, the Rift will be able to run more games, since aside from the Rift store, it can run SteamVR games also, plus Vorpx and vireio don t work on the Vive, only the Rift. I m personally holding off until things mature a little more since both seem like flawed launches."</post>
   <post id="dc40992e-8f9a-4c27-87d5-baed51e5873b" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"I was pretty set on the Rift until I watched some of the Giant Bomb Vive stuff and now I m completely torn again."</post>
   <post id="6368110e-d96f-4553-b804-ec7810727c5a" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"I really think that the Rift is a much more practical device. The Vive is over-reaching. I am not setting up a special room for VR. Sure, some people will be more than happy to. I don t want my games confined to the size of my room anyways. Using the type of controller I already use in conjunction with a 3d headset just seems like a much better idea. I read before that these two devices want to be friendly with each other in regards to locking in exclusivity and Valve allowing Oculus games on Steam; is this still true?"</post>
   <post id="bfe5f7fa-9a77-4ee3-8336-8afd00ea534f" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"atom said: ↑ I really think that the Rift is a much more practical device. The Vive is over-reaching. I am not setting up a special room for VR. Sure, some people will be more than happy to. I don t want my games confined to the size of my room anyways. Using the type of controller I already use in conjunction with a 3d headset just seems like a much better idea. I read before that these two devices want to be friendly with each other in regards to locking in exclusivity and Valve allowing Oculus games on Steam; is this still true? Click to expand... It appears to be. Games on Steam will actually let you know which headset it s compatible with and it seems most are compatible with both."</post>
   <post id="0112bccc-e2f5-4f56-b303-dda458147a59" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"It really comes down to whether you ever want to do roomscale vr in the future and how you feel about closed ecosystems,. You can make arguments that either hmd is better optically as they both have pros and cons. Personally, I don t like rifts policy on its walled garden or information collection. I have both on order though I will end up keeping only 1."</post>
   <post id="65d15bcb-cf7c-4449-90ce-3ee432268b15" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"So you cant use the Rift standing up?? I read somewhere that, there is like a "seated" mode for the Vive?? is that true?"</post>
   <post id="def7215f-7084-471c-9986-c80dfb0753a8" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"After two days with the Vive, I can honestly say VR is extremely underwhelming without motion controls. My play area is on the small side (2m x 2m), though I had fun playing most of the games standing still. Unless money is a concern, I really don t understand why someone would buy the Rift over the Vive."</post>
   <post id="269be152-8b9c-49f3-a5a0-39eb78524030" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"I went with the Vive. Order has been placed, not sure when I can expect delivery but probably at least a month out. I m sure I d have been happy with the Rift, but since the specs on the headsets are so similar it really came down to getting room scale and the controllers for 200 more. It s nice that we have options, and with the weight of the companies pushing this tech I am confident it will be getting plenty of love on the software side."</post>
   <post id="2e184451-1816-417f-9519-d550e9d57808" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"grifter_66 said: ↑ I m still leaning towards the Rift as it has better FoV Click to expand... Are you sure about that?"</post>
   <post id="a0a2d6eb-bf32-4735-9155-b00373af13e8" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"s3rvb0t said: ↑ Are you sure about that? Click to expand... While the Rift, in fact, does have a slightly smaller FOV compared to the Vive, it isn t quite as big of a difference as that image would lead you to believe. Bottom line, though, is that if the FOV is a huge factor for you then the Vive slightly edges out the Rift. BTW I received my Vive yesterday and used it for 2-3 hours. Loving it and the room-scale, this coming from someone that thought the Rift was going to be for me. I still have a Rift on the way, but may just sell it. I will say that it is a bit of a pain to use the separate headphones, but I think I can get used to it. Having room-scale and tracked controllers right now is absolutely amazing. Also, those fresnel ridges disappear when in use. The only time you might see them during normal use is when the bright on dark background situations appear and you get the glare (which is on both Rift and Vive). On the Vive, the glare takes on some of the geometry of the fresnel ridges."</post>
   <post id="d497b8e1-2dbd-4c97-859a-0e1414deeafb" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"s3rvb0t said: ↑ Are you sure about that? Click to expand... Yeah, I got my specs mixed up. I really want to play Eve Valkyrie but the custom launch "games" for the Vive look much better. I think I ll be cancelling my Rift order and save a bit longer for a Vive."</post>
   <post id="39f006d2-f294-40fb-9efb-e7193247f25a" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"tetris42 said: ↑ Yeah, the Vive apparently has a wider FOV, although it also has this radial glare from the lenses that the Rift doesn t: Also at launch at least, the Rift will be able to run more games, since aside from the Rift store, it can run SteamVR games also, plus Vorpx and vireio don t work on the Vive, only the Rift. I m personally holding off until things mature a little more since both seem like flawed launches. Click to expand... While the vive might have some fresnel glare the rift has some wierd issue with crupescular rays (God rays) on text and high contrast areas that is reported to be highly annoying. Also, there is less tolerance with the rift for vertex distance from your eye, meaning fov gets hit harder the further your eye is from the lens, that s important to someone who wears glasses or has long eyelashes."</post>
   <post id="c916ccae-233b-48f4-b0f0-ae59f52858e7" section="VR and Head-Mounted Displays" discussion="Rift vs Vive">"Chaos Machine said: ↑ While the vive might have some fresnel glare the rift has some wierd issue with crupescular rays (God rays) on text and high contrast areas that is reported to be highly annoying. Also, there is less tolerance with the rift for vertex distance from your eye, meaning fov gets hit harder the further your eye is from the lens, that s important to someone who wears glasses or has long eyelashes. Click to expand... Yeah, I m waiting for more reports like these. I don t care about motion controls, I care about game compatibility and display quality, so I d love to see more user comparisons between the two come out."</post>
   <post id="51d41dde-7e85-47cc-979c-76339a33e7b5" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"On May 7, Intel and Oculus will unveil the first retail demo of Oculus Rift, giving people an opportunity to try out the long-awaited virtual reality headset, connected to an Intel-powered PC. The demo will take place in 48 Best Buy locations nationwide, exclusively those with The Intel Experience – a dedicated in-store zone that showcases the latest emerging technologies and amazing experiences that Intel brings to life. Currently, Intel® Core™ i5 and Core i7 processors are the only processors that meet Oculus’ recommended specifications for the full Rift experience, which renders realistic images and natural interactions."</post>
   <post id="fb1bcc4b-1725-44b4-846f-21b78442cda4" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"So they ve got enough units to roll out to show at Best Buys all over the country and even sell at retail in limited quantities but if you ordered one direct you re likely still waiting for it. Nice middle finger you ve got there, Oculus."</post>
   <post id="d6a1bcf9-57b9-4c42-9a29-f444da031ee3" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Disclaimer: If you are feeling sick after 10 minutes of use, please vomit in one of the 4 cans placed around the display. This is stupid."</post>
   <post id="ac4adf24-9aab-49e1-8c5d-f4d191eb1e4c" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Dwango said: ↑ So they ve got enough units to roll out to show at Best Buys all over the country and even sell at retail in limited quantities but if you ordered one direct you re likely still waiting for it. Nice middle finger you ve got there, Oculus. Click to expand... Yup. Mine isn t slated for shipment until the 9th-19th (ordered 12 minutes after launch). I ll probably just try to get one from BB or Amazon and cancel my preorder. Oculus Rift Hits Stores This Weekend, Some Still Waiting on Pre-orders - IGN"</post>
   <post id="538f5db6-b6e7-43bc-a0cd-0ab69d8da876" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"My face is ready..."</post>
   <post id="eb5706d4-29bb-4278-82cc-890c686b535f" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Since they are screwing over the pre orders don t expect any real support or service. I got two words for Occulus Rift one starts with F and the second one ends with u. VR is just another worthless fad anyway....."</post>
   <post id="cf0393e3-4163-44d2-a495-813022fdf5e1" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Youn said: ↑ My face is ready... Click to expand... lol. May the fever blister sharing begin."</post>
   <post id="7bf328cd-ad61-4ae4-a1cc-0453d4bb024d" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"zalazin said: ↑ Since they are screwing over the pre orders don t expect any real support or service. I got two words for Occulus Rift one starts with F and the second one ends with u. VR is just another worthless fad anyway..... Click to expand... Here is my ETA as of this morning. Order Status Pre-order Tracking # (TBA when your order ships) Order # 6130000XXXXX Estimated Ship Date 7/25/2016 - 8/4/2016"</post>
   <post id="ecc89439-c1cb-486e-9464-09d068ff712e" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Kyle_Bennett said: ↑ Here is my ETA as of this morning. Order Status Pre-order Tracking # (TBA when your order ships) Order # 6130000XXXXX Estimated Ship Date 7/25/2016 - 8/4/2016 Click to expand... Looks like a Groupon."</post>
   <post id="a88cbec6-3f86-40ce-9f15-d11ea3728598" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Nukester said: ↑ Looks like a Groupon. Click to expand... Not really sure what that means since I think I have not ever used a Groupon."</post>
   <post id="60804809-5376-47a7-971e-781941da912c" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Kyle_Bennett said: ↑ Not really sure what that means since I think I have not ever used a Groupon. Click to expand... Mainly just vague. Don t really feel like it s a solid communication."</post>
   <post id="81bfc6eb-e0a5-49c0-96c8-286987fe6c55" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Nukester said: ↑ Mainly just vague. Don t really feel like it s a solid communication. Click to expand... Well, FWIW that was just a cut and paste off the Oculus Order History page, there is a lot of other information there."</post>
   <post id="01d7bb39-81d9-4e3c-b920-7fc18bfa68fa" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Kyle_Bennett said: ↑ Well, FWIW that was just a cut and paste off the Oculus Order History page, there is a lot of other information there. Click to expand... Did you order for reviewing or for yourself? Are you not concerned about the time limitations of wearing this before starting to feel ill? I remember the when the shutter glasses came out for nVidia. I got suckered into that. They made me sick."</post>
   <post id="cfcf29bb-42cf-44d7-9f6b-846b30588920" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Nukester said: ↑ Did you order for reviewing or for yourself? Are you not concerned about the time limitations of wearing this before starting to feel ill? I remember the when the shutter glasses came out for nVidia. I got suckered into that. They made me sick. Click to expand... Reviewing - Yes - Yep"</post>
   <post id="793ce78b-cc27-437a-ab3a-161a89c79a52" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Just got my rift yesterday evening. Had a few hours with it. It s definitely a mixed bag. Not surprising as it s first gen. Project cars is all kinds of awesome with a steering wheel + pedal setup. i m going to see if I can further tweak gfx settings though as I just used it as is. I felt my titan-x was being under utilized . I need to get my hotas properly setup for ED before jumping to far into it, but I want to try that out. I had problems with eve valkyrie and constant ship spinning, but I suspect it s because my rudder pedals were plugged in and eve has no control options I could find. Stupid non customizable game. It sure looks perty though. Now the unfortunate part of all of this is I have a Vive coming in tomorrow. I ordered the Vive because of the constant delays with the rift. I logged into cancel my vive order yesterday after my oculus experience and saw the tracking number... Anybody need a vive in the austin area? . On actual topic, nothing really surprising they are doing with putting them in retail stores with pre-orders still behind. People will be angry, but companies do this all the time with launch day in store sales and pre-orders being separate."</post>
   <post id="d220cb53-83c9-4d72-b55c-e6bdbf609557" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"Dawill said: ↑ Just got my rift yesterday evening. Had a few hours with it. It s definitely a mixed bag. Not surprising as it s first gen. Project cars is all kinds of awesome with a steering wheel + pedal setup. i m going to see if I can further tweak gfx settings though as I just used it as is. I felt my titan-x was being under utilized . I need to get my hotas properly setup for ED before jumping to far into it, but I want to try that out. I had problems with eve valkyrie and constant ship spinning, but I suspect it s because my rudder pedals were plugged in and eve has no control options I could find. Stupid non customizable game. It sure looks perty though. Now the unfortunate part of all of this is I have a Vive coming in tomorrow. I ordered the Vive because of the constant delays with the rift. I logged into cancel my vive order yesterday after my oculus experience and saw the tracking number... Anybody need a vive in the austin area? . On actual topic, nothing really surprising they are doing with putting them in retail stores with pre-orders still behind. People will be angry, but companies do this all the time with launch day in store sales and pre-orders being separate. Click to expand... Did using the device for extended periods make you feel a bit sick?"</post>
   <post id="f4eb9233-25a7-4b55-996f-a92a93b84c4b" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"3d tv s google glass smart watches annnnnd"</post>
   <post id="9381a762-466c-452e-aae2-78e7eea85a4c" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"P4B said: ↑ 3d tv s google glass smart watches annnnnd Click to expand... Enough already! Until you ve personally experienced a Rift or a Vive, you are spouting uninformed nonsense. Seriously. I got the Vive just last week (Rift is due in another week or two) and this isn t going away and it isn t a fad. It s MIND BLOWING as to what this tech does. It s definitely Gen 1, but it is here to stay. It is only going to improve as the tech advances, but this shit is real! Trust me on this."</post>
   <post id="8eee83d4-1a51-4301-8e1a-c2b7c755645e" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"They mentioned it would be available at retailers at the same time they said pre-orders are live:https://www.oculus.com/en-us/blog/oculus-rift-pre-orders-now-open-first-shipments-march-28/ I m in the same order group as Kyle though I did not order one until March 1st. I didn t feel sick using the Vive at all until I played Windlands. I had been playing for a few hours at that point and that game is rough vertigo wise."</post>
   <post id="b104609f-8187-4ec1-8622-bec27379d35c" section="VR and Head-Mounted Displays" discussion="Intel and Oculus Bring Virtual Reality Experience to Best Buy Stores across the US">"I ordered a Rift the second day of preordering. No clue when it s due. I bought it for combat flight simulators. Now I see that Vega is not exactly overjoyed with the flightsim experience and I m having some doubts. I m going to check the Rift out when it comes to a Best Buy near me. If I m not happy with how it fits with my glasses or the resolution I ll cancel my preorder. Next gen will mostly go wireless and fix most of the ergonomical gripes people have with the Rift and Vive."</post>
   <post id="f69133f5-a268-4eb8-833b-66995fedf79f" section="VR and Head-Mounted Displays" discussion="VR BOX for LG G4 compatibility">"Hi all, I just purchased LG G4 and I am looking for a decent VR headset. I was thinking buying this one: VR BOX 2.0 Cardboard VR Virtual Reality 3D Glasses I m just don t want to spend money on a vr headset that will not fit. I know it is fit for up to 6Inch phones, just asking, did anyone here tried this headset with the LG G4? (5.7 Inch) Thx"</post>
   <post id="be9e73c4-60ca-4183-b391-97b36484551d" section="VR and Head-Mounted Displays" discussion="VR BOX for LG G4 compatibility">"As a reminder, these other headsets are merely slightly-better-built Cardboards. There is nothing specifically good about them. If you re going to buy one, get as high quality as you can, like the zeiss headset. Just comparing it, it seems to be a little bit better for quality (price is same as the Gear)."</post>
   <post id="587458fe-2c12-4793-8ecd-e80b733cf815" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"Well, I ve gotten a few questions from folks on how I built this, so I thought I d post a few more pics and share some info. Here s the completed Sim Chair: Not counting the HOTAS, wheel and pedals, it cost just under $500 to build. Got the leather seat from a local pick-n-pull junk yard out of a Volvo v70 ($19) Cannibalized a GT Omega Stand I ordered for the wheel mount ($149) Used 2 square metal Ikea table legs I cut down to build the throttle/joystick stands ($20) Used parts from an Ikea chair frame for the arm rests ($50) Installed a Dayton Audio SA100 100W Sub Amp from Parts Express ($85) 2 AuraSound AST-2B-4 Pro Bass Shaker Transducers from Parts Express ($80) 4x4s, 2x4s, plywood, stain, caster wheels and assorted hardware from Home Depot (~$85) Cut up a cheap black door mat, also from Home Depot, for the flooring ($6) Also re-purposed an old 12V supply I had in a closet to power the chair adjustment motors Took a couple of weekends to put it all together and stain it. A few more pics of the "in-process" build and the completed chair: I think it came together nicely! Getting in and out of it is a bit of a pain, but not too difficult. Everything is extremely solid - all the controls feel great, with no sway or wobble at all. The chair also adjusts forward quite a bit, so my kids can easily reach the pedals (oldest is 10), so they are going to learn to drive in VR well before getting learner s permits in about 5 years. Luckily this sucker is in my basement man cave, so it didn t need wife approval before entering the house."</post>
   <post id="edd8cde3-dcd6-4310-8bcc-fdc239aabeda" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"you swing the steering wheel up and away to get it, or "jump in it"?"</post>
   <post id="dd4c8359-04c3-4f44-b5da-21c07f23ed96" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"That is very cool, wow. I love how you can actually use the car seat controls to adjust things. I ve seen where people will repurpose actual car seats for projects like this but it never occurred to me that you can power and use the car seat controls."</post>
   <post id="85b385da-5b87-4dc9-8134-31d5df9b4822" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"Youn said: ↑ you swing the steering wheel up and away to get it, or "jump in it"? Click to expand... It looks fixed. He jumps over the seat like BATMAN."</post>
   <post id="2ea1f4d4-d144-404e-86e9-f69901f5d9e3" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"I didn t notice the castors before, that s handy. Now you just need to motorize it so you can drive the whole thing around."</post>
   <post id="487dabbd-e050-4458-a89e-907e3b30e4a6" section="VR and Head-Mounted Displays" discussion="VR Sim Chair build for Vive/Rift">"Ryan7968 said: ↑ That is very cool, wow. I love how you can actually use the car seat controls to adjust things. I ve seen where people will repurpose actual car seats for projects like this but it never occurred to me that you can power and use the car seat controls. Click to expand... Yup, really allows for lots of adjustment to include lumbar - trick is to score a seat out of a higher end wreck. :-p Dayaks said: ↑ It looks fixed. He jumps over the seat like BATMAN. Click to expand... Pretty much this. I am BATMAN! I did consider using some sort of hinge setup, but it would have over-complicated things and I wanted to keep the mount clean and as solid and wobble free as possible."</post>
   <post id="5e82b3bf-01d2-4069-9afe-93b95ff810f6" section="VR and Head-Mounted Displays" discussion="Gear VR - Worth the Limited Experience?">"I m sure it s been asked a million times on this forum, but my wife told me I m just throwing away money. Can you guys that have used it give me some ammunition to use on her to throw away $100 on this?"</post>
   <post id="fc811945-8c8e-482d-b63d-ddd0bb462843" section="VR and Head-Mounted Displays" discussion="Gear VR - Worth the Limited Experience?">"After trying the Rift at Best Buy I can safely say that, wow, glad I only paid $100 for a similar experience."</post>
   <post id="fdd5fb35-5474-4125-bc15-f09fac9a863e" section="VR and Head-Mounted Displays" discussion="Project Cars. Rift vs Vive. (Video)">"Here is a video where the commentator discusses Project Cars on the Rift vs The Vive. Seems that both had their pros and cons, but he definitely favored the Vive in the end because it was simply more vibrant to him. He also thinks that the asynchronous time warp feature of the Rift benefited lower spec computers than really fast ones. I thought it was well done and that it may help some make that choice of which to go with in the end. Vega Time to get that wheel stand and cockpit to go with that (3) 8 pin power GTX 1080."</post>
   <post id="86b8b912-7d96-4485-9e32-f5902c569ce6" section="VR and Head-Mounted Displays" discussion="Project Cars. Rift vs Vive. (Video)">"Really LOVING Project Cars right now! The latest patch update really rocks with the Vive. Also works great with the sim chair project I just completed yesterday: Also have a Rift arriving next week, which to be honest, was really why I built the chair.... for Elite Dangerous. Decided to throw some pedals and wheel into the mix just for grins and now I m glad I did! I know, no stick shift, put the wheel has paddles at least. I scored a very nice powered leather car seat from a Volvo v70 for just $19 at my local pick-n-pull junk yard and hooked it up to a spare 12V supply I had sitting around and voila, fully built-in seat adjustment - all the seat motors work perfectly! Home Depot for the wood/hardware to frame and mount everything and dropped in a couple AuraSound Pro Bass Shakers and a sub amp from Parts Express for some low end rumble/vibration effects. Anyway, VR and sims are a match made in heaven!"</post>
   <post id="2eeb512b-bc4c-4087-9bfc-b292996409e2" section="VR and Head-Mounted Displays" discussion="Project Cars. Rift vs Vive. (Video)">"That is a pretty awesome setup, surprisingly compact for what it offers. I m sure you can figure out a way to get a gear stick in there somehow, although at least there are paddles. I would really like to try some driving stuff, but my old wheel is in a box in a garage on the other side of the world. So I have to make do with my daily dose of dogfighting around asteroids in Elite."</post>
   <post id="2a032503-8523-4eb3-a25d-8a501cd43d6a" section="VR and Head-Mounted Displays" discussion="Oculus CV1 Calibration">"Anyone have tips for calibrating this thing? Couple specific items that are troubling me so far: 1. It seems like in some apps/games I really have to crank my neck and head upwards to actually be able to see things. I looked into this a bit and I guess it s because those apps/games assume you are standing. and I m usually sitting? When I run through the initial calibration with the sensor and whatnot, should I be standing or sitting? Should the height value be my standing height or sitting height? It s all very vague and I m surprised there s not separate instructions for each. 2. No matter what I do I cannot get the green horizontal and vertical lines clear. It seems like I can get the outside ends of both clear, or one or the other, but not the entirety of both. Is it even possible or am I just trying to perfect it too much?"</post>
   <post id="3e1ffa9c-ed95-4d4e-af3e-7d4a728fd860" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"Google is reportedly announcing a standalone Android VR headset next week Looks like a Samsung VR competitor, probably a simple housing that you pop your phone into."</post>
   <post id="2f5eca77-7a7d-4e30-879c-50393c1bc6d9" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"Thought that was second generation cardboard VR there for a second..."</post>
   <post id="c4143a42-edff-4535-889e-043e3b8b8309" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"Standalone"</post>
   <post id="11c9ce6d-a7c6-433c-9c81-b93c4e73dca1" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"Gatecrasher3000 said: ↑ standalone Click to expand... Gatecrasher3000 said: ↑ probably a simple housing that you pop your phone into Click to expand... So which is it then? These things are opposites."</post>
   <post id="8296d696-d7bd-493e-8603-41c4174a1c42" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"Im just quoting the story man, Im guessing it will be something similar to the Samsung VR headset."</post>
   <post id="931e5302-f734-46cd-897b-aa8bbed56ed0" section="VR and Head-Mounted Displays" discussion="Google is reportedly announcing a standalone Android VR headset next week">"According to the article, and all those tweets, it is a standalone unit, NOT like Samsung Gear VR"</post>
   <post id="0ab80a04-5f79-4738-b042-79d70289caf1" section="VR and Head-Mounted Displays" discussion="some questions after a Vive demo">"I recently went to a Microsoft Store to get their demo of the Vive, 10 minutes isn t exactly much time to get a good feel for it, but alas I don t know anybody with a Vive so I could get a longer demo. I have some questions about the tech. I was really excited for VR, especially after reading about how the SDE and resolution has gotten to the point where it isn t really a problem, but the experience makes me think the tech it isn t ready yet. First off, oh god the pixels, they were HUGE. Trying to look at anything smallish (fish in TheBlu, drones that weren t right up in your face in SPT, even the controllers held at arms length) was just maybe a dozen of those huge pixels, with giant gaps from the dark sub-pixels. Thanks PenTile, doing such a good job at making a high-res screen look low-res. I hated you on my phone when the screen is only 4" and held at arms length, now that same awkward sub-pixel arrangement is filling my vision. I understand there is nothing to be done here except wait another generation or four for the resolution to increase. I understand that the Vive uses a "low-persistence" display, but I haven t been able to find what rate it strobes at. Is it 90Hz? To me everything had a sort of flickery ethereal quality to it instead of looking solid. It reminded me a lot of looking at a CRT. Are there any HDM adjustments that affect the scale of things? Everything looked too small to me, from the controllers to the whale. When the person giving the demo held the controllers up to me I was initially confused as I thought they were standing too far away for me to reach the controllers, so I didn t do anything until they told me to grab them. The FOV and focus looked good, tracking was flawless. Being able to move around to dodge things was fun. The image tricked my brain enough that when I stuck my hand into some geometry I got a weird sensation in my hand."</post>
   <post id="5ac59797-6f4b-4fc5-ad65-2e95bddf1d80" section="VR and Head-Mounted Displays" discussion="some questions after a Vive demo">"stephen2002 said: ↑ . I understand there is nothing to be done here except wait another generation or four for the resolution to increase. Click to expand... Yes, you have to remember that not only the screen is right at the front of your eyes but the lens magnify them. Also, the pentile subpixel arrangement brings lots of goodies too, not only problems. The main problem is the dark space between pixels matrixs and the pixel density. We need at least 4k per eye. That would be like looking to a 1080p monitor. But we really need MUCH MORE, like 16k per eye. stephen2002 said: ↑ Is it 90Hz? Click to expand... 90hz stephen2002 said: ↑ Are there any HDM adjustments that affect the scale of things? Click to expand... Yes, Inter pupilary distance (IPD) and eye relief (the distance between your eyes and the actual lens) can be modified as every person have them differently."</post>
   <post id="0105bc17-ed8a-4c5f-bc96-76dcd8abd749" section="VR and Head-Mounted Displays" discussion="some questions after a Vive demo">"stephen2002 said: ↑ First off, oh god the pixels, they were HUGE. Trying to look at anything smallish (fish in TheBlu, drones that weren t right up in your face in SPT, even the controllers held at arms length) was just maybe a dozen of those huge pixels, with giant gaps from the dark sub-pixels. Thanks PenTile, doing such a good job at making a high-res screen look low-res. I hated you on my phone when the screen is only 4" and held at arms length, now that same awkward sub-pixel arrangement is filling my vision. I understand there is nothing to be done here except wait another generation or four for the resolution to increase. Click to expand... Sorry you feel that way man! I haven t noticed it being an issue at all, for me, I only notice it when I am looking for it or there isnt anything going on in the game or during a loading screen. For me the issue is the lenses needing work, also the strap with integrated audio needs a solution too, because FUCK its a hassle."</post>
   <post id="cf58e043-ccba-416f-af45-fc7545f5332b" section="VR and Head-Mounted Displays" discussion="some questions after a Vive demo">"DouglasteR said: ↑ Yes, you have to remember that not only the screen is right at the front of your eyes but the lens magnify them. Also, the pentile subpixel arrangement brings lots of goodies too, not only problems. Click to expand... The resolution seemed worse than standing a few feet away from a 90" screen lit up by a 720p projector. I was expecting it to be low-res but I wasn t expecting it to be that low. Goodies? What is the advantage of PenTile? The only ones I ve seen quoted are lower cost and lower power for a given resolution, great for a cheap phone, bad for a headset. The trouble is if you want to display something that is red or blue you only get every other pixel to do so, cutting the resolution in half, since the only subpixel that is present for all pixels is green. Seems like throwing away so much information is a terrible idea for a HMD."</post>
   <post id="9b3a5fd2-d4a4-4f61-9492-707ecf905f32" section="VR and Head-Mounted Displays" discussion="some questions after a Vive demo">"Being the optimist; keep in mind this is the first generation of this iteration of VR. All past iterations were vastly inferior. Is it perfect? No, hardly. What is needed? Well, they said it; 4K per eye to start. The answer is going to be very dense OLED panels for this; we are still waiting on this tech. Also; prices are on the high side right now. There are more companies in entering the fray with their on VR and many see the limitations of the current front runners and will try to do it better. So really taking a long view of this tech is a wise move."</post>
   <post id="a9dad43a-5aa3-4c44-8919-87c0b7c560be" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"After messing around with various versions of the device in the past, the crew at HotHardware have finally published their thoughts and impressions of the retail version of the HTC Vive VR kit. Overall a positive review. We had experience with multiple versions of the Vive throughout its development cycle, but we thought playing with the retail version for only a few days wasn’t enough time to truly understand it, so we held off on making any final recommendations. We have, however, worked with the Vive for a number of weeks at this point, experimented with a slew of software and applications, and gave a handful of interested third-parties some time inside the Vive as well and think we’ve got a firm grasp of the situation."</post>
   <post id="e184538d-a661-450d-ba6a-0231ae2e34ea" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Sad that PAX East is like the only place I know of where I could test VR equipment and I wasn t even able to attend this year! Super bummed. But, maybe when it s more commercially accepted and adopted by consumers, retail stores will have some to test out...and grubby, grimy, disease infected headbands...which thankfully won t be simulated! LOL"</post>
   <post id="bc1af1d3-12b5-44f6-86fb-266b3297cbf4" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"There are some excellent qualities with the Vive, the motion tracking is excellent, the tracked controllers work very well - Rift needs these now!, room based movement and the alert system is perfect imo. But the optics are a beta product. Only the very centre of the view is focused, the rest of it is blurred, and not the same for each eye. It is extremely annoying and unpleasant. Because it is front heavy, it has to be strapped on quite tightly. But because different parts of a game or util require you to focus in different places, you end up either needing to have an elastic neck to look at exactly the right place or adjust the position of the headset on your head so your eyes focus on a different place. This isnt so easy when its tightly strapped on. Being so tight it leaves marks on my face that take some time to go away so I have to be careful when I use it. Not that this matters much because I now strongly dislike using it. Further issues. You can clearly see the fresnel rings. The FOV is wider than the Rift making the screen closer to your eyes. This makes it easier to see individual pixels and even the RGB elements! Not a good thing. Its not easy to read text because it only focuses on a small area in the centre. You have to look straight ahead and move your head to track the words. This is very annoying when you want to quickly see a message or read something in the game environment. The res is so low that the lack of focus has a serious impact. There are other trickier situations where you have to zoom out to get adequate focus on something in the corner that doesnt move with your head. Their are strong streaks wherever there are light/dark elements. These also seriously impact the ability to read anything off centre. It hurt me to wear the headset for more than 1/2hr due to how tight it needs to be fitted. The earbuds dont fit in my ears very well and keep falling out. Inserting them can get painful. I tried Elite Dangerous and its broken on the Vive. The image is jagged edged, it looks messy. Nothing like the reports coming from the Rift owners who are overjoyed with the experience. I looked online for help and found that multiple threads about the problem are running because others have the same problem. There is a promise it is being looked into but I didnt find any information that suggested they have a true handle on why its so bad. My experience of their support is terrible. Its taken them a week to respond to the 3 messages I sent and they ignored everything I said and gave me a generic email, so still no progress. They insist you respond to them using a web interface with limited number of characters that are not enough to explain the issues. This was an insult because I spent ages reducing my support request into something that could fit in the limited space, they took a week to respond and paid no attention to it. Overall I am shocked at the state of the Vive. Its not ready for release, its a beta product due to the optics and how uncomfortable it is. And their support appears to be in beta as well. I have used my friends Rift and it is light, comfortable, easy to use, has a much larger area of focus, doesnt have streaks all over the image, has great headphones that dont need to be inserted in your ear... It is much better yet cost £250 less !! Sorry."</post>
   <post id="b7b4f255-a808-4f83-9d43-83e5af62b733" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Nenu said: ↑ There are some excellent qualities with the Vive, the motion tracking is excellent, the tracked controllers work very well - Rift needs these now!, room based movement and the alert system is perfect imo. But the optics are a beta product. Only the very centre of the view is focused, the rest of it is blurred, and not the same for each eye. It is extremely annoying and unpleasant. Because it is front heavy, it has to be strapped on quite tightly. But because different parts of a game or util require you to focus in different places, you end up either needing to have an elastic neck to look at exactly the right place or adjust the position of the headset on your head so your eyes focus on a different place. This isnt so easy when its tightly strapped on. Being so tight it leaves marks on my face that take some time to go away so I have to be careful when I use it. Not that this matters much because I now strongly dislike using it. Further issues. You can clearly see the fresnel rings. The FOV is wider than the Rift making the screen closer to your eyes. This makes it easier to see individual pixels and even the RGB elements! Not a good thing. Its not easy to read text because it only focuses on a small area in the centre. You have to look straight ahead and move your head to track the words. This is very annoying when you want to quickly see a message or read something in the game environment. The res is so low that the lack of focus has a serious impact. There are other trickier situations where you have to zoom out to get adequate focus on something in the corner that doesnt move with your head. Their are strong streaks wherever there are light/dark elements. These also seriously impact the ability to read anything off centre. It hurt me to wear the headset for more than 1/2hr due to how tight it needs to be fitted. The earbuds dont fit in my ears very well and keep falling out. Inserting them can get painful. I tried Elite Dangerous and its broken on the Vive. The image is jagged edged, it looks messy. Nothing like the reports coming from the Rift owners who are overjoyed with the experience. I looked online for help and found that multiple threads about the problem are running because others have the same problem. There is a promise it is being looked into but I didnt find any information that suggested they have a true handle on why its so bad. My experience of their support is terrible. Its taken them a week to respond to the 3 messages I sent and they ignored everything I said and gave me a generic email, so still no progress. They insist you respond to them using a web interface with limited number of characters that are not enough to explain the issues. This was an insult because I spent ages reducing my support request into something that could fit in the limited space, they took a week to respond and paid no attention to it. Overall I am shocked at the state of the Vive. Its not ready for release, its a beta product due to the optics and how uncomfortable it is. And their support appears to be in beta as well. I have used my friends Rift and it is light, comfortable, easy to use, has a much larger area of focus, doesnt have streaks all over the image, has great headphones that dont need to be inserted in your ear... It is much better yet cost £250 less !! Sorry. Click to expand... I would very much like to know if others are experiencing similar issues outside of Elite Dangerous. Frankly, I would just find it very hard to believe that such a fundamental design issue would exist between the Rift and Vive in terms of optics. Has there been no examples where say text is not blurry when using the Vive or Rift? Further, I wonder if this issue is related to the POV that each is is rendered from being the same."</post>
   <post id="dab2b57b-c212-4552-9048-7206bac9bb0c" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"nepenthe said: ↑ I would very much like to know if others are experiencing similar issues outside of Elite Dangerous. Frankly, I would just find it very hard to believe that such a fundamental design issue would exist between the Rift and Vive in terms of optics. Has there been no examples where say text is not blurry when using the Vive or Rift? Further, I wonder if this issue is related to the POV that each is is rendered from being the same. Click to expand... It s a known issue with Elite on the Vive. It has been discussed quite a lot on the Vive subreddit, and apparently the developers have mentioned they are working on it."</post>
   <post id="f9a29abb-4558-44f6-9eaa-9c34df5b963e" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"cant wait to get my vive!!!! The wait is killing me lol"</post>
   <post id="7470641b-280a-4134-ab9b-cc3d779b88a7" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"You can read appropriately sized text on the Vive just fine. You re not going to be able to read small text on either one. The Vive does seem to have a smaller area in the center where you get max DPI than the Rift but it s not a huge difference. The lenses are the Rift are generally better, harder to see the fresnel ridges etc. but both are good. I ding the Vive more on not combining all the cables into one. The Vive is also less comforable to wear, Rift strap configuration and weight distribution is superior and makes it seem way lighter. The Rift headphones are also a better solution, far easier to deal with than Vive where you have yet another thing to put on (included earbuds are horrible, use your own) plus the Rift software manages to switch programs to output to the Rift headphones but on the Vive you have to go into audio devices and switch manually. The Oculus Home software seems more polished than Steam VR, really was not expecting that. I ve had several crashes in Steam VR and maybe one in Oculus Home. Right not the only reason to get the Vive is the controllers and the ability to do room scale VR. The controllers work really well, great tracking accuracy. I haven t really gotten much use out of the camera as it s super low resolution and I have it set to only turn on when close to the roomscale boundry. It might be more useful if you were doing seated mode. One other thing to note is the lighthouse units blast IR everywhere and are set up to just stay on all the time. This stomps all over IR remotes so don t set them up too close to a TV setup or anything else using an IR remote. Really looking forward to the Touch controllers coming out, hope they can get a large "room scale" coverage with the cameras. Hopefully they also fix the Oculus home to allow apps to be installed to different drives too."</post>
   <post id="4e626cd9-fa55-45a7-8de4-0df491931ab6" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Appropriately sized text? Text has to be HUGE to read it without eyestrain. Also, the lighthouses turn on and off via SteamVR/Bluetooth."</post>
   <post id="4aa08f59-a8c3-4a3e-9e3c-4d02905cebf3" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Vega said: ↑ Appropriately sized text? Text has to be HUGE to read it without eyestrain. Click to expand... Thanks Vega. I bought VorpX and tried Alien Isolation. Much of the text and information on the HUD is unreadable. Its more or less pointless having certain information on the HUD unless you zoom out to see it, even then its not easy to read because you cannot view it dead in the centre. A small positive that TroubleMagnet had a problem with. There is an option to tell it which audio device to enable once a game/experience starts and another to select what plays audio once it has ended."</post>
   <post id="2689b768-3cc8-47cc-9ab6-693d715284ae" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Text size is relative, I can read the directions in Hover Junkers and other made for VR games just fine. Expecting to be able to read the text on the HUD for games that are NOT made for VR is not going to happen for this generation. HUDs for VR will need larger text and have more of the info moved to the center of the screen. The corners of the HUD harder to read in an HMD because your resolution drops off as you move away from the center. I ve mostly been playing made for VR games to avoid a lot of the conversion problems I already have had plenty of experience with on the DK1/DK2. I might give Elite Dangerous another chance but I really dislike their planes in space flight model. Oh, I ve also messed with Virtual Desktop some, can t read anything on the 4K screen without getting REAL close. I ll have to look into the options for Steam VR some more to see if I can get it to auto-switch, thanks. For Oculus it Just Worked, which was nice. I could have sworn the lighthouse modules were still on when I went to move them last. Could have been it was after a crash and they didn t get turned off correctly, I know the HMD has been left on after some crashes. Their LEDs are definitely on 24/7 even if they spin down the mirror."</post>
   <post id="b0427249-e064-4f2e-9b15-38e2ef13385d" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"The vive is what Oculus Rift should have been."</post>
   <post id="8e4c2423-e5f7-440a-bd6f-a1b536058d90" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"The Rift is easily the better HMD, I know from experience, it isnt even close. The Vive isnt fit for sale. The Rift is missing room space movement and tracked controllers but they are not essentials for many VR experiences. I dont want a Rift though because of the EULA and Facebooks track record. But saying the Vive is a better "HMD" than the Rift is either trolling, make belief, fanboyism or you have been bought."</post>
   <post id="206a9323-17c0-4188-81b6-41f3d286a30f" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Nenu said: ↑ But saying the Vive is a better "HMD" than the Rift is either trolling, make belief, fanboyism or you have been bought. Click to expand... That s quite disappointing, I was hoping the Vive would have better optics, after the blooming problem need on the rift. If only you could have a rift with lighthouse, and the native integration with Steam. I found the rift integration to be a bit annoying, for example the Xbox controller will time out if idle while using virtual desktop in steam then drops out of steam VR to Oculus whitescreen. Since most of my games are in steam, I was hoping for better news."</post>
   <post id="83f4d6c7-5c5f-4d8a-85a9-67cae1280de3" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Nenu said: ↑ I tried Elite Dangerous and its broken on the Vive. The image is jagged edged, it looks messy. Click to expand... Thanks to Oculus  clusterfuck of a launch I haven t had a Rift to compare it with so fortunately I haven t noticed those issues at all, and I ve been playing it happily on the Vive almost every day for the last month, usually for hours at a time. So while I m prepared to believe it might have issues compared with the Rift, "isn t fit for sale" is nonsense. I also don t find it necessary to have it uncomfortably tight. I had it quite tight at first because you initially assume it should be, but then found I could reduce the tension considerably without it shifting out of position when I move. As I said, I ve often had it on for hours at a time. But I get it, you can t stand the optics or the ergonomics or the customer support. Fair enough. The lack of motion controllers at launch from Oculus was a massive misstep IMO. They might not be necessary for things like Elite, but there are plenty of examples of games where they re a huge part of the experience. The fact that The Climb launched as a Rift exclusive was especially pathetic. It s not even a Rift vs Vive thing, it doesn t do VR in general any favours to hobble it right out of the gate. By the time they pull their finger out and release them, a lot of people will have moved on."</post>
   <post id="ede93e17-0134-4795-8d72-a53cb0429854" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Nenu said: ↑ It is much better yet cost £250 less !! Click to expand... I don t understand why you are trying to use this as an argument for the Oculus Rift. The Oculus Rift is missing its controllers. How much do you think it s going to cost to buy those plus shipping? And isn t the fact that the OR doesn t even have those controllers ready when the Vive already has theirs ready a negative for the OR?"</post>
   <post id="9c92acf3-0381-454f-8aa6-1ccb7b726ad2" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Its an argument against the Vive. The controllers wont cost £250 and I was about to pay another £100 for earphones because the in ear ones are a very bad choice, especially given the price. And the major part of the VR experience is the display. The Vive display is bloody awful. The Rift display is pretty good, certainly acceptable (res aside)."</post>
   <post id="ad762e48-8284-432e-a62a-167688775ce1" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Slinkycatz said: ↑ I don t understand why you are trying to use this as an argument for the Oculus Rift. The Oculus Rift is missing its controllers. How much do you think it s going to cost to buy those plus shipping? And isn t the fact that the OR doesn t even have those controllers ready when the Vive already has theirs ready a negative for the OR? Click to expand... I d be very surprised if it cost $250 for the controllers. The camera is the most expensive part since the touch controllers are passive, so they re little more than two wireless touchpads with a light ring, considering their power consumption (year or more before replacement with a mini hearing aid battery) it doesn t have a lot of electronics or even charging controllers/ports. The Camera is similar to a ps3 camera since the processing is all on the cpu, and not even binocular like the ps4 camera. But cost shouldn t be the primary consideration for the whole package, i m happy to pay 10-20% more for the more capable and polished product i m going to spend months using each year."</post>
   <post id="caecafb1-7da9-4446-a029-f539294afe79" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"So many great comments in here from everyone. I m with Nenu on the Rift being driven by Facebook. I have no faith in that company. They ll probably drive  social  gaming more than anything. We all know where Valve/Steam stands and that they re more likely to take a risk and stick with it, heh.wouldn t pull a  Disney &amp; Infinity  on us. But Facebook? Tough sell for me there. Can someone suggest the  best method  to trial VR in general, and not at a retail store kiosk, but in the comfort of my own home? I will have a PC with appropriate specs in near future. The things they need to get correct out of the gate are the things they can t change post-sale, aka hardware. Fit and comfort. Optics. Controllers. Software can be polished, improved upon, fixed. But it sounds like the software for the Vive was the part focused on, while for the Rift it was hardware. Anyone have serious playtime and wear glasses and have a comment on comfort levels?"</post>
   <post id="7de38728-630c-4a20-aeaa-a17ead4306c8" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"I think the Rift software is better but they are really fairly close. Steam VR just seems to crash a bit more. Facebook has been very hands-off so far, I expect that to continue for the most part. They re going to try and get devs to sell though their store but so far that seems fine, plus is what Valve does already. As long as they are ok with programs like Virtual Desktop being able to launch from either I don t see a problem. I do expect FaceRoom or some other facebook connected app at some point but we can just not run it. Facebook knows they re a year away from being MySpaced at any time, that s why they re throwing so much cash at backup plans and next big things like Oculus. Unless you can borrow a VR rig from someone I don t see how to get a home demo other than buy and return once they re available at retail. I wear glasses and they work ok with the headsets but they do complicate taking it on and off. They are also prone to fogging some in a hot room. (No A/C in my temp apt. plus warm temps for Seattle area) I tend to just not wear them right now as one eye is only slightly fuzzy vs. with glasses in either HMD. I also did the Kickstarter for the frames that allow you to put your RX lenses in the HMDs. They have both Vive and Rift."</post>
   <post id="249a0329-3eb3-4692-bc90-9963cda1d595" section="VR and Head-Mounted Displays" discussion="HTC Vive VR Kit Review">"Inacurate said: ↑ Can someone suggest the  best method  to trial VR in general, and not at a retail store kiosk, but in the comfort of my own home? I will have a PC with appropriate specs in near future. The things they need to get correct out of the gate are the things they can t change post-sale, aka hardware. Fit and comfort. Optics. Controllers. Software can be polished, improved upon, fixed. But it sounds like the software for the Vive was the part focused on, while for the Rift it was hardware. Anyone have serious playtime and wear glasses and have a comment on comfort levels? Click to expand... Not at a kiosk would be buy from Amazon or BB and return it? It s unfortunate that the closest EB Vive Kiosk is hundreds of miles away from me, unless BB started demoing them. As for glasses, I think it depends on your glasses and how big they are. I ve worn glasses with both the rift and gear VR but mine are pretty small. People have said the Vive is more roomy, though I m not averse to wearing contacts for more comfort. Glasses though seen to help with reducing lens fogging for some reason, maybe the AR lens coatings on my glasses are preventing it."</post>
   <post id="d575fa36-6a5d-4a3e-b552-ecf7bb28d792" section="VR and Head-Mounted Displays" discussion="REVIVE">"anyone here having any luck getting REVIVE to work with the VIVE. I keep getting headtset not detected and controller issues :\"</post>
   <post id="c8de1611-e57d-462f-9b57-5de15307a266" section="VR and Head-Mounted Displays" discussion="REVIVE">"It works flawlessly here. Here what i do. Put all the revive files in the same directory of the game. With SteamVR open, drag the .exe of the game to the revive.exe PLAY."</post>
   <post id="4e07b7de-7953-41e3-a20c-5f009748cc81" section="VR and Head-Mounted Displays" discussion="REVIVE">"DouglasteR said: ↑ It works flawlessly here. Here what i do. Put all the revive files in the same directory of the game. With SteamVR open, drag the .exe of the game to the revive.exe PLAY. Click to expand... so copy and paste the ReviveInjector application into the "game directory" then take the .exe of game and drag it into the ReviveInjector.exe? and does Steam VR need to be open first ? its odd I can get Lucky s tale to turn on fine but it won t recognize my xbox controller and The Climb says "no headset" :\"</post>
   <post id="3fad44ac-71f0-4e65-b044-5573c901f9fc" section="VR and Head-Mounted Displays" discussion="REVIVE">"Martha Stewart said: ↑ so copy and paste the ReviveInjector application into the "game directory" then take the .exe of game and drag it into the ReviveInjector.exe? and does Steam VR need to be open first ? its odd I can get Lucky s tale to turn on fine but it won t recognize my xbox controller and The Climb says "no headset" :\ Click to expand... Yep, simple as that. Luckys Tale is working fine here, xbox 360 controller also. I havent tried The Climb because of its price"</post>
   <post id="61d33203-9cac-4003-8ff7-1c70838cefab" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"What are some of the best games or demos to have on hand when that new to VR person comes to the house?"</post>
   <post id="b2bcd191-9234-4ac3-aed0-1e792b6d9ede" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"Really depends on who you are demoing it to... Something like the The Brookhaven Experiment for a VR first timer would probably make them shit their pants. The Blu is a safe/easy demo as is Tilt Brush... But to really trip them out, I d recommend some time in the Valve Lab as well as Universe Sandbox 2."</post>
   <post id="aa032fad-0762-49a3-ae06-1a37d00d0738" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"If you ve got the system for it, Elite Dangerous is flat-out BEAUTIFUL. Fly near a fancy star in a ship with a glass lower half on the cockpit and let them marvel."</post>
   <post id="30d524e2-adde-4222-b11d-8122ca81cb6a" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"i like the graffiti game"</post>
   <post id="900d7aff-47dd-4833-a212-2f8dfd248233" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"The last level flying up into the spaceship in "The Gallery", pretty epic."</post>
   <post id="f7dbeb15-5b9d-43f2-8683-596ea955d2a2" section="VR and Head-Mounted Displays" discussion="Great Games or Demos to show off Rift to others">"The Climb is quite beautiful and worth the price IMO. FX2 Pinball is also a nice game to show as a demo for folks who want something grounded a bit more in reality. I was also surprised how many people really appreciated Virtual Desktop when I let them try it."</post>
   <post id="5cd8e6c9-80f7-4a22-90fe-3dd24d3d4cc0" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Oculus Rift Virtual Pinball Cabinet Mod. First iteration. Oculus Rift Virtual Pinball Cabinet Mod! - Tested.com Wooden cabinet version. How to Build the PinSim Virtual Reality Pinball Machine How to Build the PinSim Virtual Reality Pinball Machine - Tested.com Video of the original. At least skip to him playing if you re not into pinball. Worth the watch!"</post>
   <post id="bea5d044-fb2a-4ce6-90ba-3e25db8de2e9" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"this is cool. I saw it the other day on tested s yt channel. I built a non-vr version of this for my snes in the 90s. used an old controller and a big speaker box."</post>
   <post id="1b955b00-84c8-4d2c-ae71-7d3e3eb44830" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"cool stuff, gotta say though, looks like the second pic that guy is about to hurl lol."</post>
   <post id="800ecc7a-4207-474e-bcaf-4a7488c70ca8" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"This is one of my problems with VR currently. Who wants to play pinball, or build little machines out of balloons, or bake cake in VR? The software is all rubbish. We need real games."</post>
   <post id="829215db-adf3-4f3d-9370-5a2d004a4b98" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Vega said: ↑ This is one of my problems with VR currently. Who wants to play pinball, or build little machines out of balloons, or bake cake in VR? The software is all rubbish. We need real games. Click to expand... Games that let you do things like explore the reaches of space, drive a supercar around Laguna Seca, save your homeland from evil by beating the labyrinth, or survive an alien invader?"</post>
   <post id="51b15cc6-4d2b-4d61-ac75-d76ffd528492" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"The Elite Dangerous implementation is really bad and blurry. Chronos looks cool. Alien Isolation, are they coming out with a VR mod for that or just use one of the generic 2D to VR converter software? I did play "The Gallery", that was pretty fun."</post>
   <post id="00e625d7-71de-423e-abc5-9a21ef11dfe8" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Vega said: ↑ Who wants to play pinball (...) We need real games. Click to expand... You have come to the wrong thread."</post>
   <post id="91bfcd8c-cfaf-445d-81fd-470b8c003d30" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"CEpeep said: ↑ You have come to the wrong thread. Click to expand... We re all inclusive. Just pulling ya leg. Vega You should try Project Cars in VR. That s a good racing game and the dev team worked on a VR implementation for years."</post>
   <post id="3a938f0c-5fc3-40fa-9060-e75bcfe9d402" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Hah, it was kinda a serious question. Is someone really going to don a VR headset for hours to play pinball? Project cars does look pretty good! Although, knowing me I d have to go out and buy $1500 worth of driving gear to "experience it" properly."</post>
   <post id="bfd14288-093b-4b34-bce9-2e019128540c" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Vega said: ↑ The Elite Dangerous implementation is really bad and blurry. Click to expand... Damn, I ve got to install that again, find out what they screwed up. A couple months back, it was just about perfect."</post>
   <post id="429274ea-2603-4c7a-835a-08d3878f905f" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"Vega said: ↑ Hah, it was kinda a serious question. Is someone really going to don a VR headset for hours to play pinball? Click to expand... Yes. I m putting together a ghetto version of this the day my Vive has a ship date. This is exactly the sort of thing this first iteration of VR can be good at. It s a physical experience with minimal sensory inputs, but a fundamentally familiar form of interaction. It s easy to make a great experience with the limited technology available. Anyone who wants VR to be a success with regular consumers should be all over games like this, because this is what it s going to take. I m bothered by the notion that pinball isn t a "real game" when it s the fucking OG of electronic games."</post>
   <post id="afdea4d2-e20f-4d6a-8e2b-79faf9173605" section="VR and Head-Mounted Displays" discussion="Oculus Rift Virtual Pinball Cabinet Mod">"I love pinball personally. Wish I had the room and money for an new machine. My dad tossed my old machine in the early 1980 s."</post>
   <post id="bf25af44-d04a-4e2c-8bfb-0b148b7e69d2" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"saw this over on reddit lol While it s pretty humorous, I wonder how long it will take before someone seriously hurts themselves and, legally, goes after the hardware manufacturers or even software developer. A few feet to the right and she could of thrown herself through a glass door. Apparently she got spooked and took off running lol"</post>
   <post id="94b48309-272d-4e53-a5e2-8538f8d5f31e" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"Hmm, I could see "gamer grade " VR Velcro straps to hold people down. Then "gamer grade" harnesses... Etc... A whole new market! Even if you won t see them, they ll be full of LEDs for color, because why not..."</post>
   <post id="34e45468-aa2a-4def-8ade-7fdc2228f633" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"dude be like "noooo, my precious vive!""</post>
   <post id="d264e04c-5197-4d8d-8759-3b2836895dcf" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"No one that old is that stupid to take off running. Maybe. I figured if I got VR and was planning on standing up I d hang padded mats in a circle. I am sure the wife would be thrilled..."</post>
   <post id="32dc7e41-d2a6-43b3-9660-4383408cf4a8" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"Sounds like someone trying to legally go after a car company for when they crash and get hurt. It wont happen."</post>
   <post id="7a108f05-4eea-4ba8-a0c0-b4e37bff8f6f" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"There was a post on reddit showing a lady dislocating her knee (nothing graphic) while backpedaling away from something quickly in some VR game. A guy was playing the Vive when the paramedics were wheeling her out the door, heh."</post>
   <post id="255d9937-23d3-4122-a448-ad3789235726" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"SirMaster said: ↑ Sounds like someone trying to legally go after a car company for when they crash and get hurt. It wont happen. Click to expand... But the SUIT will happen, so they better get the legal team ready. People sue over the stupidest shit, and sometimes beyond all reason they win"</post>
   <post id="9318ef76-88da-4034-a658-c88c13f60d14" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"defaultluser said: ↑ But the SUIT will happen, so they better get the legal team ready. People sue over the stupidest shit, and sometimes beyond all reason they win Click to expand... Its probably more likely HTC will be sued over their sub-par wrist straps first (like Nintendo was during the Wii era) than injuring caused by running into a wall, etc."</post>
   <post id="93f55c44-5352-4c51-ad65-73fc8e74ef06" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"God forbid anyone in this day and age take personal responsibility for the stupid shit they do..."</post>
   <post id="2c172ceb-6d95-48d6-ad76-03e29ac4cf62" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"defaultluser said: ↑ But the SUIT will happen, so they better get the legal team ready. People sue over the stupidest shit, and sometimes beyond all reason they win Click to expand... Because we live in a society of morons."</post>
   <post id="72a9764f-2c25-439f-ac18-e79efda7193e" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"defaultluser said: ↑ But the SUIT will happen, so they better get the legal team ready. People sue over the stupidest shit, and sometimes beyond all reason they win Click to expand... HTC I m sure can handle that sort of protracted legal battle"</post>
   <post id="e9afb155-bf7b-45bc-acee-3a90ece3d59b" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"Time to become a doctor."</post>
   <post id="57abe1eb-8c69-45be-9f81-7dc41f5ca282" section="VR and Head-Mounted Displays" discussion="So I wonder what the future of VR holds once people start hurting themselves">"akifbayram said: ↑ Time to become a lawyer. Click to expand... Fixed."</post>
   <post id="6a54ea6f-1fb8-4d6f-bbce-e17cc879e213" section="VR and Head-Mounted Displays" discussion="VR headset for virtual showroom?">"Let me start by saying I have zero experience with anything VR. But my bosses think I am a tech wizard because I build my own computers and can run/program CNC machines. Well they came up with an idea of creating a virtual showroom to display all of our products. We have a couple of salesmen that travel to a trade show every 2-3 weeks. They would like to use a relatively cheap VR headset so they can have 3 or 4 of them at a show instead of shipping and assembling large products to every show. Plus the majority of the buyers that get sent to our trade shows are getting younger and younger(35 and below), so we are looking to be the first in our industry to use VR for marketing. After some quick googling, I think the Samsung Gear VR with a Galaxy S6 would be our cheapest option and be portable with out needing to be tethered to a PC. Would it be fine to have a full 360 degree interactive view of our products? Like if the potential customer looks at a certain area, a pop out information box comes up and recorded audio plays about a feature until they look at a different feature on a product? I am open to any and all suggestions as to what hardware(preferably portable and not tied to a PC). Any cameras? Software? Literally anything that could help."</post>
   <post id="f3e6d71b-1911-4260-860b-ef5a34b5486f" section="VR and Head-Mounted Displays" discussion="Virtuix Omni VR treadmill">"Anyone else curious about this thing? Read some positive impressions on it and really curious about this considering the small room I have to work with."</post>
   <post id="fa49c4f9-3380-493b-bbf9-faaa03a98466" section="VR and Head-Mounted Displays" discussion="Virtuix Omni VR treadmill">"Looks like something out of The Onion."</post>
   <post id="e58aaffa-e57c-4a28-8437-6ed81be3b4a1" section="VR and Head-Mounted Displays" discussion="Virtuix Omni VR treadmill">"Everything I ve read about VR treadmill setups is negative. You re walking in a weird way on a funky dished platform using special shoes. It s not at all like normal walking. You don t get the forward momentum feeling, so you still experience motion sickness issues."</post>
   <post id="7a79688f-2918-4a17-9663-4c6863883a69" section="VR and Head-Mounted Displays" discussion="First Ever Full-Arm Tracking On The HTC Vive">"I ve never heard of this company before but its full-arm tracking for the HTC Vive looks neat. The gloves track hand movement using a combination of high-tech sensors (all contained inside the glove) that allow for reliable hand and finger tracking. The company also says it will be launching an open-source SDK in June."</post>
   <post id="f60d2f62-53e8-4974-9471-e238230f049a" section="VR and Head-Mounted Displays" discussion="First Ever Full-Arm Tracking On The HTC Vive">"I can see myself answering the door for the UPS man wearing that and getting some weird stares."</post>
   <post id="d218a3fc-f4b6-475e-ac58-f9dd17d3d061" section="VR and Head-Mounted Displays" discussion="Samsung GearVR MilkVR Streaming from Server/NAS Guide">"https://www.reddit.com/r/GearVR/comments/3vuopp/simple_lan_stream_to_milkvr_own_app_simple_server/ I had nothing to do with this, but just wanted to post this and let you guys know this worked like a champ for me on my Galaxy S6 which has so little onboard storage and no SD card. Only extra step I had to take was listed at the bottom where I added a  0  to the number on "maximum bitrate", as otherwise the streaming quality was poor. Setting the max super high, it streams excellent on my wireless network with no lag and the quality is identical to sideloading locally on the device!"</post>
   <post id="258fb027-4da5-4bdb-87b0-103edc472746" section="VR and Head-Mounted Displays" discussion="Samsung GearVR MilkVR Streaming from Server/NAS Guide">"Do you have to do steps 5-8 for every media file you want to play? I may give this a go since I already have an Emby server on my NAS box, but I wish there was just a Plex app for the GearVR."</post>
   <post id="5d0a79e2-f5b2-4dde-b0d1-76113adaff41" section="VR and Head-Mounted Displays" discussion="Samsung GearVR MilkVR Streaming from Server/NAS Guide">"Litfod said: ↑ Do you have to do steps 5-8 for every media file you want to play? I may give this a go since I already have an Emby server on my NAS box, but I wish there was just a Plex app for the GearVR. Click to expand... Yes, and while that part is a PITA, its a lot less of a PITA than changing file extensions and dragging and dropping it onto your phone and waiting for the file transfer to complete after plugging it in. Once its setup you just open that app, click on the file you want to play, I don t bother giving it a different name, and then it prompts to open with that tool and voila it starts streaming immediately. So like four clicks. The more annoying aspect is that GearVR can only do stereo sound, so since most of my library is DTS, that s a no-go. But that was already a known issue, and yes something like Plex would be ideal but doesn t exist as far as I know."</post>
   <post id="a5285d9b-e47f-4851-8622-493b2fc013e9" section="VR and Head-Mounted Displays" discussion="Samsung GearVR MilkVR Streaming from Server/NAS Guide">"Hopefully one day soon someone will write a program which can stream the media directly from the source over the LAN. Something like VLC, or even Kodi."</post>
</forum>
